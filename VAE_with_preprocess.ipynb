{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, preprocessing\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,  f1_score, precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, NMF, FastICA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-3b2acc67bd7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_tcga_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D://GitHub/Gene-compression-and-Cancer-type-classification/data/train_tcga_expression_matrix_processed.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_tcga_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D://GitHub/Gene-compression-and-Cancer-type-classification/data/test_tcga_expression_matrix_processed.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels_tcga_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D://GitHub/Gene-compression-and-Cancer-type-classification/data/tcga_sample_identifiers.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m     \"\"\"\n\u001b[0;32m    544\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/train_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "test_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/test_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "\n",
    "labels_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/tcga_sample_identifiers.tsv', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale RNAseq data using zero-one normalization\n",
    "train_label = train_tcga_df['sample_id']\n",
    "train_normalize = preprocessing.MinMaxScaler().fit_transform(train_tcga_df.drop(['sample_id'], axis=1))\n",
    "train_tcga_df_normalized = pd.concat([train_label, pd.DataFrame(train_normalize)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale RNAseq data using zero-one normalization\n",
    "test_label = test_tcga_df['sample_id']\n",
    "test_normalie = preprocessing.MinMaxScaler().fit_transform(test_tcga_df.drop(['sample_id'], axis=1))\n",
    "test_tcga_df_normalized = pd.concat([test_label, pd.DataFrame(test_normalie)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, var_layer, mean_layer, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        self.var_layer = var_layer\n",
    "        self.mean_layer = mean_layer\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.var_layer - K.square(self.mean_layer) - \n",
    "                                K.exp(self.var_layer), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tybalt():\n",
    "    \"\"\"\n",
    "    Facilitates the training and output of tybalt model trained on TCGA RNAseq gene expression data\n",
    "    \"\"\"\n",
    "    def __init__(self, original_dim, hidden_dim, latent_dim,\n",
    "                 batch_size, epochs, learning_rate, kappa, beta):\n",
    "        self.original_dim = original_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kappa = kappa\n",
    "        self.beta = beta\n",
    "\n",
    "    def build_encoder_layer(self):\n",
    "        # Input place holder for RNAseq data with specific input size\n",
    "        self.rnaseq_input = Input(shape=(self.original_dim, ))\n",
    "\n",
    "        # Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "        # Each layer is initialized with glorot uniform weights and each step (dense connections, batch norm,\n",
    "        # and relu activation) are funneled separately\n",
    "        # Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "        hidden_dense_linear = Dense(self.hidden_dim, kernel_initializer='glorot_uniform')(self.rnaseq_input)\n",
    "        hidden_dense_batchnorm = BatchNormalization()(hidden_dense_linear)\n",
    "        hidden_encoded = Activation('relu')(hidden_dense_batchnorm)\n",
    "\n",
    "        z_mean_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "        self.z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "        z_log_var_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "        self.z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "        # return the encoded and randomly sampled z vector\n",
    "        # Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "        self.z = Lambda(sampling, output_shape=(self.latent_dim, ))([self.z_mean_encoded, self.z_log_var_encoded])\n",
    "    \n",
    "    def build_decoder_layer(self):\n",
    "        # The decoding layer is much simpler with a single layer glorot uniform initialized and sigmoid activation\n",
    "        self.decoder_model = Sequential()\n",
    "        self.decoder_model.add(Dense(self.hidden_dim, activation='relu', input_dim=self.latent_dim))\n",
    "        self.decoder_model.add(Dense(self.original_dim, activation='sigmoid'))\n",
    "        self.rnaseq_reconstruct = self.decoder_model(self.z)\n",
    "        \n",
    "    def compile_vae(self):\n",
    "        adam = optimizers.Adam(lr=self.learning_rate)\n",
    "        vae_layer = CustomVariationalLayer(self.z_log_var_encoded,\n",
    "                                           self.z_mean_encoded)([self.rnaseq_input, self.rnaseq_reconstruct])\n",
    "        self.vae = Model(self.rnaseq_input, vae_layer)\n",
    "        self.vae.compile(optimizer=adam, loss=None, loss_weights=[self.beta])\n",
    "        \n",
    "    def get_summary(self):\n",
    "        self.vae.summary()\n",
    "  \n",
    "    def visualize_architecture(self, output_file):\n",
    "        # Visualize the connections of the custom VAE model\n",
    "        plot_model(self.vae, to_file=output_file)\n",
    "        SVG(model_to_dot(self.vae).create(prog='dot', format='svg'))\n",
    "        \n",
    "    def train_vae(self):\n",
    "        self.hist = self.vae.fit(np.array(rnaseq_train_df),\n",
    "               shuffle=True,\n",
    "               epochs=self.epochs,\n",
    "               batch_size=self.batch_size,\n",
    "               validation_data=(np.array(rnaseq_test_df), np.array(rnaseq_test_df)),\n",
    "               callbacks=[WarmUpCallback(self.beta, self.kappa)])\n",
    "    \n",
    "    def visualize_training(self, output_file):\n",
    "        # Visualize training performance\n",
    "        history_df = pd.DataFrame(self.hist.history)\n",
    "        ax = history_df.plot()\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('VAE Loss')\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(output_file)\n",
    "        \n",
    "    def compress(self, df):\n",
    "        # Model to compress input\n",
    "        self.encoder = Model(self.rnaseq_input, self.z_mean_encoded)\n",
    "        \n",
    "        # Encode rnaseq into the hidden/latent representation - and save output\n",
    "        encoded_df = self.encoder.predict_on_batch(df)\n",
    "        encoded_df = pd.DataFrame(encoded_df, columns=range(1, self.latent_dim + 1),\n",
    "                                  index=rnaseq_df.index)\n",
    "        return encoded_df\n",
    "    \n",
    "    def get_decoder_weights(self):\n",
    "        # build a generator that can sample from the learned distribution\n",
    "        decoder_input = Input(shape=(self.latent_dim, ))  # can generate from any sampled z vector\n",
    "        _x_decoded_mean = self.decoder_model(decoder_input)\n",
    "        self.decoder = Model(decoder_input, _x_decoded_mean)\n",
    "        weights = []\n",
    "        for layer in self.decoder.layers:\n",
    "            weights.append(layer.get_weights())\n",
    "        return(weights)\n",
    "    \n",
    "    def predict(self, df):\n",
    "        return self.decoder.predict(np.array(df))\n",
    "    \n",
    "    def save_models(self, encoder_file, decoder_file):\n",
    "        self.encoder.save(encoder_file)\n",
    "        self.decoder.save(decoder_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC ANALYSIS FOR K=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common hyper parameters\n",
    "rnaseq_train_df = train_tcga_df_normalized.drop(['sample_id'], axis=1)\n",
    "rnaseq_test_df = test_tcga_df_normalized.drop(['sample_id'], axis=1)\n",
    "\n",
    "original_dim = rnaseq_train_df.shape[1]\n",
    "latent_dim = 100\n",
    "beta = K.variable(0)\n",
    "epsilon_std = 1.0\n",
    "\n",
    "# Model A (100 hidden layer size)\n",
    "model_a_latent_dim = 100\n",
    "model_a_batch_size = 100\n",
    "model_a_epochs = 100\n",
    "model_a_learning_rate = 0.001\n",
    "model_a_kappa = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Tybalt(original_dim=original_dim,\n",
    "                 hidden_dim=model_a_latent_dim,\n",
    "                 latent_dim=latent_dim,\n",
    "                 batch_size=model_a_batch_size,\n",
    "                 epochs=model_a_epochs,\n",
    "                 learning_rate=model_a_learning_rate,\n",
    "                 kappa=model_a_kappa,\n",
    "                 beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 16148)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           1614900     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 100)           400         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 100)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           10100       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           10100       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 100)           400         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 100)           400         dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 100)           0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 100)           0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 100)           0           activation_2[0][0]               \n",
      "                                                                   activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 16148)         1641048     lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_1 (Cust [(None, 16148), (None 0           input_1[0][0]                    \n",
      "                                                                   sequential_1[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 3,277,348\n",
      "Trainable params: 3,276,748\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n"
     ]
    }
   ],
   "source": [
    "# Compile Model A\n",
    "model_a.build_encoder_layer()\n",
    "model_a.build_decoder_layer()\n",
    "model_a.compile_vae()\n",
    "model_a.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 4488.4282 - val_loss: 5341.8775\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3561.7466 - val_loss: 5363.7049\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3508.6122 - val_loss: 5231.4325\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3481.9265 - val_loss: 5135.9487\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3464.6562 - val_loss: 5079.5334\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3451.8864 - val_loss: 5082.8937\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3442.6015 - val_loss: 5049.0349\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3434.2508 - val_loss: 5036.4276\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3426.8115 - val_loss: 5035.4040\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3420.1153 - val_loss: 4996.5100\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3415.5093 - val_loss: 4988.8364\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3410.5695 - val_loss: 4976.7596\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3405.9391 - val_loss: 4986.6446\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3401.7001 - val_loss: 4970.1785\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3398.3648 - val_loss: 4982.8245\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: 3394.5866 - val_loss: 4974.5756\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3391.2937 - val_loss: 4969.7678\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3388.2574 - val_loss: 4969.7080\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3386.0152 - val_loss: 4961.6245\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: 3383.2410 - val_loss: 4960.4441\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3380.9082 - val_loss: 4942.9928\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3378.8034 - val_loss: 4951.667037 - ETA: 0s - loss: 337\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 17s - loss: 3376.4456 - val_loss: 4947.4297\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 17s - loss: 3374.5085 - val_loss: 4962.9553\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: 3372.5252 - val_loss: 4914.6347\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: 3371.1287 - val_loss: 4936.7188\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: 3369.7697 - val_loss: 4939.7002\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: 3368.0198 - val_loss: 4936.7617\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: 3366.7980 - val_loss: 4936.6348\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: 3365.0581 - val_loss: 4937.7651\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 17s - loss: 3363.8274 - val_loss: 4934.8445\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 17s - loss: 3362.3595 - val_loss: 4926.6497\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 17s - loss: 3361.2742 - val_loss: 4907.4899\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 17s - loss: 3359.8458 - val_loss: 4922.3312\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 17s - loss: 3359.0279 - val_loss: 4928.0064\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 17s - loss: 3357.7714 - val_loss: 4921.0040\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 17s - loss: 3356.8652 - val_loss: 4908.6325\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 17s - loss: 3355.6576 - val_loss: 4931.6553\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 17s - loss: 3354.5629 - val_loss: 4922.0523\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 17s - loss: 3354.2386 - val_loss: 4921.7127\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.0834 - val_loss: 4921.7653\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: 3352.2294 - val_loss: 4937.3253\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: 3350.9536 - val_loss: 4904.3445\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: 3350.5178 - val_loss: 4914.417035\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 17s - loss: 3349.3382 - val_loss: 4906.7669\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 17s - loss: 3348.6551 - val_loss: 4916.2546\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.6432 - val_loss: 4922.6856\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.3391 - val_loss: 4905.4247\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 17s - loss: 3346.3772 - val_loss: 4950.1819\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 17s - loss: 3345.7583 - val_loss: 4921.5055\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 17s - loss: 3344.9625 - val_loss: 4921.5292\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 17s - loss: 3344.4269 - val_loss: 4900.9871\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.7516 - val_loss: 4903.9913\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.0741 - val_loss: 4910.8235\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 17s - loss: 3342.4380 - val_loss: 4919.7710\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 17s - loss: 3342.1353 - val_loss: 4896.6003\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3341.5274 - val_loss: 4917.3977\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 17s - loss: 3341.1762 - val_loss: 4888.3263\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 17s - loss: 3340.2190 - val_loss: 4923.0355\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 17s - loss: 3339.9899 - val_loss: 4915.7190\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 17s - loss: 3338.8407 - val_loss: 4900.7400\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 17s - loss: 3338.3656 - val_loss: 4908.8708\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 17s - loss: 3337.9988 - val_loss: 4910.5938\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 17s - loss: 3337.4467 - val_loss: 4898.3156\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 17s - loss: 3336.9646 - val_loss: 4912.5401\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 17s - loss: 3336.8367 - val_loss: 4895.0423\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 17s - loss: 3336.0896 - val_loss: 4918.3815\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 17s - loss: 3335.8501 - val_loss: 4920.6078\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3335.1920 - val_loss: 4924.5578\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 19s - loss: 3334.9153 - val_loss: 4898.3933\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 19s - loss: 3334.3478 - val_loss: 4917.8385\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3334.0713 - val_loss: 4892.3053\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3334.0530 - val_loss: 4912.6235\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.3029 - val_loss: 4901.7462\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.9222 - val_loss: 4907.3166\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.2612 - val_loss: 4907.0357\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.2081 - val_loss: 4916.4618\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.7440 - val_loss: 4889.7839\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.4656 - val_loss: 4902.7204\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: 3331.1675 - val_loss: 4905.9640\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.6551 - val_loss: 4887.9459\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 17s - loss: 3330.3461 - val_loss: 4886.3906\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 17s - loss: 3330.3409 - val_loss: 4900.7334\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 17s - loss: 3329.8469 - val_loss: 4885.3137\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.3462 - val_loss: 4892.4075\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 17s - loss: 3329.3849 - val_loss: 4893.2600\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.0891 - val_loss: 4887.2968\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: 3328.8037 - val_loss: 4898.9662\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 17s - loss: 3328.7665 - val_loss: 4888.0862\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.4344 - val_loss: 4864.0102\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 19s - loss: 3327.8860 - val_loss: 4880.5779\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: 3327.5791 - val_loss: 4888.7881\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.3433 - val_loss: 4906.6592\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.2861 - val_loss: 4887.0224\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.2363 - val_loss: 4902.2073\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.7677 - val_loss: 4880.3452\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.4861 - val_loss: 4887.7114\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3326.2532 - val_loss: 4888.4423\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.0834 - val_loss: 4889.8623\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3325.7414 - val_loss: 4897.4098\n"
     ]
    }
   ],
   "source": [
    "model_a.train_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq_df = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "\n",
    "model_a_compression = model_a.compress(rnaseq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/learning.pdf'\n",
    "compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/compress.tsv'\n",
    "encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/encoder_twohidden100_vae.hdf5'\n",
    "decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/decoder_twohidden100_vae.hdf5'\n",
    "weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/enc_dec_weights.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_a.visualize_training(learning_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_weights = model_a.get_decoder_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_compression.to_csv(compress_path, sep='\\t', compression='gzip')\n",
    "model_a.save_models(encoder_path, decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(weights, weight_file, k):\n",
    "    # Multiply hidden layers together to obtain a single representation of gene weights\n",
    "    intermediate_weight_df = pd.DataFrame(weights[1][0])\n",
    "    hidden_weight_df = pd.DataFrame(weights[1][2])\n",
    "    abstracted_weight_df = intermediate_weight_df.dot(hidden_weight_df)\n",
    "\n",
    "    abstracted_weight_df.index = range(1, k+1)\n",
    "    abstracted_weight_df.columns = rnaseq_df.columns\n",
    "    abstracted_weight_df.to_csv(weight_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9465984849899136, 0.8976422091268619, 0.934437811525692, 0.941103892459609, 0.8875035103808945, 0.9402255633195212, 0.9530970492593479, 0.9318745159646948, 0.945979670979314, 0.8628509535408999, 0.8803015290075182, 0.9519612793777984, 0.9611219637708917, 0.9636368279478761, 0.9647319520921334, 0.9095505839759279, 0.9037678914534983, 0.937024559006392, 0.9496309278830085, 0.9490860780334638, 0.9454854918872054, 0.9666609415601962, 0.9813060780652365, 0.8473690035696597, 0.9319703548416474, 0.9043118691153897, 0.9261416124756154, 0.9331486420736627, 0.9481860079734217, 0.8847469435057153, 0.9237798694498927, 0.9238242254773299, 0.9240720270648013, 0.9689519619641, 0.950872550889152, 0.9453823590658428, 0.8716331528761203, 0.9385155565543504, 0.9190670924403734, 0.9571711666371765, 0.8548804566949376, 0.9325669758352104, 0.8491347380513823, 0.9301686002303572, 0.8490141033472502, 0.9526454907671739, 0.9381745389380111, 0.9433665143832861, 0.9133992098083265, 0.9496839455186481, 0.8722796212524613, 0.8395238439525694, 0.8807940035580849, 0.9366880699328671, 0.9033554162304938, 0.9095873853355518, 0.9356262408444334, 0.9573841972636532, 0.8597513585107396, 0.9217002544214036, 0.8886616341809849, 0.9633537709434608, 0.9397143416271316, 0.8700183954070253, 0.9327462290461348, 0.9425248937800152, 0.9583276584997615, 0.8895108750895646, 0.9269324227633855, 0.9601072077619897, 0.8371328235946032, 0.9333698599818284, 0.9551949393094346, 0.8964014021527503, 0.9594959640495397, 0.9561136908388691, 0.8706785931336878, 0.9279601754639653, 0.8291052060153965, 0.8484385944616046, 0.9521110168663, 0.8884248811132569, 0.8874238757997848, 0.9050695138025189, 0.9230520632344257, 0.9415212000128927, 0.921601520167635, 0.8703134293669763, 0.9195879966033639, 0.9050506798310678, 0.895158075970196, 0.854503822360027, 0.848119938512988, 0.9001006609147938, 0.9512553008051099, 0.9252136486434983, 0.9564282956268333, 0.9536528706184242, 0.9718571063502501, 0.9487051496998292, 0.9624503334475849, 0.9403392535987081, 0.8608840627742119, 0.897370243009532, 0.9585684480557364, 0.9396323724387288, 0.8775220143402277, 0.9709955801417762, 0.952458616817789, 0.9647566551609537, 0.8819903595570467, 0.8174485532249722, 0.835022423731234, 0.925917800933116, 0.8319829306135671, 0.9439879656859224, 0.9536381992801977, 0.9028763414453171, 0.8966583684032892, 0.9373901954597916, 0.8978374453490203, 0.8450465200666214, 0.9366315621049549, 0.9623632884526266, 0.9375334043720682, 0.9559440475009564, 0.9785033757143868, 0.910125119129412, 0.8797274744059319, 0.8585676623152607, 0.860115454445741, 0.9041654996383658, 0.9702016088734903, 0.9276391332660783, 0.8031149354993117, 0.9190490371717535, 0.9543643595773588, 0.926933293188385, 0.977284953589581, 0.9423337296914094, 0.9182493276891175, 0.9505750189403654, 0.8482387372976781, 0.8766995919592282, 0.949829855041721, 0.8782362760078073, 0.8973824495030523, 0.8919183810299808, 0.9039947327300425, 0.9169109909425193, 0.859407587249405, 0.9338226774706269, 0.9076804262079379, 0.9539039512473456, 0.8074374983454156, 0.9592769184825173, 0.8957004289100273, 0.9065068654844196, 0.9029315075919264, 0.9340728542363362, 0.8680983901949174, 0.8843943110535745, 0.9351521057008604, 0.9486349852197832, 0.9016512103108035, 0.8971562966907657, 0.8504674492892192, 0.8955093546276774, 0.9037435507007698, 0.910783006940168, 0.7753201045170344, 0.8762332825810147, 0.857287824194263, 0.8886595162933296, 0.9580820210466265, 0.9644187033236898, 0.9253791547849368, 0.9488331678721051, 0.9752891089085715, 0.9176108111483618, 0.9643435181187379, 0.8786828078423057, 0.9562989675670142, 0.9321309101934416, 0.9336353208358824, 0.8838993714859886, 0.8902034541770361, 0.9518606072854082, 0.938865534512348, 0.9379615351434846, 0.8886073244424846, 0.8342916358536665, 0.906262073410355, 0.9305298312910395, 0.9439502023066992, 0.9211818855000612, 0.9577905905771691, 0.9505662041053524, 0.9702557649054873, 0.8100009428701966, 0.888473201545352, 0.8307290867084853, 0.9675074041609484, 0.9244265276146698, 0.9249631128354211, 0.8410311944761925, 0.943432117975584, 0.9218308710270143, 0.9161635646250802, 0.9646396328905457, 0.940886754584481, 0.9506614760037532, 0.9773638839068028, 0.9171156637168538, 0.9646608335606291, 0.9267614947848637, 0.9239150234615201, 0.9411157043600057, 0.9790059172738244, 0.8982621610704948, 0.9333464936776679, 0.9470320034931001, 0.8647371952583723, 0.973872828466426, 0.9544440888814398, 0.9066549765723244, 0.87046364399062, 0.9041623757577011, 0.8827995501127753, 0.958370092722477, 0.9146423921519452, 0.8486241747007173, 0.9561162638045032, 0.9290907501634538, 0.8610625175834903, 0.8405224844485683, 0.9496519474431205, 0.9194141842299247, 0.9038217128579096, 0.9104670641048457, 0.8469015601358758, 0.9768809864162253, 0.9226273152249184, 0.9255376954136427, 0.8763557925064083, 0.8877443346987732, 0.8962120149106767, 0.908922507812949, 0.8989362901434326, 0.9155219983836509, 0.9340913805758218, 0.8796067540920371, 0.9104179556022376, 0.8994089398910456, 0.9523452162612364, 0.8940436207870828, 0.8789953679092142, 0.8814434501148962, 0.9644931170671505, 0.9080036686380429, 0.9540593029593556, 0.8689613943906183, 0.902816934505684, 0.9312634237578237, 0.8986269502694093, 0.9124634675113585, 0.9118199061558425, 0.9783464429791349, 0.8352630944809092, 0.9439314804582397, 0.9693054306196128, 0.890742288305673, 0.8194700464808685, 0.879754630880223, 0.9203300939455263, 0.8296398309124915, 0.9635646490226824, 0.9079430951977564, 0.9189748247449389, 0.8704721172416425, 0.9112307359969456, 0.9689366072257196, 0.9103491715579858, 0.8822187338187808, 0.8535924350570261, 0.9076900288231295, 0.9030627032726198, 0.9535322031835953, 0.8680822861572839, 0.9768482846790427, 0.8943834915191896, 0.8799609327279434, 0.8598537037075829, 0.9732066834281973, 0.9587630105251962, 0.9337576550388162, 0.9384541911695474, 0.9328853439693363, 0.9160982420082624, 0.8676080465135798, 0.9233227304664215, 0.8486769825110678, 0.94487522080803, 0.8816768334042169, 0.9110028194373945, 0.9411018458181613, 0.9458205714062415, 0.9387332307711013, 0.9472688167064551, 0.9186102328587077, 0.8490789320087433, 0.9135079809191768, 0.9572848576816284, 0.9147877189292914, 0.9677778182291739, 0.961944027556999, 0.8677069127680408, 0.8158852333036488, 0.9386494359561188, 0.9076970959029953, 0.9597772400353488, 0.9231830484328127, 0.8966310138847208, 0.9540661496933218, 0.896011619190355, 0.9169557264997457, 0.9596145592301598, 0.9670863606252099, 0.879123384168788, 0.9250090084002729, 0.9156080049602691, 0.901652543249313, 0.8355497117246726, 0.9446691600157981, 0.8721556106122564, 0.9653562866305305, 0.9495083109087997, 0.8817005796106713, 0.9428544916128724, 0.8993693625660071, 0.8787003331123827, 0.9446731695197013, 0.904337096273433, 0.8316202134290507, 0.8918075311003961, 0.9452270265855349, 0.9614658705461894, 0.9336934630583249, 0.9253268942659947, 0.8560438194458374, 0.9230129677195129, 0.9153155224309364, 0.8842448426985239, 0.955646614550896, 0.9217597540224591, 0.8886422374004523, 0.9115863650282121, 0.8481845525337858, 0.9534425743559706, 0.9406155229657192, 0.8655227673126581, 0.9024732100802277, 0.893526602094098, 0.8940587350756948, 0.9496732014677665, 0.9696483492309457, 0.8985845978569611, 0.9545777779802543, 0.9648092222881753, 0.9238631438195963, 0.8952828520909915, 0.9394801526741228, 0.9664205692158931, 0.8084099717584899, 0.9051154510918161, 0.8386468215993677, 0.8751884319903743, 0.9003955226287401, 0.911295710615592, 0.8997012116480327, 0.8555274202506493, 0.8292392315851829, 0.9093222247784509, 0.9581817796921474, 0.8944558765264972, 0.8897603971941828, 0.9540872084878868, 0.8903952943212128, 0.894939463032673, 0.9292629206237305, 0.9403652174764765, 0.9567401218419442, 0.9516394291040494, 0.9178258335595711, 0.8663635830849168, 0.8291974889167636, 0.8854123695449466, 0.9347666458580642, 0.9310527826436235, 0.919436795262315, 0.9370986608827743, 0.9191955097941079, 0.900975550609948, 0.8847844697170413, 0.9581523256223007, 0.9462996117009859, 0.9426374087427689, 0.9280986906017641, 0.920129343641988, 0.9525833862626361, 0.9355369387004454, 0.9201973003130003, 0.834560881170583, 0.9581274670862587, 0.9435274369247736, 0.8984862370960313, 0.96927131607858, 0.9541462320431864, 0.904119210120298, 0.8510448539435704, 0.9397822069319725, 0.9508206515059273, 0.9733731447730251, 0.9244155801490579, 0.9632863466499505, 0.9147242603384278, 0.9706676483311281, 0.9540008346485849, 0.9182034688290387, 0.8567534679392492, 0.943528860468407, 0.848363241784164, 0.9131167707599477, 0.915511694022559, 0.9772301340256946, 0.977256830083387, 0.9748994640624536, 0.9394044540330506, 0.9533835600525977, 0.9452100617614554, 0.9695386065198988, 0.9269606586013742, 0.9525552798855528, 0.9533292083941456, 0.9637425967616786, 0.8995630397232988, 0.8709089259229112, 0.9184067321344476, 0.9617970855528837, 0.9317802439076652, 0.9543049744348366, 0.9417434375662942, 0.9068620610700775, 0.9599751109708811, 0.9506926587945455, 0.8698015936298862, 0.8763458289427872, 0.9494593624005101, 0.9443633308923681, 0.9054862968499815, 0.9616804400700143, 0.9167348285769091, 0.9381920634647959, 0.8938998088215827, 0.9702279486867277, 0.9531636409922577, 0.8699519797091229, 0.916817351198738, 0.9481181752397903, 0.9484122347894293, 0.8963504899568708, 0.9783347510865075, 0.9581016629601284, 0.8708177929992528, 0.9254190549396607, 0.9381280659427547, 0.9139348899496909, 0.8501946455379148, 0.9425519538969518, 0.8451684321566726, 0.9438999664637293, 0.9692791103303104, 0.8763131813078133, 0.8721427921324633, 0.8504473278832327, 0.8583599466600303, 0.8684040121206249, 0.898825849338259, 0.8317993244611062, 0.8677458672939665, 0.9671471852440978, 0.8451340218036771, 0.9116327769689583, 0.9037281746225372, 0.9591052069073069, 0.8466959129301328, 0.9783368981822617, 0.9008785712867124, 0.9426836739833996, 0.8998325232336405, 0.9053141426941917, 0.871132142515858, 0.965334309140154, 0.7922395326975425, 0.9295954530182108, 0.9396618125863314, 0.9540856109634324, 0.9004482891483057, 0.8097650909146927, 0.8612802423779129, 0.9322437742990916, 0.8399844775777385, 0.9012814822485882, 0.8988633259253521, 0.885142175677029, 0.9573243053490673, 0.8851138180049951, 0.8845094504913675, 0.9529697032386629, 0.8389927444669526, 0.9209823216535153, 0.8816727032099312, 0.8262676699227941, 0.9430086832218283, 0.9472802836615299, 0.9218245932765958, 0.9011500685377971, 0.8968218660274045, 0.9018682151474564, 0.9106097225426446, 0.9464334456545069, 0.9048996655697402, 0.9537259302863421, 0.9781254281171295, 0.9234032806858046, 0.9617462107554722, 0.8596847789253919, 0.9500360043961152, 0.9181058888967801, 0.9286891407785735, 0.9474641733700965, 0.9399744786241594, 0.8858289022516224, 0.8658206869963723, 0.9065829295618404, 0.9003811417432975, 0.9574229806223744, 0.8802731269176604, 0.9094900304401684, 0.9572064966711006, 0.9065648574884073, 0.9562756273008918, 0.9256273023288778, 0.8846183583305371, 0.8817450390194239, 0.933204218886078, 0.8987554086890979, 0.9665790476252152, 0.9478949335899147, 0.878194350616792, 0.8375635958328556, 0.9342035327763893, 0.9472728772356124, 0.9065350795537197, 0.9199012297121152, 0.795077725258021, 0.9730603918419003, 0.9001850284193439, 0.9134592919490777, 0.8619495799955484, 0.9762431340952329, 0.910708256263746, 0.9580463296108355, 0.9191959933026949, 0.9625230607912324, 0.9371653792959723, 0.8975395746632269, 0.9457766390466477, 0.9558670321366264, 0.8434866144200348, 0.9750818407227962, 0.8538890934258174, 0.8826776231505489, 0.9232138029827781, 0.8924497247610249, 0.8605765676720395, 0.8905474813216294, 0.9422702529485183, 0.955160963143111, 0.9313355263509033, 0.8883122335870468, 0.9435544214186058, 0.9507682056626306, 0.9087999466918384, 0.9248546721760103, 0.936500504709963, 0.9634740928330839, 0.8240413952103574, 0.9550897765851794, 0.8856202365637101, 0.9531645626017549, 0.9255551190216054, 0.8932887269788136, 0.9499608209666496, 0.9682270095833848, 0.9055510843542431, 0.9603695387569033, 0.9047027264032124, 0.9616230873543536, 0.8642588816444482, 0.9364694863813934, 0.9370016351198076, 0.932279996796546, 0.9451213590433928, 0.939709703974217, 0.9369910294841177, 0.9125368469079591, 0.9284299434029321, 0.895867785418645, 0.9179581398631576, 0.9149644899914289, 0.9290321294666644, 0.9138970073823686, 0.9508990236552608, 0.9553164110248822, 0.8460934100721708, 0.9083821736528406, 0.9466155104382785, 0.8914738430034659, 0.9611114641477995, 0.9197874359049555, 0.8573028407373375, 0.9019999136829517, 0.89331285839647, 0.9253586586692519, 0.9063576241513635, 0.920002930227098, 0.9571034266116953, 0.8541783624312186, 0.9528474561032388, 0.8976199612038065, 0.9448511233997582, 0.9204011549493535, 0.939414679980733, 0.9387634831975971, 0.8937774882549718, 0.955715884481515, 0.9428807238117761, 0.8826235312201499, 0.788088579919292, 0.9747183802014122, 0.8534166039514377, 0.922399032290695, 0.9223886594725377, 0.906044728411642, 0.9490339027817662, 0.9619836554880103, 0.8916635166675029, 0.963041096137212, 0.8386070496289777, 0.8563181474827366, 0.8863995407742635, 0.9490941835721325, 0.9183174912542813, 0.8763622205229814, 0.9005797264154527, 0.8840960764406894, 0.9474031279644071, 0.923648855265305, 0.871076716286003, 0.8214963165846985, 0.8497747634068464, 0.936150912619637, 0.836963914829925, 0.8020984737410792, 0.8991211253349831, 0.8752488360526105, 0.8788174464489579, 0.8465211497573629, 0.9532287138925366, 0.914660826768402, 0.8630109552103025, 0.9176603811750731, 0.9026089145475349, 0.9123213982110365, 0.8785831733764992, 0.9017580444882132, 0.9303081872343495, 0.8683615112314654, 0.9604384859888451, 0.9078765314467233, 0.8750134611296589, 0.9340913853216062, 0.9082784976923406, 0.8889958538297302, 0.8780701624540712, 0.9467097970932576, 0.9185525171890865, 0.8528721062785648, 0.9747281829116365, 0.9188205598052666, 0.9378892572476419, 0.9692459160431179, 0.8762012655173466, 0.859943544909604, 0.9448945865384561, 0.941605241023624, 0.8966812709603607, 0.8715234256805325, 0.9274026225157774, 0.9248391069842273, 0.928203332647365, 0.9531632865162953, 0.9310468554203633, 0.899271493502283, 0.907213928450296, 0.9394610765386808, 0.8693175672736868, 0.9034927626764417, 0.8674327336571768, 0.9082673241953274, 0.856384348084235, 0.9070004033703587, 0.9379860162180467, 0.9206698148498154, 0.9674454841141166, 0.8905826526009868, 0.9089934728479118, 0.8964022609029685, 0.9102358417301959, 0.935448266421369, 0.9052067151945189, 0.9139955346886643, 0.8905401460138027, 0.9057265157253419, 0.8897471612446982, 0.9249847068935659, 0.960234236010116, 0.9639348850511033, 0.9431392360621738, 0.9750970056572226, 0.9054478932844592, 0.9382430888541902, 0.9504629040084351, 0.9075281230664181, 0.9446149925547069, 0.9186021950159992, 0.9173232834705873, 0.8941610608505891, 0.9111105422035486, 0.9267373508477816, 0.9272246196799091, 0.9022636111830025, 0.9093742912585631, 0.919585411043252, 0.9425722522780644, 0.9412971055262088, 0.9504758685189936, 0.862533810118769, 0.8726404816299048, 0.8930807067136524, 0.9510408913059767, 0.9290536490477465, 0.9003024883959287, 0.9273548668679068, 0.8825792893945409, 0.9121976323067609, 0.9296679643590161, 0.9656682387300639, 0.9222095888230758, 0.9519449186959601, 0.9515877398870868, 0.9143762127165883, 0.9569509010224154, 0.9685718452675727, 0.9296447660830595, 0.9326835690268295, 0.9726121336149457, 0.9217897155822984, 0.8767476753817522, 0.9078034079870667, 0.9158407579588623, 0.9487421562015065, 0.8641055912396343, 0.9155936875413433, 0.8836661794005538, 0.9470879270072535, 0.9414561864823394, 0.8512473190162536, 0.9175431549542916, 0.8695771363934759, 0.8671892177356283, 0.8679014078504232, 0.9370620090809567, 0.9549115114254235, 0.8985283183143553, 0.9205248446933528, 0.9473365772433949, 0.84322791325693, 0.8579789689080027, 0.9021285031462902, 0.9151211898071105, 0.9517406788663344, 0.9006201199994754, 0.8907329881594217, 0.9009742615667145, 0.8136623512133226, 0.943761648810806, 0.8323427158370593, 0.8441616475205376, 0.9018646672538815, 0.8749434848960103, 0.8757152646450823, 0.9723323573287053, 0.9069950377399474, 0.8561981545418078, 0.9151464788873125, 0.8696068960543077, 0.9517410383788467, 0.9656978966034423, 0.90010329800269, 0.9195912523504218, 0.9051960753661059, 0.8945244769617176, 0.9501157478759443, 0.8565612400632341, 0.9352249758178195, 0.8504133265667931, 0.9092838877060203, 0.8603706678113394, 0.9629650565831616, 0.9362508556698843, 0.9349211823094388, 0.9241896234745965, 0.9422703597952732, 0.9460367692232583, 0.9110394701284212, 0.8895876032520442, 0.9526297074493564, 0.8928664088490408, 0.9621516406484318, 0.8197172157379752, 0.9231188054788024, 0.8327769223003725, 0.7760422341637216, 0.8836588182915939, 0.8949125634978503, 0.9058298743205733, 0.9505966121204765, 0.9440141919466756, 0.9506671183773128, 0.8833667433726633, 0.950440394521909, 0.9031521523009147, 0.9291077270610255, 0.7943163467089795, 0.9133494082670746, 0.8727348324755188, 0.8923460215482004, 0.8943991227793033, 0.9570663685003543, 0.8788636928249881, 0.8660208775614798, 0.8542869252593529, 0.9357061959301968, 0.8755039319138327, 0.9727669198996878, 0.8878388479886193, 0.8643111908478562, 0.9126313350641394, 0.8440183649435253, 0.8934096783473261, 0.9178731545173606, 0.9068763885235855, 0.8660292173652452, 0.9131293939952658, 0.9416024794015085, 0.9474603745152802, 0.9043250704788481, 0.9022530361721209, 0.8484959695952469, 0.8889844060640886, 0.9360104941568871, 0.8590962920338254, 0.9140412402081308, 0.9414078902759788, 0.9272112259448477, 0.9639964338758698, 0.8693312874056301, 0.9052444867593021, 0.978145646104309, 0.9515195505780554, 0.9164736995557288, 0.886099477443382, 0.8675679034003587, 0.9460040732597879, 0.8611243107769393, 0.9128070717045865, 0.933273404439932, 0.8906834066823871, 0.8714155303388678, 0.9599484006096701, 0.9795391913907333, 0.9247970062326688, 0.9260947077236579, 0.932904542495346, 0.8820596574486161, 0.93426843320042, 0.9199338203185861, 0.9133911108908703, 0.8159701955706661, 0.8758120962673319, 0.9302507248974681, 0.9636196171048667, 0.890429868249792, 0.9381489981261821, 0.9297233555284578, 0.9052230011985146, 0.8184967174961962, 0.9016645095454452, 0.9508625634064163, 0.9617275803102343, 0.8826676633582693, 0.9176878361973588, 0.9112478800374898, 0.9301984986144287, 0.9225470827114002, 0.9502422856935935, 0.9072036909457226, 0.865084553925334, 0.8912694629751109, 0.8666017786916168, 0.9446642389793026, 0.8445824581167742, 0.9301944925724157, 0.9281098521484061, 0.9319539462290416, 0.849294285863609, 0.8410254484112891, 0.9311399708381409, 0.9642253161960945, 0.891984206842563, 0.9455779477012605, 0.9068284994019253, 0.8883161925527578, 0.8388489468193555, 0.9696164071286675, 0.959059077082425, 0.9115754991434271, 0.8642227579807672, 0.9045881288101406, 0.9142238533191658, 0.9097992630157457, 0.8613884457187858, 0.9334565854075638, 0.961594214480045, 0.9470410703500234, 0.9555531971962424, 0.9602084528279686, 0.9013926764313378, 0.9325772256946132, 0.8896437176014109, 0.939952750024182, 0.8520593758506568, 0.9369873136551029, 0.9199657410051422, 0.8729093898850757, 0.9112420046974896, 0.9170718501342505, 0.836793100494033, 0.9442073821478771, 0.9174231170193343, 0.9529767898049715, 0.9562246225663305, 0.9270899666658753, 0.9376643300597358, 0.8539036500795443, 0.9580197525851091, 0.909198355607515, 0.9433014618921538, 0.8132167874634684, 0.9508323312692621, 0.9073239294687205, 0.8712397619331367, 0.9335424604723569, 0.9287591012087801, 0.9102224644362589, 0.8373778793979071, 0.9688564528941137, 0.8779545136841109, 0.9601473369493306, 0.8951228465582418, 0.8983727776846886, 0.959082277698985, 0.8945571392616547, 0.9139757875933452, 0.8212622323698883, 0.964421627570706, 0.9036173694406261, 0.8954561286042425, 0.9050875093752866, 0.7917963274903397, 0.9163788975294146, 0.8820897808410127, 0.9294691149765333, 0.9399577945438394, 0.9255476060283139, 0.9147527161385499, 0.9526766836636075, 0.9339793392691882, 0.9454602668501215, 0.8689561061123275, 0.970655244771521, 0.936227499366266, 0.9456011029771649, 0.9174845718317329, 0.9338012316741071, 0.8639580117432647, 0.9698276294130235, 0.8655897288598728, 0.9352457888122538, 0.9492412767759995, 0.9591085086998876, 0.8909546632673255, 0.9583519407913211, 0.9408876576258464, 0.9233765230195436, 0.9590958470088057, 0.9045848241111674, 0.8664989160065875, 0.9200853217137509, 0.96506162025563, 0.913421680190057, 0.9431075278947298, 0.9324140683704673, 0.8288476883024724, 0.9178012510149332, 0.9418430179337568, 0.9440634010685344, 0.9653979729949588, 0.9274225575662817, 0.8741357835520263, 0.9323060051821104, 0.9678357084861967, 0.8881015087148854, 0.9486867289076952, 0.8300465180271128, 0.883238157765267, 0.8890509333030396, 0.9213947174036545, 0.9100754183801467, 0.9421834716783655, 0.9526839195208752, 0.8566917511901926, 0.9523586178058856, 0.8978472102624022, 0.9413583031274827, 0.9596122887755263, 0.9239187628840486, 0.964290029539499, 0.8666565968013392, 0.9257177663551855, 0.9417152413657468, 0.8981246578756689, 0.9290084466212463, 0.9668279234207895, 0.9582247614191202, 0.8873049117306487, 0.9359033950111657, 0.9624129735095462, 0.9477439984232751, 0.9490242080750033, 0.9402555778802475, 0.9248208004704422, 0.8972689439372536, 0.9410522514317071, 0.9091870410225704, 0.9194728003754402, 0.9233891218547187, 0.8707894484065525, 0.9332547063422734, 0.9522832109984927, 0.9416510200844059, 0.8835346660271082, 0.8856293601365788, 0.9232795121778807, 0.9441868493407957, 0.9392768200328261, 0.9547169552179118, 0.9260005491227142, 0.9188715308269026, 0.8986949242846403, 0.8911211029843853, 0.8991725838938618, 0.9179943607545131, 0.8325230312620618, 0.9374754196797329, 0.9306807291842341, 0.9098618482934684, 0.966589521168242, 0.8718219844847777, 0.945363425446711, 0.9624315167571789, 0.8883985674327102, 0.8958027519689225, 0.9340307805424568, 0.8635857274361596, 0.865688587886765, 0.8974563624459733, 0.9091725839548703, 0.9359286273954539, 0.9189045548921758, 0.9302564287982253, 0.8960039986216737, 0.8763894649208873, 0.9689618909204029, 0.933585129421403, 0.9144211213839168, 0.9711418395721785, 0.9430398221288856, 0.9148069564906317, 0.8866154021215988, 0.9114984980526836, 0.9506519097281153, 0.9526621025697418, 0.945812773781965, 0.9271765646402498, 0.8871368864713558, 0.9434578841039789, 0.9636960743997061, 0.9619354923022371, 0.9502607050742956, 0.9082855493680511, 0.9045603146650568, 0.9510594865631699, 0.9039169213774774, 0.897804973988932, 0.902425714329837, 0.9102640407980253, 0.9415529235690796, 0.9364569653779771, 0.905176759509491, 0.9589896082613, 0.9418202259701055, 0.9151247535285558, 0.88263273593511, 0.9080202756456288, 0.9198600671647903, 0.9562191789236969, 0.9066415380812336, 0.9494525038102551, 0.9727512553952357, 0.8725704242833188, 0.9462266113279973, 0.962844677927234, 0.8713124659525419, 0.8998451506226464, 0.8869793138834128, 0.9672545540517251, 0.9220272277258759, 0.8765641074921595, 0.9558599315250346, 0.920636738757048, 0.9031506560820279, 0.8496383479536482, 0.9713753465782223, 0.8558123214628778, 0.8535358521111737, 0.9410539616875804, 0.9163107027083527, 0.8982963381466438, 0.8854661613542806, 0.9514496982098564, 0.9283930610463987, 0.9183230368322306, 0.9217342637261337, 0.9796160749785554, 0.9054616831086282, 0.9619058197311764, 0.9256751412070924, 0.9206931153102247, 0.9619533904172908, 0.9299856436369083, 0.9632264701465835, 0.9160054293299675, 0.8443846785787453, 0.8806670834954142, 0.8996046550906881, 0.9360816024444454, 0.9575259631990103, 0.924925196379294, 0.8698248849789144, 0.9474070261066794, 0.968450965469879, 0.850055453997578, 0.9250013619171362, 0.9115938324217445, 0.8553868246752954, 0.8719027989876512, 0.9571827076469982, 0.9517390845854412, 0.9714596027994624, 0.907723983904467, 0.8351779760890503, 0.8678060453103307, 0.9731850250642728, 0.8590793889463559, 0.887280935064553, 0.9021180089179761, 0.9121266118054971, 0.8978160259903386, 0.8976247137287405, 0.9552148398467086, 0.9303239811422308, 0.9338184530120681, 0.9153582085211474, 0.8839772153445546, 0.8434054208891278, 0.8327509079326396, 0.8661729361050907, 0.9426310025626041, 0.9373088035574899, 0.9017692809176026, 0.8788284970161491, 0.9250011188432516, 0.9276935082648106, 0.94404575068089, 0.8957715729829312, 0.9464441729017086, 0.9574633433075678, 0.9281459401486551, 0.8720011605092263, 0.9022308713161244, 0.9552690015485501, 0.9245800994562876, 0.8841046850081085, 0.8655771896162747, 0.9339981775103676, 0.852624544552917, 0.9590361684539316, 0.8747184194412373, 0.970310843336682, 0.9527481324335771, 0.8754517582199819, 0.923099617126131, 0.8713485711024094, 0.890690650326575, 0.9447726378917902, 0.9480820546295443, 0.9337175326418277, 0.8896335658412418, 0.8136344772237168, 0.9447511256535933, 0.8852111032396107, 0.893256113581071, 0.9120380472741724, 0.8563054754679855, 0.9584307400605225, 0.9482667290791458, 0.9584954412505576, 0.8605615744368815, 0.9166955156459489, 0.9052795977192765, 0.9528575124150832, 0.8721600028161224, 0.8929939863025804, 0.9310804861169715, 0.9510901130836148, 0.9488025016361683, 0.9140747265572592, 0.8737492548250065, 0.9094249289692313, 0.955100726805283, 0.9269596377258948, 0.9153724033794759, 0.8818117490167012, 0.9071357479409793, 0.9444390061330701, 0.9404846784486773, 0.8953304453676405, 0.9320844778711264, 0.9481896867441271, 0.9203232185878663, 0.9185028260802954, 0.9388347234871904, 0.9303480497897144, 0.8758491519930263, 0.8892550749370687, 0.9146945126268081, 0.762911736700812, 0.9337055300777493, 0.9017240866669244, 0.9728383061980788, 0.9397368477528495, 0.9317471876356178, 0.9039446337385959, 0.8185242917323621, 0.9115794739758283, 0.8588378469965396, 0.9729005171622827, 0.9360713538639154, 0.9181520176466513, 0.8598817163513699, 0.9716152219882317, 0.8791505284983481, 0.8871673806355882, 0.9339440964615073, 0.9432841965886186, 0.9741383344032666, 0.863780228995003, 0.9586362361890896, 0.820802934638671, 0.9382981697354669, 0.8633292072325893, 0.8344470647806597, 0.8331385411471138, 0.8634816971620075, 0.9424916800850911, 0.9285873639515156, 0.9566082967914777, 0.8849987226094478, 0.873850265945984, 0.9178857769985546, 0.8968224727098291, 0.9137717035184334, 0.9170302388996969, 0.921984527363415, 0.9322689766316242, 0.8764407000455938, 0.9110603998351778, 0.9031846399165466, 0.9421712057646237, 0.9024823428584037, 0.9298309877377225, 0.9207552104004869, 0.9484537580198548, 0.9320205638621842, 0.9515443282339257, 0.9646169986396445, 0.8491829202912917, 0.9486342084370016, 0.9375710837447437, 0.9181518681935825, 0.9395415132846014, 0.9430052336155117, 0.8717034862459581, 0.8223396539285892, 0.8892567787067309, 0.9619684089857137, 0.9079320044473063, 0.9326935979748375, 0.8738254314482152, 0.8875451389079395, 0.8890757315369825, 0.9449917185202861, 0.8804086264133283, 0.967094912324431, 0.9389684433051808, 0.9649077214377421, 0.9660424341340832, 0.9670169339012116, 0.8625817165336762, 0.8987615708932726, 0.9282320966032704, 0.9115639716133745, 0.9267457929796827, 0.9227277626046477, 0.9539691352694293, 0.8793367671150994, 0.9553949529134438, 0.9355344967200674, 0.9612298907566409, 0.9235043894532342, 0.8749094971029321, 0.9572033571142752, 0.8691267542945948, 0.9313094115056637, 0.9118926852037808, 0.9464074719936828, 0.9571009285862271, 0.8991884743169599, 0.956885430401204, 0.9307015637155927, 0.906383702524352, 0.9691428304419026, 0.9278482083774433, 0.8699007074560619, 0.89730921153573, 0.8580694129677726, 0.945728830718876, 0.9340292908589858, 0.9792823275052357, 0.9390283274322009, 0.7888333233556919, 0.9792413683567487, 0.8619677124044909, 0.9153816472466669, 0.9725354536849629, 0.8299445599405557, 0.9622722375991956, 0.9300487959467831, 0.90617357913243, 0.8501261691929228, 0.9394914670750164, 0.9362031011608645, 0.8982058394375544, 0.9230437651126228, 0.8873052448654655, 0.9573542851035306, 0.9614448703705555, 0.9113090963463024, 0.8371587668211954, 0.9471477518316126, 0.9513642589287548, 0.8947193041588289, 0.8822306712053998, 0.9576008175290222, 0.9249939262413127, 0.9208934962048916, 0.9374771632005604, 0.9698367785653772, 0.8782244075638199, 0.9018373719588495, 0.8992275095449134, 0.9422054027769051, 0.8783207937023285, 0.8928242476141659, 0.9363267721057505, 0.9164789972948962, 0.9433649713003077, 0.9375267797712337, 0.9394917808526015, 0.907825556076296, 0.9516004482208656, 0.9551949560433239, 0.9505634052397831, 0.9126084646904062, 0.9676178898343932, 0.9239509513289899, 0.8668742988929558, 0.868350549033765, 0.9522153156968031, 0.9200920384195145, 0.8881948086562674, 0.9695279561776997, 0.8617319769517218, 0.9547214008642894, 0.9187963968775057, 0.9362481257718704, 0.8790073204499684, 0.9400103766360237, 0.9124705663944861, 0.9215469103017576, 0.8650064713450837, 0.8833624838108082, 0.8945556138534263, 0.8687053817202521, 0.945145574190361, 0.9295161176684004, 0.9397878477528417, 0.9427428422721069, 0.8950856295610142, 0.8010649124199829, 0.8968462920276539, 0.9567856133374558, 0.9136139845786362, 0.909625342881528, 0.9393090266097288, 0.8580795416801845, 0.9596299423400912, 0.9417402052466785, 0.93723670574061, 0.9181218355750255, 0.9508830677932565, 0.9318365263907099, 0.9240446681523548, 0.9045256973785671, 0.9371654148719254, 0.9032087525122326, 0.91268251453082, 0.8878822285725073, 0.9594283901597134, 0.910499326943048, 0.9123290036182341, 0.9607764640333143, 0.9571289771723142, 0.9598033191903704, 0.9517639638448898, 0.9248628921644784, 0.9570363074487442, 0.9024291088356095, 0.8836210480298601, 0.9048279687199788, 0.9652077213564839, 0.802448542208404, 0.900569951473916, 0.9377236073410915, 0.951218175255122, 0.9745586298628345, 0.9481923355753608, 0.9714835223468523, 0.9335363649328907, 0.9360121019536125, 0.9040639994447985, 0.9387195565419425, 0.9695395780535311, 0.8703554014010723, 0.9552947190156755, 0.9589771101417708, 0.8665418118296386, 0.9583376176486955, 0.9358676259369044, 0.9196001976290158, 0.9128261387654257, 0.9257045344495209, 0.8954814686773441, 0.9023027674707549, 0.9661599004604731, 0.8955363163499227, 0.9719734331163876, 0.8826522463611001, 0.8975201517515634, 0.8224746559723657, 0.9160043445090065, 0.9067639940856261, 0.866829040036495, 0.9645662810063398, 0.8925513170939317, 0.8820473854370511, 0.9058362314807038, 0.9596082604236285, 0.9343158414741152, 0.9308879553491585, 0.9319282338805817, 0.8308994082460781, 0.9276207894206694, 0.9196938840015975, 0.8976631980382095, 0.8762468090081283, 0.9482098234688388, 0.9416133348903148, 0.9143620988413514, 0.9227781464296699, 0.9679798913221491, 0.9757116578070302, 0.8787333348069547, 0.9033530712951447, 0.8651331445268637, 0.8057836032718602, 0.9579948054135172, 0.9331094449477446, 0.8999571057540106, 0.8753353238771038, 0.9281244548470364, 0.8529627212469221, 0.9401517661010872, 0.9549280535672152, 0.9257168454208176, 0.8446212305831222, 0.9096801305918294, 0.962174625773774, 0.9029973802738189, 0.8853996173840537, 0.7987955711502307, 0.8605872798613297, 0.9498727018980087, 0.9587407702526696, 0.8980818193071076, 0.9506518208301022, 0.956028379382992, 0.9124608011176985, 0.843631179203999, 0.920329972166953, 0.8951053920778712, 0.9578184745668916, 0.8797225053156054, 0.9328863499988898, 0.964133167824722, 0.9404106134445366, 0.8906482249815947, 0.9692171850327993, 0.88532165480197, 0.9505636731883446, 0.9526956906835089, 0.8566879982826245, 0.9466436505234805, 0.8445128159345693, 0.9678938986520595, 0.8834314989886608, 0.9443818024633597, 0.945683713978421, 0.944621184271398, 0.9114993228299, 0.8825937359070302, 0.9428369189350245, 0.8936553216753544, 0.9275902552928833, 0.8463163828950079, 0.919417267645389, 0.9447313238743394, 0.8790669359696891, 0.9449717680983412, 0.9087474302859563, 0.8972911528670133, 0.9430878619893527, 0.9754284752241238, 0.9176571267539095, 0.9067509294662122, 0.9331888595870919, 0.9363676967133301, 0.8763133294154288, 0.8660275162404357, 0.956001441821911, 0.8549604094568724, 0.8816711645555037, 0.9582194523233099, 0.9334247424727442, 0.9007038449960297, 0.861873446133203, 0.9459166204265647, 0.9085236614825734, 0.8244803880801549, 0.9191938735127254, 0.9345538690728501, 0.905212171537914, 0.9505037717588325, 0.897152270411339, 0.9581227771473071, 0.9715656838390002, 0.9220301995961261, 0.8481401609374841, 0.8901088380261414, 0.9317169057068175, 0.9316830979032675, 0.8858524138979964, 0.932179775945108, 0.9745808984840469, 0.8325880757057674, 0.8452206932022054, 0.9467120920985999, 0.9011631490228821, 0.962105961507905, 0.9029714848802679, 0.9403727994864347, 0.9097822577227518, 0.907250740350903, 0.8934749148492656, 0.9495815991977364, 0.9404055933720583, 0.8810131024430536, 0.9544798158639756, 0.9004532089700579, 0.9174937782755318, 0.8865343351660779, 0.9308103249045144, 0.9284176823158414, 0.9266086808338407, 0.9391130367373476, 0.8764878536088612, 0.9032832988278321, 0.9191850766931509, 0.8507268245146953, 0.9050190748281703, 0.9089959493716779, 0.9541445037189245, 0.9207500434610653, 0.9311662305029174, 0.8679458286899315, 0.9124610298304687, 0.9513909869872129, 0.9371202607117041, 0.9350559340510645, 0.8766877599452247, 0.9137735974286341, 0.969249537415283, 0.959638702843973, 0.8028788359116298, 0.9364341520971055, 0.8739139170327581, 0.8928864541341922, 0.9361863819076102, 0.9237726168841498, 0.9253477929166033, 0.9049237123703796, 0.9116879795343756, 0.9020808365752748, 0.915496306644107, 0.881798998609518, 0.9498532796975941, 0.903963879657168, 0.9245942894290304, 0.9209479575669591, 0.9066476026595809, 0.897518066200472, 0.9217741651430239, 0.9066303339119053, 0.925063916527344, 0.9448046886820655, 0.8998933472019526, 0.9819971551805626, 0.8923868780438449, 0.9322967378382775, 0.8167395027687591, 0.8144005252449658, 0.7912289270242658, 0.9417703642783128, 0.9079036834331937, 0.9304225696975128, 0.9309864746784418, 0.8995054323063431, 0.9605230759309489, 0.8651407900448604, 0.9436666631459845, 0.9027991496592298, 0.8613012733407536, 0.8959457458640825, 0.954591096830234, 0.9138278581850267, 0.960395317352078, 0.943547177979767, 0.8992342340203813, 0.9314083593893087, 0.9671920485829377, 0.8802885905809169, 0.9410510310939075, 0.9611155214206486, 0.9204514645535062, 0.9457818824518076, 0.9437147857829808, 0.854042546885242, 0.9450453809718756, 0.9332812817358173, 0.9669238968047911, 0.9140630891863131, 0.9583670572320753, 0.9578372540765729, 0.9524769430364922, 0.8491707256437573, 0.9605720182549493, 0.9391640111094579, 0.9381890620713413, 0.9576823971791043, 0.9704427956202526, 0.9258268124195044, 0.907230999161958, 0.9037306508488693, 0.9404965594973433, 0.8861889948126465, 0.966918660881315, 0.9648352436457711, 0.9705323362620875, 0.9464954469742612, 0.8958206225496261, 0.9451534467929137, 0.9288624098391558, 0.9269952943260236, 0.859326367064961, 0.952849980329955, 0.8629316557396245, 0.8935387604142853, 0.9050516268707431, 0.9042264163847679, 0.8635280769301165, 0.8811668795055538, 0.9125833099758963, 0.9354280622152583, 0.8792162103645489, 0.9535497357074744, 0.9207455571143752, 0.9676193193821598, 0.8723416168724806, 0.8898808158320546, 0.9100818113213571, 0.9306882839361283, 0.9032816617491571, 0.8795107797087635, 0.9459125504325747, 0.9001626031066161, 0.909806900427245, 0.9481928210555307, 0.9074674829724819, 0.9528761334337745, 0.9654618672990765, 0.8745833875893525, 0.9479125320919204, 0.9188793850779178, 0.969639558771742, 0.8954150139806809, 0.9452459284986493, 0.9468542089267551, 0.867813437318979, 0.9733952388872116, 0.8553977169798297, 0.9062086750586529, 0.9723582207055403, 0.9231369406503177, 0.9580313048764433, 0.8851167803374893, 0.924364116484115, 0.9354081599828324, 0.9680223278160087, 0.9172342778033122, 0.9323623458574345, 0.9558685475635041, 0.9017410500400656, 0.9113783644802862, 0.8598005286806647, 0.9092511737059523, 0.9243590368570458, 0.9532384524809444, 0.8625969887267906, 0.9703838443900061, 0.9624833546862057, 0.8433928992845074, 0.96014586834223, 0.9071352877900758, 0.9522761048101278, 0.8712933398312168, 0.8783491429098997, 0.948462900182584, 0.8805702151486157, 0.82820804536504, 0.9511745865164298, 0.8342462598545416, 0.967086242906172, 0.8867190610943665, 0.9113381484664402, 0.9134479597355939, 0.9073307383579836, 0.9193022605239296, 0.9386352136220288, 0.936498639077909, 0.9218402224221196, 0.8569392600781114, 0.958738962882782, 0.8747532300623531, 0.8304671370022559, 0.9380410229948803, 0.9430367608606887, 0.8083260580824725, 0.9626695589291376, 0.9475167932137889, 0.9577038568417457, 0.8123286829922576, 0.8932067937299051, 0.9015104697260863, 0.8845721489850548, 0.9218079426049964, 0.9277939084685272, 0.9449362732904831, 0.9371578145406239, 0.9393098992463759, 0.9413254642532972, 0.9070101983476158, 0.9724066241793343, 0.9224573776642258, 0.9147994041448962, 0.8286489417303831, 0.8304168484512998, 0.848680960827473, 0.9242228565205606, 0.9305252799388538, 0.8989546087378224, 0.8030646025584856, 0.9572151920528899, 0.9074237540191357, 0.8534464284399126, 0.9509546819951447, 0.8516996463281851, 0.888079787582924, 0.8890052886183046, 0.928159602214535, 0.9489139341512874, 0.9044140451701372, 0.9247964333417459, 0.8457276170256145, 0.906834283473696, 0.9430566098592683, 0.8871516767017465, 0.8903293201203932, 0.9581707368788773, 0.8792091063826555, 0.8878139928313786, 0.9113964978473755, 0.8791343629218463, 0.8644014439152556, 0.909207436552813, 0.9387469664987358, 0.8497786947372995, 0.923798907915512, 0.9437532188962072, 0.9678242269587929, 0.9450078091629242, 0.8131695011587979, 0.8065803133263595, 0.8966679729756699, 0.9515172802509788, 0.8590933124032777, 0.8451376797349947, 0.9464317427099125, 0.9506882521721506, 0.9221357050232291, 0.9285657871877673, 0.8950785794497778, 0.9111239109111599, 0.9719737954671451, 0.9235634764857616, 0.8187643720127636, 0.9198088927432042, 0.9460704639364622, 0.9637459758610604, 0.9057362999234715, 0.8806732079149394, 0.9311433600461836, 0.8715795346716949, 0.8544980100539994, 0.8396501432779411, 0.8755882931450354, 0.9193378740937639, 0.9236461120810872, 0.9710320100559179, 0.9415911500390621, 0.92548858616683, 0.8487488831178379, 0.9231165632406442, 0.9254911234479554, 0.858602279780243, 0.9127321848400506, 0.9433429011965143, 0.9429298930783587, 0.9620439242205786, 0.9477739925263134, 0.8632409181936738, 0.9684556566628966, 0.9533292828681937, 0.9154433487491731, 0.8467753823124593, 0.9064632125446934, 0.9320354259717547, 0.9736432998178691, 0.8556605128467119, 0.9439779965593696, 0.9267511865151714, 0.9774038310853066, 0.911391909623953, 0.8554066743585994, 0.8483559680209587, 0.8664142889701381, 0.9638868434873363, 0.9540183197665333, 0.8896913119575152, 0.9188618493185184, 0.9780572220851753, 0.9450076472473332, 0.9596231559067288, 0.9540496233002048, 0.9286290589137254, 0.9350102025977859, 0.9250534774173489, 0.9263866253911421, 0.9451675996090677, 0.8294282551994401, 0.8866344200927163, 0.9709094404868539, 0.9201756362318584, 0.9155200069754933, 0.9377860565084403, 0.9423764183046699, 0.9155220567930988, 0.9020750997596952, 0.9314577931370793, 0.8957764989521123, 0.8828608311253692, 0.9294226895083112, 0.8482333355388155, 0.9404454053987787, 0.9615730263530694, 0.9328526422583077, 0.9160294877509949, 0.8880779225464751, 0.9206600806942864, 0.9178003023158343, 0.9076985828108675, 0.9077885535017561, 0.9540405358254953, 0.8386908485274442, 0.9049903944436202, 0.8654496542896045, 0.9108367112860609, 0.94127713148523, 0.98421854900517, 0.9393915894421178, 0.7634505201437436, 0.8658780800697526, 0.9638689592532182, 0.9463612798816192, 0.880830391095212, 0.8835351082965506, 0.8640172772269684, 0.8723397303098432, 0.890020281950245, 0.9410789468514935, 0.8433405801810472, 0.9258794192840258, 0.9488711120387947, 0.9643629767681441, 0.9065985184441985, 0.8576648687570405, 0.9362538771199957, 0.9490447245429923, 0.9172577995530838, 0.8865776194921442, 0.8928105564057085, 0.9708557916065998, 0.8631398644355437, 0.9366131367893679, 0.8980572560069392, 0.895521128874075, 0.9417873100907352, 0.9498354852673077, 0.9157377618399941, 0.8489122543342863, 0.9185411614056855, 0.9570271902704074, 0.9677761308974695, 0.9018218182632363, 0.9382318258267568, 0.9110490113188469, 0.9337327934186502, 0.8880489789411063, 0.9029297223940654, 0.9444800542654531, 0.9185425502385689, 0.8910583486885668, 0.9658672746726473, 0.9217976257885122, 0.955924948242372, 0.9273983272097797, 0.9255060781925571, 0.9133881204097483, 0.9038517069390049, 0.9157977076936652, 0.8910467915210791, 0.9502827979484963, 0.9018433710922209, 0.946655714942766, 0.9252683644209965, 0.9740724321429761, 0.845449700142458, 0.9720133910954838, 0.9445533681009788, 0.9169072455119628, 0.9075593789548646, 0.9130984710178078, 0.9314426599513461, 0.9521282713479576, 0.8954739737566941, 0.8964860301303406, 0.9443591299841785, 0.9590505195346772, 0.8695391571308607, 0.9390114048485302, 0.9620408323079794, 0.915992190438893, 0.8706831299020176, 0.8864108130586426, 0.957041182569343, 0.959816597777579, 0.9185990982478656, 0.8998178609270326, 0.9025920024156961, 0.9528622661768179, 0.912441640837517, 0.9266231382507957, 0.9034174796135177, 0.9036341220608934, 0.9478428481556609, 0.9490704204585276, 0.8911847064502951, 0.8757422330136532, 0.9343111016785517, 0.9328661284140493, 0.8984007741496967, 0.9565116653091889, 0.8472340959593496, 0.9164527227501189, 0.9322989292876228, 0.8773160512835549, 0.9695481516483063, 0.9584765634313177, 0.9356335243762796, 0.9322889958858147, 0.9319370340581488, 0.933022944892858, 0.9015279123293405, 0.8882504472647645, 0.9575847732439481, 0.9122854614473206, 0.8828415376025338, 0.9155958266210363, 0.8642168695815946, 0.8817197651802513, 0.9167052262450232, 0.9387046152048237, 0.8791772314268649, 0.9034876115470154, 0.8524576313216535, 0.9560090633449587, 0.9271286998061452, 0.9038092527958903, 0.8638640187622744, 0.9247777091831472, 0.8773110888330242, 0.973250012835585, 0.9670951465410993, 0.9470467725963432, 0.8970492307921747, 0.8728821805258219, 0.9688347009298433, 0.8923239101794156, 0.9316247656142487, 0.8636143830295928, 0.9108090261696774, 0.8998263091580836, 0.9136935566902505, 0.9367569752211934, 0.9512863483973772, 0.8628728188790905, 0.8805985633619575, 0.9497540887656226, 0.9233541454611973, 0.9120656581743096, 0.8470189335809102, 0.9315153401512932, 0.9749089746845324, 0.8710428453183512, 0.9223189151629524, 0.9602484957124089, 0.9482936445592209, 0.9042311765141338, 0.8921833879144806, 0.9193366421483915, 0.891934720381247, 0.9485202861358738, 0.9474948275570526, 0.9032497090231304, 0.9364774570377248, 0.9067383498733426, 0.9429591343703347, 0.8446695978096812, 0.9457894104656315, 0.8594797315987509, 0.8876912437973119, 0.8973373367780775, 0.9189484033170796, 0.9380523153440629, 0.9155400598259407, 0.9434836216382911, 0.9354037467867216, 0.9602396065200494, 0.9329812735816617, 0.8689494063315416, 0.9425694748029783, 0.9336576757608652, 0.933671894686771, 0.9178120925714638, 0.9724732361030222, 0.9260337086210426, 0.8110637403691037, 0.8715758638294042, 0.9510351699764343, 0.8846174891080989, 0.8921051499013144, 0.8987822142556715, 0.9377333774248227, 0.9005627367309678, 0.8891212798396565, 0.9116583660626255, 0.9190179135406753, 0.9603720360055297, 0.954353379821518, 0.9336255924894942, 0.9721153284077744, 0.8775431517591098, 0.9267568889689983, 0.8876238366593459, 0.9263586781896799, 0.8856192043190466, 0.8750112603923786, 0.8685598803337493, 0.9517448890765006, 0.9802177799900791, 0.8919444352316148, 0.9077027621753859, 0.9315921653638426, 0.9489405811417269, 0.9466519888943028, 0.9435888020278672, 0.752005839835012, 0.9004714555083291, 0.961165939868886, 0.929410947786534, 0.9092326725641026, 0.979752163917539, 0.9689586115199782, 0.9484987161878335, 0.9368722587943559, 0.9353899482685346, 0.9623186461001736, 0.9585767016283895, 0.9128385644800004, 0.89804347211188, 0.9231813644592234, 0.8574806267484938, 0.8891034852115561, 0.893362177134605, 0.9492167724922347, 0.9659958162049052, 0.9068413656945697, 0.973359356462274, 0.9414367367468575, 0.8293820899400928, 0.9675350601565406, 0.973229531772821, 0.8634867164104545, 0.9645949384034609, 0.8867794713713741, 0.9381480234578734, 0.8413741312044458, 0.9129412814126804, 0.9079111490485794, 0.881472205381395, 0.9513841944805519, 0.9169627884721365, 0.8842686601333724, 0.8768316870375656, 0.9456198668415456, 0.8342481196447304, 0.9335609005877263, 0.9156449873968169, 0.9620693063422242, 0.854624272439926, 0.948813598394918, 0.9660194105834816, 0.9131049700561032, 0.9126613859307033, 0.9469265105321767, 0.9587422153934754, 0.9702965687474696, 0.9510751494421248, 0.9467040922438843, 0.7630123920000923, 0.9012749614051929, 0.8919131464511184, 0.9384295421048521, 0.9134393465713531, 0.9373156856795921, 0.9151444079447449, 0.8671373480555558, 0.9202862206699163, 0.9016887626259398, 0.9227568899216944, 0.8426762523074888, 0.8690978910456901, 0.905910285340606, 0.9597596457660373, 0.8187763617387342, 0.9422041372698468, 0.9276223176189613, 0.8267172205340113, 0.9681949911906347, 0.8670416733595651, 0.8969317583751687, 0.941048114410351, 0.9653017220648618, 0.8540607415773617, 0.8787386436342797, 0.9331075926657042, 0.8524432687993027, 0.9720612712283225, 0.9389221335912423, 0.9218889542763045, 0.8360793172472236, 0.9315691291910092, 0.9333626185495941, 0.9698238165521383, 0.9483472139254681, 0.9248239764885975, 0.9547550619751334, 0.9282110747437038, 0.8597357562680268, 0.9757681290006686, 0.8883774660523568, 0.961678481346612, 0.8981880933049199, 0.8995437549282387, 0.8988263554867428, 0.8139981973957222, 0.9333365380711323, 0.8927868411910411, 0.9727705402104093, 0.8771054768511843, 0.8926477505686999, 0.9312777504115659, 0.8933601296384956, 0.9017113325550412, 0.9520290328001593, 0.8889659168116528, 0.9094148391638712, 0.8735357654798311, 0.9617812948579031, 0.9557073157179601, 0.9241482211401789, 0.9457895345287803, 0.9420184853885762, 0.9189634289611803, 0.9106045637677239, 0.9014838804776095, 0.9743062513187442, 0.9672394142714531, 0.927126676584843, 0.8740490520897171, 0.9500517298360825, 0.9509724377163719, 0.8112553036813643, 0.9357731010174926, 0.8968049476877044, 0.9679937599609646, 0.9407147404265915, 0.9292338362475869, 0.8713766035571887, 0.8783940993869062, 0.9204458440601346, 0.9042607988970454, 0.9427482406134915, 0.9463685435880702, 0.9437567208435378, 0.8786144914697119, 0.9182087378250097, 0.9130727168949216, 0.961692124103137, 0.9550522951039113, 0.8903723416500526, 0.9588314083123981, 0.8968392506934185, 0.8840583355371108, 0.8064811393300589, 0.9597704950344226, 0.8564100729708541, 0.9089811606875283, 0.9510926849456213, 0.9400995143573084, 0.9309728217359099, 0.9784273782475091, 0.8776395674715768, 0.9608800194228038, 0.8630653281071549, 0.9354804224641836, 0.9768547178835527, 0.9258069617066791, 0.8844559560676815, 0.8941823740096653, 0.9530380704255829, 0.920529478425175, 0.944295926670119, 0.9249866185474875, 0.9293498119193129, 0.9103004085800006, 0.9478680427742359, 0.9268584543018202, 0.9357004937861213, 0.8835649275561526, 0.8512172531953953, 0.9159503100242088, 0.9712369557890932, 0.9640121244626662, 0.9317603068710123, 0.9160290624617083, 0.9353573730239756, 0.8685562123603197, 0.9532595507749041, 0.9024563994853949, 0.9481165004603658, 0.9712981917133664, 0.9603024986588654, 0.8701624553178655, 0.910216080984674, 0.8918362391164971, 0.9167528661720877, 0.9641011922058216, 0.9366013262233598, 0.9187183987299197, 0.96292803354957, 0.9383976689206533, 0.8488417684816085, 0.9609500006194638, 0.9407146966327036, 0.9040183186244017, 0.8971684136848654, 0.9381999731516557, 0.870369432729396, 0.9165158996665224, 0.9380125908811134, 0.9414926307731704, 0.8174734785086056, 0.9662590520457722, 0.8540824221752875, 0.9569219075213098, 0.9341885707489455, 0.8803608138290322, 0.8905058438746281, 0.8969287238843219, 0.9511769010344426, 0.9302691905246603, 0.9461112099569615, 0.8829207764065146, 0.9489562469715949, 0.9526823737607497, 0.9006386334507211, 0.9524947311778256, 0.8541694545711734, 0.8497420922736555, 0.9253112706480136, 0.8913892634776892, 0.9409354988473184, 0.9437758147408981, 0.9695997443868728, 0.6825378056619182, 0.8497754505519134, 0.9141475764495355, 0.8820658650289311, 0.9301907172161723, 0.9041178152488142, 0.9122631872216845, 0.9532253497049455, 0.9156096924279198, 0.9154590611359849, 0.8769371243889899, 0.9597592192162441, 0.921575482418395, 0.9348684668683456, 0.9310723755667221, 0.8717937297982626, 0.9139043349957898, 0.9287564584140652, 0.9231886473164995, 0.9577510401029073, 0.9598270305812323, 0.9251023676977712, 0.9301419237835185, 0.9336086335075481, 0.9413204406104378, 0.9607710502907817, 0.947016989095524, 0.8354187622095984, 0.8909611430072608, 0.8766731589839359, 0.9060239392747615, 0.8927674870888105, 0.9258844470829541, 0.9028117892643618, 0.8304734680295456, 0.926542208153992, 0.9091110487892721, 0.9363028760941372, 0.9341535163219516, 0.9194654675693346, 0.9202695630558568, 0.9003894181946497, 0.9161293483954294, 0.9155856828199577, 0.9354851871008822, 0.9232246201705361, 0.9623776152400827, 0.8579357515549004, 0.9109312889547844, 0.8839269145615802, 0.9421238821661402, 0.9702537715424093, 0.9416037390612908, 0.8985137241898925, 0.8948763238283256, 0.8741666932620324, 0.8967178520256398, 0.9339639752612463, 0.9134443577773346, 0.897485301000289, 0.958695689291396, 0.9537196473660992, 0.9649927862059, 0.8710657800051518, 0.860811402669521, 0.8949571451761134, 0.887825581970316, 0.9518182000819291, 0.9293822427284593, 0.9528554816697049, 0.9273745367119779, 0.8591487424998037, 0.8578822274034146, 0.9434694418592632, 0.8871092073996366, 0.9567835875705673, 0.8907012788925026, 0.9338902647873675, 0.9531463270309461, 0.8949060830380994, 0.9321083897103383, 0.932748160806189, 0.9238722443555989, 0.7978916283795592, 0.9439566936349701, 0.8437456890206944, 0.9566120374681534, 0.9733122491555172, 0.9261398308263622, 0.9097758015514905, 0.9032005055382473, 0.9662810321425133, 0.8498741568076634, 0.9166503630299639, 0.8753778568273755, 0.9090368327085419, 0.8237215779329754, 0.8367602972442837, 0.8721741151221769, 0.888779635962215, 0.9551149648261681, 0.9728978274408486, 0.8430214055253661, 0.9493050726839786, 0.930953065488105, 0.9559484278500465, 0.9170464036851523, 0.8657304465075482, 0.9491144976482359, 0.9540650211094173, 0.9452728100132577, 0.9518513324446348, 0.9041454331289588, 0.9357801992707636, 0.940223872040458, 0.8732206460836398, 0.9650150727457173, 0.9230720857980197, 0.9289275267425593, 0.9294275255072955, 0.957737320226292, 0.8950650477520412, 0.9279300669448161, 0.8971451079717936, 0.9047932925470414, 0.9580986862902798, 0.9444662882529302, 0.9615681570400316, 0.9403498674924704, 0.8785395203334456, 0.9741058120426895, 0.9418336738556226, 0.9282342641713075, 0.9125759141351852, 0.8792227426482391, 0.9580706074934492, 0.9524808362665531, 0.9482753770854392, 0.9201346579103853, 0.8593815501326609, 0.9461781759421773, 0.8803841036945375, 0.9764874203378251, 0.8927959758352028, 0.8988187969337894, 0.941206994054473, 0.852797217888191, 0.9251364635337274, 0.9759609593288193, 0.8706765772855567, 0.9247042741529741, 0.9432751423635918, 0.9638254829403106, 0.8610267230233968, 0.909047045851485, 0.851634523802838, 0.941961934228764, 0.9402308768499719, 0.8352099746130971, 0.9014050080755553, 0.9475380425196394, 0.8878040177107686, 0.870755142962802, 0.900251700304586, 0.951405884890365, 0.9109772249148921, 0.9507142271873668, 0.8350515084612848, 0.8926641194518927, 0.9537321593227248, 0.900528675057254, 0.9707512463285798, 0.9231387085963062, 0.8915166056806781, 0.9378654209079926, 0.9553131141024856, 0.8785189098884028, 0.9339919520866973, 0.9139963916973721, 0.9170725627231385, 0.9021046382052949, 0.8801196951039871, 0.9552499895911012, 0.9075880094567934, 0.8119689349938974, 0.9294705282488389, 0.9483168663087249, 0.9161136941444206, 0.8523930144280318, 0.9176921967722816, 0.9216988076150272, 0.9088787337921561, 0.8803978550875615, 0.9298507276224839, 0.9686117683720665, 0.9494270617194299, 0.940022044272269, 0.952224519406007, 0.8667497317134294, 0.8862321817878629, 0.9259289781806673, 0.9181372778598564, 0.9503072801688782, 0.9705695967876716, 0.9486831935486347, 0.9352180104103569, 0.95706117971217, 0.9504523716848462, 0.8564513221422543, 0.9013139454956686, 0.9095938660709603, 0.9259438810286202, 0.8937784174939057, 0.9364133036734972, 0.9018422596486283, 0.9406250770178106, 0.8591140565008906, 0.9218722209010477, 0.9406538037616355, 0.9674776118775137, 0.7820065644648467, 0.9477238179957215, 0.8913351051980852, 0.8869108928391803, 0.8955750992009557, 0.9520320200090755, 0.928969179726154, 0.8612754402292396, 0.9132454792855673, 0.9354094080875563, 0.8535366129894048, 0.9222369263895707, 0.9393266054373028, 0.8738037370683555, 0.8825081777841475, 0.9458376948760149, 0.9649630004751895, 0.8749079489348757, 0.9567432784271858, 0.9287865680798657, 0.9200754952776804, 0.9230108293369716, 0.8875001649580652, 0.9456189849515945, 0.8618442647817552, 0.8986716199762977, 0.9439520722185595, 0.913597153227694, 0.8868465890983542, 0.9316321311592142, 0.9573667464978034, 0.9501334317332474, 0.923393887985612, 0.9465249168827292, 0.8978912364277126, 0.9322447894969754, 0.9203157905140941, 0.8678439256732402, 0.823322455820238, 0.8089734738594991, 0.9154569625930838, 0.9316628376306447, 0.9353072870826282, 0.8913280038730421, 0.9169633450067144, 0.8594999008398032, 0.9461548217347935, 0.8770072275806098, 0.890954806564971, 0.9648181136329812, 0.8781535983403159, 0.9303200104573726, 0.8458449799649147, 0.949003691001461, 0.9044736845100884, 0.9452566193684652, 0.8657217925790321, 0.9798925781433855, 0.8104051059966461, 0.9050981724352533, 0.8600978306717137, 0.8673350398905397, 0.9421452128737, 0.8251526909330563, 0.9037091707789385, 0.8929887969238767, 0.9134384581200613, 0.9461358344915966, 0.9107546067278605, 0.8937916054963277, 0.872086984103801, 0.9081195558089721, 0.9284594239998119, 0.9448668258771944, 0.9438701575344555, 0.9131552996027826, 0.9056718151608041, 0.9189621252933086, 0.9230996877530108, 0.9244519313196979, 0.9177658034416236, 0.9357188193890961, 0.833913506925712, 0.9207845618075424, 0.9659910367729911, 0.917835411202989, 0.957656262833309, 0.8656340597558209, 0.9012939836192884, 0.8752607277869756, 0.9293985747748406, 0.8622194172492968, 0.9202421381562664, 0.9310731938505294, 0.8505544988800726, 0.9401812502854457, 0.9429263879512045, 0.9453547633565023, 0.9580286175772128, 0.8956174844810545, 0.8784987007940498, 0.974677533535272, 0.9387883079624406, 0.8505375140198109, 0.859672563415007, 0.8722354630642509, 0.9037598578294657, 0.8778521567679809, 0.8538303116362674, 0.9553413667796502, 0.9580038715062004, 0.8277114198047753, 0.8579307015917503, 0.9180070570897416, 0.8949406225019123, 0.9097262894983297, 0.8945761099155964, 0.950953565032519, 0.9138740293860137, 0.8765717683459925, 0.9233315282907111, 0.8548955688286449, 0.8994609639317515, 0.8921804875190686, 0.8942937116598441, 0.9159821560403832, 0.9145336053473458, 0.8750624204277068, 0.8993131627572007, 0.9749107557021582, 0.9173893326441378, 0.924666788990976, 0.959047865521085, 0.8989204788727764, 0.9604624239947134, 0.8484152426945338, 0.9477218162368429, 0.8296233364683465, 0.8684556316547926, 0.9397119192546802, 0.9225686032489755, 0.8921314327948318, 0.8905111809085544, 0.9101561418458575, 0.8952184368555469, 0.9226240573932643, 0.956470513033971, 0.9672026566259789, 0.7977648298296602, 0.834498983658776, 0.9581305024853393, 0.9422653091280118, 0.9493564630860246, 0.9290275684688776, 0.9328735338417843, 0.9175816749297179, 0.949648377481644, 0.9048835435965914, 0.9431682229162024, 0.9069703384145177, 0.9719125365365295, 0.8938079646330169, 0.9288775800973308, 0.9463465273015959, 0.9031149588359338, 0.9312243038265435, 0.9596536738856151, 0.9269340593699664, 0.8357878718743499, 0.9400974504806634, 0.8542707992101507, 0.9774594249245429, 0.9167954661155686, 0.8964704688635621, 0.857086815176632, 0.9055172299459668, 0.959166857190687, 0.9246413292279398, 0.8704826004923887, 0.8759977630103486, 0.9333239370623798, 0.886306529140694, 0.8485913935837688, 0.9232017392733902, 0.8566737047522248, 0.9107304538422484, 0.9588313079378391, 0.8866655780022548, 0.932743990447416, 0.9261234238917359, 0.934553901706199, 0.9659686581188082, 0.9405563485790362, 0.9502623205531056, 0.9589752463292351, 0.8896075494260591, 0.9029499971370333, 0.9438185929120493, 0.9665306727866523, 0.9716193226985903, 0.8607646575279368, 0.9347681974295105, 0.9127431582514708, 0.808194341200452, 0.9150243343405251, 0.8959002180460959, 0.8600923190104434, 0.8628256645508334, 0.8933889243570361, 0.8797394500576843, 0.9308076050699847, 0.9104954191205916, 0.8810680135950014, 0.9620503620789905, 0.9075866503811034, 0.9187223098699171, 0.803380656783895, 0.9092299980395799, 0.9368177600377713, 0.894219743115956, 0.8661146843258913, 0.846219862826569, 0.8913354169396275, 0.9112891391337248, 0.9758615990991917, 0.9028183222607766, 0.8649701063271976, 0.9560453393133297, 0.8949699943761711, 0.9675468194954475, 0.9359134677402897, 0.8762296672819272, 0.8864269473044972, 0.9146433922374422, 0.9675076774324195, 0.9709161829189766, 0.9038968359324523, 0.8898213243432531, 0.9286289682543714, 0.9503620730948585, 0.8761447185208489, 0.9370688999042034, 0.9335621672428699, 0.9389018630602006, 0.9712599740124555, 0.8151819889892551, 0.8678630302810595, 0.9624851007550694, 0.949467114378915, 0.9011394139555364, 0.8592028667986062, 0.9471761315544299, 0.884151563058775, 0.8905133817648179, 0.9522571929003856, 0.9538552767549887, 0.9726632064348503, 0.8788341099572612, 0.8588056634650372, 0.9136542889101327, 0.9239488101730788, 0.9753340875219226, 0.894710598137261, 0.9566415641497754, 0.9314137283965562, 0.8676884266845676, 0.9305767678504078, 0.9274461936472855, 0.9248337497980492, 0.9191339453764453, 0.8588640897144093, 0.920054162261736, 0.887748167973296, 0.9376910079008556, 0.9275962763284904, 0.8941556387272401, 0.8863745777101957, 0.9713282019341103, 0.9279932243170084, 0.798762402376114, 0.9124968237251364, 0.8558019319260086, 0.880875793400246, 0.9001202956730252, 0.9229077779855925, 0.954593740250143, 0.9660042405528104, 0.9224501439501216, 0.8818275254857437, 0.9259393309559938, 0.8700212446542244, 0.9155414303093331, 0.9104281775189303, 0.9005807435741446, 0.9109819062162134, 0.8959118800173125, 0.9244846092501002, 0.9031678315891477, 0.918635237147784, 0.8583153024376783, 0.9314414272233407, 0.8824151300654535, 0.9647880308525675, 0.9163160227584584, 0.8630214251132081, 0.956008554581133, 0.9328535082627182, 0.947138585394377, 0.8892131202148571, 0.890975941763505, 0.8768390237377701, 0.8949982638373329, 0.8924716773355819, 0.8727951026641505, 0.9504315431661123, 0.9259152273062062, 0.9341699400568493, 0.9343389010990708, 0.9211588838354605, 0.9214590694593263, 0.9270574358502695, 0.9076730136083175, 0.91061878661417, 0.928414908740734, 0.936905484885126, 0.8704945256936601, 0.90500856358048, 0.9323766670344498, 0.9378366294012465, 0.9475268479657473, 0.9261227574878783, 0.9400183406900617, 0.8950695628089785, 0.8489580365247688, 0.8941528552940695, 0.9543694602000203, 0.8938689420439445, 0.9050873298580605, 0.9002215672554075, 0.9138776063142338, 0.8889199045659055, 0.9482534982371287, 0.9106034526490407, 0.9480803712710022, 0.8939323748060171, 0.9411529882458117, 0.9648358283565265, 0.8582151234996083, 0.9382934032466459, 0.8821384788771383, 0.9265089637801222, 0.9298653914692863, 0.9617903189852484, 0.9509235765406974, 0.8983357696394253, 0.9788497288977156, 0.8692271970807222, 0.9304018863112089, 0.9353930051057329, 0.924816892297465, 0.8820574617527026, 0.9496693314624881, 0.8914584409603602, 0.8531368850711499, 0.8878565159024367, 0.936433301955846, 0.8591739739595191, 0.9706336093025851, 0.9008024476068207, 0.9074675461489204, 0.9398073341799125, 0.9399389662154101, 0.9009593165356873, 0.9638019282611985, 0.8954066154500528, 0.9164216730730709, 0.9597882713530174, 0.9643025536205024, 0.8917158216825755, 0.887054447773818, 0.9091940862629245, 0.9096681954148778, 0.9718399024316002, 0.9497585097810226, 0.9382307948070082, 0.8566214978512413, 0.86390383504504, 0.9418286293559145, 0.8924292907267632, 0.8940103080226778, 0.9440809345035099, 0.9438980375317476, 0.9374761112582899, 0.8963400297044953, 0.9116323253132026, 0.9512385368285956, 0.9545548323549793, 0.9624504063068562, 0.8444886938484354, 0.8919746607382302, 0.8983041635746589, 0.8082621063355914, 0.899168600961912, 0.8981995691989605, 0.8600180490938942, 0.9602226611460991, 0.9429966233457998, 0.9376380265447848, 0.9577759431164288, 0.9105437565742472, 0.860082886613438, 0.863665160080176, 0.8427735470827297, 0.8219531173815928, 0.9340617943327876, 0.9684359865374581, 0.9584691225148787, 0.9026454728662836, 0.9331778472574823, 0.8851012264172663, 0.9352423576413499, 0.9568624075823162, 0.878088870899703, 0.8807195393669387, 0.9070590787149396, 0.9301646285981348, 0.9365266210073391, 0.9573741824662358, 0.9617623410660633, 0.879427550378184, 0.883451518260193, 0.9398762758574364, 0.9348026192635118, 0.8612197055888565, 0.9511427190140221, 0.9572393609340373, 0.9123840421323759, 0.921177208017885, 0.8857228092222169, 0.9555511513002293, 0.9118040916948994, 0.9286851148733637, 0.9525928596304227, 0.8954124169439116, 0.8502657505372608, 0.8735168858448543, 0.8821374931779992, 0.9585330970012518, 0.9351118078989518, 0.8990419795883444, 0.9473728039795623, 0.9419018930238063, 0.942573388272218, 0.9653380683129691, 0.9386758333866045, 0.9194691795742544, 0.8776657757691121, 0.9520220552946654, 0.9329833610642093, 0.8498228462338624, 0.8913756363996741, 0.968038873009747, 0.8720235284028974, 0.8680848175770283, 0.9055162209298935, 0.8869904336854383, 0.9565154973657021, 0.8383708990091814, 0.9624488441029466, 0.9277487711118971, 0.9601722629127184, 0.942998800690258, 0.9033509858859936, 0.8632800684427584, 0.9060824621464763, 0.940558046672061, 0.9422722381153468, 0.8705620641602184, 0.9392778097362303, 0.9246485360566343, 0.9262174541152453, 0.9081726764020779, 0.8951763574808778, 0.9509118609811863, 0.9350403433912435, 0.9443985883013896, 0.9546564130879714, 0.8586552489244752, 0.9182467111086237, 0.8842612454622171, 0.9113725472129892, 0.89767498434938, 0.9669942575451955, 0.8825065561649601, 0.9308135167482886, 0.8840539113748602, 0.9137169083591365, 0.9077132623457801, 0.9479734465470496, 0.802760378199765, 0.9610971923041167, 0.9826274692991459, 0.9572966289786642, 0.8915006686791651, 0.88421200825288, 0.94239767089168, 0.8947186884045989, 0.9142524830375218, 0.9369318301994121, 0.9339102631774571, 0.8571821141895193, 0.905854489497903, 0.9015463227950228, 0.8853367990649819, 0.8919996002505013, 0.9178637413389391, 0.9533457319010922, 0.889186765788053, 0.9473626658774614, 0.955014747625335, 0.9181805221056918, 0.8235886276464719, 0.9110582159809287, 0.8590928745399264, 0.9474632355194541, 0.885577534615112, 0.9447505959908905, 0.9613127473446563, 0.9420687816059132, 0.8590628036916541, 0.913937957244641, 0.9819958238278721, 0.938743131046754, 0.9265128549996275, 0.9130431115424326, 0.9519872531269675, 0.8513239663685045, 0.8599972939186028, 0.9698092240544249, 0.883003547528199, 0.9392127034982867, 0.9205013874591579, 0.8498598326638452, 0.9693284134069479, 0.9556671231606375, 0.9372320936740464, 0.8412921234166905, 0.8392269374116186, 0.9713576898589025, 0.9194188980790697, 0.9313921476169348, 0.902432081873197, 0.8859791193583924, 0.8796930630416723, 0.9104871485935502, 0.9417518013297916, 0.9068777867196096, 0.9564687966685204, 0.9454558006337922, 0.8570191233452822, 0.9089122357060557, 0.8636753411197207, 0.9426839703509753, 0.8985987083775697, 0.9541634857695906, 0.9721037863705076, 0.8474144521378681, 0.9552766799912679, 0.8829260979200991, 0.9427677546037544, 0.8867084195068335, 0.9114653019255898, 0.9502221544136216, 0.8248381623683889, 0.9616149989264733, 0.9283969272797021, 0.9163300505539324, 0.9363072564785919, 0.9174290636829795, 0.9235891071501358, 0.8872221341736999, 0.9347076730895278, 0.9176240849904633, 0.9506250869267652, 0.8811751112576134, 0.8817584357632045, 0.9522102853749023, 0.9147375629792771, 0.9065968494362355, 0.9278140779127444, 0.9048965981651855, 0.9138547776482255, 0.9737096513168692, 0.9213299515396621, 0.9669758149375439, 0.886071583388563, 0.9646269056233026, 0.9680530144626223, 0.8919882952141305, 0.955630540154881, 0.8970740881650142, 0.8937627561924416, 0.9224205409447896, 0.9705810857622413, 0.9475658535553334, 0.9293138623212158, 0.9400812266251477, 0.8701056738303378, 0.9579336353647141, 0.915745754907844, 0.9467411646162862, 0.9018610245119345, 0.9116878998751723, 0.969963217600097, 0.8816989421386172, 0.8639337604278929, 0.8810091802687786, 0.9259021032721736, 0.9387534989040494, 0.8468583979583438, 0.9539459826328581, 0.9179140289005064, 0.8931334044570756, 0.9065906791062561, 0.93038693131804, 0.9624904877179756, 0.900377722502586, 0.9600951839048202, 0.9271527037397446, 0.8960749982904204, 0.9268129999417265, 0.894412414534101, 0.9216495019070614, 0.8769326756531831, 0.9673949705748109, 0.9335922180405325, 0.9447479800484999, 0.8581777963942459, 0.9283071460748231, 0.9504243835614423, 0.8963769416905948, 0.9015705835212483, 0.8612813584626502, 0.9724310449942235, 0.8463716043880067, 0.9487636669740962, 0.8357844271851353, 0.9282182751781671, 0.8246057613884744, 0.9189850059342065, 0.9417618511535875, 0.9298759826812044, 0.9137420653030743, 0.898912101112008, 0.8013632153024007, 0.8809271965476178, 0.8786226051313689, 0.9621353770892946, 0.9755351156015282, 0.9327652286366511, 0.9047151568233697, 0.8142670470282602, 0.961187163426378, 0.9066609522701266, 0.8824002829011901, 0.8943742380648535, 0.8796524820607833, 0.9117023510262521, 0.8982059231331101, 0.9653379855516728, 0.9162076090965887, 0.8720878216672733, 0.916159769114886, 0.8932662459252978, 0.8775999298364074, 0.9418519066585432, 0.8940409259742997, 0.8976063149547938, 0.9625597474869905, 0.8986309514062749, 0.8601261845722754, 0.9616316708251601, 0.9106422058186956, 0.9285005443748309, 0.9624791124254146, 0.8925267991731076, 0.9115875922388701, 0.9620041528723908, 0.9097768279428478, 0.7662138923039801, 0.9351573879351461, 0.8644827316936661, 0.8589183619878901, 0.8570219372218049, 0.9334391279808069, 0.9690913141528491, 0.9784046492368665, 0.936541942036486, 0.934812362186588, 0.9350061124581707, 0.9457317517459023, 0.9191711560560027, 0.8638566747038873, 0.9614973196928553, 0.9584026060496509, 0.9440827391193733, 0.9500923452465895, 0.9022562583036596, 0.912665924410548, 0.9325834566772848, 0.8497014312991193, 0.9309052378508689, 0.942807865184617, 0.8640801114589528, 0.9368876090450706, 0.9021871745816384, 0.866163258378782, 0.9231228287077662, 0.9330651806642694, 0.8775537078594782, 0.9274938403910266, 0.9457232155660726, 0.9054548347259683, 0.9745336256508551, 0.8975749601179311, 0.9368181512303086, 0.959956659394013, 0.8617495673350362, 0.9158314255552323, 0.84581324155357, 0.891051814730495, 0.9398431037660679, 0.8784732579469784, 0.8867094589208127, 0.9485206104687924, 0.9203185256544237, 0.9150752380437261, 0.8842511631472405, 0.9172774527650629, 0.9627081099478436, 0.8924910866538844, 0.8759602048276642, 0.8994069387635802, 0.9515769165516956, 0.9602360301364607, 0.9701870139383542, 0.918403695160499, 0.900865482218443, 0.908924216179609, 0.8875686902750425, 0.9376693089401649, 0.8588072041128407, 0.9490806385777839, 0.9123088896673877, 0.9085848244308561, 0.9268811109345763, 0.9309650440867384, 0.961033673686742, 0.8786962976120445, 0.9546510917940401, 0.971800209266644, 0.9362733237163943, 0.8854195697962549, 0.8043562021716901, 0.9386533974055787, 0.8689164448419413, 0.9148647927909377, 0.8883631802012038, 0.8574326472546949, 0.9663049347054932, 0.872772419550017, 0.9404947555297616, 0.9186245364110706, 0.9425750490040687, 0.9049476088808784, 0.8540671971988316, 0.9378295551351594, 0.8963247838367349, 0.9157237611452858, 0.8882594785954585, 0.9417677613655224, 0.962024730926714, 0.9109708759819688, 0.9592735010228709, 0.9510640122204637, 0.8473162818223554, 0.877661468380874, 0.9335691897288083, 0.9114935645987323, 0.884251022007584, 0.9426434775673223, 0.906232711431737, 0.9297298478975544, 0.9754013292709125, 0.9360655590129952, 0.948717901179109, 0.9450079155809159, 0.9793370113645752, 0.940306600815069, 0.9445213380086002, 0.9483201160608719, 0.8425811887106491, 0.834518711012586, 0.9385933845073836, 0.9385479286301479, 0.9033474393756485, 0.9272756176807884, 0.9542087978114688, 0.8333455992689885, 0.9283848371625837, 0.8619680494682513, 0.9577186116148597, 0.8806658070143504, 0.9484207356129315, 0.9496411380897539, 0.8810940090928124, 0.7973483954525478, 0.8774258434360583, 0.9592128079998772, 0.9439844862723926, 0.966943773857085, 0.8794975928643916, 0.9170340694094632, 0.857357866758345, 0.9571811273712281, 0.9542414291553377, 0.8929359270721093, 0.8423378664688532, 0.8886367622891342, 0.9519019600475149, 0.8289106623774214, 0.9105903179143069, 0.9470317729403985, 0.8821503770037766, 0.9030121979850895, 0.9379878419028793, 0.8885875208688361, 0.9478907342362031, 0.8916917900488595, 0.9156219586885261, 0.9109653515049333, 0.8505483612774942, 0.8278858056156047, 0.94123448349438, 0.7974412955131607, 0.9655352782438682, 0.9209729434679622, 0.9678299160328995, 0.9268404123589732, 0.873340731735461, 0.8666462064392623, 0.9082790816713118, 0.8293245344948744, 0.8498702798739626, 0.8870856101046958, 0.7666312740963692, 0.9214996759786485, 0.8907499021949743, 0.8902975382674634, 0.8979814070925691, 0.9450115676484727, 0.957549776991547, 0.9558099726527057, 0.9208609097551255, 0.9165033318979433, 0.953547163116935, 0.8939996629419513, 0.9507963046609031, 0.9558031044059045, 0.9634698512013115, 0.9815990685982723, 0.9171666783702734, 0.8705940549390818, 0.9170566058235055, 0.8468351096434368, 0.8204606061232906, 0.8970855966661302, 0.9250921446609256, 0.9064406806249596, 0.971923245545648, 0.8663834688520784, 0.9097499430523452, 0.9549767511947558, 0.8994128336806879, 0.9677689218138334, 0.9171272725591686, 0.8726549424921943, 0.9326203611717195, 0.951002233378188, 0.8619815687416134, 0.851160562272902, 0.9085107381022101, 0.9305010689120222, 0.9224612411952959, 0.9552738359940197, 0.8889958106350415, 0.8533932219942872, 0.942819242460101, 0.9415439079694854, 0.9605194634667565, 0.9178235180078496, 0.9192923898133373, 0.8920520869539434, 0.9550844550322786, 0.9369504896416011, 0.8413426405267566, 0.9254509587098383, 0.9507818908194892, 0.9177423468256278, 0.944526922213853, 0.8973566684092386, 0.9107722504610185, 0.9276514795998128, 0.9023785268945554, 0.9188140708454715, 0.8505071403801036, 0.9151082669811398, 0.8841820785819392, 0.9548200607808196, 0.9175161982561603, 0.9330231102705716, 0.9192138230519152, 0.943101140491637, 0.8534669425755907, 0.9111597109209321, 0.9247990781979268, 0.9525184217972624, 0.9238797273152025, 0.9402947384055005, 0.9241178991524448, 0.9338505026211616, 0.9501581242965114, 0.9759969623246103, 0.9450275852895554, 0.9397090324978812, 0.9220252173670284, 0.9467030012561594, 0.9478100056176422, 0.8680105637015919, 0.8861684802070154, 0.9639474165944647, 0.9576500096731433, 0.8521393699489783, 0.9358275555150963, 0.954303568140812, 0.9645044207901394, 0.8543344714855576, 0.9554829107472631, 0.9778768004947594, 0.9513663017847795, 0.9564058061326832, 0.8167735334663964, 0.9057804160429889, 0.9794061952426216, 0.9564120054152583, 0.9089117857856785, 0.9290254208208735, 0.9378910387798596, 0.9478688407409239, 0.8433276352297998, 0.8808638177548864, 0.9722034222770363, 0.9608064276664434, 0.9196037092720113, 0.9209513253465194, 0.9492548392770733, 0.891985466945598, 0.919921707794536, 0.9687167428904538, 0.9358248359677449, 0.9527032240658581, 0.9078947215115248, 0.9007316729643828, 0.9202108203947355, 0.9715957069847683, 0.886381294815614, 0.950108850753323, 0.9713748225021933, 0.9444836730057287, 0.8786371476542327, 0.5910372743835011, 0.8842763826168532, 0.8993049337723831, 0.9525479542220818, 0.8993747683851125, 0.7968910076575813, 0.9144870747133795, 0.9503277253077538, 0.9061821786545985, 0.9525034433781934, 0.9324431209830613, 0.9251020545017596, 0.9734375993023594, 0.8731939737479036, 0.92599147146795, 0.8530353384817837, 0.945956648731989, 0.840492480443952, 0.9266433175342299, 0.9599805629656312, 0.9304394962771768, 0.9301371410917569, 0.8737441323541616, 0.8268451619301527, 0.8933894816215443, 0.9149120943831215, 0.9434983994515506, 0.910791596485411, 0.815449434013819, 0.8517280454883238, 0.9135320260879688, 0.8614387218511248, 0.9269132273896172, 0.9066279144201131, 0.9439560032278037, 0.9381021367648266, 0.8921278408864071, 0.9033902420395011, 0.9592496147134881, 0.8447987030219263, 0.896887558820322, 0.8969167106735072, 0.8847244231193017, 0.9306589240745926, 0.8690142833163056, 0.8399237004331236, 0.8912080235636087, 0.9003503072781588, 0.9058495826202184, 0.886816280008489, 0.8988007470452575, 0.932197873852251, 0.9085927722179538, 0.8601728540792961, 0.8974654669505258, 0.93149903462845, 0.9446938644615648, 0.9044521595991515, 0.9423796161538776, 0.8494198257680542, 0.9082637660032502, 0.844498043594379, 0.9211016116224334, 0.945027348948354, 0.9295217156074229, 0.9538504027515079, 0.9490013911328135, 0.9270337527572019, 0.9257653925161713, 0.8754934863982787, 0.8054090134453917, 0.8887277335966107, 0.9200277444853642, 0.9107738103074297, 0.9106583571053573, 0.91434260420607, 0.8872077643156514, 0.873985745292714, 0.9604528112400319, 0.9234707173193522, 0.9145459921607993, 0.9151759039747906, 0.9466561776696361, 0.8785091697215834, 0.9022661046420815, 0.9508969852069549, 0.8705540762057138, 0.931231744996733, 0.8923240023149023, 0.9541301629141906, 0.9328419323853658, 0.9670745276930117, 0.9300345800452572, 0.9300315938125614, 0.920112272476822, 0.9730571361928102, 0.9713702504508905, 0.9398019488866731, 0.9116242557942613, 0.9205882405607376, 0.9057118962850415, 0.927899746181925, 0.8162152111403271, 0.8647153030557999, 0.9389213154172082, 0.9155853051726773, 0.9343016325419682, 0.8671451604175064, 0.9318475046445697, 0.938839011887389, 0.9581564528643876, 0.9386872502462689, 0.9288157325568416, 0.9311832277157697, 0.9689049978109191, 0.9371612469801036, 0.9242629603207851, 0.9275273489518855, 0.931645083814129, 0.9422757119324021, 0.8354020391091503, 0.8950159910490091, 0.9546033056480498, 0.902916314650585, 0.9565890839330418, 0.9481760186931871, 0.9547996219887263, 0.9090256244944162, 0.9040959759175391, 0.8834508127684664, 0.9342736635435563, 0.9445285723935928, 0.9664211223961597, 0.9532735488458339, 0.7641529179576438, 0.9115413174124651, 0.9494432273228883, 0.9169744141147687, 0.9040821496930931, 0.9510334994409633, 0.9118057444546088, 0.9220905683249205, 0.90938045625172, 0.930285222207716, 0.9078652340597793, 0.9608145248290487, 0.9587118805480324, 0.836610994613996, 0.9249982991718217, 0.848753608680079, 0.8876152668502962, 0.9425025591518634, 0.9649913428093599, 0.9682920250575586, 0.9552171347668182, 0.9151275103913011, 0.9382267825195791, 0.91205336238478, 0.8491705166374257, 0.9223736992811502, 0.9082782431575895, 0.9051420398497665, 0.9536677770936884, 0.9132505253221928, 0.9714712973660389, 0.9667187660446751, 0.9280294564744118, 0.9464124017089599, 0.9180403067562454, 0.9560179030606567, 0.9386511519533844, 0.8736610816919697, 0.9599851121568668, 0.930295755643368, 0.8943141273259286, 0.8942035922855596, 0.9532003751212147, 0.9478806445947973, 0.8815859204020255, 0.9464105615252953, 0.9470994855882557, 0.9284832275468204, 0.8887460342257878, 0.9723872641813365, 0.9566364360931674, 0.9325300777512711, 0.8309835208020188, 0.9294090090120719, 0.91002947081484, 0.9208982109170571, 0.9314375031157085, 0.8984044544717563, 0.9072375211142488, 0.8868206699297324, 0.9446568786689686, 0.8465050929178107, 0.8905185562311806, 0.92971617866823, 0.9493856503522033, 0.9198706962982552, 0.8422401711244509, 0.9270272913958983, 0.9250110922394819, 0.9637735141597884, 0.9155363512310549, 0.9170734122514939, 0.8599841938818714, 0.8007804823663494, 0.8482927087295202, 0.972229572215785, 0.944936389947798, 0.965740044293574, 0.9772765395981989, 0.9441298886637719, 0.8590962712551817, 0.9087646598579175, 0.8899533462557732, 0.8637644523680161, 0.9203746214223494, 0.924500820624456, 0.9729897666636285, 0.9657052380099634, 0.8804389753577025, 0.9240128845303595, 0.9208853746399162, 0.9665078505885768, 0.9197051067399042, 0.949886642888, 0.9212702393218704, 0.9561580600767906, 0.882880408900794, 0.8661041275895198, 0.9237685755249316, 0.9689158048089059, 0.9529608185785975, 0.9135973566205444, 0.9612897068436265, 0.9434856025117788, 0.9162462828892908, 0.8818276875713025, 0.8989946523181928, 0.9457928380755176, 0.9196162929586025, 0.9683414390899038, 0.9377050595924018, 0.966480774720431, 0.9463301150314185, 0.9307845244124133, 0.9643080110875496, 0.9141938544427493, 0.9591579398965101, 0.9275433596702248, 0.8775073027070067, 0.9521364997178695, 0.9268810112835266, 0.8931258164664365, 0.8982945752418977, 0.8888971093461633, 0.7551270810582951, 0.8622884393566291, 0.9149038177804576, 0.8299158075357688, 0.9706625899147452, 0.9397075031887121, 0.9308150054140488, 0.9053068130535449, 0.9602628919339945, 0.7990496406782206, 0.9083669134919234, 0.9532506174095013, 0.9328140273668032, 0.91407282097706, 0.8820990238283344, 0.9385615306009505, 0.8816213996822146, 0.9325193836750777, 0.9278158250045208, 0.8946684584216442, 0.9065373886455476, 0.8623653286743296, 0.9162741413361539, 0.9201104010841671, 0.9423136367710475, 0.9662062261333653, 0.8943879197029141, 0.903788865027194, 0.9214085991817094, 0.9626799041786798, 0.9146157402155426, 0.9212154652069133, 0.9515126575435178, 0.9523965170011165, 0.961020702912932, 0.8889059825325136, 0.951752679945382, 0.9202841238563677, 0.9044023682476219, 0.878019737038163, 0.9665870156052379, 0.8383395849191095, 0.8724784684514602, 0.8878631829440911, 0.9669000744090288, 0.8699869648061047, 0.9490495545610322, 0.8615915087866645, 0.9266944995111812, 0.9253215730973195, 0.8612185929998856, 0.9127453996867054, 0.9055855788869773, 0.9137640234810873, 0.930276165132337, 0.8477223911122451, 0.9507557775350458, 0.9044300605545808, 0.7771282813342473, 0.9030257843705529, 0.9130612623194888, 0.9403812453702722, 0.8366192345107917, 0.906774401804955, 0.9069339192502676, 0.8146010240435081, 0.8963430523125298, 0.9314892860292612, 0.8381350889650548, 0.8873005365164566, 0.9092122252971355, 0.9672651159173117, 0.8031415900548777, 0.9619961278104803, 0.9737601356730353, 0.8843050557670452, 0.9099258067666256, 0.8924806331009035, 0.9343229739709823, 0.9287353269030898, 0.9407201301038571, 0.9138276426389603, 0.8393014778113768, 0.880250064045968, 0.9452182427362961, 0.8954828094061353, 0.9108642552693602, 0.8761269269297073, 0.9545037064026543, 0.9193935555576535, 0.8648298672037368, 0.9180778273687833, 0.8875344580223581, 0.9025665027121943, 0.8297526037447837, 0.9423989008385514, 0.9624063035638795, 0.9525008994801416, 0.8948533892518191, 0.893971768483889, 0.9411616836409518, 0.8724208616450504, 0.9239881262988544, 0.962970228255432, 0.9344512451377478, 0.9327487878226337, 0.9318147413108324, 0.9000738090812254, 0.9024748692808933, 0.9381278401752119, 0.896216338017024, 0.9385560813146486, 0.9464190420584174, 0.9306129169336446, 0.9622253083443463, 0.9206342664273062, 0.9259628697580047, 0.9513587379766607, 0.9653900572892746, 0.8803829206672109, 0.8911238687142088, 0.929738767258016, 0.9140142276484897, 0.9367170473917497, 0.91188740878792, 0.8692138970397887, 0.9572736726150031, 0.9220567759496756, 0.9452812483806928, 0.9153497795708123, 0.8931235987074745, 0.9212667034100928, 0.9027310369990298, 0.9157335745833215, 0.9289732293282755, 0.9735267790948477, 0.9269789606524255, 0.9276440754710694, 0.9601226252135506, 0.9017383145660338, 0.9260879105325667, 0.8906203888814087, 0.859750719657836, 0.9192990208681665, 0.904027619544357, 0.90719235652956, 0.946103349813643, 0.9621122428228528, 0.8987590050065177, 0.9320118038899554, 0.8921659614028896, 0.9490380532169925, 0.9218066627138763, 0.9315879266989412, 0.9740514138771676, 0.8856966059734765, 0.9188138136206092, 0.9531559519566133, 0.9533732376946632, 0.8899574526470713, 0.9633511621359749, 0.8379119708921619, 0.9663900322464656, 0.9600857970390662, 0.9518560175168157, 0.8795725415592835, 0.8431103906640167, 0.8794571185712297, 0.8793923165547453, 0.9324036259964805, 0.943122701142871, 0.9276210750911418, 0.8876581163487631, 0.9466888227121323, 0.9593075847191664, 0.9351473361523468, 0.969286404031963, 0.9016935774362476, 0.9502520720275004, 0.9122007211520788, 0.9563680695374775, 0.95561457416689, 0.9675280473881003, 0.9481781598524085, 0.9079253485798251, 0.9211400324360555, 0.8989740262087069, 0.9185442486139469, 0.9550438039821628, 0.9185881009181225, 0.8510781742964226, 0.9266977234106679, 0.9163981957754854, 0.889376088203776, 0.8989593665473592, 0.9158532865816587, 0.951016714080863, 0.9178748820773721, 0.9514680756230138, 0.9785183865539423, 0.8739327911323499, 0.9248081988854666, 0.9405003699734477, 0.9697289310665099, 0.9542807976410772, 0.8721891893154317, 0.9273791310025288, 0.9709632076868273, 0.8947593590775891, 0.8419658764158737, 0.8943740661257921, 0.845651942095537, 0.9289636579823815, 0.9554375553532117, 0.8909325087768549, 0.9184143840838909, 0.9075495050033576, 0.8941777276423306, 0.7785649473073544, 0.9041631790348367, 0.9548476136566455, 0.9337603329046934, 0.932295479845015, 0.8795133199707099, 0.8679471072697194, 0.9102340787500758, 0.8745540986724922, 0.9011897578097844, 0.9231075810679997, 0.9056905629812828, 0.9204248697577604, 0.9540525775083182, 0.9363837957320709, 0.8662209086052284, 0.9253906526585168, 0.9572600567840331, 0.8868253584621073, 0.9009303192205802, 0.8815140937915846, 0.9484790433117192, 0.86861363459544, 0.9591654417562611, 0.8790430923370081, 0.8928839253651295, 0.8999150965149092, 0.8770221108444876, 0.9128500678388742, 0.9532367391593242, 0.9392544562187115, 0.9503723888126492, 0.7826124618515918, 0.9544259841749826, 0.9216179924769939, 0.9632149014519192, 0.9407495621330619, 0.9389024483004808, 0.8735877345587144, 0.8899068742825317, 0.8968667046446027, 0.8874989380095273, 0.6495066311820878, 0.8943397464918742, 0.9430078237922548, 0.9622763189017651, 0.8325097997278084, 0.9341816889048928, 0.9116839957376733, 0.8701837913459718, 0.8788892682737722, 0.8900447740630448, 0.87044423929291, 0.9677848234715294, 0.8881908114295972, 0.8488953605639376, 0.9404551217214451, 0.9053891324910771, 0.8560627404461142, 0.9490377786012594, 0.9659157832213239, 0.8471508738374647, 0.9129456213866275, 0.9257496192563807, 0.9717914474579816, 0.9209966039623876, 0.9400470498583507, 0.9471539548356936, 0.945354996073419, 0.9255351872417749, 0.9256003473809156, 0.9061204381554193, 0.8972166471764065, 0.8851432566155844, 0.9332247131812255, 0.9760750040751854, 0.907452655058719, 0.9016032538280065, 0.9457972255871194, 0.9063759682444746, 0.9289473972374698, 0.8918477660693056, 0.9443172777272968, 0.9156218554080715, 0.8978704440996667, 0.9351248418746252, 0.8723907480561051, 0.8964921818205742, 0.8938504897553812, 0.8890318790467835, 0.9617445848940622, 0.9213061091755204, 0.8952602220823512, 0.9489895429517554, 0.9074402848039382, 0.920854799662413, 0.9805306097536697, 0.9184605015549507, 0.978086903433617, 0.8879662705164546, 0.9461758880666227, 0.8996404485650171, 0.8785745223541346, 0.9220524142599722, 0.9531692920284581, 0.9011057058126561, 0.9132936874709976, 0.9430150400481528, 0.9371247090757742, 0.8466348321143725, 0.9224773032990887, 0.9530152635250897, 0.8940167235207682, 0.9491801406877977, 0.9038255653397151, 0.9515731450433158, 0.8643751890383669, 0.9764982579623984, 0.8854747188962868, 0.9776636367246188, 0.9310025092618464, 0.8485823741156737, 0.8810636809168424, 0.8982273746219583, 0.929748545901298, 0.9365592881436379, 0.8482243600601344, 0.8831506841587733, 0.9391242175028558, 0.9414962515988597, 0.8984050275684073, 0.898900485332291, 0.9446802882746883, 0.9109108972495173, 0.9591684491209226, 0.9122050500994238, 0.9252181688541261, 0.9271892430691265, 0.9532429495592867, 0.8959387146046172, 0.9064852273006094, 0.9410785104875266, 0.9165535447278383, 0.9577663697588177, 0.9653664009635928, 0.9107542011273382, 0.8516301209596049, 0.8944862300383976, 0.9021832222312121, 0.8550360559597026, 0.9712487378485029, 0.9306350489531692, 0.9305445423762884, 0.8745543667478357, 0.9421947870509044, 0.9426473170271606, 0.8813176958906127, 0.9434562189631874, 0.9341046460117273, 0.9655560699770438, 0.963143340606446, 0.9210539753963262, 0.8547292301676181, 0.8701292268251628, 0.9633581732402439, 0.9713425150523142, 0.906290313295513, 0.9602373066173793, 0.9310005206686668, 0.9142286725429346, 0.9327850178034801, 0.912402019071297, 0.959216886901409, 0.9420376886833612, 0.8941784848865924, 0.8655991147221429, 0.9701661362924758, 0.9140042233954653, 0.9411806239820801, 0.9477901414079386, 0.9294891732490475, 0.9333410230150058, 0.8984352785839484, 0.8430758032225822, 0.9217910353412955, 0.9648670787074698, 0.951658555199021, 0.9170180222521411, 0.9002398076012011, 0.7877280616919278, 0.9392865326592776, 0.914630854859639, 0.9270353591037552, 0.9392429862286145, 0.9464579846483134, 0.9386981570886779, 0.951440990473904, 0.9689922640192934, 0.8488303297345495, 0.8936682043993132, 0.818617821178961, 0.9314624406905866, 0.9664467270326749, 0.8685563633248207, 0.8698737476048204, 0.8837747934152456, 0.9487304801226699, 0.9676758271078877, 0.8904024910316602, 0.9089261134245035, 0.9789548247510483, 0.9078278267639207, 0.9349293990552436, 0.8781199729536289, 0.9562036624739823, 0.9614686207141723, 0.9673781493377236, 0.9383784019681045, 0.9114019919283298, 0.8964782079626274, 0.9382098950597725, 0.9176740554522015, 0.9184668126184523, 0.9558951500392552, 0.9032540680743959, 0.932603025794769, 0.863077113894971, 0.8675410640855501, 0.8755940703705544, 0.9082983842068197, 0.9650532467701336, 0.8922902389316031, 0.967746452705844, 0.9159266181766869, 0.8986741012688915, 0.9566638773638073, 0.9612590064526456, 0.8949300770783783, 0.9464032484304113, 0.9497412864396401, 0.9487311416841053, 0.9001342950723306, 0.8498542034014371, 0.9744029910385821, 0.9370206082377532, 0.935018149806039, 0.914603493138298, 0.8768195090601907, 0.9557245700795354, 0.9008797906630989, 0.9508841477283265, 0.9780489933038516, 0.8457643254784758, 0.8209664233219875, 0.9427483230558327, 0.9259410541134986, 0.8595415730211068, 0.9427172376415454, 0.9606810540393932, 0.8801131228777045, 0.8847356766411135, 0.9356071186990398, 0.9810032911883472, 0.8520282922918649, 0.8873183644478311, 0.9616013114510522, 0.9749724361970641, 0.9544634048748404, 0.9457046684609163, 0.9328632603273237, 0.9362818486172423, 0.9354940333220207, 0.8929173124634452, 0.8302225137341059, 0.9525751952683624, 0.9747951800123008, 0.9234634829057977, 0.8601784370183517, 0.8662370991089209, 0.8828099005776958, 0.8809603600153351, 0.9076011167055368, 0.8442907353396023, 0.8580886801133567, 0.9574841839547557, 0.9212365027391497, 0.9220138430746648, 0.894809834724689, 0.9266690635937281, 0.9303471056535675, 0.8527060823463937, 0.9376225492778082, 0.9562685771935708, 0.871800792933696, 0.932494857673088, 0.9195191620402913, 0.9176792256905736, 0.880592101789086, 0.9159529383141871, 0.9499322605001153, 0.8898503957179613, 0.8921583104052102, 0.9295036839860988, 0.9482136412692472, 0.9507224330615383, 0.9223524455659218, 0.9158099306327201, 0.8780022715385281, 0.9460141261133717, 0.8763448181150737, 0.9497999195893554, 0.8921439479638751, 0.9737178037381466, 0.9479654554261259, 0.8879107995293729, 0.9471460639755075, 0.9032405946815143, 0.9318105074243632, 0.8871015780420096, 0.9415052701280001, 0.891742549036127, 0.8770435208465205, 0.9494108666247031, 0.9182633872998459, 0.9636062331964519, 0.9494760707287142, 0.9225077718829207, 0.9084065894914823, 0.9640239089616446, 0.8888303859509153, 0.9149018826157724, 0.8699497902318705, 0.7625026005936939, 0.9159434026267976, 0.8653127620356287, 0.8200869729956757, 0.8660877444315112, 0.9630121716010895, 0.9221210217696525, 0.8814740711831959, 0.879626986950178, 0.9753285537351706, 0.911650545448438, 0.9443018747244909, 0.963281289562768, 0.9504143781933213, 0.9082726038237678, 0.9594847838171623, 0.9369653382083889, 0.8874122428802689, 0.9339118541461298, 0.9201916418479921, 0.9332936765807838, 0.9191376080152175, 0.9260199273874056, 0.9444496241737796, 0.9447643835090519, 0.9440407534907678, 0.9177845644324851, 0.9566179187016768, 0.9034683983615642, 0.8983043267568764, 0.8586572626239934, 0.9304116553848354, 0.9392276371836985, 0.9179127183402924, 0.9208789642626639, 0.9149589692956961, 0.9262495793376381, 0.9165803254128259, 0.8984680927853113, 0.8811823787569002, 0.8338447136241893, 0.8857584336313127, 0.9208799003113135, 0.9632029551308012, 0.9637536065861919, 0.9213873488420056, 0.9108928432293009, 0.914627588980118, 0.9378914465664642, 0.9101130428982956, 0.8809870742704348, 0.8443046213785665, 0.9348783138660881, 0.9535729025251177, 0.8272360859856455, 0.8758406518558264, 0.8976181265957701, 0.888341660180042, 0.926306146618068, 0.9262512415928414, 0.9346245368744437, 0.9022463979958886, 0.9605582980488858, 0.9036249989409377, 0.9061821031746925, 0.9425177304666511, 0.8811808921385695, 0.978375360525938, 0.8796260768577702, 0.950531516238283, 0.9657883426284097, 0.8410651302823988, 0.8890548891941159, 0.8594547954362668, 0.8621972522713223, 0.8883440805332684, 0.9488288039034621, 0.863232700997528, 0.9344180031617704, 0.9004820936988769, 0.9599372323800441, 0.9341468760113097, 0.8709887881784572, 0.9575390662801805, 0.9208618189136688, 0.871805669026019, 0.8666994692985838, 0.8137964361763952, 0.9428678264034778, 0.9787553411861087, 0.9528747172835227, 0.9037098593189962, 0.8898289909533663, 0.9016761931256925, 0.8896209065582444, 0.9342473248492866, 0.8275845164676515, 0.9203930798163132, 0.941984638410799, 0.887480266395045, 0.9413062593744931, 0.8863766675258471, 0.9262490193925024, 0.9199087170818141, 0.8250339047444251, 0.9043026213920335, 0.9268339224688599, 0.9339146891828335, 0.8854824687064436, 0.9519363654495241, 0.8759465072167991, 0.914496106474359, 0.8571318112739958, 0.8561007299414478, 0.9766358173652361, 0.9504844630857359, 0.8624932075619685, 0.8929123396125956, 0.8936316293814047, 0.9345012488387172, 0.9183109108537568, 0.916505969036184, 0.8874778531866185, 0.9292622779478188, 0.9455505089332497, 0.8636906887345176, 0.9364526502479549, 0.8716899873077203, 0.9670038570313948, 0.9070374885349598, 0.9029990152791019, 0.9010592559337982, 0.936141239881507, 0.9410121218857695, 0.9554981476955852, 0.8404146363020757, 0.9143253579461535, 0.9210863715260579, 0.9627103972551674, 0.9270630802449745, 0.8798510959870965, 0.9776077512623296, 0.9192977548413327, 0.9751689308108222, 0.9136395691114861, 0.939272611999828, 0.9058567634156443, 0.9365855614737096, 0.922526051546124, 0.8903117071915375, 0.9083496349064881, 0.8112696699767179, 0.9236071332632343, 0.9146749678884656, 0.8781131727980569, 0.8770628404642763, 0.9058960410143494, 0.9197301762137935, 0.9576368341783079, 0.9128212062879797, 0.8890809571439547, 0.9254684749223844, 0.9598014979614845, 0.9004253654088671, 0.9146291134881275, 0.931045015395316, 0.8736436096160234, 0.8923170916386781, 0.8833942537458292, 0.9537325209217318, 0.8830553136717948, 0.8985669785160659, 0.8970780573858373, 0.9518863822964136, 0.8817011277816358, 0.9360591917957903, 0.8310600097901072, 0.9267354097070074, 0.950882126239356, 0.903709478033887, 0.9111468010938688, 0.9195854177832175, 0.949546638409656, 0.8733853918593965, 0.9103319580486112, 0.9277560484936745, 0.9492070531803625, 0.9244787300074283, 0.955134157440064, 0.8391899130346588, 0.9490608858563547, 0.8821248864480498, 0.9241435255323274, 0.8432404169291976, 0.9182685120151126, 0.9333000364705812, 0.9051795694652434, 0.8963274293230105, 0.9390676955105834, 0.9424999033622534, 0.9268698253196317, 0.9013382597183952, 0.9771907361429107, 0.9619627944404524, 0.9471433007990435, 0.9793282442527471, 0.8888197869811916, 0.8779036688658854, 0.9091388463783716, 0.938063708257411, 0.783642990278546, 0.8816904826330626, 0.8934559758121781, 0.9288492545577477, 0.9213085547778193, 0.81647786634312, 0.8958356319544316, 0.8782007177923525, 0.9592061568417266, 0.923951497052474, 0.8874620970737439, 0.9630614731443694, 0.9443063477035014, 0.9473522975300293, 0.9607828187082701, 0.9258703229098237, 0.8945375447556655, 0.9599917699785856, 0.9309984080297793, 0.7846755722160961, 0.865097157297728, 0.9208051566193474, 0.9364602202284698, 0.9103862131602412, 0.9709315344407181, 0.9285945093364844, 0.8896119561025071, 0.9260286405711171, 0.9457907988509573, 0.8486148822701242, 0.8684426134684311, 0.8697938066262367, 0.8885723036541894, 0.9050540078276197, 0.9524168778205249, 0.9142946637715402, 0.9220727973494582, 0.8787691433306604, 0.9759330094651717, 0.9205850581298493, 0.8382596030459406, 0.883299971472309, 0.8925180420412134, 0.852472947045949, 0.9284756571629491, 0.9122460407320186, 0.8651070953825624, 0.8709810951881447, 0.8517712142285967, 0.8918886198327651, 0.9339032941982044, 0.8833702931823749, 0.9233983165860653, 0.9523452552843442, 0.8559401779910244, 0.7909472428662607, 0.9256908900542243, 0.9060556935611018, 0.8876257277196815, 0.9543048350233986, 0.9411444081716961, 0.905025227377943, 0.8685909030045756, 0.9382571369949908, 0.8689031011946652, 0.9439572790651164, 0.9474588414576297, 0.9425098087350781, 0.9140751138945568, 0.8927635517185063, 0.9276808657294879, 0.9823127619026181, 0.8870695030885054, 0.9317199949960393, 0.9469633122349432, 0.8807133285467328, 0.9335353351866185, 0.9508562259883786, 0.9678792113999481, 0.8626450790323236, 0.846849118648608, 0.8105435229039757, 0.9210332605650978, 0.9627801629911982, 0.8991423069905247, 0.9666075418004306, 0.9011961049406765, 0.9446133220592745, 0.914656749585628, 0.9772493099360359, 0.7975173229837047, 0.9050915186510978, 0.85700390979648, 0.9017739605332844, 0.9102714440464759, 0.9527461398999684, 0.8202811774156885, 0.8620162011081764, 0.8963752795191224, 0.9506302148478687, 0.8830491255086561, 0.8848023212199014, 0.9381918998223194, 0.9207532179751317, 0.8662675030368103, 0.9123505444597273, 0.8869472152409781, 0.9117048153582121, 0.9092010489144351, 0.9337918842570567, 0.9420694110433964, 0.8351075981591434, 0.9236495201101027, 0.9242519493014553, 0.9670092772263469, 0.9491786577497707, 0.8997340390936022, 0.9110789670072688, 0.9456847238730465, 0.8701620620544948, 0.8420039522703161, 0.8697659647751266, 0.9661506851664917, 0.9586262342207846, 0.9519624728051859, 0.9520774164864311, 0.9403523179085933, 0.8882002959250058, 0.9111547552426265, 0.8742388466596897, 0.8985016154356846, 0.9475716583309038, 0.9123701566848458, 0.8995682343684328, 0.9524458634583987, 0.941246507652628, 0.9281849872956853, 0.8858900886097201, 0.9595883583808718, 0.8813918861284735, 0.9237800515276352, 0.9218710672716437, 0.967688812094323, 0.950903359836279, 0.9304958778631333, 0.9296391936164523, 0.9448173135360233, 0.9022132595623706, 0.9545576985716637, 0.8592447917250388, 0.9475575464785053, 0.9619416011759788, 0.8990423862327045, 0.9420247234259039, 0.9500751650597649, 0.9139974582446673, 0.9494159412627318, 0.9731974856456751, 0.931834281211557, 0.9657496753899221, 0.870967629950874, 0.9421019352178667, 0.9670788161116054, 0.9609783693138375, 0.8514706089016627, 0.9673240248369102, 0.8610706350506999, 0.9563490280971826, 0.863980309777812, 0.8690052330852203, 0.8886301419383097, 0.954434049496833, 0.9486593944647645, 0.9523892212010372, 0.9539333671145467, 0.913982749188467, 0.9714348147059151, 0.8871055898114623, 0.9111034312726083, 0.9661837409599491, 0.898533803084818, 0.92293417577417, 0.9616666929124483, 0.9216845417790793, 0.9736524575565292, 0.9367686974844505, 0.9183905331970281, 0.9390408325879133, 0.9466838813086447, 0.9475591625880504, 0.9308194798280096, 0.9742170544996588, 0.900159554998209, 0.9200000164102815, 0.9547163723833498, 0.9556160937621818, 0.9009905309598278, 0.9343874489360823, 0.9002509644463838, 0.9000898038104925, 0.9545169807162203, 0.8731127465654331, 0.8771322562161814, 0.9579012076095978, 0.929289882029488, 0.9457094094726431, 0.9107356496630604, 0.8906966623314647, 0.9268830625587001, 0.9224724458527997, 0.9441787776508271, 0.9338073744287401, 0.9258438416106433, 0.9505097573092525, 0.9342148842421416, 0.8963800249925349, 0.958333753374248, 0.8646693571638173, 0.9371333108823766, 0.9242115180011528, 0.9477180699672942, 0.8960816360162304, 0.8428601292532589, 0.8434186761681859, 0.8871037062257994, 0.9371448963651616, 0.8700471839055824, 0.9350529860924928, 0.9107246449177017, 0.8911975766792783, 0.8849957382997526, 0.9494058124171141, 0.9393087911506881, 0.9512294285806431, 0.9149788321547134, 0.8896289710715153, 0.9530165842826872, 0.8723031379139609, 0.8591939689517333, 0.9441676032974582, 0.9350190252565613, 0.9533549292230823, 0.9376381493404707, 0.8829184291055944, 0.9028319926611377, 0.8413846731040938, 0.8948017815433349, 0.8758199102047616, 0.9315794285553418, 0.9353201319228214, 0.8683855738301949, 0.9327617826778004, 0.9512167979810426, 0.9199978787300691, 0.8920035444633789, 0.9380682354100823, 0.9478866432846895, 0.9321455285041307, 0.8728258793473184, 0.9201081547400473, 0.949425136305909, 0.9322386086470829, 0.8509039080944709, 0.9512772738913512, 0.9249488762702331, 0.9508694200080782, 0.9312873237752457, 0.976917581811747, 0.8993863043273926, 0.9498815227745524, 0.8859263153423542, 0.9673234376903472, 0.9329912217328452, 0.972678261909797, 0.9266843918117667, 0.9563968721141476, 0.8937619572494677, 0.9198948635839121, 0.8938277694915469, 0.9640376135786074, 0.8909225582920212, 0.9479312806407041, 0.831288924988271, 0.9011415895959168, 0.9110202090911912, 0.8615077618631588, 0.8312689644727254, 0.939728861642587, 0.9545847992600465, 0.8820363806074019, 0.9399738106705675, 0.9671309249259405, 0.8557843949325689, 0.8830188756712856, 0.8919809360392096, 0.8888821044777468, 0.9198472026300422, 0.8804293194468291, 0.9089144307091129, 0.9391277461519036, 0.8987204691481735, 0.9604627296569028, 0.953162574900096, 0.9265351327532384, 0.8700194822407842, 0.9008610963450943, 0.8537287036858126, 0.8695047914500408, 0.9428662779961756, 0.9474000709781578, 0.8973197112534369, 0.8816687348064082, 0.8917598283327827, 0.9315235748603241, 0.9772354468044578, 0.9463332416520748, 0.8924821818886192, 0.9558843790771525, 0.8832851085362219, 0.8667665621787022, 0.8642292192762637, 0.8855501672499684, 0.8888422765637041, 0.918825705904449, 0.9726973486037604, 0.9281678744720144, 0.918551613875104, 0.8453674549057693, 0.8726938274592808, 0.9193675242531418, 0.9312874139478957, 0.8820732410569749, 0.8620171624901184, 0.9528995733995289, 0.9786752369592664, 0.8494419391081497, 0.9170311792665946, 0.8993313672096996, 0.9165708891466219, 0.9256340735564471, 0.9219493476692824, 0.9081413194325294, 0.8534841655758616, 0.9515263605985159, 0.88969398239224, 0.9479765962395079, 0.9162563440873844, 0.9071945267239445, 0.8456092003887988, 0.8825328437879583, 0.9359252741810555, 0.9096120361987117, 0.9039004464029428, 0.9330769260553322, 0.9114241110697953, 0.9112113684606862, 0.9527389929136367, 0.9178458123534642, 0.9591322597007529, 0.9692811018882641, 0.9649752037174273, 0.9598476523934651, 0.9469556729948264, 0.9041419171026744, 0.9198105822547894, 0.9180946140991925, 0.8823752563366103, 0.9250081838083105, 0.8825619949634728, 0.9595506387361792, 0.8969595385897051, 0.8526293202953829, 0.866017783553358, 0.9620004926316615, 0.9449473362868479, 0.9093993518919976, 0.8733415719878845, 0.9038324660906849, 0.9230504294037165, 0.871285999482867, 0.9602632311710004, 0.9745888273384568, 0.9542790413555569, 0.9117892702923032, 0.8668367180724627, 0.8421494953095326, 0.9395579707621472, 0.9106830933695844, 0.8481275470587792, 0.8991989426465778, 0.9604082166650743, 0.9544365574633242, 0.9104876143872094, 0.8642656346533311, 0.8964006764596877, 0.846234492571662, 0.9198787588413548, 0.89429866400469, 0.9244911152253139, 0.8855929931316676, 0.8509236806033539, 0.9319240769164421, 0.8854713847073253, 0.8975379854355093, 0.8299650598673646, 0.8878252236813182, 0.9359805524137026, 0.9497808277096167, 0.8349189076589452, 0.9703072544810689, 0.9280723447817603, 0.9221466775489737, 0.8660860281888726, 0.8820426727917029, 0.9623138028547445, 0.9227936156944533, 0.8720208064880178, 0.9153721292301915, 0.9435820779680721, 0.903815974761041, 0.8836378288997703, 0.9671450845438195, 0.961672872094794, 0.9521034566182351, 0.9385668111477053, 0.949368998883386, 0.9441131041621967, 0.9018524925811908, 0.9140465007368757, 0.9634393757755938, 0.9164308313792231, 0.8968665315390434, 0.9246702039145185, 0.9381894791906732, 0.8263214451326022, 0.9479060925461388, 0.8727554352682064, 0.9157476144179393, 0.9240571294268546, 0.9061032336524655, 0.8446946382814498, 0.9685444521528579, 0.8574245573871516, 0.9648262904102127, 0.9114858691547121, 0.9674202049408817, 0.9766651510793404, 0.964362217061929, 0.9274420310003887, 0.9334220838250835, 0.9132735488995426, 0.970818335802373, 0.8901293184487451, 0.7846369429980307, 0.8940530863969955, 0.9442577371846317, 0.9306425091931618, 0.9076547115062792, 0.8262854966381545, 0.935422737172511, 0.9578789367003847, 0.8943819249104793, 0.9184824546939332, 0.9073596969321892, 0.9282227305785447, 0.9584762934781444, 0.8769246003684185, 0.9582776531222282, 0.8652100352919156, 0.9192362591341466, 0.9282196377146474, 0.9501329176997693, 0.967114085118814, 0.9031721727533395, 0.8475663529610272, 0.8745411835816292, 0.9087305356902612, 0.9047534628977406, 0.9048238241576818, 0.9599829646352837, 0.9289876480974595, 0.8394163555890845, 0.86857460175166, 0.9384165919956229, 0.9317635261207092, 0.9774278501499816, 0.9383863459018824, 0.9139255642311894, 0.9174307523260843, 0.8355818363137966, 0.9455038052041025, 0.9045775955213181, 0.8909054702596597, 0.9624261176120492, 0.949113133377804, 0.8888859943281993, 0.930139872984636, 0.9472644611097274, 0.96288058000429, 0.9764544827021451, 0.9403563662516847, 0.9093299009939622, 0.8967877814997347, 0.9742253682944402, 0.9249106147601038, 0.9455405575569901, 0.9485305414004708, 0.9027369902877984, 0.9308249973717078, 0.9238791503355137, 0.9393344156414123, 0.867459895485291, 0.9231969014686792, 0.8212728782816763, 0.9435980667488366, 0.8909594221919408, 0.9740036686199463, 0.9365911762402137, 0.9530480028004125, 0.9394772902338927, 0.9118991948753498, 0.8998031567382443, 0.9071560269309573, 0.9016632741640656, 0.8548584755564694, 0.8815051626009907, 0.9484470488585204, 0.9626316913571207, 0.894466521715441, 0.9509299597296403, 0.8279979705105921, 0.899852525353757, 0.8988263348343055, 0.9483363609568205, 0.8954705706184601, 0.9287141750205143, 0.9807139019617214, 0.9093037925011234, 0.898664575150858, 0.9371400049475237, 0.87718313942532, 0.8987565137526832, 0.9333846688250929, 0.8445791189342419, 0.9171407795059556, 0.9507549224041119, 0.9460128214455314, 0.9503147353963468, 0.9214931656450251, 0.9522156030190874, 0.9338578572505059, 0.8486393217343196, 0.8794168246082052, 0.9422979346441918, 0.9306841680479055, 0.9012165281173063, 0.9379075089728393, 0.9460215741859002, 0.9023733968018869, 0.8919660517797496, 0.9501351573058686, 0.8778109122995416, 0.9101059192916624, 0.972248080503304, 0.9557897119465761, 0.8803903672533411, 0.8759030087003588, 0.9321552322903642, 0.906215760019692, 0.9607672955121479, 0.9015430099721853, 0.9638125978004618, 0.9595302442907419, 0.9646571722916714, 0.8718469270084142, 0.9126905694867032, 0.9541627516519027, 0.8995862554885949, 0.9361057146748907, 0.9383985959079768, 0.8809801599090467, 0.9047531584226999, 0.9571681822843205, 0.9753807090394762, 0.9590810883376859, 0.9619948903099349, 0.9481872938331624, 0.8737468874113862, 0.9683037994463719, 0.8222402571319563, 0.8845946820559929, 0.7720302848681733, 0.9525098997442503, 0.9663892473798212, 0.8395509248107671, 0.8911506917839236, 0.9249094600312762, 0.9500057591177961, 0.880902135058099, 0.9672141482801202, 0.9537905173962921, 0.9053524988130436, 0.9560208562965969, 0.9355571624304286, 0.9299180979570922, 0.8588389892286712, 0.8852134286733402, 0.881423026099643, 0.9097302127912094, 0.9260675624535984, 0.9111870023571479, 0.9189488586623098, 0.9362598170037382, 0.9020917984881405, 0.9527839634233766, 0.943062769524528, 0.9525374833232076, 0.8666438627807211, 0.8934184165996975, 0.9509848052714016, 0.9612725182413606, 0.8712895821073672, 0.8376500973127623, 0.9365105289267542, 0.9219983461114996, 0.9464055203573196, 0.8507954920708021, 0.926819627406731, 0.9378065973022156, 0.9244440937070919, 0.9122900325912198, 0.9632582858370016, 0.8284466452291454, 0.8902938244246265, 0.9371336103353836, 0.884082186645201, 0.9600177328770827, 0.9248886361726456, 0.9230853783002578, 0.906818696310142, 0.9517715600948634, 0.9139023872320243, 0.939815483535705, 0.9094918590557659, 0.8458199116165424, 0.8666179485157323, 0.9098097200016007, 0.9389650094180642, 0.8285818083923864, 0.9462787896759617, 0.931018597335384, 0.9406729098635184, 0.8680199674680917, 0.8860835845352136, 0.9183340486329543, 0.8460706958457154, 0.9535562669944524, 0.9205454226051223, 0.9070419484658597, 0.8227082118145513, 0.9164808631693502, 0.9479460238325192, 0.9363493349720589, 0.9323423570321152, 0.9344810120436764, 0.9166394002795283, 0.9075424332969909, 0.9486475993899071, 0.8886694743781456, 0.9513994694813337, 0.8093050991275234, 0.9034740589985188, 0.9140901639962855, 0.8557318411013055, 0.8994242248622735, 0.925153951093904, 0.8043653429788065, 0.9428691770335751, 0.9724859716140026, 0.8331507239668348, 0.8427150947167618, 0.9345299334396248, 0.9061916536918382, 0.8379280570604409, 0.9021012778550175, 0.8932014975728666, 0.8893272202036255, 0.9656197275204378, 0.9020879932604366, 0.8986320748543539, 0.9499973799952695, 0.881042817881387, 0.9682256756500505, 0.9335023630654825, 0.9489862154347275, 0.949872854009445, 0.9541410480498289, 0.7532344637550308, 0.9064856041171907, 0.878756126728085, 0.8600640812250131, 0.9460368622878762, 0.9640573444540614, 0.9198277176165033, 0.9382798000353945, 0.9338114750121506, 0.8525605045523765, 0.9117868000776639, 0.9503059649733878, 0.9057699542150239, 0.8711633585211024, 0.8778744824685509, 0.9755440800685695, 0.9165285544242601, 0.9009454950432632, 0.9263134967912836, 0.9435574029700389, 0.883624772238017, 0.8983230916019949, 0.9316116726123176, 0.850212409228048, 0.9171216434642839, 0.8722331896550302, 0.8704991078874964, 0.8836187857130562, 0.8763733106315266, 0.9045404227132647, 0.8606434970943241, 0.9529006367088972, 0.8986724284741429, 0.9401760510491677, 0.8620991265683718, 0.9539516612085334, 0.9738062171751893, 0.9253587559368984, 0.8964361660457355, 0.8898088237642011, 0.9007643620229447, 0.8855325737300368, 0.8859381391640808, 0.9116887936607365, 0.8872322332131102, 0.9030499837664419, 0.9503625798698856, 0.967126006686015, 0.9024576122837795, 0.8757281179720011, 0.856921213667823, 0.9167254551485619, 0.9248518910362737, 0.9347422468130234, 0.9337382007257238, 0.9390855045207849, 0.9521587639760769, 0.9025835732128857, 0.9622988205445232, 0.8114429249011036, 0.8896542908605113, 0.8911515024499026, 0.9149954592340024, 0.9082945652970448, 0.9238661958992265, 0.9697213697082678, 0.9156510269620897, 0.9524835130348437, 0.8897235355692021, 0.9607383969533241, 0.8596485888650739, 0.8397575893949001, 0.9458916171971179, 0.9434748465321487, 0.9554859582974364, 0.9183371463096078, 0.9266232270060888, 0.9160358466197152, 0.8761714949295274, 0.8889577220518152, 0.9564178463862498, 0.8869342201829256, 0.9218871780154052, 0.8438402384852522, 0.969928553720822, 0.8722574266992611, 0.9774669348248565, 0.8320449391306497, 0.9487667680217088, 0.9538519474137777, 0.7900439284453227, 0.9707167704017113, 0.8434414119809759, 0.9259638706820004, 0.8952092128113855, 0.941279964461494, 0.8750314634103219, 0.9562739958939266, 0.8042183185372977, 0.9615717773609725, 0.9371396710163997, 0.8916487209849575, 0.9759444935847299, 0.9353719489543248, 0.9399557325262915, 0.9630335754835371, 0.8670026665643464, 0.9190538889176233, 0.8567003200380654, 0.9271591919989091, 0.9251530964339765, 0.9593616511277407, 0.8969749392177487, 0.9337255348163228, 0.9493986180785856, 0.9606114407402538, 0.8928507823841516, 0.8529667006259565, 0.9291437213848147, 0.8521762423517256, 0.9119880541231515, 0.8539150056255669, 0.8826583424903097, 0.9834186286312485, 0.902661875539117, 0.930530146579454, 0.9229563271306687, 0.919152684345615, 0.9597371503001056, 0.9225664917447767, 0.7619606249590394, 0.931551231248545, 0.8669346673447584, 0.9432132675810878, 0.8973733477142194, 0.8942091105241219, 0.9082357544257662, 0.9310374210845158, 0.9442230365842912, 0.9111800777549834, 0.974202359046105, 0.9315130178479034, 0.9006486448488678, 0.9231478112588979, 0.9155011517336336, 0.857498145366958, 0.9176494098828729, 0.9672197261319535, 0.9042379265688079, 0.8864698874067907, 0.9045072193944631, 0.8951638246864164, 0.9708161412389641, 0.885099502522651, 0.957724554074922, 0.8876611209644953, 0.8997417408726496, 0.9359068769797874, 0.9426613310796039, 0.9544909889474573, 0.8736558951950979, 0.9567441620346073, 0.8846690350137288, 0.967956436977322, 0.9726775708716016, 0.9150797688215155, 0.8653399445430452, 0.9466172579153882, 0.9100785448432989, 0.8904973710219581, 0.8411451920962513, 0.8729873666750209, 0.9459984103145639, 0.8265067552898893, 0.951462461558204, 0.913700396626022, 0.9202443436967602, 0.9481506364944092, 0.9455956742723397, 0.9390626912291734, 0.9374328501980289, 0.939880628388996, 0.9452573213370772, 0.9598937019001355, 0.9667466128168778, 0.9307658947129904, 0.9736575149333274, 0.9428852360389504, 0.9476098690813216, 0.9523550079770097, 0.8510767976569827, 0.9732274266942593, 0.9594436126561647, 0.9375254809602793, 0.9303535476162729, 0.934285056252363, 0.9337057390914103, 0.9266330489714311, 0.9029485972567641, 0.8830546970690775, 0.9076937721086162, 0.9389750839707838, 0.8794715325834571, 0.9580744051910468, 0.9532920777295019, 0.8658288177267176, 0.9133524480700366, 0.9234779694433837, 0.915073491589416, 0.9482764909363272, 0.9004030001506274, 0.8968324109015937, 0.9293672752843172, 0.9341043082894107, 0.8951192566443592, 0.9301998736206486, 0.9148990262671398, 0.9687748285175034, 0.9301875727533587, 0.9231955732271391, 0.9122515018809693, 0.8685087139918782, 0.9642729251473053, 0.8562731903853533, 0.9706875284021845, 0.9101687146978026, 0.9031456524512905, 0.9536194156108604, 0.9121704963864509, 0.8903918845972499, 0.8944916875095259, 0.9329177989295538, 0.9311226941805986, 0.8018722049386559, 0.9186126533713584, 0.92108554540614, 0.8902133622141346, 0.9191090231138155, 0.9122985752828351, 0.9713515181478956, 0.9586995196238499, 0.9639356680853788, 0.9189846672844616, 0.917649500043948, 0.9652835253878349, 0.8935552024031528, 0.9580280277870067, 0.9474733938220764, 0.9305375955710977, 0.8446550716308564, 0.9513049802478815, 0.9459435173923925, 0.8863079949365104, 0.8778590630173635, 0.9761453833117266, 0.965356543221659, 0.8691223266091518, 0.8748905701423603, 0.9718260680060204, 0.9212555940684177, 0.9035109237131509, 0.9449947355564727, 0.9672523019476162, 0.9258800842868007, 0.888285237035018, 0.9166486693935543, 0.9043096671932658, 0.9256184161499144, 0.9697002281439009, 0.878756343988261, 0.9325660015960013, 0.8830994790796902, 0.9066318619007439, 0.9165951195181166, 0.8931652683681275, 0.8968542549119645, 0.9184463719395481, 0.9304787643821237, 0.9621043845224745, 0.9155548861242503, 0.8986279508746478, 0.904037732933966, 0.9743718226605336, 0.958788787622385, 0.9634702144520617, 0.8499491458595472, 0.8952448410940078, 0.9422720739180774, 0.9431966975368002, 0.9454909994992631, 0.8954519857583713, 0.9596827774649332, 0.9634782536469486, 0.9354372842247065, 0.8730874642336345, 0.9000913437137189, 0.9435964642159855, 0.9585718519025941, 0.8678038640257966, 0.9026484285580721, 0.966665238799636, 0.9502242566853167, 0.8988481087610608, 0.9340154771336778, 0.9742167987352554, 0.9158519993672595, 0.9711200953151491, 0.9584941570874383, 0.845354164768991, 0.9067149688900188, 0.9224085903624123, 0.9108366867859865, 0.9318435966434205, 0.9091436694551436, 0.8472528879465762, 0.8670266355396321, 0.9215144087631439, 0.9612268515797502, 0.9191045433946139, 0.9697369211081559, 0.9581775995274584, 0.9586764870318851, 0.8843623650557806, 0.8548873423158669, 0.9471147446425776, 0.9240277762068128, 0.8814703532496404, 0.9072780735892874, 0.961542506645986, 0.9048553070998752, 0.8519590841799962, 0.9663295875546402, 0.9498001082791516, 0.9052794798639558, 0.8973415511418945, 0.9409650802054617, 0.9037950645179413, 0.9225940706375512, 0.9768137083640944, 0.8720417453216215, 0.9260902985534889, 0.9700429864660709, 0.9253970029790615, 0.9280010183726795, 0.9155432995271491, 0.8807886367557547, 0.9708686524636363, 0.9346961865905344, 0.9471446438583964, 0.8844997144035969, 0.9563831555516158, 0.9405893223607861, 0.8948687885219236, 0.9503096435673763, 0.8989264742425224, 0.9075794417928515, 0.9048614575311066, 0.886394613719298, 0.8793837953485143, 0.8825258314934316, 0.9572161866115989, 0.9412416507053065, 0.9051313205965381, 0.8944118329890123, 0.929355002436577, 0.9420622154935341, 0.932354289173531, 0.9309549188502702, 0.9282505589402751, 0.9253569497481082, 0.9450256657894476, 0.9609727541282151, 0.934806684940972, 0.9617619519567451, 0.9147570325212718, 0.9480906166541225, 0.9649094083067493, 0.9118815011464358, 0.9086630513775004, 0.9183313561313884, 0.9497976464689204, 0.8993944799615614, 0.9411065294709985, 0.8394257034650601, 0.8699930071053259, 0.9310031338420488, 0.9504674562606075, 0.9119115006222607, 0.9417148735288522, 0.911590952281311, 0.9310586498892099, 0.9442479604500933, 0.8661697238976405, 0.9554474857144564, 0.9464924094038809, 0.8708750102487615, 0.8680367429286722, 0.8337180550726295, 0.8769755358694332, 0.9495121639834285, 0.9533449941934877, 0.8885336826908973, 0.9228769438457004, 0.898146472904107, 0.7932520163083129, 0.9355721026427828, 0.9475291492421776, 0.9208438507532728, 0.9402230269358242, 0.8964989265563561, 0.9102761240589438, 0.9476840688530102, 0.8902982786072654, 0.9281394587703796, 0.931331687533441, 0.9284770324430496, 0.911466595994552, 0.9377130835168819, 0.9571324965058096, 0.9635477143060371, 0.8693710891680086, 0.9532839177912827, 0.904581407104881, 0.8132750485165383, 0.9509853678279383, 0.9668141728416685, 0.9538319134112042, 0.906864198434794, 0.9504513840579262, 0.8596227616081973, 0.9052665791416032, 0.9377629855516162, 0.867280856874906, 0.9152298613990753, 0.9117937885750531, 0.8773430515690888, 0.9054585622137306, 0.9378461397378197, 0.8430239065103877, 0.8614689131055441, 0.9749582693709529, 0.9214368210895043, 0.933381317655512, 0.9173416578409951, 0.8830001656459545, 0.9603110897812606, 0.9594803121656557, 0.9529860429242847, 0.9168854927794872, 0.8958526690454687, 0.9096791307511055, 0.8412764052220325, 0.8627173375292498, 0.8879285779299488, 0.9173690756582378, 0.948543066980677, 0.8846569256926793, 0.9487845701703618, 0.9044427138207966, 0.9096834717424294, 0.9748104000285718, 0.8496026428968422, 0.9122633187118959, 0.9569893757220519, 0.8581102357560575, 0.9621659324078183, 0.9269837281322274, 0.9327321961603502, 0.919797483113953, 0.9194177116350428, 0.9572716154112725, 0.9311713822330302, 0.9226100029466526, 0.9327674728985158, 0.8918993522753709, 0.9359615180289278, 0.8965665393999824, 0.9243827404804472, 0.9042068472803861, 0.8906465326343942, 0.8594374313165564, 0.9553462687234676, 0.8960658610136241, 0.9176006554933129, 0.9651043369953919, 0.8766179572320403, 0.921949861211507, 0.8635721715293709, 0.874455333761758, 0.8541749116393645, 0.9241937829658194, 0.8673017277766959, 0.9306460154581019, 0.9378411203516961, 0.966224388520593, 0.9189506185994152, 0.9168742257289011, 0.8903407854686893, 0.9301378685521582, 0.8176784310060548, 0.9702060072181459, 0.9309243879790787, 0.933924065324911, 0.9192815158780204, 0.9070186051567997, 0.8988928348476287, 0.9370590252939199, 0.8775206962532264, 0.8943738690873919, 0.8960064169783654, 0.9255890205035984, 0.8883106651580758, 0.9208694081727945, 0.92256584054472, 0.9476946854224271, 0.9261185758447156, 0.9183596153702588, 0.9207926420860834, 0.9168315296454063, 0.9679080427642652, 0.920174996772496, 0.8733445707381039, 0.9222016882218917, 0.876970101423414, 0.858017406010826, 0.9559519925329052, 0.8438859316550595, 0.8981632910098566, 0.9171676528298305, 0.9157629963859901, 0.9196718799460234, 0.9581827183126825, 0.9193070276700656, 0.9076576649451116, 0.9460207376363892, 0.9172047004770971, 0.9625156283408081, 0.9441994666892661, 0.9362286226973167, 0.8663257309314278, 0.9111492915293549, 0.8501085099689285, 0.8851185896234468, 0.9154945315032921, 0.9734902464555474, 0.9103990281610178, 0.9681295037756958, 0.9587904491448993, 0.8264591983675487, 0.8981930490201909, 0.9398951419468727, 0.9065561510220361, 0.9566789658803349, 0.9220713521808603, 0.9189599479154897, 0.9580954994422773, 0.9332584236287078, 0.9614188899457649, 0.8107594548449539, 0.9387170639042149, 0.9471008842578703, 0.8474733981318124, 0.944865427987607, 0.90508542830782, 0.9016818505051972, 0.8831003254742409, 0.8816442305252421, 0.9507650673373558, 0.9297693381064551, 0.9684865225835544, 0.9406128359487562, 0.9655851128124264, 0.9314977893834444, 0.9438381711241486, 0.857810711724746, 0.9284736510015125, 0.949465521841725, 0.9022681775935244, 0.8498803726576292, 0.9120095156550956, 0.9562248900929013, 0.9105083660095695, 0.9078511208254064, 0.9189268571886231, 0.946159927830354, 0.9370216149727157, 0.9659747541827266, 0.8876435123969841, 0.9493098852074909, 0.9257092870480936, 0.8709609586882194, 0.9137871830975015, 0.9719319223524795, 0.9073554640059425, 0.9263188318190239, 0.8793207103994362, 0.9248658766154123, 0.8629408942427681, 0.922464492401021, 0.9623208895382586, 0.9435987907353762, 0.9323805740910862, 0.9545635964342688, 0.9356564035011863, 0.9143034410911095, 0.8575900878958193, 0.9519803373001601, 0.902636324360281, 0.9306603591644628, 0.9392081655825983, 0.9132101320457582, 0.8283407787143837, 0.9558676485776332, 0.9357763215970207, 0.9612315693189306, 0.8773924620226898, 0.8852929749874857, 0.9483388300606033, 0.9125221877537752, 0.9058801248196877, 0.8869669388640781, 0.9587427844430294, 0.9105582082005412, 0.9365151546864645, 0.9300661791347522, 0.8908267962433806, 0.900026425835347, 0.8822074181531818, 0.9095141738407281, 0.9430148231866966, 0.8911660598321905, 0.89057584068208, 0.947176244703266, 0.847918810852394, 0.9011631636322734, 0.950504427283033, 0.9696240233471534, 0.8817570865144324, 0.9244650195707396, 0.9448967115024964, 0.9220121527709002, 0.8859265876070607, 0.9650941150062822, 0.9047274373491908, 0.9242144272290487, 0.8721232836213053, 0.8565098047974278, 0.8869675979852343, 0.9566823371492921, 0.9508306923186871, 0.9621984510185345, 0.9237381355588157, 0.8810357662691325, 0.9166658999138882, 0.9131143999514232, 0.8972977891025204, 0.9245921301104668, 0.8963339387895972, 0.9067068919125849, 0.8609703934245221, 0.8427444275327809, 0.9387223006333361, 0.8851213837216285, 0.8670731942432512, 0.9030870268559152, 0.8992371508437542, 0.9411770408890638, 0.968974758131924, 0.9396387069668994, 0.9625917292972078, 0.8488100962405627, 0.9440724320784595, 0.9441138731930393, 0.8521239455630811, 0.9393584753064691, 0.8749753920598122, 0.931565546927522, 0.8924050162199652, 0.9617948140772536, 0.8807522186605429, 0.9180151841567096, 0.9482279303339829, 0.9456168348870513, 0.905704207788921, 0.9026768419448901, 0.8576164256984328, 0.8645341849078494, 0.8824355319858181, 0.9593537209881953, 0.9393394286347716, 0.9329720353318403, 0.8479884003069453, 0.8804994798812636, 0.942542492849248, 0.969795341601618, 0.9427278910155291, 0.876143258891205, 0.8968381643231574, 0.9799484919727188, 0.9311243220346476, 0.9401332053300133, 0.8720170934281337, 0.7587228461249658, 0.8953050464318568, 0.9297750379426173, 0.864546831490244, 0.9510748424525731, 0.8914213107554054, 0.9525939508061922, 0.9016210354091563, 0.9223158624575092, 0.895695679077751, 0.9115067972074731, 0.9547784358173579, 0.8527811074086636, 0.9601320416487593, 0.9040883035458158, 0.8998108026682313, 0.957088663566518, 0.9135619862630694, 0.886157245905533, 0.7855223163655751, 0.8859065096117819, 0.9253164288354339, 0.861418169313221, 0.9449627624905449, 0.9176848640965539, 0.9185761903713744, 0.8877215280098513, 0.9230295864076496, 0.8979640974860985, 0.9471282787711666, 0.9243634369592462, 0.9256320438346097, 0.974368433189517, 0.9082861879553688, 0.9582822152682846, 0.923348762368327, 0.9502759384928879, 0.9559895753765256, 0.9288212189533381, 0.9286066746136548, 0.9008174652057737, 0.9116117481684981, 0.898634969243849, 0.9045031823601016, 0.9407437047643041, 0.8193019083093733, 0.9450445679083821, 0.9115645323708278, 0.9212111044124061, 0.8359498172197573, 0.9415101103737246, 0.9273504026941659, 0.9016584823181428, 0.9149148865315787, 0.9318217015402513, 0.8791282257324212, 0.9379079569845046, 0.9100032823164783, 0.8715043991715228, 0.9102264788227546, 0.8577455597623976, 0.9069819566699409, 0.8756861586150897, 0.9000787596060305, 0.8971867728191806, 0.9761548974751735, 0.9621623781047156, 0.9540468821033123, 0.9440366564669669, 0.9467063599267324, 0.8888368579775368, 0.9232455187391344, 0.8082265544521415, 0.8886567310898221, 0.9393194646764177, 0.95710292909659, 0.9445073029848305, 0.8855428749358989, 0.9558419743878062, 0.9463539839884682, 0.8974993079051032, 0.9127371918281031, 0.9476070476680631, 0.9483419645348528, 0.9257398932874659, 0.9711209655283292, 0.889413370861432, 0.9528390777467673, 0.8728295583274521, 0.9227665660844714, 0.9117486955771493, 0.8593218901446927, 0.8762278244494897, 0.9547009390141459, 0.8519386969425761, 0.905074160677859, 0.8510441794041153, 0.9609927538576105, 0.8456735845504102, 0.8707819860901909, 0.891209824433126, 0.9597275998981869, 0.8929300553020252, 0.9559321715648773, 0.9223293667825055, 0.8671479407506343, 0.9515311765520302, 0.9164225952847032, 0.9516664012113691, 0.9530253584467288, 0.9053458546363481, 0.8480993544823763, 0.8717828827326681, 0.9024431255153876, 0.9473430410750356, 0.9038331603509194, 0.8946352721378794, 0.8591971034528847, 0.9301862116978483, 0.9326818373348406, 0.8822386700181721, 0.9467479010415045, 0.9265728371259792, 0.8828453741807024, 0.9642832302869078, 0.9081954111540984, 0.9259447556806121, 0.8991702175474081, 0.9001208394256273, 0.8382871149682144, 0.8916585579258861, 0.9276777145519877, 0.9264237990300301, 0.8972467864428725, 0.9183044506179119, 0.9421518661200345, 0.8805875876775675, 0.952411099988657, 0.8670751648845197, 0.9183418390552872, 0.7751343249930354, 0.9227975361614239, 0.9526992729535748, 0.9053789367469958, 0.8673867394189848, 0.9394537980049669, 0.8185237226856764, 0.8770745239283467, 0.9001086678592163, 0.8691644824433422, 0.8915617841237554, 0.9179863582409387, 0.92790586325032, 0.8768212370899622, 0.8469279196393337, 0.9009313896621689, 0.9671111111198837, 0.9484043926203869, 0.9619477198408204, 0.9417377578902336, 0.9484271702881333, 0.9209783739419708, 0.8995066032269917, 0.9544862735163326, 0.8898996902127506, 0.9523094797730891, 0.95744457091546, 0.9308230997071807, 0.9087786108030513, 0.9142217666718151, 0.8042189081194375, 0.9330926629101891, 0.9225867370599086, 0.9307431705681467, 0.871892644710823, 0.8123444490153167, 0.9112654230727781, 0.8996013998583057, 0.9625293005732446, 0.8490467823147434, 0.9756775066775698, 0.8440230403286134, 0.940453512454387, 0.8255299561772693, 0.940285381696556, 0.9176440820520155, 0.8437757844684031, 0.9186704214263842, 0.9067408476964474, 0.9187982726065201, 0.9140981495423466, 0.9351416397134703, 0.8471942242031917, 0.9065238276928567, 0.9311811952004678, 0.8994513080785205, 0.9752315134993981, 0.9655626889235505, 0.8434016500283188, 0.9647348092513024, 0.8592812251924827, 0.9193035218036509, 0.8630859107651755, 0.9154655827661515, 0.9332007181921775, 0.9480608939379908, 0.9397111079430921, 0.9556470350781121, 0.9400985970068816, 0.9543598670843271, 0.9596265286788759, 0.8722292152334364, 0.9095310821437141, 0.9341472990415998, 0.8836666049400271, 0.9118490024647022, 0.9330168251528439, 0.9276511327931409, 0.9432565267920002, 0.9414248864783719, 0.9292633306264042, 0.924976597587897, 0.9052585621053211, 0.9561182362936165, 0.9804176398454391, 0.9197776021907612, 0.9184633895418399, 0.9116151478988604, 0.8767427591487994, 0.9416957877049844, 0.9592443005032685, 0.9635668573658249, 0.89497219033714, 0.8969219259288204, 0.9606744775913998, 0.9350792594560848, 0.9321277394597334, 0.8352320703994551, 0.9224826585511341, 0.8992383597823658, 0.9497756932069548, 0.9513621870025546, 0.9411489847128122, 0.9742365519537641, 0.9374214205241207, 0.894693808586025, 0.9169926116798692, 0.9119395640295039, 0.9680047214092992, 0.9826120876869294, 0.8858651333671894, 0.9192334924324012, 0.9118949248001996, 0.8949221674309221, 0.9599183874851702, 0.8782161937345545, 0.8835563088618617, 0.9482375353822262, 0.9476687595025879, 0.899128832270943, 0.9108966626259809, 0.9308185805660414, 0.9495355298406047, 0.8898695012369346, 0.9090229100901729, 0.8326456542295559, 0.9304045519024216, 0.9214043076215687, 0.9755812899709445, 0.9433966398145073, 0.8885491398553087, 0.9598080124530487, 0.9465951818340204, 0.8533253880527902, 0.9004174852237279, 0.9089331022329492, 0.9381514989666453, 0.8849588150817863, 0.8929380851759635, 0.9138686633196823, 0.925479114798923, 0.8198360585165236, 0.9613672118437968, 0.8522218930711938, 0.9460159233263725, 0.8701741369674464, 0.8030656505673945, 0.9697599037286491, 0.892081408995958, 0.9219286404769862, 0.8860488704697751, 0.9013045385044269, 0.96249589896672, 0.9092671613973178, 0.91638884473136, 0.9667495845529306, 0.9655302712422037, 0.9708459293976487, 0.9644430664440928, 0.9161354271212563, 0.8870518448468357, 0.8607267448388759, 0.9457184745185334, 0.8891624823186748, 0.9148101548154707, 0.9110632185462413, 0.8679622597680364, 0.9087995943808127, 0.9276363617868277, 0.9689404017533313, 0.9695865123838046, 0.9052864422346463, 0.9229489272554707, 0.935764665174592, 0.9666897568618271, 0.9541868524394597, 0.9646709001781313, 0.9489090567527981, 0.8741977409224163, 0.9546329591307421, 0.9523368201987485, 0.9716764017101384, 0.9343963018434404, 0.8901722115400644, 0.9131779637497643, 0.8818795505472858, 0.9545186235560763, 0.9238239087720622, 0.9641568814267798, 0.9228645594803695, 0.9160409551379416, 0.9149140854783582, 0.9207665993873253, 0.9788820246184406, 0.9244789527292756, 0.8093679048605882, 0.8365710513195463, 0.8968231681625615, 0.8263808037259144, 0.8855638450883909, 0.864616772019088, 0.8490776235924925, 0.9791610880096415, 0.8702194401620302, 0.9236440074474368, 0.948144080561862, 0.9688722915367334, 0.9490353240403491, 0.9232487520672263, 0.8958953513429488, 0.9000231099830177, 0.9126461186508891, 0.8561177983380988, 0.887687786500254, 0.9230145726276501, 0.8851820174780207, 0.9305728036371426, 0.9181683388114463, 0.8156300288824627, 0.94106077898674, 0.9151045370523654, 0.9633616472102646, 0.8777554375843981, 0.9417637571379811, 0.910134056458547, 0.853304226268548, 0.9580341219445487, 0.9733600846254546, 0.9380114288446144, 0.9288657090209551, 0.8835974955738858, 0.9167948898941443, 0.8768469177277028, 0.9364038740470199, 0.8527197878387612, 0.8948016931448644, 0.9602935725979829, 0.9400986194938526, 0.9478564503761582, 0.8926847509947653, 0.9399461697362517, 0.9556791837613571, 0.9369516191156658, 0.8097814499459404, 0.9423152620561006, 0.8499035382128668, 0.852512150247846, 0.8743075876132747, 0.9036094939099493, 0.8813684520101984, 0.9280161294345435, 0.8940361356040323, 0.9047134041893092, 0.9318670658447441, 0.9306268360506872, 0.857441304085088, 0.8888496082614437, 0.9264716644598859, 0.8608243760296204, 0.9604740509138685, 0.8943715827394805, 0.9235612527713244, 0.9071659489060078, 0.9552369507373106, 0.8460674561879789, 0.8786127289537131, 0.8806191130660838, 0.8444532007652028, 0.9390252797795338, 0.907201451558235, 0.8429704772667062, 0.9247282651437241, 0.9472054251820731, 0.8612214297821615, 0.9094445953483505, 0.9233293549723725, 0.8840722954125553, 0.8929838305395268, 0.9106202647450474, 0.9212037702696366, 0.8796860333100099, 0.9496722272356543, 0.9254185530186239, 0.9166609939118323, 0.9418015557831965, 0.9309440128255337, 0.968564961207401, 0.9350216262156004, 0.9658689577700326, 0.9186797665557951, 0.8961083811050377, 0.9478225133797351, 0.8407267121130804, 0.9570093234670836, 0.8720093074704687, 0.8620796100365997, 0.977823941852077, 0.9340430025934914, 0.7708209545757864, 0.9197871393243491, 0.8224283277329212, 0.8952349827513933, 0.8737451587435715, 0.9174985504688167, 0.9653620536766654, 0.9263556073649147, 0.9026130680090945, 0.9436360446990448, 0.9060732946946645, 0.8710233564725466, 0.9485541513800235, 0.9499824411818985, 0.8828266343695721, 0.9567341682915073, 0.951066107298337, 0.9039803854183963, 0.8501111106082887, 0.9648768028701227, 0.912035971217779, 0.8814749940679766, 0.8834982903530175, 0.85705427866212, 0.9053812045196294, 0.9229551012877872, 0.926859383823061, 0.9506698290969908, 0.9000660597602794, 0.9469012948723526, 0.8988661425562787, 0.9279491476614641, 0.9194416905261091, 0.873871418879907, 0.8981956853184425, 0.8661646778611645, 0.9226932322447736, 0.9681591296997438, 0.9219492629437516, 0.9495756531637947, 0.9816985944574603, 0.9182338139302157, 0.9316644249283628, 0.8766733002359666, 0.9416194171641294, 0.8958358255082193, 0.8736819053410609, 0.9519098963573929, 0.9152866166649759, 0.9427077993773506, 0.9151381338643428, 0.9464392405762145, 0.9377299284494146, 0.9049395784341782, 0.8464274673379895, 0.9408222917245032, 0.907322106895155, 0.9702756436015603, 0.889931345329399, 0.9247031825235034, 0.9593526444276725, 0.9337012076757006, 0.9126230729623978, 0.9513893072470457, 0.8846535841788715, 0.9441933923102974, 0.9308030920991681, 0.9356746474130895, 0.9595968528497464, 0.8324846314923745, 0.9754332412273992, 0.9346736167337888, 0.9665916333626117, 0.8754349525409637, 0.9346659421826187, 0.8922721114303215, 0.8235847623376762, 0.9274772726508907, 0.9088825223119381, 0.9291685410520781, 0.9729380814958668, 0.879547365641777, 0.9151421183786359, 0.9004580823824299, 0.8944298195704132, 0.9329196501717616, 0.961985924009481, 0.9267318673615428, 0.9386075315878175, 0.9388795662910981, 0.9232864053583825, 0.8689617627670654, 0.8964814699560839, 0.938436183625977, 0.9030707498566874, 0.870887758540052, 0.8631310257669523, 0.8997564050181026, 0.9236672722183091, 0.8660160093693999, 0.9547394567556635, 0.8486061629361455, 0.8809585928159253, 0.8994226315057541, 0.9639423121051777, 0.8931455105194034, 0.9410396449049221, 0.9598812121513379, 0.9257421289566324, 0.887630148607057, 0.9297665759406071, 0.8867078871328335, 0.9575119156386679, 0.9755366769374376, 0.9377332098586568, 0.8908984900173227, 0.9374545166638789, 0.8878924005683093, 0.8942133245551169, 0.9593235728598425, 0.83397592154937, 0.9768911704334402, 0.8333207536686733, 0.923642496537966, 0.9492073562336169, 0.8961959118614287, 0.9076859576706288, 0.9250166022052393, 0.848179607297181, 0.8665259002860726, 0.8644103590944735, 0.9211469455496749, 0.8694718937896015, 0.905809263771934, 0.8849091899820198, 0.9187891371874805, 0.9306522400836618, 0.8995509081077463, 0.8658984165407836, 0.9465345560874329, 0.9521091015434006, 0.9570214150275964, 0.8764023207652902, 0.9530746428872547, 0.9098049229226084, 0.9037193198763687, 0.8516763589534708, 0.9605978086821503, 0.9246850706784118, 0.9384683167121289, 0.8507007461358183, 0.919516412755964, 0.8757788137593173, 0.8915193883619628, 0.9449624665459602, 0.9567086800954487, 0.972163733919306, 0.8880169991346645, 0.881287092472548, 0.9034096936003074, 0.8214308715455363, 0.8967555592329695, 0.9402849682034119, 0.9498252643237592, 0.884788328939266, 0.8791808437116526, 0.9612545202970264, 0.9234209157568628, 0.879463303594844, 0.9171650277467539, 0.9394299048817928, 0.9448506695984825, 0.9668703397642844, 0.9338554960394155, 0.9468749009128503, 0.9315324296037292, 0.9623710400486911, 0.8281131778023044, 0.9626065653514592, 0.8196284672343657, 0.950898415365053, 0.9293300064221095, 0.9391200353039585, 0.842447328394144, 0.8902443920512446, 0.9561154080598494, 0.9101306906585465, 0.9746692541980837, 0.932518453738306, 0.8973552933256044, 0.9460673101992793, 0.9308961504780057, 0.8905159942941988, 0.8582854074960627, 0.9229459809823981, 0.91453574215422, 0.8939056809593571, 0.8167805970775049, 0.8181742475126923, 0.8478804282285367, 0.8824681706766513, 0.8645220619739117, 0.8962627956092357, 0.9073030275679626, 0.9299155840438922, 0.9621499774202846, 0.9388359583440138, 0.9429756162645246, 0.885392146871821, 0.8327184362157878, 0.9571377831593451, 0.9464152030319397, 0.9026802219541257, 0.915804702735783, 0.8871391402941424, 0.9372719294356794, 0.9452404601401114, 0.928510632095142, 0.9243957698888172, 0.9378186159397157, 0.9137523917478063, 0.9634797569684312, 0.8882545697201636, 0.9455985521083884, 0.9047256546771467, 0.9501972023926509, 0.8695678741435356, 0.9186175951992948, 0.9296170472800386, 0.9101115274785073, 0.9403405646552436, 0.8665112634976493, 0.8819313431150739, 0.9424852855016397, 0.9645431577045085, 0.941963814729303, 0.9114003791150216, 0.9473773926012103, 0.9539019996542037, 0.8774799108031293, 0.9694870348758575, 0.946274123656014, 0.8505358516452074, 0.9370866139135697, 0.8843544153154662, 0.9344047731387558, 0.9105940018966012, 0.9242175787863913, 0.9629558831627398, 0.8736486349673817, 0.9533930027737523, 0.9627226877784224, 0.9433416841178048, 0.9498367684073243, 0.847608196921789, 0.9677350564278419, 0.9636887736641961, 0.9471568552461394, 0.9107404193019889, 0.91575949146469, 0.8868940043214251, 0.9289608441710504, 0.9716878744933559, 0.9241434569279536, 0.9594727320531831, 0.9492985885488663, 0.9080760073493479, 0.926891279800387, 0.9010337944658559, 0.8552124995963148, 0.90205359858725, 0.9481695205242825, 0.9369993407040456, 0.8865643090312333, 0.9474251288982636, 0.9031020021495172, 0.9002767931236878, 0.9501041262551413, 0.9510978230687013, 0.9500189590571275, 0.9373162105568046, 0.9033399783208867, 0.8799877323129544, 0.9330486314391931, 0.9245804348154723, 0.9124635723247245, 0.8938301161099541, 0.9438059434636237, 0.7901542444887639, 0.9434407629799152, 0.9790260609814296, 0.9081184810692478, 0.9418097219600008, 0.9311797503536354, 0.9479344502460176, 0.9770550480233787, 0.9244795771698473, 0.9308705159781452, 0.8831067115498867, 0.9007188915077987, 0.9554166082395097, 0.9163217235476393, 0.8784904137908549, 0.9489198479715512, 0.9505480804461955, 0.9464181500209881, 0.8727279292937489, 0.9590599955611774, 0.9032930355439291, 0.8615355033247664, 0.9004049519799411, 0.9299628783369296, 0.9037582047919037, 0.9398683650939603, 0.8927207373098061, 0.8783169037351092, 0.9321169926570385, 0.8674178282249232, 0.8728285225042767, 0.8377371831120077, 0.8665045681260537, 0.95584220512026, 0.9317619814120984, 0.8542682205319562, 0.8768274402804973, 0.9192746499633859, 0.892225511623974, 0.9187312011141234, 0.9427361858309133, 0.9720540146981245, 0.9663694753554622, 0.8984093743734267, 0.8945472834370214, 0.9490545416874755, 0.9172983901913101, 0.9045019519839511, 0.8569307866678801, 0.8155926694577484, 0.9350605420743291, 0.8984507939933395, 0.9339294970705053, 0.9258157390791563, 0.9108457739211633, 0.8744154571825575, 0.78960329501887, 0.9132515982624234, 0.8962543272434896, 0.9039272810754551, 0.8962861818907268, 0.9373772012626309, 0.8962822599040965, 0.8435551829143484, 0.9219022705889266, 0.890730772250688, 0.9052252946696755, 0.9235443524240861, 0.932256001636512, 0.8909040137077416, 0.9593902873608097, 0.9549189359527099, 0.9411914581062442, 0.9129808266894054, 0.9108199841508199, 0.9273463129637711, 0.9573084003522703, 0.9053966096828306, 0.85782172979384, 0.92680232561359, 0.7287178759018056, 0.938987413975437, 0.8955161031284041, 0.9429023978609723, 0.9685178237050103, 0.8915138145677497, 0.8974504615867244, 0.9109939027730559, 0.9281137357862854, 0.8992076484103007, 0.9471533091236878, 0.8498334285865876, 0.9485509563232662, 0.9477033968746641, 0.9465989240272334, 0.9554703609892747, 0.8350209883148128, 0.8570169998911952, 0.8714949407709216, 0.9143824168241834, 0.8927256036846152, 0.9013175493346114, 0.8970990001963821, 0.9598921878709523, 0.9309352780634912, 0.8815509686817313, 0.9412766356911384, 0.915602558472007, 0.9478847875873576, 0.8882106938708256, 0.9472873614672366, 0.901296148880866, 0.9278495843350738, 0.932167954961029, 0.9529657744462287, 0.8649665648109051, 0.9534536335648075, 0.9303405091369431, 0.8819871121083254, 0.9040720065883658, 0.8975020976494428, 0.8999592287615823, 0.9428827805977754, 0.9189903320152933, 0.8700937131548587, 0.837559781409939, 0.9356596557319398, 0.8914238385825751, 0.9511654849560567, 0.9293899699628336, 0.9389504081645037, 0.944188746197952, 0.8768898750610601, 0.9678116036360971, 0.9369128504262102, 0.9090224734554222, 0.8381785020099735, 0.8934091536170942, 0.9534110061056418, 0.9200182064725471, 0.9560587068375141, 0.8762470812142933, 0.8886046390826055, 0.8874468504907708, 0.9678215745967889, 0.9221817924835465, 0.9070615057867462, 0.8727742270673874, 0.9544145395221924, 0.7980785010605971, 0.9562440165960278, 0.9253202554608209, 0.9120283402696623, 0.9140365663481876, 0.9157193028089243, 0.9282338328273217, 0.9333575753085562, 0.9095963236026501, 0.9356061881812479, 0.94266307494914, 0.9114553283301643, 0.8744250661643669, 0.9422471363814386, 0.8217074772026548, 0.9101994278853202, 0.931936080535017, 0.925638591030452, 0.8624834388931977, 0.832125700050939, 0.9542206512913324, 0.9606363402808552, 0.9521633005539665, 0.8985829768914998, 0.9324384682310236, 0.911845618739435, 0.942052540125589, 0.9191662689138742, 0.9281332437040005, 0.8583503072232996, 0.8595921613100611, 0.8594800614611446, 0.941675752266333, 0.9125133213871048, 0.9735105806219886, 0.9468750508937613, 0.9433949528091701, 0.9422657476575446, 0.9106920648247365, 0.9361625616559734, 0.9162681655044216, 0.888548658424436, 0.8670924825160817, 0.864890571722698, 0.8705224543588231, 0.7947941375722106, 0.9488541263580857, 0.9616631711034909, 0.8478332476450581, 0.9564431437690749, 0.8573996794449122, 0.931041520898635, 0.85544354960824, 0.9536342214106999, 0.9132514762375238, 0.8581762967508006, 0.8260941441686465, 0.9058876693570677, 0.9457404436882346, 0.8804652375836366, 0.8813219948374831, 0.964101475062103, 0.8649157290153617, 0.8799749042144848, 0.8390889242586932, 0.9515415453432476, 0.8770725690603587, 0.9281987474670144, 0.9384580783872877, 0.9443746297135862, 0.9370433430078315, 0.9582191208805784, 0.8942067499543327, 0.9631944937538061, 0.9025300197227825, 0.8967691251720109, 0.9123965097320574, 0.9755440272529508, 0.9172624487537658, 0.9657342683927609, 0.9526209822040173, 0.9073065088529438, 0.978174650139496, 0.9639762627197374, 0.9678663586036356, 0.9355676367638699, 0.9289789329527115, 0.8917085453566168, 0.9329961693563279, 0.9674254684785906, 0.8794205009634288, 0.922902774649739, 0.9514364423584801, 0.9056320410338792, 0.9573694838283544, 0.9583279101380677, 0.881108760929787, 0.904251578205352, 0.9166807620460251, 0.9322729104495127, 0.9650385108730705, 0.9432821415341603, 0.9178737156359056, 0.8303533250499979, 0.8690577797964982, 0.9000560841360925, 0.8876988837087731, 0.8446205814867873, 0.8628885962483948, 0.9415749732966051, 0.9411642611206044, 0.9040637518169905, 0.9247654641506344, 0.9246760029886325, 0.9040533849950743, 0.9380538412591315, 0.9041918642247522, 0.9367301244211319, 0.9373886840691134, 0.8882068477797859, 0.8977520883806694, 0.848762432617584, 0.9037122178268927, 0.9085634604750387, 0.8852068928919482, 0.9417580287151955, 0.869767756627016, 0.9459330597425638, 0.9097692055071103, 0.8856403620350942, 0.8890278514094343, 0.8891720679736921, 0.9500693653712504, 0.9463685270141048, 0.9773513668790242, 0.9465804523346963, 0.9499540084661229, 0.8980308191929924, 0.9011528949135427, 0.9765668374030048, 0.8865673608182507, 0.9135064149469347, 0.9037736938235007, 0.9020670609302394, 0.8088435930961413, 0.8896775771381797, 0.8551048295094342, 0.9700810448890385, 0.9537305644433237, 0.8690216700537243, 0.8635815181765073, 0.836441446613264, 0.967556237435322, 0.9410851372006965, 0.9277467789153038, 0.9283636044032171, 0.9587218621920026, 0.9641672010148689, 0.8874426171260812, 0.965577967269797, 0.9721905998716742, 0.9262534228439127, 0.8536393630485795, 0.9378573531044714, 0.9417405615989016, 0.9129256563647031, 0.9499411301923062, 0.8754173111520461, 0.9439442150877944, 0.910879396151242, 0.852050955156226, 0.8944561346450497, 0.8808777467064619, 0.8858576317497829, 0.895582021684622, 0.9210154639881807, 0.8528995199238443, 0.9284720322791614, 0.9400984558030121, 0.9234817055192859, 0.9426530048095457, 0.8260766880936077, 0.9429864701500204, 0.938329755614844, 0.9509389673110917, 0.9356859860156117, 0.8564928950741161, 0.9338288227992513, 0.9159462407558925, 0.9026166955679049, 0.8896436914195304, 0.9049903614865779, 0.952738460549948, 0.8950902611736538, 0.9437069581496307, 0.9166128150219237, 0.9431855014174612, 0.9682872214216489, 0.8924064481073789, 0.9544916877330287, 0.9444241558434834, 0.8118292591153191, 0.9508822502039026, 0.8829889601766785, 0.9339615054666104, 0.8835207414619518, 0.8992675843251099, 0.8460103222323531, 0.9070333661396232, 0.9236658201887822, 0.8241693284723728, 0.8857397697886443, 0.94988573150084, 0.9019742496236264, 0.8325625295790812, 0.9064515080638083, 0.9152119158075405, 0.8857789432103597, 0.9484708570216662, 0.9681535304350626, 0.8862924929272767, 0.9484251213611878, 0.9436824307559705, 0.9394372139098985, 0.914936417566095, 0.8402571456259265, 0.9413398901766847, 0.8981349121564528, 0.9385039300573808, 0.8874394308369828, 0.7982521661701503, 0.9590297013667752, 0.9221616936967996, 0.9264749837087383, 0.903706812818465, 0.9427766034076615, 0.913297253331593, 0.9118447848389818, 0.9340715712536536, 0.9460629282236993, 0.9341662440027194, 0.8556383368611334, 0.954920453200851, 0.88016252850116, 0.9425589996313215, 0.9122775161197255, 0.84431103805921, 0.9092972060103225, 0.8170204459482803, 0.914657934669955, 0.9257653072019818, 0.9018325945133959, 0.8772958176788326, 0.8796064857538965, 0.9471301596896093, 0.9762846584453119, 0.9213290215896073, 0.8601024657805783, 0.9475420989915033, 0.9094626397342962, 0.9136675081609713, 0.9020634847542509, 0.8035468176501641, 0.8660290206243098, 0.9712967282319184, 0.8303718534720472, 0.8128757062501009, 0.9654006293007622, 0.8231390941638749, 0.9308495859298114, 0.9390143080854239, 0.8655805050883114, 0.9590210736681712, 0.8660630706120285, 0.9044559438595896, 0.9549929886559849, 0.8435150239062486, 0.9633431563600181, 0.9257433317219425, 0.9496181759697143, 0.8846525924621929, 0.8565862630295125, 0.8901240193856007, 0.8581853153205381, 0.8965336716643251, 0.964913438070186, 0.8932117249343788, 0.9350760359372154, 0.8201982663513911, 0.935508710544348, 0.9232232248065768, 0.894926774785902, 0.875729883394373, 0.9308251812012514, 0.909529979180647, 0.919555156164359, 0.8950600185803106, 0.9629851646070784, 0.8190611730682156, 0.8885321350923474, 0.8989908655431059, 0.9272936814967897, 0.9449739531518284, 0.9420512936409431, 0.9493393674844794, 0.9382275752439072, 0.8870585273960452, 0.9200512637345388, 0.8936860216814831, 0.9602352273445646, 0.9128302404073987, 0.9086696041424618, 0.8514739772032833, 0.9370254986794475, 0.9260543234556625, 0.9018018062222473, 0.9447206227107312, 0.9582900204061133, 0.9007501095948506, 0.9004181157722477, 0.9472155363400824, 0.9242318541811669, 0.9287915094810636, 0.8968272814040852, 0.902998471912426, 0.950895724340119, 0.9414395195386789, 0.9534090048799799, 0.8794200577754441, 0.854162276418309, 0.8813218112088352, 0.9255410957450747, 0.890607229694541, 0.9178332309827848, 0.9192230708484521, 0.9484908312225007, 0.9347523803752974, 0.9226789745333359, 0.8016866783302677, 0.9044789802586357, 0.9230643831192139, 0.9358100730862466, 0.9542777199345505, 0.968385184424131, 0.9467150958934353, 0.9372999109657417, 0.9208637639409765, 0.8585426113076382, 0.8964335569657345, 0.9117875119465866, 0.898551121183248, 0.8664965437415306, 0.9451492833257863, 0.9292038802789975, 0.9528315759956516, 0.9159198600606113, 0.9377996220378494, 0.9091402048127901, 0.9282503032851563, 0.9536088316626061, 0.9209861556888475, 0.9061555981695643, 0.8628310307161449, 0.8987707063516523, 0.9332371016131163, 0.8994705057566139, 0.9146212728667339, 0.9564089607364203, 0.9094427017182529, 0.9628716766578477, 0.9538834559743546, 0.9210670646234389, 0.9076015352067315, 0.8613706871150335, 0.973370675050173, 0.9639951190198945, 0.9024086396633166, 0.9677512588233701, 0.9290599156748419, 0.9193218033570613, 0.92377840935399, 0.8973976793534487, 0.8981774911670888, 0.9484043224397936, 0.9296265350469465, 0.869155584020053, 0.9387761698454715, 0.9303889822547731, 0.9218036868000798, 0.9312732747403052, 0.9712301752166074, 0.9780526523901695, 0.9373834481149315, 0.8986547589888028, 0.9231374081676706, 0.891203371157569, 0.8884236195258955, 0.8847583798334158, 0.9089598670711009, 0.8997453269986675, 0.9448435248659965, 0.8949441824438578, 0.9529676537266403, 0.9329611158979267, 0.9216217694580854, 0.9410978851300467, 0.9367991587695608, 0.9132330080960678, 0.9633927950324219, 0.9339003753393805, 0.943792157995951, 0.9135675881683666, 0.8642824624349079, 0.8841583930547225, 0.9720872617092748, 0.8814710571149356, 0.9119915071185023, 0.9431098687098817, 0.8496158332283339, 0.9390410920355103, 0.8520337517284398, 0.9484806126371228, 0.9182940657456915, 0.9453546074589033, 0.9058232283437102, 0.935998080097065, 0.8684918400536435, 0.9193995208692678, 0.8979673650519733, 0.9592738836863266, 0.9309743278775122, 0.9211644702602448, 0.9163223232911462, 0.9127258688698285, 0.8335853240195854, 0.8638157825338966, 0.9405766640555968, 0.8433401977995649, 0.8629955108914569, 0.9290237054595067, 0.9393358264300775, 0.8983066085156652, 0.9103574403193657, 0.9246950836942563, 0.875441259103568, 0.9453779522280903, 0.9704166870843122, 0.9318601674594682, 0.9517308517802214, 0.9511958347711259, 0.9510975867724509, 0.8848859927684376, 0.907085074758088, 0.819308862820195, 0.9332647104679372, 0.937241115024733, 0.9709515433613479, 0.7696403348205384, 0.9473327229751871, 0.9352290132963521, 0.8668130815708939, 0.8911352913098372, 0.9755259487104145, 0.9241014403443131, 0.9593334473477013, 0.9594417033379772, 0.9154660087279018, 0.9229941642946224, 0.9334029505658301, 0.9534813435623262, 0.971400981149678, 0.8609846633287982, 0.8953056492433562, 0.9093748360554612, 0.9553311841369068, 0.9162695031204322, 0.8966878795253561, 0.9265153766856209, 0.9564877972241353, 0.935315422841932, 0.8834774213862087, 0.9672480660876956, 0.9641366666624174, 0.9526191466153177, 0.9401201857886133, 0.9801841735851582, 0.8550971519035095, 0.9461847438832891, 0.905761342580576, 0.8844552809712972, 0.9304643476809534, 0.948263421290406, 0.8793546598427308, 0.9579954028758302, 0.8460792190064161, 0.9421417203730751, 0.9285642374202779, 0.9272835926888685, 0.9138156737805581, 0.8944560179878215, 0.9289053401481657, 0.8599532745779697, 0.9446117812693988, 0.9082319900210079, 0.9272081032237506, 0.9097086175498423, 0.9727591015516028, 0.9218385692052838, 0.9495293745798548, 0.8970806784103962, 0.9670992674136858, 0.9650386215071491, 0.9653466808922065, 0.9376135763806313, 0.9256244956589792, 0.9569178587985306, 0.8880048793872973, 0.8558655270565383, 0.9493502658231384, 0.8598808599555126, 0.8008553194033967, 0.9131804734835436, 0.8497249055424928, 0.9306550977696582, 0.8368707414441343, 0.9323508933758469, 0.8100814676787976, 0.8642527282925687, 0.8023605174473903, 0.8372098008408021, 0.9550757505887689, 0.9355534474142868, 0.92293562033674, 0.9780820325053273, 0.9247792806703942, 0.9196648230863279, 0.9246874608408069, 0.9106665190908818, 0.9307804561463446, 0.8925518554240521, 0.9422121561715172, 0.9324402210155744, 0.9784651285764447, 0.9219700819939891, 0.9430286499588737, 0.9258992207925218, 0.9042269661144691, 0.8789170608608654, 0.8265021421576279, 0.9262452553793843, 0.9298397813888049, 0.8809409986815487, 0.8952287100714886, 0.9066142366769611, 0.8898660773722779, 0.8701765457635401, 0.9493091119028587, 0.9284593336250047, 0.8727602877587173, 0.9027614572219755, 0.9379768307447733, 0.9457619418449317, 0.9161013383699341, 0.9299983077225167, 0.9073792032095506, 0.8972436067810388, 0.957539288211897, 0.949370210960605, 0.8962184544492521, 0.8389792829539335, 0.9463844465446551, 0.8809957779697025, 0.9133164254742986, 0.8839798922348283, 0.8960006743857529, 0.9340216237682425, 0.9556124786522263, 0.9172302559611154, 0.909320592074276, 0.9665310086687106, 0.9621391030176895, 0.9485398300379502, 0.9223186259309664, 0.8471847827653312, 0.9540644120574766, 0.9496709637424069, 0.9514778298243055, 0.9291814131283771, 0.8416411203265828, 0.8113012867489119, 0.9389064610281432, 0.9516000313687016, 0.9437537430343611, 0.9180683617557069, 0.9418700963211608, 0.9487298872169254, 0.9509643140089116, 0.9201776912565561, 0.9503819117871014, 0.8959992855745164, 0.9259998003981662, 0.8693095686194752, 0.9091759423240462, 0.9148907743519151, 0.9437546017968927, 0.9564776088775802, 0.9461899683105045, 0.8760673311484923, 0.9723851918312683, 0.9440060300229327, 0.9071736296152559, 0.8522854087249474, 0.9372310884044815, 0.8778872359021719, 0.9387625997215605, 0.9582312050198021, 0.932065680357178, 0.9281504432656089, 0.9106065377619923, 0.9342023500444943, 0.9662826922568166, 0.9492305692380072, 0.9458712242748625, 0.9393427456957045, 0.8510978106064396, 0.9435965210405678, 0.9303630993881697, 0.889851500126688, 0.9095766947342233, 0.9101929689284818, 0.9770353678812587, 0.9009895691809189, 0.9404058387933881, 0.9032920572551886, 0.9419591698885116, 0.9132304581942177, 0.9092780567508646, 0.876871786042493, 0.8808425251354818, 0.8637425394857124, 0.9059054128779319, 0.9000885213893952, 0.9427294133202253, 0.9224950689485657, 0.9578714064173539, 0.9678404256776858, 0.9586886075864804, 0.9340173085211831, 0.8427524753891098, 0.8957872679877946, 0.8811564033721841, 0.9199625640018751, 0.9352210384034296, 0.976061244373516, 0.8571428017417566, 0.9537576448785533, 0.9522396129812852, 0.9410970182681363, 0.9724770008553707, 0.9112770937761798, 0.868501596058771, 0.912309634763474, 0.9495439508254635, 0.939655477141569, 0.8615497346870795, 0.8588635803694308, 0.9407672604475561, 0.9259455560894008, 0.8821632585718722, 0.892336124701033, 0.9216648232154665, 0.9053741520261788, 0.8820965383341879, 0.8646922875978174, 0.955477469557249, 0.8810811946919345, 0.8937144623151713, 0.9018817324052602, 0.9426565613288469, 0.8728392940297125, 0.9446533438240485, 0.9245799747496428, 0.8420761959891745, 0.8378340052004646, 0.9658888420187937, 0.9392486269448114, 0.9356205146359992, 0.9255078367307807, 0.9227552800204328, 0.9545627279965925, 0.8921330688941673, 0.8953268535232671, 0.8982355301293169, 0.9377998436005561, 0.8763089370269934, 0.954003513332203, 0.7969495801926536, 0.8570784467864413, 0.9178165195988068, 0.9304994971666467, 0.9396266813999854, 0.8304351014048449, 0.8898741111039012, 0.9598661416537193, 0.9146943000704122, 0.9503190373392806, 0.8925411153427845, 0.9372351244805871, 0.9585942169426787, 0.9247121668965622, 0.9372772140904583, 0.9413206805415139, 0.8932229425239633, 0.9535770731174045, 0.9686406958114633, 0.9468749586451644, 0.9018436172154406, 0.9025001998259257, 0.9371915710374455, 0.825551322068777, 0.9390107136777551, 0.8874512998035715, 0.8125760910162939, 0.8797078629020918, 0.9482113894451892, 0.9738342446231776, 0.8654028920707675, 0.8926439643837648, 0.8398102174809385, 0.9565592032848209, 0.959254272109838, 0.8934181248086803, 0.8931905504359563, 0.8849636752511558, 0.8955819253133293, 0.9358770797976852, 0.8478590277394896, 0.8962343034155833, 0.9426498403302079, 0.9115209758098823, 0.8655468731395534, 0.9450772454591614, 0.8896438412474967, 0.9049537976485023, 0.918838080605932, 0.8979155626054556, 0.9080576341833013, 0.915349638066772, 0.9391522757163164, 0.9345284150912736, 0.9497433639527586, 0.8877719640581516, 0.9347513730169615, 0.9661472774315998, 0.9456306645966875, 0.9151218698529417, 0.9577695274693988, 0.9588697931850072, 0.9026682892978044, 0.9591937209565329, 0.8733031401480065, 0.9202606776438099, 0.8972158543221972, 0.9510397531932395, 0.9120537040653367, 0.9224020793663608, 0.8695544526552268, 0.9303505274462724, 0.9612661902331586, 0.9388615329450953, 0.8821674006737747, 0.9307130716302374, 0.9801865998546254, 0.9546768987194313, 0.9255651439973585, 0.9184036094398066, 0.956491440529041, 0.9119663991547045, 0.9063462040734607, 0.9372282520866324, 0.9290138993316478, 0.9709467245187404, 0.8535737349213048, 0.9385723628241145, 0.9517724834563881, 0.8743629883939895, 0.9356164632989294, 0.9676854885342929, 0.9433802866004668, 0.8634458075492413, 0.8553434920357661, 0.9727267991126562, 0.9075049336365871, 0.8900550980622561, 0.9157625885076819, 0.9032010707562619, 0.9213379783009673, 0.9384617427486437, 0.9041631514387494, 0.8942729002857266, 0.8862021913295401, 0.9067139686473613, 0.929746236476831, 0.9291221277012269, 0.9638278563997431, 0.8731816846252298, 0.8655295831672399, 0.9341626994041066, 0.9480932787167087, 0.895147972552444, 0.8629403067762055, 0.9366129094973942, 0.9059441430990649, 0.9592491807141833, 0.9011445986313422, 0.9393448317496358, 0.9524213162728669, 0.9650418044702554, 0.9419525083741733, 0.9618762794832979, 0.9403870396586524, 0.9172348144782667, 0.911224762642284, 0.9553957690414707, 0.9262979029755789, 0.9794237309646149, 0.9512895665090004, 0.893481585344152, 0.9587627776598786, 0.8836560164122912, 0.87012093722289, 0.871901812180102, 0.8432031276349349, 0.9427501419365544, 0.8103194027856708, 0.9528628608837298, 0.8695752880624383, 0.914144760477999, 0.9253623362564353, 0.9692780451367147, 0.9695000940276401, 0.8937367315086728, 0.9303261877332303, 0.9547778210114232, 0.974800627270993, 0.9305125349024006, 0.9488511078303914, 0.8802134002653517, 0.9576044458483052, 0.9551005590926188, 0.792670804872943, 0.9269264128974056, 0.9014282728832013, 0.8894094517491715, 0.9626427454165495, 0.9632293536893677, 0.8624016752164241, 0.9342481134306015, 0.9651308287702397, 0.934713442688087, 0.7929715724830236, 0.9204189889834501, 0.959367636753902, 0.852718854004392, 0.9489786254776316, 0.8755386479288946, 0.8905268208673394, 0.9260289339221766, 0.9514363780997556, 0.9467797675500574, 0.9140859013274434, 0.8799938767920146, 0.9480502788239737, 0.933333763485245, 0.9097955547808787, 0.9442625185479322, 0.9378382674301957, 0.798243331646972, 0.8765029939205196, 0.8776586386936984, 0.8957639196735652, 0.8953572985559957, 0.9088474567558378, 0.9510188894762426, 0.9054643267368715, 0.9573803728034059, 0.9220973855336363, 0.9581451337211612, 0.9396755035275242, 0.9454245919873014, 0.9240131072110773, 0.8861525089254683, 0.9258374287901715, 0.905694409560077, 0.9175864516449773, 0.9186260093833104, 0.9278027648748913, 0.8756268434820383, 0.8683167735195704, 0.8673559016813086, 0.9554556095693701, 0.7988033387108222, 0.8933970873929489, 0.9045300176052449, 0.9410610656980869, 0.8696062764169479, 0.9180455158313011, 0.9450935612558305, 0.9060542108989436, 0.9207319653214432, 0.9288656162549578, 0.9519225867988028, 0.9556018653859172, 0.9210790556899611, 0.8767153362213898, 0.9262506771067691, 0.9538222577014017, 0.8534682083938478, 0.8812803007385831, 0.8870898216723286, 0.896500163444871, 0.9512991198125182, 0.9120491100449157, 0.9468755403993913, 0.8603194812235692, 0.9191824224606789, 0.9614394021279687, 0.9425845531366521, 0.9004774200365081, 0.8414158633265685, 0.9520855288117047, 0.9307076865171422, 0.9252322902246144, 0.9339546592533738, 0.8850405007214404, 0.8489200493797837, 0.9605738153431406, 0.9310528115436336, 0.9560222951657846, 0.946457865063748, 0.9045040209698398, 0.9075104438542265, 0.9474313756522299, 0.9462963884321612, 0.8615778978970479, 0.9072049812670138, 0.9483882553079497, 0.9032142596612048, 0.9600531357492865, 0.9301865261521156, 0.9082648750975115, 0.9291975314016443, 0.9612111820683606, 0.9092569548888945, 0.8830615238261851, 0.9512764359261765, 0.8836205598148479, 0.9361281034670712, 0.9520787189717954, 0.94319079425042, 0.8944921362276237, 0.9431370383245697, 0.9086203134762836, 0.910463406997396, 0.8774012380311919, 0.8581865173366984, 0.9535549998972379, 0.8276924658622624, 0.8665067705700068, 0.8561904157604571, 0.8977591916186738, 0.9229410639108019, 0.9062678714901501, 0.9515940376898049, 0.8993113894058906, 0.8476336069942063, 0.9707240286117211, 0.9441388691422985, 0.948415887287992, 0.9333836504082383, 0.8961963752809792, 0.8939395988163727, 0.9170848802997777, 0.9289351261716298, 0.9548039150567669, 0.8865271483816022, 0.9263690638961269, 0.9036998369292082, 0.9813670757947098, 0.9209529908636002, 0.9304054820240769, 0.9476369578098409, 0.8893744125760894, 0.8996223686944954, 0.9581716031716221, 0.9728798176362242, 0.8780380496439619, 0.9118511130877052, 0.9040909593656725, 0.8592682796270178, 0.9611119134750282, 0.9031719464708653, 0.8829432710355135, 0.9416527653873212, 0.8744555957031556, 0.8818519403263496, 0.9396736851635716, 0.9172359816670144, 0.9512876496478488, 0.9245946894066809, 0.841962869372366, 0.8918750602906038, 0.8727934917791148, 0.7764275982819249, 0.8678537523733894, 0.9600478006512061, 0.8926122051835474, 0.9541458513977057, 0.9189892923585938, 0.9623138601198797, 0.8801001597100755, 0.9562408601105288, 0.9545108218114443, 0.9572721839185199, 0.9326884836250791, 0.8937993081120617, 0.8942188354529117, 0.8894724419809027, 0.9385037622123031, 0.8692865358106034, 0.8732332060520583, 0.9153461073522732, 0.917835171392909, 0.9584082665681807, 0.9575178327968459, 0.881614154904113, 0.9496950470111433, 0.8782634870570145, 0.8982749408810096, 0.842902456732006, 0.9382991853742609, 0.8631449124038408, 0.9131361406597315, 0.9047347584939625, 0.8604404016027553, 0.8878981233850545, 0.9374452106553858, 0.9268816584560344, 0.9043581375161841, 0.9070621607968413, 0.9257753770414268, 0.9033228984315352, 0.8928015908785865, 0.8941850518783111, 0.8850383513732474, 0.8958719031292818, 0.9730184384287291, 0.8838515184037143, 0.9468949656738028, 0.978023760800276, 0.8202246247939033, 0.9073477199808898, 0.9387785737715703, 0.855300712682248, 0.8609407568679048, 0.9089553665681873, 0.9332989968290318, 0.9205431970754624, 0.9311077716801202, 0.8619846677324098, 0.9638977433998842, 0.9517054877381514, 0.954585142846061, 0.936692417082812, 0.9488898523583742, 0.9576568401879453, 0.9511355607917702, 0.9244742036172742, 0.9350089023033006, 0.9143493364726354, 0.9454144624365568, 0.946364183081586, 0.8893537027773198, 0.9169751610584413, 0.969014520809103, 0.9267109672200108, 0.9717738340456139, 0.8805722468512476, 0.9308221580847638, 0.9325513963850218, 0.8519678816277438, 0.9476084109138158, 0.8589769574807293, 0.9597737980557193, 0.9126525916114197, 0.920080843630448, 0.898118991959321, 0.8267582989750375, 0.9080535449192462, 0.8750515388292642, 0.9563723975126559, 0.8790690767414657, 0.9343691235312255, 0.9330852103594705, 0.9239227713229461, 0.949195853510753, 0.9373158892338703, 0.9106532962561462, 0.7572165115936876, 0.964608484250407, 0.8685840870075152, 0.9299706761217676, 0.9374494761082246, 0.9153690482040882, 0.8424945252351455, 0.8631505436506197, 0.9247031964930095, 0.9284766112958751, 0.8725515033224795, 0.9407512585568258, 0.970924902598834, 0.8451878217826215, 0.9253287916109437, 0.82492497260172, 0.8612574387079603, 0.9110205040182262, 0.8943222396301874, 0.9181862770125402, 0.9114870786911835, 0.9450859826148975, 0.8826500264494375, 0.9586191988946992, 0.852172455577732, 0.895264751238976, 0.888501703508144, 0.8464796461747364, 0.8854184538902187, 0.9039434983874655, 0.9066950372876565, 0.9600743719799225, 0.940106800898101, 0.947249927873282, 0.93863110915567, 0.8996100195016952, 0.9403989418856818, 0.9024656591728285, 0.9670574647561117, 0.821684583604156, 0.9107950625041605, 0.9342151950693635, 0.8927782104545221, 0.9130989868476739, 0.9587624785770541, 0.9339493667644447, 0.8876762976253646, 0.9237246507908514, 0.9333444348792386, 0.8535004432673365, 0.9249365245884972, 0.8921451312590475, 0.9316580963056577, 0.9233115865014472, 0.8832216673299688, 0.9179232928499188, 0.9128056374055654, 0.9780409750614534, 0.9369167097072884, 0.9566151708464872, 0.9131616309450779, 0.878184579558329, 0.9328365285620798, 0.9377842774913533, 0.9064129897771269, 0.9218369642389745, 0.907619542509283, 0.9126871594912185, 0.9084216726483693, 0.9101308777793486, 0.8448969066381145, 0.9092220757658828, 0.8802983613263884, 0.9173464269943277, 0.9015977995077686, 0.921678011239534, 0.9485916523459822, 0.8628786751412709, 0.9505939320371111, 0.8937584498049015, 0.8812641437820793, 0.9320372804058823, 0.9453728116567945, 0.9096092077793175, 0.9468198177233338, 0.9589518541051597, 0.8828895875150007, 0.9298502728181465, 0.957688225498162, 0.9569305088714029, 0.9510455356431351, 0.9566532566687982, 0.9380582632726949, 0.8421007588878979, 0.907434502396152, 0.9573040285842619, 0.8699257933939257, 0.9213688584358201, 0.893533530150152, 0.9410253007579148, 0.9379736254395808, 0.9540109022183888, 0.9616286126530318, 0.9482737120571029, 0.9386289945337261, 0.9127698186163279, 0.8695963583445387, 0.9638681361082454, 0.9395437713239523, 0.9703925246735489, 0.9182421690984741, 0.8379148149324995, 0.9390050719359307, 0.9479413900191732, 0.9287654146765554, 0.8599592316398532, 0.8644518578259591, 0.9046844872712515, 0.9491921022067126, 0.9141734327547736, 0.9576080813580183, 0.9359228085087915, 0.9601426539122941, 0.9265195160875278, 0.9241185527731346, 0.9496665291673613, 0.8956272130685198, 0.9346611065553337, 0.9438237245684491, 0.8765365563271513, 0.9445117346615184, 0.8995210720286871, 0.9037854570450949, 0.8960033944779183, 0.8431784381836737, 0.8971121038617921, 0.9013654200123886, 0.8647968668835413, 0.9110762536131748, 0.9463384682985391, 0.8475736588352987, 0.9522684049651391, 0.9487344971272915, 0.9054091154463905, 0.9056769347149242, 0.8425079786163625, 0.9213360408874889, 0.94409656168168, 0.9481223721278077, 0.9043567248552365, 0.9056192757029284, 0.9316085637629213, 0.7456593122008985, 0.8749444327617327, 0.9563178882756826, 0.9114489882013518, 0.8758170474844629, 0.9527127582082584, 0.9241596659674232, 0.9428525875290776, 0.9117644880013718, 0.9061089326775897, 0.9702442456231206, 0.9426737426094978, 0.9667858790001876, 0.8366197188716404, 0.9458920459688333, 0.8910279987165626, 0.9468269845226922, 0.9024676770272841, 0.9318110801482566, 0.9043938376845826, 0.9494164018850048, 0.9601117790949949, 0.8882135093969583, 0.9470292926866065, 0.9294373538312446, 0.8743697505783157, 0.9147649801995804, 0.9147662815404001, 0.8659881790107022, 0.9111270650799205, 0.9132310188540386, 0.9137896563211747, 0.9478567457871458, 0.9472343424489547, 0.9579234360637309, 0.8355992311533886, 0.8890947514210907, 0.9701426203168053, 0.8934636242587002, 0.9095329610594511, 0.950151776920992, 0.9524568118063905, 0.8970083713445866, 0.8932782947916258, 0.9420880348406234, 0.9072716678297044, 0.88810311852736, 0.906366020734946, 0.9524791864285507, 0.9282704607639505, 0.9093130188797671, 0.9355226029445649, 0.9549846359088439, 0.899879326847475, 0.9567872513390538, 0.9620619400701613, 0.8999801035682755, 0.8883507344978342, 0.9358333625415468, 0.9602098384795891, 0.9617424722560897, 0.9387566682327543, 0.9369642645421246, 0.7828225013426025, 0.9463606055802171, 0.8742725934626072, 0.9375078520220147, 0.9274455808242021, 0.9323174618785303, 0.8684544283102921, 0.8880389472932861, 0.931006129048021, 0.929977286609555, 0.9399462971914858, 0.9178339102612539, 0.8437273068005408, 0.9587874797891368, 0.9385862331450494, 0.9470588268789615, 0.8729927933310315, 0.9678617898944109, 0.8940382571685178, 0.8902969784581602, 0.9229764947596286, 0.9586395811012304, 0.9200770937585332, 0.9116379294650989, 0.8443558177954411, 0.8585385970969452, 0.89031937524069, 0.9217734144836831, 0.9119382851675798, 0.9597035692371736, 0.9574941483037244, 0.8983796290031714, 0.8209989912938299, 0.9486517775341554, 0.9595820054623487, 0.8980662056243829, 0.8952415324072203, 0.957891296539688, 0.918781092503506, 0.9317027501076701, 0.9220678647208986, 0.88005184483707, 0.8956271332416121, 0.9173004465546428, 0.9198622822256871, 0.8700708242433154, 0.955717104657194, 0.9297546813825451, 0.8426898223539101, 0.948694008641904, 0.9449105782605607, 0.9234000261485508, 0.8845737370051485, 0.9439926554469573, 0.8837464175284593, 0.8447069621803023, 0.907415528267727, 0.9147658515402226, 0.8950059518282723, 0.870460425864671, 0.9206031326770979, 0.9314679143540339, 0.8749337829176429, 0.9387992599617923, 0.9242604746492363, 0.95156000981764, 0.8730221782381486, 0.8907081849843763, 0.8648393261555676, 0.8794490451258534, 0.9583042146906824, 0.8835299830680398, 0.917394624817425, 0.9174414104720408, 0.8837332346026364, 0.9028681857247358, 0.8646485837901559, 0.8494860793616782, 0.9609213968207563, 0.9005246246046583, 0.9474401195284832, 0.8793039506578686, 0.8938597030091602, 0.8979169171071504, 0.9200548398277998, 0.940792751572433, 0.901262320515847, 0.945792792483833, 0.9272929526028282, 0.8847406091008478, 0.8931510067109568, 0.925419229461171, 0.9075452030342107, 0.8847236292615123, 0.8774364768905409, 0.8899626227654471, 0.8711644013052875, 0.9546077967060682, 0.9567689382645364, 0.8737595335622006, 0.9407357234909015, 0.8868642268680196, 0.9010254141979922, 0.9127728225240792, 0.8482290904951475, 0.9491373637332228, 0.9127409122829733, 0.8825583278352044, 0.9336541686442223, 0.9389881895765523, 0.884633019965807, 0.9507857581363495, 0.9158821943188212, 0.9234817035576594, 0.8350040700696177, 0.9431998511786699, 0.9065842391302936, 0.9645938274315551, 0.8389032731011008, 0.9017460717728912, 0.8620941474005537, 0.8990232792666675, 0.8963029741909014, 0.9222046180086463, 0.8602959883599608, 0.9588142517055998, 0.8683987274024425, 0.8932642352354534, 0.903197202015749, 0.8213294152422612, 0.9708586488031692, 0.9477223156643633, 0.846970300252348, 0.876580908878086, 0.8670068490430183, 0.9343862396745191, 0.9657802915787801, 0.8475476464635024, 0.9323725750691179, 0.953838554355487, 0.8231305624686243, 0.8812356978396552, 0.9110637229721057, 0.8844463352696639, 0.9301771631437983, 0.9391547512043008, 0.8781878090185071, 0.9524918662415773, 0.8893841004813525, 0.9204929354566374, 0.9433819892370707, 0.9379366893551772, 0.8716592320691825, 0.9001440480402257, 0.8665802158684267, 0.9269752709862384, 0.970645874547063, 0.9692283029320353, 0.8907695934963328, 0.9347747256612575, 0.8473937335062223, 0.8548148154482365, 0.9175426108743312, 0.9624432184749669, 0.9219435851068184, 0.9497147924420686, 0.911218199820039, 0.9756086379531308, 0.93362899551608, 0.9272835576728788, 0.8844471617361787, 0.8707645440865999, 0.9185758490426192, 0.9366584873711605, 0.9444420043266424, 0.8695252286981789, 0.9058541950226737, 0.8956103312908643, 0.8756368402068357, 0.8851214377075166, 0.9137418708499018, 0.9354322553184733, 0.9081537105039985, 0.9610143311183162, 0.9734073231022072, 0.8751153277024624, 0.8652286836303066, 0.84646837392436, 0.9485125470259669, 0.9459318712002902, 0.8644214713138926, 0.905114338399514, 0.9265372225573539, 0.8749751922689527, 0.9649994292339323, 0.9408925211721382, 0.8692103762623856, 0.9498578238737323, 0.9272233581231082, 0.9335467221723118, 0.914903323066875, 0.9132339735155931, 0.9380024835450865, 0.9450666688505378, 0.9553864891624682, 0.9202405216158754, 0.9393491302982614, 0.9596872282184263, 0.8390158454974392, 0.903915215734711, 0.8880729677253599, 0.9016782449920855, 0.8733635648684819, 0.9729191437012086, 0.8899223234452079, 0.9507710865480206, 0.9397693213570877, 0.9248109277022798, 0.9721569491081178, 0.9050464335522783, 0.8545249209076654, 0.945809563137048, 0.8621593696973099, 0.8637562458479017, 0.9403658759893139, 0.942623948765553, 0.9556376032799554, 0.9279722241777872, 0.8844936353299134, 0.930221490646502, 0.8643091464363986, 0.9500252974354041, 0.9418443959578207, 0.940723564310778, 0.9426998976513097, 0.9285866932198058, 0.9062098231631472, 0.8434501851304521, 0.9109148496475122, 0.9373966841689522, 0.9323830008486037, 0.8426911836170553, 0.8544440566212119, 0.9148871021891954, 0.8613194678472857, 0.8633916935949941, 0.935980934339645, 0.8380638418032409, 0.9159984153094116, 0.9429732153151934, 0.920852107862638, 0.8771196211054832, 0.8816561120408426, 0.9226466692492337, 0.9534397676226036, 0.9141451596709564, 0.8819137475951337, 0.9362830444688759, 0.9105852335765732, 0.9482442035253793, 0.899330418043677, 0.9366228045672971, 0.8523537011416902, 0.8672650176160848, 0.9064050691647538, 0.9314480412547337, 0.8690330976838334, 0.8935422410677869, 0.9240712475055674, 0.9608358303748964, 0.9257268986711612, 0.9373894090357151, 0.9766757950431827, 0.8487668698385715, 0.9287735348461362, 0.9278203868705626, 0.9531982746272794, 0.8981589693027684, 0.8733172320868221, 0.9160772666967425, 0.8889389715341376, 0.9120751679162404, 0.978992391801318, 0.9306879698128643, 0.9461417284766458, 0.9625959890555963, 0.8470733345625614, 0.9576715990900249, 0.8818203579126753, 0.8781968361399943, 0.9348830689346753, 0.9230571784869294, 0.9155935006480604, 0.9165332805176911, 0.8658634434181123, 0.9477410687290269, 0.8913431041747386, 0.8910415139574659, 0.9069081743733612, 0.9507157821287221, 0.9217294082013576, 0.9357693124191703, 0.8957867832943526, 0.9747093586377887, 0.9472877317994154, 0.8192719457073356, 0.9488956351539273, 0.8297330391757555, 0.8662381220017397, 0.9115874631586643, 0.8380190010770637, 0.8573963015745414, 0.8205293067135814, 0.8844957587890925, 0.9031920634230453, 0.9284144386067801, 0.8569532460032169, 0.9132507372509596, 0.8918469544140307, 0.9568495419094585, 0.9004987960967926, 0.9274393479155466, 0.9375694625292388, 0.9643741518706059, 0.9044817351626042, 0.9408734849519093, 0.8648519438004547, 0.9656571448485533, 0.9202527801471977, 0.9095582084755344, 0.9577771703976972, 0.9182244216816303, 0.8900661964548522, 0.9405353915818124, 0.869175525317262, 0.9581820438298772, 0.9042746526419541, 0.8486929836467751, 0.958349129513949, 0.8274375046178244, 0.9693924949092736, 0.9333004297144247, 0.9424826554804735, 0.8996275869570202, 0.8754489866840733, 0.868190506467205, 0.9758811019148717, 0.9465829357785839, 0.9637829616525924, 0.9268589977615178, 0.9725449781009725, 0.8889914106779904, 0.9292305004102887, 0.9345424510001032, 0.9655374110988088, 0.8971847219593649, 0.9107950724963411, 0.9407834121681491, 0.9354647053829971, 0.9300040426352398, 0.9422721846409788, 0.8678463056494718, 0.8593412632052667, 0.9135024824125627, 0.9217018082111132, 0.8703606025071002, 0.933233536037702, 0.9389171089344767, 0.9217192263183043, 0.9018460558405245, 0.9460502853119048, 0.9225799920306859, 0.9197647765401948, 0.9298566978674054, 0.8844835302947129, 0.9297939727682961, 0.8850387649256831, 0.9712269967109181, 0.9468096723992694, 0.9398289288585713, 0.9193506594977884, 0.8427068851821503, 0.9270754605063045, 0.9287324864778566, 0.8942833965564183, 0.9152034635275954, 0.9221064504325482, 0.9538322562818227, 0.941161204105784, 0.8756005530741724, 0.9339944955641419, 0.8519246370343334, 0.8984502726875891, 0.9410380448096157, 0.9211120872569526, 0.8768141222883037, 0.9261202567075626, 0.9279719879676542, 0.9059659809601947, 0.9268205933429884, 0.8888609936853261, 0.9182718981499565, 0.9236733220701605, 0.8992353660479019, 0.9599466295240321, 0.906923100965537, 0.8990005571599224, 0.93019184130354, 0.9337575885464625, 0.9352890596375223, 0.9437709074063735, 0.9104475928334923, 0.9543667594714924, 0.8750786691552558, 0.9219446589428247, 0.928252118358084, 0.9546279938701011, 0.9489125639863188, 0.9420665590710497, 0.8874640772895688, 0.9359776357598664, 0.910271147235413, 0.9445249515421525, 0.951906453822712, 0.9315895630165869, 0.9359447176174764, 0.8997925931124987, 0.9147590520564172, 0.9364206876474452, 0.9457255368215471, 0.9732620521947286, 0.9069715721409451, 0.8697461821486296, 0.8733839233066114, 0.8619116991565299, 0.8915097542264467, 0.9383237371212598, 0.9312824853687411, 0.9465200979279971, 0.9239602497600677, 0.9573148195771026, 0.9304154621133398, 0.8226579602190489, 0.9167478831523286, 0.9079970367296073, 0.9611877709549612, 0.9323188356069408, 0.9568430103608137, 0.874488384253389, 0.9299193684867736, 0.896223974026252, 0.8644334159346048, 0.8669564131876847, 0.8720773652991025, 0.9391726707774182, 0.9529733259476008, 0.9053444081009634, 0.9348299900987781, 0.94266533789982, 0.9585513582865801, 0.9441616464299424, 0.909339601714456, 0.8878478111183559, 0.9388233743414796, 0.9125093662470593, 0.8471655329456448, 0.9177626922854926, 0.9526667602460374, 0.9463028368375066, 0.9181916799225266, 0.949345058805513, 0.94082591709568, 0.9434614397271572, 0.8643043224634122, 0.8623833245585626, 0.8850468742676632, 0.8943552450948131, 0.9151102383246474, 0.9510315065782805, 0.90897997759229, 0.9183057123646967, 0.9373726876683459, 0.959403332874978, 0.9796556760849305, 0.8284099296186676, 0.8629552447917888, 0.8667123059099372, 0.9213186191111123, 0.9210561888730855, 0.9666010118460484, 0.8464613465343589, 0.8073894990575996, 0.9814674885028323, 0.9088016180726393, 0.9607450809691253, 0.9121823309653659, 0.8902419964317162, 0.8923808964611278, 0.8261110681232912, 0.8430544602692474, 0.8700004213705039, 0.8640566889904415, 0.9305094732666823, 0.9322212838910349, 0.869419809581871, 0.924109336979811, 0.9075443858625153, 0.9051373010199328, 0.9055912843706526, 0.8959306568604759, 0.9571629630127083, 0.9514686028288738, 0.9049684404574301, 0.9667344801181903, 0.9544470338370414, 0.9408951326816148, 0.9264304931751981, 0.9092982762551965, 0.8781734571443405, 0.9331582893065078, 0.9155918357733734, 0.9717194469750101, 0.9414790216336675, 0.9328555260428992, 0.8900547164260046, 0.889984861367877, 0.9598559179417627, 0.9570171613371139, 0.944312523215035, 0.9348822065563394, 0.9306480856325398, 0.9254470336606404, 0.962854724224621, 0.9551729439888006, 0.9609571169814302, 0.9717680338596403, 0.9196765000163414, 0.8567622883857899, 0.9510609149248994, 0.9612896193790464, 0.7792091080185477, 0.9072104853223638, 0.920437453106011, 0.8792460779433577, 0.9448929647442754, 0.9506270057389451, 0.8717357793999507, 0.8339499743352399, 0.956388942203802, 0.9000933708844198, 0.8794693924319816, 0.9624358964083073, 0.9371837440436867, 0.8854528431959761, 0.9507389765213758, 0.9585868632391591, 0.823107150441865, 0.9004248760466129, 0.8942001950733516, 0.8821961205949085, 0.9476613047329201, 0.9559972064545159, 0.9638173508405484, 0.9031931647098872, 0.9042774443961967, 0.884706177176109, 0.9080499757182854, 0.9068014422332249, 0.9251915068280407, 0.9299876526491292, 0.8464275394777998, 0.8571128750968979, 0.9406959516150074, 0.896882448844958, 0.9420584234272602, 0.9432422555055486, 0.9091195984915602, 0.890550217474224, 0.950169284212517, 0.8724940121665454, 0.8940809003236944, 0.9573596141519968, 0.9443652347216633, 0.9209063561019305, 0.9561551803193342, 0.94813051011351, 0.972420135451346, 0.8154169843773351, 0.8897772693889197, 0.9765798919057701, 0.9214064844840433, 0.882592554133728, 0.9434949071014066, 0.9564757206519096, 0.8820306284483884, 0.9600343629937979, 0.9249173552998634, 0.9169447417603233, 0.9580601405072209, 0.9225651956185587, 0.9190934556220416, 0.8855046851946389, 0.9410318201089615, 0.90452079174138, 0.914242769531137, 0.9617170044321215, 0.9134334391595601, 0.9332772105407119, 0.8298984336154753, 0.907017370804295, 0.9000797886452627, 0.9482487639055774, 0.8819677354587071, 0.9245057175051486, 0.9667967766453147, 0.9227323069840694, 0.8476837271307402, 0.8831460573094987, 0.9135009536130462, 0.9539601607383138, 0.9549797416770001, 0.9093122883012222, 0.9127364019627551, 0.8959912805548542, 0.9492910873805775, 0.8787037433412148, 0.9552800871661241, 0.9334262512998666, 0.9255823428899255, 0.8850845752902671, 0.9374588842833839, 0.8885585653380481, 0.857492323691463, 0.9058344813669124, 0.9113793336920317, 0.880720106019889, 0.9613756217617195, 0.904561017659893, 0.8798899157871403, 0.9159222955307202, 0.9289617652341692, 0.9523924353487867, 0.9509762417556276, 0.8986912389542395, 0.9170679645283227, 0.9337296567396022, 0.8437130601489427, 0.9244052205048223, 0.9470727250466732, 0.9428485073105972, 0.8840888343723422, 0.9744644728034971, 0.9388828862676031, 0.8882993518680595, 0.8364365992451035, 0.9554879929304649, 0.9698100956197371, 0.901958154702547, 0.9421947807556983, 0.9388219662824746, 0.8786463213111045, 0.9553530290532143, 0.9149223684317587, 0.9340476166288735, 0.9181529872825469, 0.9525683778358179, 0.956828522280933, 0.8859074019491984, 0.9405356743168187, 0.884823281763497, 0.9467098173048509, 0.875401871722383, 0.9444111985857442, 0.8704011441544972, 0.9455844588684028, 0.9660990686239723, 0.925300067745352, 0.8843727139866839, 0.8982348926643813, 0.8802304769442639, 0.9249605036764547, 0.9127712528812405, 0.9353713595021675, 0.925414506031853, 0.9426997071619515, 0.8665808777137267, 0.9462633571248897, 0.9323546993969014, 0.9048951428019321, 0.8330901751108654, 0.862070626543116, 0.892515386849732, 0.936732773849573, 0.9308723811651032, 0.9128966878059861, 0.9505731949830241, 0.9583488798629632, 0.9236351080604401, 0.8926129620015848, 0.918054062086546, 0.9753978669397321, 0.8548401106572858, 0.9158564909657312, 0.9286977190438385, 0.8062795236297279, 0.9209402420943517, 0.9443262274559245, 0.9516298942959411, 0.891254440698575, 0.8926336313906342, 0.8564064026753107, 0.9010846514969446, 0.9167873098382067, 0.8616478244795577, 0.9660471277220182, 0.9212593688405781, 0.7602882564346845, 0.881553606560537, 0.8212711297365551, 0.8538605079713179, 0.9341111364899677, 0.9347562618885543, 0.9203874408381918, 0.9350468059919868, 0.9006691486570921, 0.9748652139633518, 0.9374008554303724, 0.9612177075169664, 0.9649284715153914, 0.8823703445785385, 0.9723394620135308, 0.9342143565716894, 0.9420553949195117, 0.8866627121861126, 0.8999344457314475, 0.9580791236838824, 0.8911525832855303, 0.9338917690727836, 0.857061641820473, 0.937617156866993, 0.916377635368799, 0.952986145904424, 0.8900295112680547, 0.8953212696078153, 0.9307389486664304, 0.9563762649677372, 0.9689281198983868, 0.9074102894153611, 0.8813692946114455, 0.9632430936768602, 0.935047474942793, 0.9191596236663357, 0.9087994571766561, 0.9697004351501981, 0.9084859929656147, 0.9353355765432796, 0.9315545528892664, 0.9400761278033597, 0.937062743167365, 0.9615603081433203, 0.933237686782235, 0.9300107617926562, 0.8414001213009933, 0.8587978718480977, 0.9115677187185037, 0.8929547230496513, 0.9091611994340498, 0.918852584662921, 0.9406650242299945, 0.9080659481006225, 0.9119837245186831, 0.924000882289006, 0.8701719115805793, 0.9671718447555628, 0.8903134406509586, 0.8732091037973038, 0.9258104550583581, 0.8967818848500206, 0.9495905651747052, 0.9065663037268132, 0.9678650824256241, 0.9645502844954986, 0.9453876718264826, 0.9119587477683722, 0.9496506949924388, 0.9444296706746654, 0.8380947568785309, 0.8986243091288956, 0.8888351849666896, 0.948679935582951, 0.882384083363678, 0.9451737258983699, 0.9179840975144957, 0.9064473615948835, 0.8608242091150833, 0.8397448400320304, 0.9183971823493845, 0.7118809937234306, 0.8731826094277626, 0.924419135180349, 0.9449010233636552, 0.9192555434311529, 0.9052107913194098, 0.9111235229996816, 0.9505319861975894, 0.9447042226418028, 0.9295042969886858, 0.9021184106708101, 0.8682777922774084, 0.9647765217479701, 0.9470948446166483, 0.973078943825963, 0.8390236755445961, 0.9488727497405824, 0.9436574896910301, 0.9608315396966522, 0.88501419811904, 0.8360290017243734, 0.931308604169155, 0.9619032399032955, 0.9296544159484543, 0.8697685691481354, 0.9534502145792527, 0.8821226249548659, 0.9306774075927677, 0.937094179709383, 0.88407025953931, 0.8436225733042566, 0.917526310840876, 0.9121966295082048, 0.9015763881279564, 0.9410461220407695, 0.92484511673654, 0.8765985427074352, 0.9337028650106769, 0.9561643946648408, 0.8849810333323822, 0.9490148519847521, 0.9395210213300382, 0.9356761047383466, 0.9292851105667851, 0.9143198373120834, 0.9061878311455525, 0.9407707229311543, 0.8833097774176909, 0.9017057046258317, 0.9442444381244725, 0.9144338022987476, 0.9198729408061848, 0.9321936779761768, 0.9154035055153502, 0.9453223551519168, 0.9499153130003399, 0.9151802477717953, 0.9713715363303911, 0.9440327706263905, 0.9420990544661731, 0.9638852457891062, 0.8373124645933812, 0.9280108776067247, 0.8860195916536958, 0.9472657570389859, 0.95918116198713, 0.9609290038774077, 0.861950328669796, 0.9319114184248398, 0.9665686889401628, 0.8295840470525423, 0.9478655107897241, 0.9171109870137635, 0.8854011949531899, 0.965858560655941, 0.9626293529892083, 0.9453048111427116, 0.9051225792977383, 0.9304958207344564, 0.9144215619020563, 0.932091471173902, 0.9428491665192871, 0.9467720287360817, 0.9180297968268472, 0.8991874775731458, 0.9347818295617717, 0.9633636853055361, 0.9543745391544978, 0.9169144944049474, 0.9018010125792546, 0.9285028259873043, 0.9522137872772235, 0.8042220387601327, 0.934332706571265, 0.937029267374292, 0.9341129727149801, 0.9577653753672002, 0.9168023386074342, 0.8754056623097256, 0.9544062462777811, 0.9022367778094755, 0.9144551744841647, 0.9488690565286704, 0.9137121605201137, 0.8851216526649894, 0.9024941054714621, 0.9605436225257213, 0.9295125424409494, 0.8924483890193896, 0.9091196131068999, 0.9541011811983029, 0.9473690419411624, 0.8704482159475341, 0.9089360863746452, 0.9472218377070241, 0.8952561163966138, 0.8490526809133302, 0.9540567152681376, 0.9158513475052938, 0.8754910423691442, 0.9461852579179733, 0.9226074199301793, 0.91656427794181, 0.9578969433495563, 0.9778716517817162, 0.8606531613390638, 0.9199047188161245, 0.916429086511933, 0.9112378957855776, 0.9252716813402999, 0.9723910614309604, 0.8999206056043517, 0.8910589561071862, 0.9733733689957798, 0.9164152084951158, 0.960331947287365, 0.9377392809316183, 0.9081908598903328, 0.9168823994547659, 0.9480399243632321, 0.9500952071109353, 0.9626693863121459, 0.9500694908374385, 0.8482082481871958, 0.9465389915600757, 0.9201149065102254, 0.9032002841174365, 0.9025780241675683, 0.8475911327131299, 0.8866800693814383, 0.9231019433360534, 0.8231408345845684, 0.8927604983576005, 0.9522509111963062, 0.9324974435277777, 0.9147871489224662, 0.9163785154352145, 0.9077218106808136, 0.8689677733036145, 0.9186227818214291, 0.8259540983003557, 0.9523759491316508, 0.8444664572375684, 0.9040847012025914, 0.8267066349168544, 0.9541616205070118, 0.9535702492687603, 0.8742245172138652, 0.8924817448028288, 0.8274650941151582, 0.8809322791024472, 0.9451107650814747, 0.8918842370911145, 0.8898795581188457, 0.9236405662962204, 0.9061590904381783, 0.9335312256748183, 0.9508483031757768, 0.8203381732278179, 0.8366006578423912, 0.900161017618216, 0.8989657170713616, 0.966816098886139, 0.936057321169254, 0.9366745819381674, 0.9048936665285998, 0.8792876953292617, 0.9108205934088336, 0.9424737385734192, 0.9371689614163639, 0.9198204645887207, 0.9516612798917663, 0.9034054607247335, 0.9100115579586565, 0.9143364522704525, 0.8397423309198546, 0.904110052397323, 0.9088904163157495, 0.9462313004421711, 0.838357945411907, 0.8775742174028506, 0.9393733137326229, 0.8798258598618591, 0.9367904809663385, 0.9555082263787836, 0.8409294994901693, 0.896651134292803, 0.8182561312492732, 0.9310174892441005, 0.955442959606548, 0.9171236743367193, 0.908049412197963, 0.8583151552493907, 0.9528441191793714, 0.9112265688303731, 0.9062720290826556, 0.8966787570348319, 0.9347146432684919, 0.9436816338532628, 0.9426088720378185, 0.9253182815485756, 0.926927424254411, 0.9567493255615283, 0.9314293721429627, 0.9023179873057015, 0.8936826183317809, 0.8535160280771946, 0.9710429686872127, 0.8953295754181684, 0.9485574710991218, 0.9128302922039898, 0.8652911538406541, 0.8687620679066012, 0.9737907222403998, 0.8938540311292578, 0.9109439708760069, 0.9187163179145486, 0.8744426977144247, 0.9291793213656202, 0.8632541908410096, 0.9082454425984523, 0.8567259855515914, 0.927183785380122, 0.9060384497787104, 0.9221988098827041, 0.8872017806046735, 0.9144303664059938, 0.9140809640322372, 0.8863383390120446, 0.9117217792241489, 0.9203018014598437, 0.9212703826491899, 0.9470054116906008, 0.9220915559952942, 0.8685425072866529, 0.9202407785000282, 0.790791472500648, 0.9430929719631062, 0.8801525679722657, 0.9205131630572501, 0.8940112064207943, 0.8871620763476606, 0.8733859885927966, 0.9779107323640852, 0.858124086183621, 0.949362124806489, 0.9527181410939405, 0.9408391352153316, 0.9189611593543919, 0.8861438450183925, 0.9558071688759101, 0.9386125381329082, 0.957586650511241, 0.9180876665633673, 0.9218261780753552, 0.8760909517947085, 0.9442482248936248, 0.87051977945209, 0.9557283498352087, 0.8848718815651231, 0.9247784161301846, 0.885862390191424, 0.8324355733840292, 0.9471645220402919, 0.9569856933696501, 0.9336664794854379, 0.8976924437682388, 0.9435062043446887, 0.9276517271984459, 0.9341476196903589, 0.8865501354554082, 0.9589377569474115, 0.9038527818026294, 0.8120771254242485, 0.8594050034310694, 0.9691686584855167, 0.9214552574217095, 0.9584394590375505, 0.9118547376077405, 0.9052586108021552, 0.8830173032751976, 0.8729361910000087, 0.9175171688380326, 0.855298445960734, 0.8174972236791901, 0.9514114913111117, 0.8683771783965816, 0.9352378380338364, 0.8834428595126511, 0.9525129303652963, 0.9419198394373112, 0.9100255556894583, 0.8719101359229413, 0.9521948762081547, 0.9451170337722891, 0.8322347260170573, 0.8775920089087998, 0.77526690744894, 0.897647132535063, 0.9381545183178592, 0.8553085252157161, 0.956584548313824, 0.8986710034388898, 0.9047285812718213, 0.8937848408362119, 0.944734989208161, 0.8576580662575999, 0.8708368413939351, 0.9783282132291866, 0.8629469963898171, 0.9063271002650894, 0.9312532393199874, 0.9538364814645672, 0.9349021021157717, 0.8796599446679392, 0.8690163638342085, 0.9782923275354585, 0.9491732348198049, 0.9149055664469089, 0.958410924549149, 0.9144426181614856, 0.9775489379125162, 0.8928824398215494, 0.8679660717068478, 0.8849312934872906, 0.9635612828767334, 0.9197041696665504, 0.9407204576710484, 0.9270864568004213, 0.9391630162589197, 0.9726179907385923, 0.8255819888252426, 0.9400163014186658, 0.93326109334473, 0.9281697453187984, 0.9386056846379416, 0.9516424166542613, 0.9282559481601909, 0.8885425610542644, 0.9580809446342392, 0.9694192624343931, 0.9417555877419437, 0.8809859133691857, 0.9004772854943173, 0.9648802357245835, 0.912486270412376, 0.9200325613771311, 0.9661501307565141, 0.9293992041924827, 0.9560924387774865, 0.975347047754531, 0.938721611259828, 0.9156749701156622, 0.9289576706600394, 0.9563488620655044, 0.9031211070568046, 0.914670474246684, 0.8595232903700755, 0.9415352124176001, 0.8869240106331151, 0.9619811421477732, 0.9158011779415953, 0.8807706625901843, 0.9567172183127713, 0.957258278922021, 0.9296910471818851, 0.9234867136040379, 0.9722099054967903, 0.936524598332934, 0.9824928824300778, 0.9363973269744175, 0.9482983083861092, 0.9621499724931484, 0.9724721830907772, 0.9514085905386993, 0.8220891644859729, 0.9118390334349955, 0.9150489914432416, 0.9730408518223763, 0.8980868445161749, 0.952496774875369, 0.9032514957350315, 0.9518161586623612, 0.9220117018069537, 0.9439853018166346, 0.8896687787544832, 0.8888483202954063, 0.9559390674335275, 0.8774742081629917, 0.8761272856477675, 0.9183846439165473, 0.8914901444718543, 0.8849771624710855, 0.9631176690935611, 0.9479935345781055, 0.9331097750385163, 0.9182607418333524, 0.9168374315250973, 0.9188615632309677, 0.873065965762134, 0.899165287978537, 0.8499516575719666, 0.9345972513984273, 0.9488372077387719, 0.9395979318413501, 0.8993723910790575, 0.9696339772147844, 0.9591723432699745, 0.8870463156818593, 0.9172897781340026, 0.9453872520367839, 0.9273384504190035, 0.9113497642693148, 0.8594944328958622, 0.9485068822098497, 0.9070564727097796, 0.9195977166087292, 0.9436020331349046, 0.9338056087157804, 0.946110652205755, 0.9429980279489463, 0.9097581335644036, 0.9274032045964307, 0.8692232602703399, 0.9417293519889848, 0.9480618264701323, 0.9477776193694281, 0.8819601185943101, 0.9175275303294435, 0.8447575807529054, 0.8552808860255056, 0.8957047797567004, 0.9054352867528003, 0.8493089822980381, 0.9047000478805423, 0.8944353957432203, 0.9369798068093322, 0.9088671487492339, 0.917585936216383, 0.9073123281041351, 0.8874603476255696, 0.9048332631450903, 0.9107155969156926, 0.9247349582071684, 0.8424542098819543, 0.9382962155145759, 0.8975869548131687, 0.920363713477684, 0.9565411505952984, 0.8929998088553007, 0.9426172702860774, 0.945362074329513, 0.8919460878665775, 0.9307855698633257, 0.8952799239736478, 0.9372921608915359, 0.913614208940472, 0.9626374454813487, 0.9627229207625416, 0.9231344041446976, 0.9289752983176922, 0.9724266196588669, 0.895283021422704, 0.9489786897331074, 0.8819180570567473, 0.9367026632725105, 0.9120579965229012, 0.9748891256748853, 0.8570299187871105, 0.9217159289764157, 0.9212559410723907, 0.9026547951363229, 0.917564207816819, 0.964004477197327, 0.8679183289725223, 0.9524566855967491, 0.9270228670201227, 0.9179036865714071, 0.8857495792047102, 0.8814664849090644, 0.9648871515600898, 0.9312237173427502, 0.9555537247131115, 0.8860235782711371, 0.8902896836002755, 0.9093947209828078, 0.9386817867528768, 0.8911398397605672, 0.9005802539239857, 0.9107637423347448, 0.9204930716236249, 0.9288154110461474, 0.8979986187375791, 0.9231456387445507, 0.8596890782409785, 0.9167571220202336, 0.9137574765149246, 0.9094245118342914, 0.9706430175458305, 0.844009214501436, 0.9247352573089, 0.9069988850349353, 0.9280461673263078, 0.907932329037939, 0.9327927936394805, 0.8843103703646071, 0.9510316240793686, 0.9074041698527622, 0.945528030820513, 0.8901625548134473, 0.9442294889317863, 0.8873036427230951, 0.9405337127437318, 0.9556777929628153, 0.9499508002238447, 0.950000369267795, 0.9103051447602273, 0.8915081361005383, 0.8650031387962818, 0.9306836746635374, 0.8612582373930068, 0.9564490723379229, 0.8594441057472724, 0.8765215656849661, 0.9339321037798425, 0.9175396064347396, 0.913384850256271, 0.9221489577295018, 0.9125969278700075, 0.9364318782240382, 0.9153267602197808, 0.936527089687996, 0.9313219962575687, 0.9161289881192103, 0.9435179455942649, 0.8787603019446601, 0.9324415569657949, 0.8661931317011862, 0.902522309686746, 0.9580152411849813, 0.962780190758548, 0.9486529793301343, 0.9606833674918549, 0.8891380473186128, 0.8218254291084887, 0.9012820484017174, 0.8434781442989525, 0.9151551219364757, 0.8647786125983533, 0.8710093227614446, 0.8363255376769323, 0.9537432939768853, 0.9326234795420759, 0.9285717008413402, 0.9045195562473951, 0.9013351774756214, 0.9591285108714787, 0.9650579805900001, 0.9370105052957033, 0.933006401666471, 0.9445263143360844, 0.9196872382848771, 0.8933243674979741, 0.9263603215079761, 0.9503443586456812, 0.9279073485279501, 0.9445711375233987, 0.9577599556722749, 0.9305364545432171, 0.9552768462829511, 0.9422325880251456, 0.9438363445781468, 0.9029141457718637, 0.9268457985355711, 0.960882116896277, 0.9364566792165545, 0.9227312094235981, 0.9584002914620745, 0.8815686501801465, 0.9631335626594639, 0.8554998272737615, 0.9244347791822688, 0.9392027303887122, 0.905803234422023, 0.9553157058256935, 0.8475036918729633, 0.8476642317819302, 0.9676379623290963, 0.9257458742444442, 0.9588240391723063, 0.8466890165467589, 0.8945410829617755, 0.9069342510184979, 0.979710074796684, 0.9503241393624191, 0.9603009318060791, 0.939676162297079, 0.973437898293603, 0.9527518753392905, 0.8534527180771595, 0.918627249997313, 0.9498136186220849, 0.9203938205676794, 0.9697641044897487, 0.9036182196035779, 0.9540480834256735, 0.9271274038018056, 0.8797341336883814, 0.904071115767278, 0.8917368132443599, 0.9168007584014884, 0.8628658083881059, 0.9367204353117176, 0.9249771816588664, 0.949912683719768, 0.8886871460493668, 0.8936311316804023, 0.8973476428605596, 0.8780274176530067, 0.9332006843743881, 0.9382818625708879, 0.8925823445837062, 0.8870401164529466, 0.845881211365237, 0.9269777772660842, 0.9066681932440491, 0.8752596183707998, 0.9227338982632052, 0.8785129897883279, 0.9504761592945763, 0.9410653133310468, 0.9298558716927829, 0.9336203695966773, 0.9420774754269081, 0.9373610803248897, 0.9421425632269376, 0.9773904368176849, 0.955718683514116, 0.8571743841344517, 0.9387036974011215, 0.9676106622934408, 0.9302295510897334, 0.8567038996607073, 0.9784951053790193, 0.8604947882127992, 0.9037501392198579, 0.8989255134958891, 0.8763244887236906, 0.837170561847326, 0.9388641921184904, 0.9514821708256469, 0.8940672473139157, 0.8638887393738777, 0.846626084820403, 0.9601175607931589, 0.8346943892743592, 0.9489311952544655, 0.9714627525647648, 0.8750052863043329, 0.8696394285213042, 0.9663785290712084, 0.9644700397854156, 0.9325909161278692, 0.9690962449008983, 0.9021749600341459, 0.9270880985919614, 0.8856050899123786, 0.9630438566518846, 0.8827130728792942, 0.9687783065821254, 0.9608175477294134, 0.9729345688785611, 0.9317853103349596, 0.8874994310417961, 0.9110583900343004, 0.9275411935573841, 0.9333404139384361, 0.9586021043490516, 0.9033432087380748, 0.9286840883288654, 0.8939308761954079, 0.8844629205948479, 0.9431518303787547, 0.8985243620909903, 0.8975215625570565, 0.909390761212572, 0.8807051408013689, 0.8588952235843872, 0.8214482882673794, 0.8973951899307955, 0.9732936500839324, 0.9025539694183804, 0.9605815638456551, 0.9032340950408445, 0.930235302419154, 0.872009807859135, 0.9744730746739679, 0.8158721494266888, 0.8939614172910669, 0.9162387925772695, 0.8941101371956134, 0.8780621734324356, 0.8651604611781465, 0.9453827528714169, 0.8958833509470945, 0.8941332328942533, 0.91212118759246, 0.928706635233017, 0.8598712909819233, 0.9353574271395422, 0.8409885926000955, 0.9481482442063566, 0.871876669868574, 0.9098282135726521, 0.9399623799815371, 0.9096879479475762, 0.9503838533194263, 0.8549230031156717, 0.8829441148214773, 0.8578063251250896, 0.9159368250347459, 0.976051012953747, 0.9103353231059236, 0.8759446078070865, 0.9619216611581465, 0.9657074065092233, 0.758033375701081, 0.9069707066245691, 0.9482190661901446, 0.8666390231220332, 0.873949294539053, 0.903548345929119, 0.9170079528499873, 0.9597675540161122, 0.8541279188403406, 0.936177507794689, 0.9130319451942932, 0.9483523671298099, 0.9755741550054426, 0.9308099500669837, 0.9562778106198391, 0.9334134185975103, 0.8878909808626142, 0.9543137640477957, 0.9495278389226574, 0.960897688031625, 0.9257798189248809, 0.9042150050433255, 0.8176020157192123, 0.9033646354495772, 0.9027530714823091, 0.9433324549947438, 0.8757757320471246, 0.8245716661230524, 0.9281718210626038, 0.9200719331368948, 0.9448462180820788, 0.8677025154494777, 0.911790601899635, 0.9139213450508662, 0.9208347825566487, 0.8858225924247534, 0.853628161031737, 0.8391883438755328, 0.963521353473684, 0.9187952959979774, 0.9745131262461775, 0.9174155493714843, 0.9408639706194926, 0.8546566891324188, 0.9356757062211734, 0.9405776028993034, 0.9117614177030782, 0.86987857113342, 0.9398269272100586, 0.9132622660759604, 0.961656777598853, 0.8942879771972003, 0.909929387310271, 0.9589974068477639, 0.8775935375745649, 0.9627653678361415, 0.8470587114936342, 0.8811487935258462, 0.9564050659440648, 0.963660420377617, 0.9501225825992342, 0.9169836579285751, 0.9100763517854817, 0.923535955563731, 0.964885574347326, 0.9473241134730387, 0.9175086958647609, 0.8393626028893393, 0.9479408630456445, 0.9323230214866256, 0.9379440441156273, 0.9402384125999994, 0.9657256500947136, 0.9177587894347617, 0.8572382100308249, 0.9060411610698604, 0.9152694181483476, 0.8864961497030407, 0.8501119792330424, 0.9340909119410341, 0.8688125914151302, 0.9547364534936905, 0.8940930353960201, 0.9482167833011157, 0.9653360166368512, 0.9563008191756893, 0.8983953361783521, 0.8593583570409147, 0.9063270604570087, 0.9004297075943527, 0.9311044916788014, 0.9665087996880657, 0.8880388939084194, 0.9085379449249922, 0.9134900249019919, 0.9202295283425254, 0.8889744737121539, 0.976981702179079, 0.8831631671887337, 0.9176403612486856, 0.8699001137485032, 0.9663856581111729, 0.8559527020802402, 0.9198956876538461, 0.9491322622127585, 0.9587720555710355, 0.956885001132182, 0.9712851047762217, 0.9568948533114308, 0.8758052766151225, 0.9317415248630814, 0.9338822647126989, 0.8801842536029267, 0.8787832604829169, 0.8948886307006455, 0.9434515324867788, 0.8574543242856838, 0.8478131350790047, 0.9310456571837636, 0.9712810920631332, 0.8907213336775863, 0.9357510681920196, 0.9422510008806665, 0.8505025173518932, 0.8856371839980834, 0.9464365351753143, 0.8414948464355632, 0.8931866551424141, 0.9143909361687494, 0.8778243545697682, 0.9434514228480138, 0.8520979454448344, 0.921774524358243, 0.9060871616741791, 0.8774031324579843, 0.9412668179554338, 0.9041180942366321, 0.8915648757140303, 0.9341035318846479, 0.8898046491236429, 0.9773805463251684, 0.8729939950306577, 0.8545429213080153, 0.9219319422580791, 0.9389722451281055, 0.8869066001652035, 0.9090580734855038, 0.8781686524980622, 0.8624570217886924, 0.7750572501409025, 0.925819564361833, 0.933825323534542, 0.861451478937589, 0.9345605098636147, 0.9809691444171729, 0.8997774386121034, 0.8586519121426821, 0.9357676547080271, 0.8997188881475255, 0.9410194791713309, 0.928345087377521, 0.8982922648562451, 0.9265112139276497, 0.9595330129221882, 0.9111664751083849, 0.9266792060748132, 0.9523956370629288, 0.9410608813941181, 0.9093966267144329, 0.778981441015685, 0.766160764251373, 0.8117876432430089, 0.8152312907598813, 0.7248828082605998, 0.707310877637374, 0.8113852996679932, 0.7550545703476571, 0.8110963107584145, 0.7684210309329116, 0.729816313995146, 0.7906224661429582, 0.7809208796433393, 0.7990113702715422, 0.7921962730913048, 0.6726490544834695, 0.6826323925088873, 0.8001390125756965, 0.7210585086759309, 0.7832883709988846, 0.7911782128395501, 0.7167133848813623, 0.7616047565839632, 0.7591336591356199, 0.7874453617403286, 0.7974812180364812, 0.7372665195020036, 0.7516624144902742, 0.8172747973618713, 0.7911123457666877, 0.8251104691740054, 0.8003518847664182, 0.748585943394986, 0.8319012938125239, 0.8136875771670556, 0.8000334943064878, 0.7019107467984507, 0.705819762373664, 0.8378048817261534, 0.8474191312150974, 0.7928587413436101, 0.8334659753804515, 0.7570443832920546, 0.7379976328475718, 0.8289865559589726, 0.8389139119818844, 0.8696361506161199, 0.747711877041612, 0.658062934087032, 0.7236076408324226, 0.7738262272127706, 0.7882390984040213, 0.8155073998546059, 0.7936869392410479, 0.8070844632193526, 0.7655230971135851, 0.7055312337287385, 0.7111830938001631, 0.7977183144474874, 0.7665384152622333, 0.6845385231449548, 0.7569921476373139, 0.7774948935421617, 0.7960134465505087, 0.8370955861665869, 0.6571353032419363, 0.7885835893757629, 0.776605609804952, 0.8596702819598355, 0.7813484510667263, 0.7708128303574417, 0.7804223364274878, 0.7438218556025585, 0.7620459875120775, 0.7881659672927925, 0.8169046387474986, 0.7698045153407539, 0.7264709861288992, 0.7239398646034081, 0.7764918023431793, 0.753681456878209, 0.7910206611816297, 0.8150074388391181, 0.6742461256234145, 0.7421323341641319, 0.7453276914170682, 0.7067958120330907, 0.7951558777326257, 0.7670398718129723, 0.8045000609273468, 0.6988396222883028, 0.7317793612383988, 0.8247591378060005, 0.7154477536432483, 0.752272953675814, 0.6935695617258082, 0.7725409678014885, 0.7758141323310161, 0.8455002369992726, 0.7293155338355428, 0.750173952048204, 0.8129068821417129, 0.7459987937082642, 0.835588240217191, 0.7970143642430108, 0.7318941686238662, 0.7865380107760955, 0.763943577449816, 0.8333076983900585, 0.7767278391995852, 0.7197030123049976, 0.810057274050886, 0.7826039792721475, 0.8190672878679612, 0.8312574563222341, 0.740201037150353, 0.8404172294589545, 0.833336828692277, 0.7836623354283636, 0.7326886963331416, 0.8385045661898837, 0.8326540290931659, 0.7621698492079064, 0.6863077031483831, 0.8065240861962746, 0.7275087732421563, 0.8144597094625143, 0.7721809607407858, 0.784716827589713, 0.677779876387304, 0.7682532807330819, 0.7135347162735539, 0.7509051297925681, 0.7257411488424532, 0.8233137956497476, 0.761359375890041, 0.8066928747345554, 0.7885910147691992, 0.75004079186931, 0.7721440273003026, 0.7110085472290095, 0.7817182536469698, 0.8036022191928787, 0.7327774380672538, 0.8142220951070187, 0.8417826226200891, 0.7461552394457075, 0.7048818045200373, 0.7724329867229092, 0.8157216361004586, 0.785653812883693, 0.7355791530932467, 0.7664990884203711, 0.819350200024026, 0.7182538882566492, 0.6988705205782828, 0.7753973191226695, 0.7323676843325704, 0.8446820239686703, 0.7712992912602119, 0.7707708460836059, 0.6520814430920667, 0.8013094898212145, 0.7446427911782705, 0.8288681604689763, 0.7862985242287244, 0.7213706126681569, 0.7790487346440724, 0.7380021606301379, 0.771545455473909, 0.7278740285534776, 0.7313846350727072, 0.7195276060172441, 0.8359943593510588, 0.8053824991949141, 0.7822316141027488, 0.7779198927128677, 0.7277159587902646, 0.8299970729329029, 0.7375758395783046, 0.7739395607358776, 0.8472368831026137, 0.7829186978536806, 0.7294952168778698, 0.6609457561958039, 0.7731924062946507, 0.7506496193992, 0.7993794402005605, 0.7973522310550865, 0.7161903835604602, 0.8316896010798707, 0.784009829355216, 0.820904233416639, 0.8169954467793739, 0.8323358603057195, 0.7923688866262706, 0.7676698647630695, 0.7483570608113328, 0.7693872539084706, 0.7163404975309274, 0.8256023797938699, 0.756686388047138, 0.6461955892230533, 0.7509015835648439, 0.7184267068718551, 0.744900969473163, 0.7152508376809479, 0.72284259403038, 0.8013332839958276, 0.754153766589487, 0.8016093799548631, 0.7658725781682088, 0.6866956937601454, 0.7384337879405665, 0.7667435228474843, 0.7245593373200316, 0.8491799114465943, 0.7289273749249766, 0.7447066695924962, 0.7200167039713556, 0.7239877826939498, 0.7842225226331976, 0.7627547480610405, 0.7523615060949178, 0.7733229986739883, 0.6982315665259407, 0.6886475767322455, 0.6286409362525073, 0.8060615684249615, 0.8087257874145207, 0.6826794305008068, 0.7878105643847352, 0.8333317736940318, 0.7574232510890573, 0.7918561446421295, 0.8098374284549943, 0.7440802392382718, 0.8275215723001919, 0.8279630124431692, 0.7195217251454566, 0.7937323360465615, 0.7865924317506762, 0.7478011280186183, 0.7691267538496689, 0.7081822179549336, 0.7177980603652159, 0.7692237265603197, 0.7044127305566112, 0.6762210854285395, 0.8080009980931533, 0.7097740178708741, 0.7999790980268339, 0.8112081383121672, 0.742896056417304, 0.7509061582077285, 0.6952442500385254, 0.8227714157495573, 0.7729779882828454, 0.7989856093880767, 0.6678255779206465, 0.7447806658243492, 0.7728011168695463, 0.7602166402332362, 0.7004509665758369, 0.7816086256275998, 0.8365928482199128, 0.7367328882874328, 0.7284943846658725, 0.7864324200205376, 0.8412109485271997, 0.763048956103451, 0.745302195010881, 0.8215475994059667, 0.8353703828671919, 0.7535072596620871, 0.7399888977811726, 0.7908370579819448, 0.7498605248947121, 0.8259112974635691, 0.7715504674986013, 0.803420286354266, 0.7264240294633262, 0.715280569415053, 0.696757261586176, 0.7966068366370155, 0.6868287659054384, 0.7200508628454568, 0.8180497756821736, 0.8114933947173931, 0.6812838380449993, 0.81512982411285, 0.8205100281646365, 0.80009379076879, 0.7397204740783746, 0.6938227042812422, 0.7852745423280365, 0.8306861698235403, 0.7541131073223596, 0.765186696578483, 0.7902984398828092, 0.7488937414615744, 0.6840888790922355, 0.6894846532203229, 0.7365222153072093, 0.7832115226185346, 0.7583665500485011, 0.7881203885249038, 0.7525664023785102, 0.8028878274099106, 0.7801529709623002, 0.6982848564024235, 0.735770526415015, 0.7049098114326205, 0.7424099514646845, 0.7887371949005397, 0.8045428786345235, 0.8225027284587293, 0.8238695496076582, 0.8475085158284523, 0.803405541369566, 0.7919950514599354, 0.7108667801988302, 0.7110352793893044, 0.812728360746376, 0.7139044165413091, 0.7314524655915664, 0.701783776479628, 0.7076798183861233, 0.8310692138273694, 0.7018612172306927, 0.8197043588173589, 0.738148014471655, 0.7584858364381728, 0.7933617758458081, 0.8199224922335517, 0.8317942126688556, 0.7739500069858765, 0.7473979679581526, 0.822436826212714, 0.8293909801279752, 0.7849483155749066, 0.8286324057759861, 0.8343923520186981, 0.8235750257552445, 0.8066022250505173, 0.7808971908879191, 0.7494841440882366, 0.8365586185819055, 0.7372889714185499, 0.8046228643072108, 0.7707255934032348, 0.7815547720769167, 0.6281813857794674, 0.7739554374540994, 0.834090514550476, 0.7762266719389597, 0.8559829211528945, 0.7957829086584141, 0.7578448436943654, 0.7209419450528914, 0.8399095429405286, 0.7964403879988387, 0.7981047939487571, 0.7534971368990455, 0.7331832320116152, 0.7070921263992866, 0.7257469728346526, 0.8300292594780094, 0.8439613130091486, 0.7570111211380115, 0.6429216411626629, 0.8077758653320946, 0.8128400128102685, 0.8206592964791017, 0.70284723737129, 0.7308953063077924, 0.7806923183231879, 0.7693967970047428, 0.7176742266473699, 0.7367278482962644, 0.7756106251408552, 0.7632610435145184, 0.8405268652363306, 0.7620853733356706, 0.7257152376522766, 0.7763973001657059, 0.6879534539380794, 0.7826250307843128, 0.6451164786625834, 0.7843240306491852, 0.7907174192079289, 0.7579857159903312, 0.8122043823764146, 0.8731817100201087, 0.7072814421281983, 0.6857880300424848, 0.7699338668279884, 0.7520228933599405, 0.8014516634896691, 0.8402646015203881, 0.7763492232131686, 0.7434889345548883, 0.7829846955036351, 0.7890444399785124, 0.7954117724758691, 0.8224801729486151, 0.7221914533098157, 0.7533570663172311, 0.732229248814521, 0.8006648240217322, 0.7999609291154637, 0.8079122800333536, 0.7181431897767876, 0.7698691272304409, 0.7962376191228169, 0.7542981645785674, 0.7304513936750132, 0.7326442618998494, 0.7684058204989759, 0.8555056037890876, 0.7613456233318336, 0.738903082615, 0.7952418494288676, 0.783246742065621, 0.71638583763114, 0.7246069168746252, 0.7798583862474247, 0.7682197031328305, 0.7968563707798966, 0.747144168665785, 0.8303722414035094, 0.771764412918805, 0.7518488674520265, 0.7345523088951044, 0.8009406148117835, 0.8512350847996407, 0.7161848261089282, 0.8008305483520889, 0.7903764452207493, 0.8014459441259822, 0.7749146162514968, 0.8192243260459593, 0.8086072843998349, 0.8417814896317367, 0.827153893035116, 0.7914201132552825, 0.7933738568089933, 0.769152825764664, 0.8365784131172669, 0.7919497398230686, 0.8001783802393281, 0.8248800600336095, 0.8175946459061166, 0.7395682712236666, 0.7444044346874604, 0.8123326731519726, 0.8089443212144625, 0.719924854542524, 0.7952683511201911, 0.8032025822353546, 0.8124654993866143, 0.7113225282249405, 0.7178984154780801, 0.6690798311463324, 0.8130782334972082, 0.7360531793536923, 0.7270987423654411, 0.7818428027343498, 0.8054244950348853, 0.8323585668479405, 0.7302581308718923, 0.8041955322381817, 0.7032921456983084, 0.8002893863516521, 0.6587861904227981, 0.7741697752117174, 0.857712270610253, 0.7373352228047422, 0.7185257814272303, 0.7523820770545641, 0.8222102306028796, 0.7179417955441075, 0.810909539292847, 0.7487991864328349, 0.739256687835631, 0.7912696534493739, 0.8257014980953059, 0.7109650426288681, 0.8305948300039366, 0.7759189332455798, 0.7549501521107163, 0.8373730730174413, 0.7906883677087007, 0.7533144985757626, 0.6785747671905178, 0.7592583819294986, 0.8381966763942668, 0.807612282635287, 0.6735890431793965, 0.7820516305773622, 0.8066458689079778, 0.8511205442004945, 0.7277769182812953, 0.6155505167495787, 0.7395013932056926, 0.698798225379158, 0.6755911011764779, 0.7745230068433732, 0.7440621630857853, 0.6941193484483941, 0.7944299212193758, 0.7105466917396406, 0.7844830889949128, 0.7641874997960287, 0.8121996878292441, 0.7598791203772866, 0.7216646231106947, 0.7248149363052407, 0.8098013355315956, 0.7045310697460718, 0.8160011974137631, 0.7270167550246527, 0.6842876504948693, 0.7259701415723537, 0.7072369633652674, 0.7066041917329566, 0.8078655857511401, 0.7386496585794556, 0.8267631257054165, 0.784741746691407, 0.8070566804177616, 0.7516373217941135, 0.692287959817175, 0.7585063085246311, 0.821740306659281, 0.7850566110324906, 0.8318008706918811, 0.731338191511103, 0.8238496796216641, 0.7710163746242916, 0.7900521899670486, 0.7527289725971444, 0.8377257132977224, 0.8359601985231053, 0.6592858175775635, 0.8487642486544048, 0.7470668989638457, 0.8401558004732093, 0.7511213361405811, 0.7907793065451683, 0.7065794555922393, 0.8193720698376066, 0.799572942934291, 0.7714039117122883, 0.7172505517247875, 0.6793435613675433, 0.6640917002279141, 0.72041307383733, 0.7913708233712115, 0.6999513489498204, 0.7525813856495135, 0.7507043097397847, 0.6549062667971943, 0.807779853564139, 0.7013393689105548, 0.7081071417541269, 0.8554064549400893, 0.7303182073527126, 0.6033330462314414, 0.6853287532918996, 0.8293510767690833, 0.7527034709404306, 0.7065686913569138, 0.7039731460923481, 0.7469578508780254, 0.7923631000228597, 0.8525122377151768, 0.7273334438801354, 0.8398576226952011, 0.7412604582092581, 0.7893838101220887, 0.7261022119231362, 0.7522546359311391, 0.7845256509712961, 0.6451414530870304, 0.8423381239140351, 0.8810927665583187, 0.7051742565904884, 0.7725457479787914, 0.702009559029783, 0.6712725793759549, 0.7942260505764243, 0.7147273132897811, 0.7400836095880226, 0.7434256485623518, 0.8548496607588436, 0.7903871356819223, 0.7865045566893214, 0.7552359196095716, 0.8345992783298979, 0.8091930473611086, 0.7857881463985856, 0.7650533448887846, 0.7835553030041025, 0.8066367282001657, 0.7638873427689672, 0.6901515364388917, 0.8006793981020204, 0.790824147811432, 0.7565404287642356, 0.7844597577411452, 0.71821732048891, 0.7329565116571435, 0.7416738922565109, 0.7963152631448082, 0.7824096995922446, 0.8393194559865083, 0.6901672394760456, 0.7179911588643778, 0.7627348922115726, 0.8190354276701232, 0.7947093060442815, 0.8009466166902557, 0.7672534786619036, 0.7487046007893599, 0.8218942088571008, 0.7217611637894392, 0.743801136537412, 0.6845865663510303, 0.7505243716629038, 0.7813104663230176, 0.8013172881500524, 0.8459246383947409, 0.7128626185579983, 0.7880675926630462, 0.8280357042867377, 0.7870096647117899, 0.7638683320451687, 0.6789944233110716, 0.8144948737768183, 0.7203190832748854, 0.7711120439476142, 0.7788777367842995, 0.7932866898868974, 0.7365682391719749, 0.8278289818379976, 0.7689407908947149, 0.7937738633349521, 0.8196060908081672, 0.8244758103088984, 0.7863965842639333, 0.711309549857231, 0.8297121593814425, 0.7543368577907161, 0.7187325487187712, 0.7984379212153623, 0.7384717485686751, 0.7842189004612439, 0.7956341260344207, 0.7368873099152714, 0.7318121331680324, 0.794801652873256, 0.7802703642845574, 0.8033252290265686, 0.786372840133884, 0.7864152201910429, 0.7699574110526503, 0.7725622657231558, 0.8507686195746594, 0.6968542132477724, 0.711712657327302, 0.8319420561729296, 0.8064679040323419, 0.7434882297929627, 0.7272399033978292, 0.766909193312956, 0.7187584752573432, 0.748602782630437, 0.7280015456889918, 0.7697174971390683, 0.7344972803906603, 0.8205262957706865, 0.8389940755812542, 0.6490964917591329, 0.8326241263028133, 0.6994149099169302, 0.8394817046578547, 0.8177914093192676, 0.7470921225733838, 0.7163894655910339, 0.7643192571511355, 0.8151206744808497, 0.7604571509523076, 0.8168313711232766, 0.742199229345654, 0.7330613935092392, 0.7937446618415469, 0.6484214190851947, 0.7160705057310914, 0.7854802209174131, 0.8370749588437714, 0.7240446021393102, 0.7633108321162538, 0.7552416622596965, 0.6739597328153409, 0.8173083194144135, 0.7950964878945189, 0.7044505050394716, 0.8475794043337216, 0.747474861884743, 0.8004788305315167, 0.7845322120422678, 0.8083997976556481, 0.6963285849413726, 0.7531661630223132, 0.7456917741501736, 0.7567349009434126, 0.834778575726669, 0.7147573883191489, 0.7299785039574704, 0.7790479603076822, 0.8392774143069184, 0.8061971072084734, 0.8080163244581899, 0.71132840030667, 0.7771403653830108, 0.7939625451400257, 0.8014672995999228, 0.7632213043784544, 0.7958067447516008, 0.7846368347411863, 0.7371229364199268, 0.7205922218781892, 0.7641067656450548, 0.8276654093742575, 0.7116329459663113, 0.8375437989543404, 0.8193202910168249, 0.8052425871714473, 0.794805972979471, 0.7403623824937895, 0.7335673510027642, 0.7754555467661755, 0.7622390989916097, 0.7605262280538039, 0.7882851947440384, 0.7355532399225541, 0.8198457580693744, 0.7592197219076948, 0.8230985342514745, 0.7645621671992996, 0.7405090835428991, 0.7907674308457363, 0.7907213132955994, 0.7117115000900637, 0.80906652340151, 0.7584372696046364, 0.6796583738868553, 0.8195949884977387, 0.7485496326829393, 0.7960567134429541, 0.8003586697537055, 0.8201327573909285, 0.7118409115248139, 0.7947442187200374, 0.775055643089912, 0.7362546046757734, 0.7622840308838565, 0.7792624864621696, 0.7264341002679019, 0.8188258663041192, 0.7790644310774607, 0.8437971733508046, 0.6648107699578302, 0.7688967105991282, 0.811523108878254, 0.7189127471199489, 0.7632624930773755, 0.7355499684939468, 0.7402965594868581, 0.769157209282355, 0.8099058532844363, 0.6272906328811702, 0.7753627371348965, 0.7042541137431928, 0.7960776709015088, 0.8124554977445618, 0.7089184875062399, 0.6918726130612735, 0.7680459749429098, 0.7755364728458874, 0.7964227465243028, 0.7560480981310778, 0.7696341765645542, 0.7319497794057217, 0.7085958848450669, 0.776516301329755, 0.7808202543531163, 0.7676546040397979, 0.7691280203166758, 0.7228985898933027, 0.7275949661641756, 0.8155250195321139, 0.7310109360631476, 0.8099829689718269, 0.8070737581266607, 0.7224323921680126, 0.7953885052142275, 0.7243124572801908, 0.7889805771444132, 0.7402085720762792, 0.6500066859815543, 0.741207301378398, 0.6971083435053964, 0.8125945254892393, 0.7659229846049617, 0.7904073267225427, 0.752166375004184, 0.7932170515217649, 0.7545106030653783, 0.7512775329447448, 0.7897562870575272, 0.7604623068798939, 0.7553097915744005, 0.8477475196382789, 0.7279397029074886, 0.7393414668201296, 0.772104901439955, 0.76903649755761, 0.7633651044339387, 0.7999901293172421, 0.7306383743056803, 0.7620489752795747, 0.7226086575238448, 0.7458844818880075, 0.7990197560660606, 0.7943685428304466, 0.8052223857462328, 0.7062600129563394, 0.7170039173115885, 0.7657186594321908, 0.7888583693621514, 0.7386791601694439, 0.7221835746503187, 0.7530168816451563, 0.7797125417297806, 0.8079700205929021, 0.7793021656875829, 0.7399172194532478, 0.8004178218685546, 0.8169942308189151, 0.841128081737772, 0.767847650673114, 0.7779794671770259, 0.7526596598542417, 0.8114128700325745, 0.839891130443193, 0.7649051036386005, 0.7110255594157758, 0.7916713124316472, 0.7380562622571423, 0.7237552432258674, 0.7313303676588928, 0.8251457785852244, 0.7675906907593907, 0.7938446920483155, 0.8530403186885819, 0.7413701223454322, 0.7641532230262018, 0.7998454133014451, 0.797781763977032, 0.7809644671030488, 0.7262064874685439, 0.7108793816971762, 0.7488895033643305, 0.6601568878618498, 0.7379701546385012, 0.7547359041321131, 0.7557550950828251, 0.7920330065643821, 0.7826533900594856, 0.7656310229869072, 0.8079909360518656, 0.7743340470392261, 0.701855984211485, 0.8086775481826962, 0.8251346518349981, 0.6623413601419432, 0.8048354809868847, 0.8137649350644541, 0.8148687883235423, 0.7800165172481117, 0.7951815168440846, 0.7529815614293798, 0.8028819242962616, 0.8017747894898668, 0.71217368591205, 0.7677095885187597, 0.7201017197906207, 0.8148993058385051, 0.7151989789936606, 0.7908665505886552, 0.7222271086681076, 0.6896431400324331, 0.7016729216378071, 0.7185403982956722, 0.8311435790895986, 0.7131465135623787, 0.7426162738420834, 0.7907468511476203, 0.7446992109873886, 0.8276191255900345, 0.8049836178453342, 0.8310101929362983, 0.6883952389157908, 0.7803794273197102, 0.8156772948625063, 0.7663109984557805, 0.7092919232319894, 0.7167401020133105, 0.7828269077301888, 0.791743254947036, 0.7350786249702397, 0.737639776342732, 0.7517346836589253, 0.6860313102655213, 0.852820581572807, 0.7881530261232925, 0.7560533715700588, 0.7652573150873646, 0.7412171357665129, 0.8427531361257733, 0.8133950625631402, 0.7484675085500674, 0.8265259668244114, 0.7413978044315565, 0.767829332058112, 0.7499562349665889, 0.7611440708785056, 0.7488231694665878, 0.7115115779093991, 0.8032956694809426, 0.7742583785290151, 0.8347904241821938, 0.7265255311499564, 0.7780727010879944, 0.8026267772861357, 0.699441489636799, 0.739721758821531, 0.7076364884770967, 0.811464942798364, 0.758991346971917, 0.7686944036468171, 0.731843444158666, 0.7691443152308375, 0.7712731973006983, 0.8547268608736946, 0.8201484889660817, 0.8070384856644772, 0.7920485298082813, 0.7102102414583669, 0.7682235925875863, 0.7653242099582586, 0.8265086533585396, 0.8297494448133574, 0.6673726179808829, 0.757893538733837, 0.8290474248791156, 0.7263270022596257, 0.8048161374719632, 0.7672981670833434, 0.8443929002293504, 0.8106653679660365, 0.771955008388627, 0.8048205729060847, 0.7674650121812012, 0.6831038824440678, 0.7677965784239495, 0.7494237201072745, 0.8222135459882889, 0.7722853496494694, 0.6633957399862718, 0.7555503433199773, 0.7186189064352562, 0.7188212886123806, 0.7636651225711495, 0.7649892854119714, 0.7810064295685164, 0.7847623211754823, 0.7578836629929608, 0.7583711014243919, 0.8412367682560291, 0.8049874138466031, 0.7455101644665533, 0.7840884423668686, 0.8084472370590545, 0.8096033487464351, 0.8402729747394766, 0.852185092469636, 0.47737800976659295, 0.7538137096630529, 0.7798239375085507, 0.6793505807175843, 0.7367229442032392, 0.7750971712935605, 0.715936507386844, 0.6688089500662163, 0.7011687660590838, 0.7349072410765931, 0.7834284890256222, 0.6828001865778158, 0.8411424871458816, 0.7889609973866508, 0.6519629582347943, 0.7775499881475971, 0.7964610816436632, 0.682540208786268, 0.7133113544806974, 0.7410141271686093, 0.7673445043290813, 0.7682804262438017, 0.8549446244574538, 0.7165814124848269, 0.8418222411613525, 0.7645682839359083, 0.7282745446001698, 0.6727499912606099, 0.6797300480927158, 0.6924929065729665, 0.7981993710940873, 0.7386146305571717, 0.6805615156315817, 0.7626422180655661, 0.7700447783060569, 0.7959011441587587, 0.7700412664071878, 0.7998027475451983, 0.7395162262046908, 0.7724713143165984, 0.8094113301321171, 0.7279835611759105, 0.7688377046311123, 0.7943614881396481, 0.7953618167249585, 0.7307363062149674, 0.6976760451270315, 0.7958589503273239, 0.7278878926689403, 0.7838029984627572, 0.6992736275452084, 0.8168404997791218, 0.7652100830593306, 0.6728324501876672, 0.7284318873807796, 0.7576648332799962, 0.7024168345602594, 0.6705719698290932, 0.7816327488714461, 0.7835317849769989, 0.7287063207570637, 0.7645101543310191, 0.8055976161935983, 0.7294471399239071, 0.8070205816099099, 0.80615408196901, 0.8009932215752981, 0.7930575542999122, 0.8124018399566845, 0.8058186962090536, 0.7093200039311387, 0.7231020254471864, 0.791708674686588, 0.7473774076072043, 0.7484758812976645, 0.8287475878475433, 0.8341842781027369, 0.7392367146294916, 0.6810911287597775, 0.7900841760276847, 0.8067436226474325, 0.7557441396120178, 0.7772483855919213, 0.6944351601098666, 0.839687870637841, 0.736171842553342, 0.755132190846631, 0.7610935232830333, 0.7368818913309331, 0.824743676214482, 0.8170375705318251, 0.7573004151450939, 0.700148364470123, 0.8148915212116699, 0.751783435482926, 0.7330460077503163, 0.8070603647574093, 0.8249034259308949, 0.8241589423770255, 0.7776101383610509, 0.7778302322954986, 0.7384957034954106, 0.7385135022090301, 0.8103178387826996, 0.7284270013777318, 0.7781511114546447, 0.7209895401253388]\n",
      "[0.9666783035444899, 0.9476863002025591, 0.9640175428574272, 0.9613273228769051, 0.9406015515251015, 0.9643099622843818, 0.9668455401039847, 0.9594853151157979, 0.9696533128737587, 0.9416017310193976, 0.9337683747416032, 0.9760548925537257, 0.9759731706150421, 0.9774729418254564, 0.9791012493229142, 0.9466572033638185, 0.940461628990433, 0.9543094701537288, 0.9709060947939266, 0.9708006293411776, 0.966946691035947, 0.9801374346751612, 0.987665241813008, 0.942998508409789, 0.9515174469188412, 0.9545022809642674, 0.95451984035503, 0.9448260981090916, 0.9682087299263457, 0.9436584725235321, 0.9558279401665405, 0.951900678228792, 0.9554252643237937, 0.9791382434935851, 0.9737358991014716, 0.95850740870305, 0.9366466244094259, 0.9605578290868181, 0.95589825962553, 0.9673114682447833, 0.9215027238691306, 0.9522372720726497, 0.922154121323038, 0.9595907157248961, 0.94145730049651, 0.970050450747657, 0.9603998817806411, 0.9650488868128494, 0.9470375412858478, 0.9638020676298387, 0.9419127518108328, 0.9062452915627598, 0.9508429315614111, 0.9610177074100278, 0.9460246383439307, 0.953623618710261, 0.9631436073481822, 0.9746759120178354, 0.9302747026212661, 0.9598177293752754, 0.9530477068213965, 0.9768224475551673, 0.9682728793413384, 0.9303814511420627, 0.9598710949756708, 0.961968717109671, 0.9743253873962179, 0.9312194081325397, 0.9613127491302255, 0.9793738834042224, 0.9094331437855762, 0.9579170223908531, 0.9773872340241175, 0.9435286685341744, 0.9779741271055837, 0.9766966205109732, 0.928595822549336, 0.9691951064591636, 0.9418249127520305, 0.9384946412884289, 0.9744495061965227, 0.941708294925538, 0.9408354962100844, 0.9521307477458658, 0.9541166984842678, 0.9546105576294198, 0.961387557208183, 0.9406715430068832, 0.9496691754272326, 0.9440737086074006, 0.9402120749360083, 0.9328302297209705, 0.9458926728533328, 0.9486772910984369, 0.9717111685903425, 0.9589243230501502, 0.9750467786395225, 0.9754015963011334, 0.9808464705455986, 0.9679034552354395, 0.9759085448474577, 0.9652858068935367, 0.9248501047997252, 0.946833988916262, 0.9722444943447743, 0.9658451344586968, 0.9396246112440086, 0.9779912365835, 0.9783074238075624, 0.9808649678412715, 0.9386218304870043, 0.9282305211328783, 0.9182825494136972, 0.9534702902722546, 0.9193031980038132, 0.9653081396823024, 0.9709063563792877, 0.9497941433009076, 0.9474978706174803, 0.9702685945430927, 0.9408895008937113, 0.9183823717288591, 0.9724012076913228, 0.977770597092655, 0.9589963649671087, 0.9727478217584096, 0.9862576731992222, 0.9447024946629914, 0.9481240864960526, 0.9277752165470243, 0.9353102461925534, 0.9420325547394057, 0.9781421996686482, 0.9566963740818113, 0.9011740057851069, 0.9584130225912373, 0.9729226234718793, 0.9578165278925225, 0.9834995371459041, 0.9548983782766045, 0.9570672617778138, 0.9665662297539885, 0.9303851199791, 0.9278090337242341, 0.9680001842921625, 0.9364045270722561, 0.9432469893672142, 0.9426133159441789, 0.944606492108711, 0.9581785650109086, 0.9240261725177751, 0.955550248706924, 0.9443531214131303, 0.9684772177591879, 0.9139318932766894, 0.9780737016405616, 0.946621191541874, 0.9456331755789562, 0.9527413973674677, 0.9664557945745242, 0.934186874806821, 0.9333202410319448, 0.9616281280359602, 0.9595562656972407, 0.93762692736947, 0.9498907321195411, 0.9174517231212823, 0.939626845880716, 0.9421748835082346, 0.9605840006613748, 0.9135769124396789, 0.9406776692870866, 0.9284043065554669, 0.950612269734071, 0.9731831850436219, 0.9791569299301143, 0.9503099540771777, 0.9658415218096396, 0.9856383381347711, 0.9653302649325425, 0.9796280153031015, 0.9462231989314461, 0.972695287586672, 0.9592957275310741, 0.9606369868073914, 0.9433353174690633, 0.9471950626649154, 0.9691272254185572, 0.9615047022330587, 0.9586942409902909, 0.9391320465826426, 0.9417717749670125, 0.9487747216579028, 0.9650574260252893, 0.9622742546826293, 0.9610618208896788, 0.9688222050935926, 0.9717348234655565, 0.979659361796599, 0.941278679320624, 0.9407592022716039, 0.9332026506613236, 0.9760329986641005, 0.9532265399476815, 0.9639296380805314, 0.9216449480391706, 0.9654050519103108, 0.9480650669494222, 0.9554702831103825, 0.976549570833453, 0.9670211177239749, 0.9723090484146437, 0.9732720802835426, 0.9423452536924583, 0.9772343207078644, 0.9547788698885449, 0.9636163716525262, 0.9591063352594978, 0.9805962023701611, 0.9476591706983843, 0.9572963799540071, 0.9712578281813666, 0.9162312290900005, 0.9837829256337112, 0.9687090081392856, 0.9504280383014742, 0.9459440669745182, 0.9455043207921924, 0.9430502554320052, 0.9793963481254119, 0.9448235246416351, 0.9214086332364928, 0.9792692629726475, 0.952444050703621, 0.9235803762454479, 0.9218359355436898, 0.9707926860148036, 0.9507641829833343, 0.9482540264473001, 0.9495910039077733, 0.938764254570935, 0.9851542790212056, 0.9391402251063949, 0.9536928787972624, 0.942078700089207, 0.9461106539774171, 0.9496066988609385, 0.9416049670815766, 0.9425339236066053, 0.9578638991897788, 0.9551193206037534, 0.922046294028106, 0.9502089280506644, 0.9498137327509876, 0.963292925969856, 0.9406612100267503, 0.9342219247236718, 0.9362521740872103, 0.9760036080429904, 0.9461460911809546, 0.973243808796669, 0.9385805304316754, 0.9481689510929395, 0.9610622072052845, 0.9461828863585141, 0.9486172868015235, 0.9515662036556515, 0.9823747666848484, 0.9276086539236411, 0.9669137370254381, 0.9825560246708837, 0.9278658774989369, 0.9105044469735579, 0.9276320292160156, 0.9621639312343249, 0.9218945505273332, 0.9752380964414813, 0.957153769488893, 0.9557457694035415, 0.9265797535858984, 0.9586053609280651, 0.9807790886887136, 0.9522534153264636, 0.9317918411767074, 0.9402952048906694, 0.9459588825546222, 0.9450728100278047, 0.9732556601081314, 0.9228252199076522, 0.9843998399537707, 0.9497846358722762, 0.9320107512093058, 0.9138861858869609, 0.9849179469112058, 0.9749809905093464, 0.9580781053722204, 0.9668441174658717, 0.9562804877216213, 0.9532791762817869, 0.9314364160615026, 0.9574240037621509, 0.9170879228212419, 0.9652502976177837, 0.9294351347194642, 0.9437028288705275, 0.957201878429835, 0.9690859869411579, 0.9590845540547321, 0.9669230217068733, 0.9470387058887922, 0.9340105958642995, 0.94912927784035, 0.9728648267956839, 0.9479333482839843, 0.9807261237801094, 0.9798584929458042, 0.9374723673653759, 0.8947320818494287, 0.9307191227741323, 0.951028012732073, 0.9728362034606647, 0.9596982427003361, 0.9515424294217179, 0.9717692220699647, 0.9505224339560226, 0.9427631362196449, 0.9762314352024063, 0.9732919311153477, 0.9335395104874612, 0.9524525748605529, 0.9644660191960752, 0.9458837230434449, 0.9286861736879557, 0.9747303332457046, 0.9328441185012074, 0.9767882453027821, 0.9710454612667426, 0.9387554890666415, 0.9572926537078047, 0.9510257430933561, 0.9321508300152731, 0.9733957592696943, 0.9434422075625437, 0.9378576181385674, 0.9516379865278433, 0.9701757092050866, 0.9752829976480062, 0.9653261509465153, 0.9522269668258905, 0.928265190192529, 0.9448412159418905, 0.9583444423586859, 0.9470913064666469, 0.9761283765127894, 0.9494182942552841, 0.937979107949463, 0.951614833605599, 0.935292649138724, 0.9757568106607356, 0.9584780920382772, 0.914243554925361, 0.9361053718278106, 0.9392400587369873, 0.9464408416732497, 0.9730793246452162, 0.9806706851481435, 0.9494697997330763, 0.9742823421958051, 0.975834997699846, 0.9609433936616422, 0.9436419264027971, 0.9554330070759787, 0.9736241903390068, 0.9222277808845218, 0.9557753712143059, 0.9275621716023591, 0.9389785632738585, 0.9459042476989785, 0.9536365151722027, 0.9479150020052219, 0.9336042804638893, 0.911926868360927, 0.9532871615691162, 0.9796331749215527, 0.934089221193921, 0.9388126320089709, 0.974925048145462, 0.9468441301243626, 0.9360987899436035, 0.951291368324871, 0.9754232544220729, 0.9748923794477938, 0.9645396706906366, 0.9530264012457409, 0.924879622196245, 0.9196324391913927, 0.9312281777772754, 0.9565143599955366, 0.9623919705075449, 0.9496804197824205, 0.95877970399579, 0.9565540652615422, 0.9463054756976551, 0.934647449297416, 0.9742482855107348, 0.9664173103042214, 0.9628786125322241, 0.9431288134538545, 0.9545246498423097, 0.9707881069163291, 0.9608406894304543, 0.9603580454396599, 0.9149304754092387, 0.9697089612605018, 0.9695803356053709, 0.9500208822439673, 0.9821020689371852, 0.9624104156319391, 0.938199679775612, 0.9220441106620654, 0.9650049445820277, 0.9741898632186257, 0.981075393597746, 0.9607118866680642, 0.9771592884808067, 0.9143584703657532, 0.9786292864343746, 0.974809908876925, 0.9359273931698656, 0.9346816888608367, 0.9684279301606302, 0.9273156648463735, 0.9495153412695315, 0.95141746389069, 0.9849107733072656, 0.9809461426325018, 0.9792105795151714, 0.962943572953611, 0.9721478171946114, 0.9715152203142549, 0.9785517665787551, 0.9651992306963079, 0.9722152205198578, 0.9733897191856764, 0.9783397003190097, 0.9347511367294389, 0.9468817804799954, 0.9566102784063494, 0.9766971692055598, 0.9555997143394327, 0.9740383084482355, 0.9623141268382186, 0.9492805406697361, 0.9699723722251055, 0.9653532666381085, 0.9260073753170143, 0.9378701411135166, 0.9715922958381045, 0.9683577515121339, 0.954940055199568, 0.9745903422341585, 0.9529717693117281, 0.9634011446371261, 0.9447175727057655, 0.9822234062275854, 0.9741117027427686, 0.9356282083399331, 0.9430146453721365, 0.9667071488177392, 0.9653021775472408, 0.9414849233890799, 0.9858537032955694, 0.9749281338531469, 0.9436728431937688, 0.9516772498620124, 0.9597032882163493, 0.9574069922486564, 0.9275412787402658, 0.9653699005046931, 0.916799031533541, 0.9703258691148532, 0.9821891400934492, 0.9391618867490406, 0.9468172400199775, 0.9147245442800752, 0.9247294657347414, 0.9364216253912986, 0.948997986205817, 0.9452201675281361, 0.9325286503503751, 0.9744999798148337, 0.9063826795354896, 0.9446294349153307, 0.9554423109764455, 0.9768875175332126, 0.9125665351711018, 0.9806331565447601, 0.9536933328142231, 0.9636303780215205, 0.9291294591882748, 0.9529325281110532, 0.933359952295428, 0.9808479665667728, 0.924456800633121, 0.9596966094471464, 0.9631211050457098, 0.9722848061998886, 0.940569586302896, 0.9263578894819363, 0.9343751276472422, 0.9576787977279577, 0.9234325195136488, 0.9459815143731893, 0.9304519579249331, 0.9499250380120915, 0.9709097083206325, 0.938643405876984, 0.9333367208419502, 0.9710686581518558, 0.9197798854471576, 0.952673495483575, 0.9425078033645304, 0.9271459036519796, 0.9633882613866607, 0.9658559136604516, 0.9492654598318157, 0.9611128888060362, 0.9471862220325852, 0.9523788805676471, 0.9441595394970691, 0.9666031887262718, 0.9470244975676911, 0.969429446100786, 0.9869027451304262, 0.9583340408730213, 0.9782412746846811, 0.9068527631717974, 0.9705359784926313, 0.9524781932480403, 0.9591505758629569, 0.9618333798071751, 0.9668364223126068, 0.9460660180854705, 0.9393446943722312, 0.9370454012397279, 0.9380373089899313, 0.976972382016952, 0.929062121515121, 0.9492218576149534, 0.9792910290825056, 0.9439422666745708, 0.9703198458334252, 0.9611044299781724, 0.923966050528162, 0.9295495564894819, 0.9590131181858499, 0.9512173893039007, 0.9808524561545463, 0.9686058545884075, 0.9394360346590821, 0.9082700997434547, 0.9638447402361214, 0.9649840303346083, 0.9521887591632168, 0.9555733423316705, 0.8977819413065969, 0.9818271903603314, 0.9461846491370052, 0.953423138985985, 0.9314220378470991, 0.9856704834391952, 0.952749274575376, 0.9721240484548166, 0.9409897996270709, 0.9788355064790537, 0.9621937891925729, 0.9490077973449526, 0.9714810592705543, 0.9751598904342398, 0.9216645221668076, 0.9850601088307532, 0.914513162479657, 0.9455521904732389, 0.9517613703363247, 0.9399567282275333, 0.9358346303225289, 0.9463376709945256, 0.9655262538118743, 0.9754957715932071, 0.9587695181702581, 0.9438597517975451, 0.9637211929189008, 0.9693686110053329, 0.9497097272116949, 0.9534421138263744, 0.9613396622062658, 0.9715534531208628, 0.9025512921760819, 0.9731769410315214, 0.9424219791706426, 0.967930165009609, 0.9616786461537701, 0.9471259429195373, 0.9766485563247196, 0.98011048657481, 0.9516242781402948, 0.9778789739591831, 0.9399467229240067, 0.9752106203777807, 0.9244300834936677, 0.961546208640259, 0.9720863753354202, 0.967272953681248, 0.968114476854144, 0.9634647859561453, 0.9685668608183385, 0.9519274935773517, 0.9517289022279964, 0.94474417724285, 0.9578499588613075, 0.9610632922260329, 0.9538053722913208, 0.9536805065685642, 0.9658537263163117, 0.9696086175171762, 0.9156083334784958, 0.937837692362569, 0.9661756664905267, 0.9295250941925906, 0.975273211731303, 0.9615377822732452, 0.9186911540688045, 0.9432069786214383, 0.9425678583325883, 0.9594845073219627, 0.9495878072408911, 0.950966387940354, 0.9741896046018592, 0.9038621456371346, 0.9710067373206409, 0.9512614674453799, 0.9689838876334064, 0.9484974595567595, 0.9642247710377848, 0.9607243977153365, 0.9543806902772071, 0.9770053930103504, 0.9683688155097504, 0.9476855331570087, 0.9061627157152516, 0.9823422479736076, 0.9347143654795363, 0.9550741882981304, 0.9592393236598725, 0.9585793410404666, 0.9631566514919722, 0.979300092031617, 0.9406087236132132, 0.9746585423155422, 0.9237259925604888, 0.9258138223260424, 0.9304694097261382, 0.9654985074148751, 0.959520503171489, 0.9272249805802524, 0.9482332768802723, 0.9417302997439811, 0.97475468669437, 0.9531825381768478, 0.9406068981280854, 0.9380464849328538, 0.9226432745109603, 0.969458550362906, 0.915922911425756, 0.9036831275974133, 0.9426211452075882, 0.9385895868126956, 0.9459725940624719, 0.9187921090520332, 0.9736952529054796, 0.9511119317360085, 0.8936605133983654, 0.9559532833687108, 0.9449026034078513, 0.9623196373672817, 0.9345839056626666, 0.9560578791363461, 0.947990786752157, 0.9279524187000567, 0.9796271587395424, 0.9492443841058388, 0.9440664854237987, 0.9555534794886066, 0.9439867955795721, 0.9483032242473696, 0.9401973496335617, 0.9668256992024933, 0.9575761258362149, 0.9187908677319304, 0.9817848875749182, 0.9565513841595071, 0.9649868901195167, 0.9816240616669042, 0.9280540201146836, 0.9331113355669411, 0.9758792429209617, 0.9652529034799209, 0.9426026689910791, 0.934939884454226, 0.9581648361002439, 0.9596380453875493, 0.9535557750449094, 0.9748530731705759, 0.9639442502070766, 0.9293941337843122, 0.9551506890482789, 0.9621822781877446, 0.924191293988948, 0.9495023098607568, 0.9293403181396991, 0.947622703651178, 0.9311077298288488, 0.9467160903291876, 0.9723280008677219, 0.9537324719590844, 0.9778408738530094, 0.9319026178840392, 0.9470060112250628, 0.9385708681695553, 0.9435214072480151, 0.9656702211070216, 0.9444161105373368, 0.954358955438976, 0.9446431824736636, 0.9488367618773796, 0.938760737701302, 0.9523281839111982, 0.9758872980152854, 0.972789354671448, 0.9627095578399842, 0.9829339047191076, 0.9442528554343245, 0.9627294166419901, 0.9723684461482518, 0.9397544432435758, 0.9625171463245721, 0.9527206445918006, 0.9533702236542239, 0.9343038488029124, 0.9516631089073672, 0.9540948074675807, 0.9553203247369597, 0.9430049993475335, 0.9525208242323241, 0.9547071300811443, 0.9645591349961331, 0.9617144955967513, 0.9688752735889486, 0.9275023498297794, 0.9391305327926807, 0.9383826047865526, 0.974086093443412, 0.9557197505741262, 0.9526423867200381, 0.9581525173328415, 0.9461178554907774, 0.9428216527316499, 0.9630197144627048, 0.9793807032086089, 0.955775224125185, 0.968364245078885, 0.972758187430771, 0.952341027319193, 0.9776790745114365, 0.9764331099627115, 0.9575450591790069, 0.9610245724799017, 0.979680653219055, 0.9624977979454805, 0.9390199878492438, 0.9477663600323911, 0.9498382793824653, 0.9602494313010393, 0.930531150923136, 0.9538486760866283, 0.9306589868802841, 0.9631447461253148, 0.9670908291244835, 0.9243858153800099, 0.9577686001898416, 0.9143106635082586, 0.9349819601328537, 0.933125158206246, 0.9539148256732568, 0.9690300675228817, 0.943105175291911, 0.9492295527607063, 0.9679529261859837, 0.9359824923442096, 0.9354637692611721, 0.9467394543837097, 0.9501646878338316, 0.9714313039035936, 0.9418626575446273, 0.9431970530259953, 0.9503070481526124, 0.9215909569051326, 0.9667068082505853, 0.9135321491049047, 0.933846019538459, 0.9522483687293263, 0.9461546348604106, 0.9383227107942554, 0.9807467907201181, 0.9400013608827764, 0.9339091094567779, 0.9573607772418871, 0.9079591238674486, 0.974087624881513, 0.9786422685023054, 0.9427900787277845, 0.9539624305910649, 0.95668529834574, 0.9448952665097619, 0.9690325827655306, 0.9264842080536192, 0.9618447884354877, 0.9308642240903529, 0.9581586522628404, 0.9327258911883848, 0.9753938506504137, 0.9626878670576258, 0.9667686925783191, 0.9469719151796574, 0.9569043721473676, 0.9632506377409764, 0.9498965568330331, 0.9471331642200659, 0.9739976171423559, 0.9535261673313861, 0.9801453848432864, 0.9168174052898651, 0.9630481310771694, 0.9085296650579965, 0.91941016436744, 0.9581377304390761, 0.9462271091777757, 0.9444493954218234, 0.967778915484711, 0.9630737002121457, 0.9697667445049694, 0.9354987418996712, 0.9678957432759766, 0.9421986603470577, 0.9609270560556635, 0.9427672270776913, 0.9505446350648012, 0.9323047808110064, 0.9384287825726315, 0.9506145245270826, 0.9781084368567429, 0.9358535345797738, 0.9362406867524197, 0.9259633814813069, 0.9634984848255744, 0.9333891132833448, 0.9847478155207139, 0.9460511321429801, 0.932609054943686, 0.9509146286000956, 0.9312421823049284, 0.9421825743085124, 0.9548979332993097, 0.9488122446662154, 0.9272671148947417, 0.9526385824460284, 0.9729013313994929, 0.972392300955877, 0.9395016088029111, 0.9569921676222131, 0.9099970865095286, 0.9345803360584738, 0.9588947463530946, 0.9366709178535025, 0.9514518271708291, 0.9571227031454141, 0.960357099556895, 0.9783327278296052, 0.9414676189046063, 0.9588765999158171, 0.9868021521164944, 0.9684128928885831, 0.9656916045984547, 0.9368282536020371, 0.9264301950008369, 0.9653852255639088, 0.9389233932055616, 0.9402998578681941, 0.9625785492129024, 0.9052810016632675, 0.925844339599122, 0.9805951176800687, 0.9868641123604783, 0.9581059256436446, 0.9527438753406525, 0.9592599785773424, 0.9331179167326054, 0.964482604722448, 0.9576494502409688, 0.9494477014583613, 0.9371525048739452, 0.9350306890550774, 0.9573597189387002, 0.9770734791266316, 0.9324422315945726, 0.9768539765187618, 0.9597860184344379, 0.9477420348950334, 0.9336216944338956, 0.9536672193524116, 0.96243652297276, 0.9810670038558638, 0.9401131580060712, 0.9503589318577721, 0.9427279823797794, 0.9584728970796006, 0.9503348456158666, 0.9690223753172498, 0.957840424025415, 0.9363679378860692, 0.9400459025816523, 0.9229160222549313, 0.9715962047113382, 0.936653569760502, 0.9639890273585469, 0.950165227640574, 0.9549923762352632, 0.9471986054218461, 0.9199623625450156, 0.9612900938043007, 0.9782230935988913, 0.9375624246424713, 0.9686754008147642, 0.9399972697344929, 0.936455233519509, 0.9154417979094656, 0.975635971687328, 0.9769790331509842, 0.9542648561368561, 0.9350603736347353, 0.9470661292761542, 0.9510623150004905, 0.9496227479976773, 0.9270746201876076, 0.9655655288093584, 0.9728729541365213, 0.9652962819777172, 0.9631504935901206, 0.9741576405629226, 0.9482381302635532, 0.9681486903261061, 0.9378387105115228, 0.9646052660162877, 0.9215524864688173, 0.9563201131593002, 0.9547401531013928, 0.9373709444281907, 0.9467681556438264, 0.9575287600012218, 0.9209569350616459, 0.9623364086708082, 0.9536773387471427, 0.9698648129267698, 0.9753194376095203, 0.9522852679442861, 0.9625439031586773, 0.943934496686899, 0.9758373231599964, 0.9497409588166906, 0.9690093919827321, 0.9214233752862878, 0.9669006660332274, 0.9513646724472926, 0.9382394162223141, 0.9567444065322713, 0.9614286341293631, 0.9486594410490761, 0.9132580633360359, 0.977588458611141, 0.9247491433679558, 0.9727165119090478, 0.9410905451879178, 0.9448003420474229, 0.9738102695332436, 0.943838595080426, 0.9531825505768663, 0.923734402662025, 0.9789829081526737, 0.9485320190582943, 0.9403626269722374, 0.9532310678792578, 0.9142041855025693, 0.9638239582752577, 0.9426504307067668, 0.9580325958311386, 0.9713333162634225, 0.9550884747658293, 0.9525151707741022, 0.9676384959781842, 0.9629002234119883, 0.9712854093317931, 0.9280372299898797, 0.9816498666193384, 0.9662854541088599, 0.9598147678455964, 0.9526633974718275, 0.9620746655697789, 0.9315925146357475, 0.9747195466845827, 0.9317753116240942, 0.9717252739883101, 0.9691901955705773, 0.9758516093825903, 0.931318872407099, 0.9646608980070449, 0.9648046275098672, 0.9594019957542606, 0.9666350182679712, 0.9507577426300501, 0.93189260826413, 0.9523989239470608, 0.9811273104910108, 0.9537627578354405, 0.9653716321425105, 0.9562117106703246, 0.9248273940760218, 0.948098023756562, 0.9707128114709415, 0.9689410134554507, 0.9809050731303866, 0.9440139258587342, 0.9265666302950635, 0.9719107527568847, 0.9792607368129361, 0.9294205661698904, 0.9728776280419603, 0.9203734979319885, 0.9422062867486747, 0.9569700040794235, 0.9491918586427991, 0.9295696552287961, 0.9612066797209496, 0.9732337369247267, 0.9221604137432086, 0.9706823239296252, 0.9567852683173427, 0.961871626594887, 0.9747741945165402, 0.9579530095361448, 0.9735003683647757, 0.9325949166627273, 0.9592220947145867, 0.9670642549867019, 0.9468018608072558, 0.9600445286945583, 0.9802706406378295, 0.96905504159537, 0.9420289583822471, 0.9580261466614223, 0.9709505423468159, 0.9658943069347674, 0.9733560552767802, 0.9658181264711654, 0.9548892293389944, 0.9530702437559136, 0.9662175650798104, 0.9502080761374576, 0.9550948951825116, 0.955539990577076, 0.9405987353023725, 0.953636344018787, 0.9651730104480272, 0.9684852605958967, 0.9415672385382595, 0.9362817917827257, 0.9526177649258969, 0.9677839642724351, 0.9650003751310802, 0.9726505324786288, 0.959507417632786, 0.957964511612255, 0.946193634274222, 0.9402259994152843, 0.9504886137141038, 0.9455867713809758, 0.909192146702592, 0.9647690439788196, 0.9506804858490792, 0.945895259332969, 0.9774512469833717, 0.9366573510118545, 0.9610985366957921, 0.9814874597338384, 0.9388717482932831, 0.9447088236900435, 0.9568351169564461, 0.9463066871651195, 0.9162523807950179, 0.9421067755109989, 0.9420835811637843, 0.9623671082781671, 0.9520262786425492, 0.9542201628456586, 0.9482201421960716, 0.943204989056318, 0.9809479686734186, 0.9650808356762716, 0.9299008988284021, 0.9827171893873055, 0.9653540463555041, 0.9476452172444282, 0.9500841480675815, 0.9474234375974062, 0.9708839233410752, 0.9749796389782571, 0.9753000686384274, 0.9622602700304734, 0.9340501828920297, 0.9716426256946956, 0.9700980808473754, 0.9735547534792269, 0.9704863984234077, 0.9492881158984003, 0.9521782918729828, 0.9709943631259508, 0.9544269100496441, 0.9480918429385102, 0.939458199540147, 0.9594951392654788, 0.9588988121277906, 0.9606905577483449, 0.9462216010355925, 0.9792880431232598, 0.9684622538805937, 0.9506556723790932, 0.9224015058165667, 0.9497830633246691, 0.9468173625135577, 0.9720983382631614, 0.9501264267618001, 0.9684191695392799, 0.9826951257883069, 0.942850333061275, 0.963598931742469, 0.9750394567727545, 0.9332566196458869, 0.9401092115963053, 0.9348288482872334, 0.9758729232552805, 0.9576182967302318, 0.9323932886817943, 0.9743718983365001, 0.9423264243908225, 0.9490620942261909, 0.9250736986248117, 0.9806937939485225, 0.9248471181813656, 0.9405114955528301, 0.9669902044569375, 0.9571429317466889, 0.9486913889577372, 0.942600593964132, 0.9665077617430063, 0.9495026723295841, 0.953660648241466, 0.9547909343689912, 0.9798055284252319, 0.9434693605069319, 0.9770381466791276, 0.9572280169182317, 0.956551607781358, 0.9761520119389859, 0.9534463695156071, 0.9796098169174364, 0.9531529172414024, 0.9173746023445318, 0.9313993998526799, 0.9485029989057077, 0.9519730439564194, 0.9773627319499267, 0.9561660114150139, 0.9388566421831398, 0.9728828683238357, 0.9770180048827372, 0.9340307146631285, 0.9544905099246637, 0.9497024175067196, 0.9332626072713299, 0.9450237892755897, 0.9738075850017095, 0.9698125210166134, 0.9778606596697217, 0.947439331790498, 0.9194942289595118, 0.9420740578568492, 0.9833038743011344, 0.9225782736467383, 0.936464861367244, 0.9463712658407379, 0.9548481373925962, 0.957224048395728, 0.9571328752287255, 0.9714932230127177, 0.9578123713508951, 0.9637232067317334, 0.9570744233055756, 0.9370647451101831, 0.9191686286901061, 0.9264687483075628, 0.9314109855501947, 0.9699171300841488, 0.9599860603552667, 0.940739519684066, 0.9494633627978495, 0.9551016153137122, 0.961596551516276, 0.9671629081712395, 0.9432028196540723, 0.9698320848546278, 0.9704872772993816, 0.9282974351626986, 0.9437637379146764, 0.9517109937968324, 0.9755769744230741, 0.9591764512526665, 0.9298257721035391, 0.9373683289699163, 0.9562861136146671, 0.9342105543583775, 0.9760123812181016, 0.9346411097342378, 0.980357317067975, 0.9709072191656095, 0.9318012683429284, 0.9581364829435532, 0.9280052800011409, 0.9467682912072566, 0.964145031814157, 0.9681763317542964, 0.9635284138127732, 0.928048111770187, 0.8886352057672876, 0.9699617474190031, 0.948151686203831, 0.9582298361831522, 0.9570387626704538, 0.9301234650003366, 0.9749895323419343, 0.9669454868549117, 0.975430743815828, 0.9260503794875832, 0.9539197801163708, 0.9467480275647442, 0.9651048935189004, 0.9387664935142048, 0.9383703200767658, 0.9538071499760064, 0.9708672260351706, 0.9667445365617523, 0.9530001246460604, 0.9357860930017248, 0.9423640093541419, 0.9744876494209973, 0.9626181572851972, 0.9466365489206118, 0.9358067140867476, 0.9513936196586735, 0.9728288936431261, 0.9656121362008504, 0.9522093789524443, 0.9615354300224089, 0.9683998207898128, 0.9543369720466416, 0.9556693408599322, 0.9643086075267935, 0.9623194662015049, 0.9430589588696332, 0.9379368800334409, 0.9427191209467991, 0.8991009531007113, 0.9550463707286844, 0.9538226436441798, 0.9854107743403785, 0.9684703883390654, 0.9604355121903446, 0.9487590718846086, 0.9160916521135024, 0.9516221732019762, 0.9252472482099116, 0.9831311070964915, 0.9597541337369826, 0.9406669304478762, 0.949868231392096, 0.9723945680684623, 0.9374016673603226, 0.935230671738473, 0.9663137339880262, 0.9628235996330692, 0.9743372059755587, 0.9333714794934995, 0.9759734093348238, 0.9198372565879577, 0.9633392112727301, 0.9300676698053865, 0.9221262283135931, 0.9156920558058856, 0.9271830213576215, 0.967194460248564, 0.9558108841343762, 0.9741579219169061, 0.93815158565328, 0.9298600805527018, 0.9617065054217666, 0.9435811103982398, 0.9335053626452375, 0.9619254734130172, 0.9560108417677616, 0.9559508888078606, 0.9425847440265325, 0.9531720267755421, 0.9474608556157408, 0.9609488442189669, 0.9486653795869836, 0.9531686132657405, 0.9543943984692612, 0.9714170927773776, 0.9598552976212643, 0.9695541302176642, 0.9787497061980537, 0.9323605513714545, 0.9643455389019432, 0.9658460919849424, 0.9492294088215336, 0.959033367269394, 0.9664130262867601, 0.9044098589570329, 0.8986337206140154, 0.9488553988065725, 0.9757212623646206, 0.9570911902419539, 0.9655045724055166, 0.9347425931040045, 0.9312633979293908, 0.9388244890742026, 0.9724762695801121, 0.9302792457069586, 0.9800139654772503, 0.9622412501559231, 0.975711612443218, 0.9799124948999737, 0.9779463086945936, 0.9270326818771998, 0.9419714562909453, 0.9574690860616131, 0.9447996606983594, 0.9613892166894931, 0.9558533180685469, 0.9631533102826179, 0.9455485146999597, 0.972431202350935, 0.9677404530149502, 0.9793798609741688, 0.9475189460711219, 0.9342363301794588, 0.9742667616835754, 0.9388563983439565, 0.9685190794021976, 0.9555767239999226, 0.9631879983506275, 0.9730530806597595, 0.9528307670272876, 0.9754546911958911, 0.9578709846789416, 0.9439963720751318, 0.9763045408107719, 0.9556865035962632, 0.925017214167501, 0.9431732312936529, 0.9255201648735513, 0.9658047749191196, 0.961553577009974, 0.9854726509570667, 0.9631926809358742, 0.8955256772686256, 0.9862204484821971, 0.9283186039691314, 0.9603324941078738, 0.9837020635368953, 0.9186892390016482, 0.973044284266564, 0.9685551796936059, 0.9360780587232891, 0.9290222110248496, 0.9637469856179077, 0.9681130628002438, 0.9415407473220342, 0.9545016800108869, 0.9518959969608758, 0.9742737792401951, 0.9698179510110424, 0.9503356124615003, 0.9114510676281657, 0.9679461499879768, 0.9717933400799874, 0.9321613247358105, 0.9404554545165417, 0.9759044098788825, 0.9462384694669581, 0.9596035719679986, 0.9598262687114176, 0.98108120827088, 0.9377561856120967, 0.9462573131594134, 0.9320200865648711, 0.96573160395548, 0.9244443179778508, 0.9399158718074194, 0.9522944378982086, 0.9490946608501761, 0.9723376160679659, 0.9558129573823806, 0.961513924472665, 0.9449902107864623, 0.9682601384088759, 0.9728974947251317, 0.9712541257839927, 0.9478712217061201, 0.9798675376464139, 0.9600351950920242, 0.9327729658060783, 0.9312048598587361, 0.9754613843280402, 0.9546329720271205, 0.9519554593855382, 0.9822536632471452, 0.929666120934372, 0.9741317241496681, 0.9566303424170011, 0.9611184675020576, 0.9443288579831111, 0.9603896889179235, 0.9520685923893547, 0.9502143672215722, 0.9243954723157309, 0.9425413145460346, 0.9519270420705062, 0.9288678324622818, 0.9704618769805309, 0.9551904012527903, 0.967414323933414, 0.9711712603400039, 0.943271272403881, 0.9019741104050744, 0.9405846126281483, 0.9732042819126366, 0.9463856128033044, 0.9480323300343655, 0.9605538717864929, 0.9280645104649352, 0.979468164773954, 0.9686597750467497, 0.9674873078515238, 0.9497830239851648, 0.9650443846076358, 0.9597358452797804, 0.951315550153924, 0.9552432180038805, 0.961038397226092, 0.9563274325990837, 0.9525558272944471, 0.9305637328759848, 0.9749486182042326, 0.9545979626587505, 0.9418935972715448, 0.9768736366936595, 0.9779179932800717, 0.9736567156532251, 0.9633155648055683, 0.9590459612426165, 0.9765024835207725, 0.9513097736870612, 0.9254649818778227, 0.9373396642406082, 0.9780569092169058, 0.9296913317929772, 0.9359486337155893, 0.9643579932401694, 0.9700215884113346, 0.9772858348562203, 0.9658239313238884, 0.9823191350667373, 0.9568420743112772, 0.9586096005319358, 0.9491841097690237, 0.9662195514246881, 0.9770832483282156, 0.933431693075795, 0.970631976384884, 0.972933054779688, 0.923320627194579, 0.9681789652248542, 0.9630618245101047, 0.9488036662568918, 0.9496645295023779, 0.9624176315650387, 0.9500075791238656, 0.9379411887000454, 0.9801951373411116, 0.950356883264057, 0.9843026424814626, 0.9318320373477311, 0.9356735735287401, 0.9179327660578372, 0.9446164741221136, 0.9479514020279948, 0.9272930384357558, 0.979317307293004, 0.9424326932673853, 0.9352686030561174, 0.9473703019204567, 0.9757789504739108, 0.9623601675802713, 0.9512558234508535, 0.9707283433851374, 0.8892917838968811, 0.9490296306183501, 0.9464991224618027, 0.9480792367812928, 0.9310948900057539, 0.966330606376026, 0.9710192388416815, 0.9446728667940291, 0.953234577593634, 0.9815074650946769, 0.9844785406939792, 0.9386924901624383, 0.9459948431233787, 0.9196132121866776, 0.9164000940470753, 0.9732081581974645, 0.9583343124005091, 0.9430280080635656, 0.9277149483380615, 0.9548411726985193, 0.923706001826484, 0.9631564852243406, 0.9752547782220612, 0.9538006469341455, 0.9108895124378193, 0.96433206748645, 0.9768654909682407, 0.9549768684728333, 0.9480331882723482, 0.9139327559517008, 0.9292942713940155, 0.967372939307625, 0.9717401774067504, 0.9391078498160912, 0.9679605050029524, 0.9740634680453989, 0.9462467467524392, 0.9275601601230252, 0.9540044096544122, 0.9390165211740482, 0.9749906853065087, 0.9343043759527384, 0.9624451546203519, 0.9822754021297345, 0.9687194005765294, 0.9463267793921647, 0.976964840476481, 0.9446234114515483, 0.9690241942882685, 0.9696241367234342, 0.9250830605143766, 0.9661365207911076, 0.914245993450841, 0.9823879900863347, 0.931674011252665, 0.9646869010996952, 0.9705976067131695, 0.9625533307062837, 0.956141213273006, 0.9450195572378375, 0.9654060803420257, 0.9381738080370604, 0.9530373643731145, 0.9386017408471677, 0.9524244393712606, 0.9677309869806332, 0.9343280454916331, 0.9604756297383437, 0.9581369969233686, 0.934093585791012, 0.963317386115609, 0.9807684089089274, 0.9579625295162848, 0.9562549773280073, 0.9572835554864363, 0.9571833967705549, 0.9403562523470124, 0.9344263505098044, 0.9729773748385662, 0.9361613488029945, 0.9341927744276105, 0.931074548659446, 0.9593040209667523, 0.9452739195656684, 0.9346322238763809, 0.9633101028827962, 0.9455398293626662, 0.9314102860390201, 0.9612948708871872, 0.9605178881556903, 0.9513475445624658, 0.9655508199439411, 0.9411074361629951, 0.9786699786063247, 0.9812032094742771, 0.9593905740753119, 0.9330213016354366, 0.9423452093402268, 0.9609560326976178, 0.9583016922384036, 0.932614655437885, 0.9688533511111828, 0.9817383102545494, 0.9142359626465865, 0.9275064985885709, 0.9720591496880663, 0.9387513631458728, 0.9776979298770564, 0.9460833033456749, 0.9574533934903834, 0.9431930068496008, 0.9536091652644503, 0.9508963629777879, 0.9703606396896294, 0.9696047618815892, 0.933644985512263, 0.9727658001528715, 0.947125762706714, 0.9559358775804279, 0.9437774526299725, 0.9552499427090357, 0.9619611213383394, 0.9518900632718473, 0.9649130461273837, 0.9428611372553337, 0.9595076897712073, 0.95249659151553, 0.9014056439329509, 0.9507465354920395, 0.9451698302083948, 0.9731221000268683, 0.9634743068556467, 0.9607650937936082, 0.9306953766523272, 0.9505522118736155, 0.9741455683055972, 0.9648459363537607, 0.9695251739570935, 0.9200268066310711, 0.9488024291240545, 0.9799832578076706, 0.9691014878257107, 0.9018682960131634, 0.9624642361837724, 0.9300426263428934, 0.945948129709355, 0.9610675796372389, 0.954867919920971, 0.9654231626004164, 0.9447831028503063, 0.949123907034237, 0.9438787599057658, 0.9527956218473493, 0.9467822266871604, 0.972706476349673, 0.9522430477307623, 0.9593397683328384, 0.9567296461110638, 0.9472968389376475, 0.9534768071108786, 0.9573275923382636, 0.924966367622926, 0.9549375042603148, 0.9639833482681703, 0.935753509768732, 0.9853119242550489, 0.9462751467668165, 0.9568007575101063, 0.9097859833354469, 0.9232039585968707, 0.9308348125105738, 0.9606329195033378, 0.9474375729077263, 0.9665601970876898, 0.9601437556842654, 0.941807956168649, 0.973487863966081, 0.9376458526144783, 0.9635785900577708, 0.9492894120721628, 0.9265152877233518, 0.9455056648977673, 0.9774824618337767, 0.9495459889390722, 0.9797374956384469, 0.9661776909243819, 0.9435800415919129, 0.9629372477854599, 0.9817340328485223, 0.942759506117303, 0.9627078443949006, 0.9753162246601124, 0.9569017991097425, 0.9598666042523044, 0.9649427594765378, 0.9191573242599753, 0.9750987304846399, 0.9578985814652851, 0.9797059046581736, 0.9494354459220012, 0.9721610847739117, 0.9746318981255843, 0.9756090809902608, 0.926419790884687, 0.9774712169886488, 0.9729407744972743, 0.9603737663928821, 0.9730757268455229, 0.9810439210216207, 0.9510818314788667, 0.9380390247060646, 0.9423807898824007, 0.9706261336775858, 0.9403216438224445, 0.9815176748586206, 0.9784010157231456, 0.9777680764049457, 0.9671940483651191, 0.9479403605009363, 0.9692815974632778, 0.95604948437689, 0.9591462073305299, 0.926359115044096, 0.9655513706917784, 0.9244867931750417, 0.9385865879266895, 0.9548797223091744, 0.9505708522996631, 0.939112567331096, 0.9217952879286434, 0.9480511274665143, 0.9710070538882312, 0.93851722020581, 0.9742024086143849, 0.9605095617422911, 0.9811475228039984, 0.9212070960986011, 0.9355955833955056, 0.9668013854903219, 0.9624636859312417, 0.9507767181285678, 0.9387353672563507, 0.9521416359766816, 0.9501158098078024, 0.953298991678064, 0.9684313753212864, 0.9582294518916831, 0.9705016967756347, 0.9748533402832121, 0.9419332464292741, 0.9649450411874786, 0.9527420793155487, 0.9793510720098757, 0.9483432209364869, 0.9751052680798915, 0.971422314673886, 0.9246415232691402, 0.9812255513083273, 0.93443638659636, 0.9499587192549519, 0.9815560873916415, 0.9582801369083536, 0.9670930142641583, 0.9456833836832592, 0.9464735639517728, 0.9634864203727155, 0.9808450513306122, 0.9512796407368784, 0.965161272142906, 0.9738178530560813, 0.9412762201887265, 0.9461631981366564, 0.9329227614187752, 0.9490906034138786, 0.9528886423486996, 0.9648134470863236, 0.9287212777912682, 0.9810430467470204, 0.9733139097679733, 0.9178531133228579, 0.9782040209770623, 0.9533950821862105, 0.9746661583137218, 0.9343426420121604, 0.9411219945620211, 0.972031630887197, 0.9342011736896557, 0.9396292693488232, 0.9709569076936685, 0.914610010476872, 0.9776415809405252, 0.9396773385181895, 0.95311791779764, 0.9473500590950275, 0.9461774896994087, 0.9408842010782837, 0.9643264766907775, 0.9691875544880079, 0.9574921381450416, 0.9344152738591395, 0.978939354062292, 0.9279189215695194, 0.9179977982082294, 0.962757374723671, 0.9667529599858029, 0.9162125253158958, 0.9803741937714232, 0.9724567807417881, 0.9717172383157628, 0.9073024598689203, 0.942771619243957, 0.954162360747326, 0.9397761021684772, 0.9489515736662272, 0.9569612347869262, 0.9662208529224126, 0.9663193082735482, 0.965847311792912, 0.96169709229598, 0.9486557821565953, 0.9789083706234786, 0.948519504613749, 0.9519403082810908, 0.9123298009818642, 0.9141369768422234, 0.9244108103311254, 0.950044866941222, 0.9622006234740693, 0.9492728917807951, 0.9065347285236209, 0.9700951459630663, 0.9556799739028089, 0.9250918809908266, 0.9650842800464791, 0.9201009735200126, 0.9375443931799565, 0.9496195141461033, 0.9566093562954624, 0.967674656239012, 0.9466288118898427, 0.9606822043534471, 0.9162508141657606, 0.9373979867166995, 0.9617342258546009, 0.9459147860379543, 0.9370843089367342, 0.9741633439759398, 0.9429428310035041, 0.9347522748134789, 0.9427482970752153, 0.9283545185615819, 0.9355766905571635, 0.9487570571495755, 0.9613991939793985, 0.91460967758093, 0.9418741018022091, 0.9659083227553925, 0.9744468158781103, 0.9550007737937027, 0.9044981797345157, 0.9003281794810364, 0.9421921051565265, 0.9673325910151023, 0.9516312891816945, 0.927809688095172, 0.9731305548675971, 0.9687726521131562, 0.9602794572989517, 0.9614942044202489, 0.9479251837258443, 0.9473365879316232, 0.981020075434264, 0.9539479253513446, 0.9243143573403905, 0.9506490214582947, 0.9713697944622309, 0.9776239008743873, 0.9536425801432032, 0.9331639126925632, 0.9610609279732534, 0.9347542994796447, 0.9311693036403248, 0.9211520182613127, 0.9204054819354289, 0.9592813839558241, 0.9568437535957219, 0.9772971757779013, 0.9541400616848486, 0.9553078245076574, 0.9275392018995291, 0.9540430170951744, 0.9542240606617928, 0.9372830846047716, 0.9529713250958957, 0.9634422553944837, 0.9643720102539839, 0.9767690723895943, 0.9647093653549631, 0.9378929080081027, 0.9796376870875547, 0.9770397369621265, 0.9388652624311662, 0.9189847342857237, 0.9405173600543111, 0.9623623275228056, 0.9835458090434218, 0.9184973101464027, 0.9674386188830332, 0.9545548182148008, 0.9880236615347776, 0.9518510312210647, 0.9252696965471802, 0.9229166831935591, 0.9479239972241433, 0.964530452730596, 0.9769538721445743, 0.9456598541360008, 0.9479174544330037, 0.986417113182822, 0.9720802044210511, 0.9724820324360509, 0.9710680446014571, 0.9626386545525509, 0.9611045121396945, 0.9573281638792585, 0.9470407780916565, 0.9643012593794464, 0.941724506200545, 0.9433266675338222, 0.9805221365842661, 0.955531409750884, 0.9548276288638975, 0.9610820119965311, 0.9695701560568635, 0.9479309969293276, 0.9480451078591106, 0.9547400941590272, 0.9472412872536198, 0.9347328688320622, 0.9561288063317931, 0.9353859388343635, 0.9599177658812984, 0.9804281937655426, 0.9505454406130449, 0.9432922972019472, 0.9448904283740364, 0.9500734786065379, 0.9448339033179226, 0.9522923428818134, 0.9443864622908409, 0.970017145363888, 0.9125730874922994, 0.9432294801422683, 0.9379670314283937, 0.9406767093976579, 0.964343636168492, 0.9897031525703182, 0.9608887872531409, 0.8785158150859061, 0.9338782066838237, 0.9707849227463173, 0.9651775364326968, 0.9444890660415478, 0.9384328071765052, 0.9320526084489501, 0.9392545029710349, 0.9337795121916329, 0.9584701868549875, 0.9285252836104775, 0.9621001479705644, 0.9716220834103774, 0.976199308252467, 0.9447740690102845, 0.9268939532201572, 0.9656176238190224, 0.9666351945123725, 0.9531337551879696, 0.9382601570494501, 0.9400981638482349, 0.9819101503320816, 0.9312331846641588, 0.9683919860870112, 0.9450551444152828, 0.9508682105617907, 0.9687625276424905, 0.9680351881949038, 0.9551766108296179, 0.9304497695005833, 0.9503521788835361, 0.9575808624331008, 0.9824002958308016, 0.9500079318846619, 0.9667545613009357, 0.9561506494039921, 0.9614739997028561, 0.9451443800256927, 0.9496225178571617, 0.966716563318271, 0.9567639635568074, 0.9383021899007831, 0.9750711512381589, 0.9532962952237088, 0.9702047663695753, 0.9534050636532944, 0.9573712913427491, 0.948868338599155, 0.9495741050340395, 0.9466689559067695, 0.9446481651674168, 0.9766061896273658, 0.9424695768961275, 0.9753504816413481, 0.9569587927872305, 0.983823860970843, 0.9183864954805491, 0.9832019676216728, 0.9740514028166329, 0.9444658216171263, 0.9520225668946114, 0.9471889567567644, 0.9565080909491884, 0.9726759832546428, 0.9439884819019091, 0.9506096988848968, 0.9607839949711539, 0.9698762527022526, 0.938042811442621, 0.9661423534436135, 0.9814881351547723, 0.9525875735837536, 0.9400660561296105, 0.9421020965474407, 0.9707307563786932, 0.9754607864860041, 0.9506391520642085, 0.9508858347643342, 0.9511917019230632, 0.9737262629780299, 0.9493896865297553, 0.9579182844293376, 0.9541586818992513, 0.9510783746449679, 0.9722321611255029, 0.9715356157251738, 0.9339769185492536, 0.9392052888233092, 0.9644322386507804, 0.9651870351476048, 0.9429966802349891, 0.9745714228338583, 0.9241044831349396, 0.954920549944745, 0.9614640876852394, 0.9373145864481404, 0.9791020715877398, 0.9753989169578029, 0.9664224143172544, 0.9386274213412101, 0.9557891843978585, 0.9633401477834999, 0.9445694120212306, 0.9318193152390745, 0.9719484632522558, 0.9458572282045823, 0.9376460669056588, 0.9517568151059224, 0.9192996408968263, 0.9334551364231463, 0.952384302378456, 0.9601066396519703, 0.9257097633747468, 0.9395085605797101, 0.9272766304062481, 0.9764603742058414, 0.9680907722410295, 0.9370567702375829, 0.9232622599210578, 0.9576415803924334, 0.952217755717495, 0.9822602288919813, 0.9766680658795861, 0.9637063488321432, 0.9457060041105022, 0.9421471011331247, 0.9810608845280031, 0.9401390973241545, 0.9612089973957142, 0.9304705617623922, 0.9413840097771649, 0.9521468102656581, 0.9558936779726998, 0.9641466889214112, 0.9702244970613207, 0.9252006788385719, 0.937538766125994, 0.9706294965486078, 0.9547069359050044, 0.9519419195247116, 0.9191234704359799, 0.9580909705035958, 0.9846103916975474, 0.9306443069587765, 0.946759749073847, 0.9790281982005957, 0.964870628527616, 0.9452429157889339, 0.935088318242295, 0.9612841073382873, 0.9585618347293307, 0.9676884088428526, 0.9669132617908779, 0.9430763476756107, 0.9558606053814762, 0.9396591109700232, 0.9663136781463324, 0.9301520088243976, 0.9681594844117378, 0.9221122207963873, 0.9482877992829637, 0.9469528239551903, 0.9523513774692711, 0.9594068240601182, 0.9507427127261556, 0.9705735380801732, 0.9648364488437238, 0.9736864022373541, 0.9581031325966415, 0.9278444298203758, 0.9664585520270077, 0.9562571565557642, 0.9580431853723548, 0.9423868382086649, 0.9834277151864786, 0.9541902326510688, 0.9155608920570224, 0.9407593208243408, 0.9686559197712795, 0.9457563844968389, 0.9495439742465545, 0.9444991017422601, 0.9572579649839774, 0.9456388726056175, 0.9424123250875631, 0.9593312187992865, 0.9618415463304986, 0.9693136962370733, 0.9683564295543954, 0.9639230467655364, 0.9837558704507235, 0.9349448733835455, 0.9586927289677992, 0.9425583350240865, 0.9565806389490036, 0.9433225899814596, 0.9315736406660543, 0.9300032056610545, 0.9688500267697159, 0.9804195607155736, 0.9410810211368094, 0.9410515121206892, 0.9636492015770175, 0.9639583280312326, 0.9718242639968512, 0.9631111980890309, 0.9011747388361216, 0.9439408175992328, 0.9765538568012558, 0.9567738964297748, 0.9514444562393511, 0.9833329428770836, 0.9822891409185717, 0.9705542176255882, 0.9639052554749772, 0.9649488045477128, 0.9701818061302523, 0.9740549738228438, 0.9524517793090492, 0.9487574205373119, 0.9528625654817526, 0.9266837723104254, 0.9336664250665803, 0.9357314849208873, 0.9643904635992495, 0.9708397864188855, 0.9482737951491234, 0.9811573953894013, 0.9586969349018493, 0.9078414084582059, 0.9799259026391602, 0.9831170316647173, 0.9438759701353933, 0.9765526849889579, 0.9455278291750584, 0.9629961496093455, 0.922428714220598, 0.9497015909449191, 0.9486556281399211, 0.9400377482499565, 0.9679394851511347, 0.9501569330173111, 0.9482409729601226, 0.9269579935673443, 0.9686751225494795, 0.9126159489363894, 0.9489528888806799, 0.9540253926649807, 0.9708764708190667, 0.9186108088483347, 0.9654756305840314, 0.9758803244648502, 0.9535903736106306, 0.9584260981939133, 0.9665571989382886, 0.9701862867252654, 0.9835765322865603, 0.9725404760229148, 0.9706306079458129, 0.8670002133663033, 0.9524869943376527, 0.9486363069465489, 0.962198202716122, 0.9524318915079899, 0.962752270579939, 0.9493167001269376, 0.9204525971789024, 0.9586298898612577, 0.9425723990981566, 0.9534729742602454, 0.9119755170525043, 0.9519101473777586, 0.9474007376532789, 0.9778643487207552, 0.9194262446595498, 0.9596116981645363, 0.9584747135914179, 0.9273036336559237, 0.9778309872026325, 0.9354474692695485, 0.9450156847871181, 0.9698338999870761, 0.9784740929050558, 0.9181199723098821, 0.9268345619815562, 0.9507645856193225, 0.9198659203513679, 0.9819852286017491, 0.9598025892722889, 0.9508104650785132, 0.910937135431545, 0.9577884041911173, 0.9629440151869484, 0.9834404497959826, 0.9675975565161979, 0.9547768979536484, 0.9736301802755366, 0.9651499015280334, 0.9261399003983253, 0.9851002713066168, 0.9591530594410351, 0.9733034618710811, 0.9440892238578135, 0.9453725377495862, 0.9516215725253891, 0.8944422853334923, 0.9626791793959386, 0.9487716174140387, 0.9811553673339226, 0.9292355275557563, 0.9497020953742851, 0.9576315056233826, 0.9437014495785775, 0.9459469167397426, 0.9673940735197908, 0.9392336836476698, 0.9422511262840861, 0.9312920048027625, 0.9782076106352966, 0.9689579996396831, 0.959341250686279, 0.9654948563390807, 0.9644287087424742, 0.9468947534748119, 0.9505830516566091, 0.9434110514131415, 0.9787759034356346, 0.976712374285627, 0.9614283141451772, 0.9338303317894138, 0.9677855012365602, 0.9666093849977386, 0.9010485494638613, 0.9656448128934678, 0.9389588354160499, 0.9811670683742514, 0.9674538381522122, 0.9575207389123055, 0.9323042981745334, 0.9260361321357697, 0.9528378481671653, 0.9594519557375701, 0.967287243579177, 0.9766603175931322, 0.9682383245468961, 0.9387168819811244, 0.9512621986507346, 0.9504600617922653, 0.9705569165261306, 0.9663709469260717, 0.9349881405275912, 0.9768202920471144, 0.9320513637526888, 0.9396345489383069, 0.907353512740485, 0.9746323888840566, 0.9188822741578966, 0.9599361567671237, 0.973065955867671, 0.9681402408408396, 0.9616119071885009, 0.9808809919424127, 0.9547304651365695, 0.9766471355331954, 0.9160502204324655, 0.9585072445688598, 0.986174632570293, 0.9517343579720835, 0.942270183848418, 0.9518401671214753, 0.9705226244972769, 0.9504923057977831, 0.9659031517450818, 0.9619900857615331, 0.9631772721874191, 0.9513051991651029, 0.9728109521976628, 0.9595581503405283, 0.9676466175508651, 0.9459915343188133, 0.9486305035972227, 0.9578572310617998, 0.9817499554219206, 0.9780943280855073, 0.9649105523398399, 0.9527701297118101, 0.9535650230395426, 0.9400954657966666, 0.9725205381013553, 0.9475782593213418, 0.969114806769384, 0.980884418823598, 0.971474379207441, 0.9324631918330137, 0.9438979509461723, 0.933387834867642, 0.9516014208975863, 0.9813326483203183, 0.9634229937667945, 0.9534423937614199, 0.976430036341718, 0.9658727004339507, 0.9275185280605959, 0.9785968599321028, 0.9660028265650652, 0.9435131637871839, 0.9484909459528895, 0.9688555933581035, 0.9406923461640715, 0.9461428674265665, 0.9618876681390326, 0.9649356993090364, 0.9147565388597765, 0.9797478003414696, 0.9337774744497693, 0.9766103893432343, 0.94973297052116, 0.942938772870044, 0.9432864954371618, 0.9411779794049677, 0.9701201738547054, 0.9597391748249001, 0.9653635541338697, 0.941750593404616, 0.9667262266095836, 0.9761220627554459, 0.9539485736416979, 0.9743376280575995, 0.9298625534069537, 0.9290718037888407, 0.9525404827266354, 0.9444184474336097, 0.9634402430934177, 0.9620472974043485, 0.9806068503236077, 0.8632725345985424, 0.9545799895964502, 0.9506114007447378, 0.9440142855756934, 0.9589951563070346, 0.9492461199369802, 0.9520787886852281, 0.9765664865974782, 0.96292644449902, 0.9429405806676648, 0.9141842795359602, 0.9746790521740595, 0.9617815323623844, 0.9613475725073858, 0.9636060626184275, 0.930865875702832, 0.9484716493691987, 0.9626711508450884, 0.96230990661643, 0.9736975445215555, 0.9723926727884157, 0.954670108319163, 0.9615175591051369, 0.9665085826124441, 0.9651657352977946, 0.9705175302086707, 0.9670544915661204, 0.9117869784583289, 0.9420909683821549, 0.9342952497301988, 0.9564126702972328, 0.9473067868959041, 0.956370051508579, 0.9527729922150462, 0.9346837596477224, 0.9637849723279633, 0.947544399304767, 0.9625410161495825, 0.9606340764109573, 0.9532644699299012, 0.9487779735959297, 0.9429500445636538, 0.948393332108634, 0.9516916619660583, 0.9624464816624799, 0.9545351828363686, 0.9725381413036203, 0.9192038349338224, 0.9444559324773417, 0.9468029585439229, 0.9627723365019356, 0.9743180603161881, 0.9668788439117746, 0.952463049617681, 0.9322413146456262, 0.9571250711850722, 0.9391756384924762, 0.965762882460507, 0.9590236998644117, 0.9427923353204972, 0.9792759197351816, 0.9658324397823768, 0.9768278667654822, 0.9415201956635879, 0.9320326465270352, 0.9445958743127942, 0.9472547874627394, 0.9625868878124109, 0.9546259838419247, 0.9633373381706929, 0.9573243714561477, 0.9152619066171656, 0.9115141353860312, 0.9630623052971334, 0.9364958988366227, 0.9763489005652041, 0.945733196375628, 0.9567250919120498, 0.9787182854143677, 0.9381299858515696, 0.9518906556848, 0.9567794102994621, 0.9563255784954562, 0.908868506630494, 0.9713615243840192, 0.9389758225645842, 0.97264323433243, 0.982688918967713, 0.954091286664165, 0.9501743484147923, 0.9434382294359536, 0.9810200268305138, 0.9224233360971182, 0.9597189283491259, 0.9462103688112824, 0.9527043100394704, 0.9104729845989302, 0.941504680543013, 0.8851958865344645, 0.9379466047939761, 0.9706829795433776, 0.9807631242846004, 0.905787908407992, 0.9737055158078574, 0.9570615123186159, 0.9669688625351146, 0.9533927897432763, 0.9413742945182945, 0.9729712456358983, 0.9739594580767952, 0.9674667269108648, 0.9742798388280846, 0.9419021587020509, 0.9627921788194831, 0.9622065615978325, 0.9417206779517794, 0.9791275858415956, 0.9552850277662842, 0.9526873787966392, 0.9621065751562516, 0.9682894591705014, 0.9468136919088619, 0.9582693489039162, 0.9475783882905977, 0.9410436262206656, 0.9733199631083536, 0.9645444446101993, 0.9760851554707014, 0.9642530838008352, 0.9434446599929807, 0.9798194667868115, 0.967755659440292, 0.9518596645474474, 0.9460425708897906, 0.9291006132404557, 0.9692860084548142, 0.9718433966801098, 0.9626531254100074, 0.9512285487267867, 0.9378346310706487, 0.9700810083554658, 0.9377289800822712, 0.9851564756066435, 0.9405382147396181, 0.9404840006899483, 0.9690434812944952, 0.93136720765244, 0.955437691081924, 0.9870658366233711, 0.9286342408310342, 0.9475712879212779, 0.947393298218951, 0.9751365285353573, 0.9205464769139544, 0.949218207799396, 0.9096077652562236, 0.9618211746444523, 0.9602251619611837, 0.9339639180921362, 0.9366057937562262, 0.9667374155636971, 0.9362270184206377, 0.9313646445849841, 0.9454101171753444, 0.9648475370083188, 0.9490382210726408, 0.9699605908580203, 0.9326353918097807, 0.9528741301002217, 0.9712856907467381, 0.9389963212992021, 0.9748028586218828, 0.9581425353325933, 0.9431018300528832, 0.9561637805083446, 0.9664661709193647, 0.9410798396062627, 0.9617681650613193, 0.9448557414838223, 0.9541861673041961, 0.9383729096087238, 0.939672664296528, 0.9712432601953768, 0.9544711949216677, 0.9178707881245249, 0.9560942821745272, 0.9699546953511718, 0.9580992480575684, 0.9255781293143781, 0.957594760698326, 0.9558076352780313, 0.9490639228961093, 0.9250557526771748, 0.9450592452374234, 0.9791071986278521, 0.9647661902808595, 0.9644532713596313, 0.9612436695161923, 0.9283551053007582, 0.9406156971733575, 0.9541445979347831, 0.951556139599096, 0.9676030870440817, 0.9830549864883755, 0.9703247990246237, 0.962996999879773, 0.974514179680179, 0.9696861667531889, 0.9240334482965517, 0.9433627417817426, 0.932513428848893, 0.9508770784360778, 0.9425504503255556, 0.9622543917168375, 0.9385190048074797, 0.9621078309394689, 0.918127404740268, 0.9482934809955044, 0.9548739871685408, 0.983915366699642, 0.8715286434947058, 0.9694634575638912, 0.9360098107096464, 0.9318264259411231, 0.9513598594631746, 0.9698097258773055, 0.9668654905556142, 0.9414535671558877, 0.9512761839677741, 0.9622647538774939, 0.9355054002062454, 0.9558557836484806, 0.9690953424872386, 0.9366484435313478, 0.9397108596134257, 0.9672693247978271, 0.9789759318211975, 0.9429086299271424, 0.9731366505721568, 0.9587571382698652, 0.9578256241530417, 0.9564326103721394, 0.9384841140420762, 0.9648082524643442, 0.9092335170696487, 0.9437129921784215, 0.9716125463771359, 0.942114890556643, 0.9394982034403282, 0.9626484346194345, 0.9715950110708811, 0.9684147675421593, 0.9533863132215163, 0.9651885690137098, 0.943617961476145, 0.9527783137062656, 0.960282975151326, 0.930775304102369, 0.9054531653690421, 0.904663629994024, 0.9523999084546155, 0.9594832655878934, 0.9708987031149166, 0.9261622366375545, 0.9592364250458745, 0.9278356965848902, 0.971022699797136, 0.9419977163970856, 0.9283150304712279, 0.9742730345308055, 0.9411257751950841, 0.9590951440526777, 0.9105644216490321, 0.9632318857638844, 0.9474446009728449, 0.9709236358878847, 0.9269984122138298, 0.9781508879104679, 0.8939964181873598, 0.9579759962374527, 0.9221727087536586, 0.92991453603208, 0.9669488099806182, 0.9263912611044146, 0.9527558465129865, 0.9364788753048114, 0.9596328700377701, 0.9659956416519481, 0.9487541501078187, 0.9465170754311343, 0.9312578283860623, 0.9429646581507898, 0.9654061554879336, 0.9684714120798317, 0.9647200096538082, 0.9508059225265233, 0.9498159735166446, 0.9553464157879814, 0.9521113467697739, 0.9594465371202839, 0.9515260084399093, 0.9647506626256848, 0.9177767280316017, 0.9588264413193166, 0.9781448748037236, 0.9547820547924876, 0.9726870819715396, 0.9209448952008571, 0.9384691639223631, 0.9203211035826343, 0.9621893579665595, 0.9244425948164164, 0.9459145558262031, 0.9468888345875097, 0.9413423363545856, 0.9651402755046642, 0.9650112470117589, 0.9577288721566533, 0.9749320511745593, 0.9468214596005748, 0.9447767998228845, 0.9839022951572995, 0.9743803809084054, 0.9324569681944102, 0.9419887024646415, 0.9319483950763761, 0.9476463694105668, 0.9248157345563225, 0.9294933953049285, 0.972107239774312, 0.9732361433532817, 0.9107132605114835, 0.9118152671942402, 0.9516149712252153, 0.9441024126330003, 0.9406399157111969, 0.9492692109400778, 0.9634434025684268, 0.9596946747207425, 0.9353505252113057, 0.96221074337313, 0.9405999988225883, 0.9575447079605732, 0.9450363428521836, 0.9515005596127107, 0.9481103930078862, 0.9449791821842868, 0.9317894458944042, 0.9408634886813316, 0.9811519407292779, 0.9534198094298034, 0.9533301863654962, 0.9766903193446334, 0.9460169055598432, 0.9727938278983163, 0.9355902339590622, 0.9730537350486619, 0.9152505712853688, 0.9344489376261494, 0.9680878906315293, 0.9530217764028148, 0.94865151100362, 0.944538379142325, 0.9563540718779979, 0.9453105870137252, 0.9522262060058205, 0.9743737244077343, 0.9777403671004944, 0.90276218943622, 0.9147828674251821, 0.9728596255829257, 0.9682416899715813, 0.9667487064277004, 0.9638432907579386, 0.9647068292076281, 0.9559736849705524, 0.9689894470796971, 0.9385798781701382, 0.9635342429563382, 0.948841860092431, 0.9843458595816617, 0.9525758613100036, 0.9629955112564483, 0.9616622350498286, 0.949152186829689, 0.9617754651355127, 0.9754276471750238, 0.9692252659259933, 0.9097001259520476, 0.9557205368840798, 0.9192642835547287, 0.9847334346407249, 0.9560462711239779, 0.9423733776775215, 0.9081460431362934, 0.9515957435960773, 0.9754883046797098, 0.9735436476721239, 0.9349658351895553, 0.9294558302681936, 0.9609964839840529, 0.9301255363113609, 0.9234584823335867, 0.9645017165981626, 0.9360315648341887, 0.9481000634433938, 0.9756848426878854, 0.9331018506619522, 0.9649773962414727, 0.9519464119992909, 0.9584655631180669, 0.9745310380124094, 0.9591599703885743, 0.9666337948824483, 0.9737361089417852, 0.9425397083841769, 0.9425272978798187, 0.9614339177891944, 0.9725093775141053, 0.9729435456594397, 0.910122304868183, 0.9576760468016672, 0.9472805178393828, 0.8870046990468995, 0.9555387343315914, 0.9495095315259621, 0.9612705718233008, 0.9284073044208297, 0.9466193684856432, 0.9331904096538368, 0.9538131745471174, 0.9439561758573219, 0.9370703803346748, 0.9789602013179999, 0.9540089039502015, 0.9594257419672773, 0.9084478800942574, 0.9432745862861954, 0.9620188618526081, 0.9332164847314637, 0.9258152514088126, 0.9166885994036603, 0.9370284828884143, 0.9509849168468325, 0.9861283390864001, 0.9221627731544325, 0.9318928168092446, 0.9732465986034908, 0.943668015319373, 0.9796070350027103, 0.94962781250719, 0.9328599136230306, 0.9423624330870584, 0.9419908586381259, 0.9819077663317144, 0.9810837050188337, 0.9376300774561189, 0.9483859496458997, 0.9580016795997987, 0.9730939874511578, 0.933445699182153, 0.9593389089538198, 0.9665566481455196, 0.9599681473931029, 0.9830214950191856, 0.899900306421674, 0.940619604691119, 0.9748962650091056, 0.9647169549372673, 0.9464126376691481, 0.9252500442994571, 0.9684175631968672, 0.9358883380767674, 0.9407018257807632, 0.9745512081081218, 0.9723784478148417, 0.984197507527383, 0.9317101372420444, 0.9201785697906044, 0.9515204116041746, 0.9639571388868453, 0.9834114056498213, 0.9392993636590088, 0.9760332659445509, 0.957817508550315, 0.9476264814874855, 0.9507841455508054, 0.9604116403073567, 0.9636372818068987, 0.957019635911533, 0.9203702290278153, 0.952559051890892, 0.9372217817332533, 0.9634934436095073, 0.9499878068705274, 0.9297400569061156, 0.9399681067741928, 0.9817008804366039, 0.9551070055526404, 0.8901627180876098, 0.9437771354757886, 0.936195574830413, 0.9213945213365607, 0.9379967511814635, 0.9606310566351856, 0.9720488559934113, 0.9775777970298624, 0.9570529191564867, 0.9401659254224598, 0.9577911367650329, 0.9256440823075617, 0.9512988122491424, 0.948082330158929, 0.9406285543607659, 0.9518914282170771, 0.9322197140665233, 0.9559770311678379, 0.9484678519469112, 0.9502588990484954, 0.9257654462496027, 0.9472455272138667, 0.9400775977064422, 0.9755625254645691, 0.9569239763823051, 0.938960228095682, 0.9743174415755178, 0.9627612483027693, 0.9700303946661938, 0.948175447952516, 0.9267436517732365, 0.9341249896614359, 0.9533850279053495, 0.9491850754094464, 0.9334920588475907, 0.9602957256287955, 0.9619706784661034, 0.9595733757941879, 0.9626249693855916, 0.9562268825075116, 0.9508950398752958, 0.9588549413402112, 0.9401594282941436, 0.945778844823458, 0.9511978020434539, 0.9617133503269842, 0.9348104633315845, 0.9528783930389759, 0.9554836150310658, 0.9592964440923774, 0.9672409668137146, 0.9544588845771136, 0.9645166689944447, 0.9440227611421401, 0.9280656263188524, 0.947092198758475, 0.9725796247826545, 0.933121786322054, 0.9511061389423052, 0.9375497912813652, 0.9473147180218271, 0.934534370456139, 0.9702622738786337, 0.9568223423154114, 0.9663334295067308, 0.9479183598501568, 0.9637826748216675, 0.982891204582543, 0.9309746425239719, 0.9658933621581004, 0.9506146282534819, 0.9501469022999873, 0.9473473198560834, 0.9793560872785517, 0.9657584495738268, 0.9359267375260248, 0.9876673479185877, 0.9236350859117596, 0.9597482181468472, 0.9668303081609778, 0.9616391046236232, 0.9485362939379026, 0.9733769372688391, 0.9436996270530794, 0.9368298360970354, 0.9408278330912305, 0.9668233491917717, 0.922047025387162, 0.9782540039481804, 0.9374758488138283, 0.958175197110701, 0.9678774279153762, 0.9610588238240787, 0.9445855552045433, 0.9761000092913825, 0.9421704415830083, 0.9573614042080584, 0.9691696605153212, 0.9817373070945872, 0.9438002087905305, 0.9355652451787749, 0.946070596223961, 0.9520516925763365, 0.9808588701049273, 0.9702855727487542, 0.9659689533015241, 0.9177148379857818, 0.9313668840784523, 0.9607020134040538, 0.9467491097912571, 0.9408160307310223, 0.9687111980457522, 0.9650912650942374, 0.9723873849917902, 0.9509758847221078, 0.9585833701124709, 0.9750247992664455, 0.9739401482938109, 0.9793240724882205, 0.9317798418249663, 0.935316523666032, 0.947234916187403, 0.9038856187717464, 0.9391040661564106, 0.9458090135788805, 0.9386189039255572, 0.9753557796959139, 0.9624493478983315, 0.9604893922951583, 0.9780885872453468, 0.9393610136478627, 0.9324340001733133, 0.9155627721807162, 0.9227552336151025, 0.9168593270236544, 0.9619419384858203, 0.9812733092065574, 0.975683892578571, 0.9458838574800834, 0.959839667014084, 0.9363505732260012, 0.9605092197945356, 0.9752479635857324, 0.9405330273866581, 0.9344419452531433, 0.9481440949113611, 0.9650507874493395, 0.967844151366484, 0.9789023153454901, 0.9798735995010789, 0.9396561231782736, 0.9272807761500949, 0.9612557279320423, 0.9629282487744995, 0.9326459869607842, 0.9738956846063561, 0.9749257661999767, 0.9473709450914003, 0.9467615285139002, 0.9354792094505117, 0.9730874709597064, 0.9472559866598936, 0.9650560365882611, 0.9667627494875065, 0.944143015818152, 0.9156938842597547, 0.9244065771652074, 0.9325103924012993, 0.9795747970453916, 0.9589323124835203, 0.9404943869471759, 0.9669975540698543, 0.9683532362022441, 0.9654165601909281, 0.9808138382548671, 0.9606113752572667, 0.9493436054111969, 0.9422367977691034, 0.9704439594924691, 0.9583685169358346, 0.921205719075863, 0.9411885046474919, 0.9744429098991502, 0.9322282333320029, 0.9362039904509115, 0.947244744335319, 0.9445783670345534, 0.9770958514183439, 0.9222922649683553, 0.9765354325080156, 0.9654454044137266, 0.9763783361102424, 0.9638820198178679, 0.9356724020454243, 0.936643878412309, 0.9541953491938117, 0.9623729657420113, 0.9658018741111977, 0.9308213658471831, 0.964780016370249, 0.9552559774471973, 0.9519357495905647, 0.9486166612291931, 0.9535150388667829, 0.9656527300439824, 0.961771022572249, 0.9717160510484316, 0.9709171183097486, 0.9310220413070299, 0.9533519999984924, 0.9411530613280307, 0.9526132150723035, 0.9467173552515439, 0.9809007606345341, 0.9436772719724583, 0.9614442944476546, 0.9345627889276527, 0.9565360537062892, 0.9496752270936729, 0.968809747704491, 0.9097359651003113, 0.9794604320617634, 0.9871234210830243, 0.9678408355839987, 0.9363331266190885, 0.9485140611424018, 0.9566334250582866, 0.9430687231581374, 0.9460235035435672, 0.9599848690030309, 0.9657679345554683, 0.9202619984348697, 0.9515867073181238, 0.9503390502928377, 0.9344086547928798, 0.9499325940757842, 0.9490341044698034, 0.9736271535017069, 0.9340521926228226, 0.9578813054862075, 0.9640664747366997, 0.9530081275299996, 0.9211230894633146, 0.951205894621707, 0.9313278674889157, 0.9696476333797521, 0.9365397928478073, 0.970258134899799, 0.9815208898157861, 0.9564985889249333, 0.9256458996926933, 0.9526132689889841, 0.9860820401321948, 0.9511606706544817, 0.9548706783562756, 0.9463730825730228, 0.9709542487553738, 0.9288718398962811, 0.9180773032920525, 0.9783796430737177, 0.9321833696792174, 0.9648697933371913, 0.9495581697944404, 0.9076304472332315, 0.9792155696038226, 0.9711018666568485, 0.9599306659122402, 0.933321257699547, 0.9208476797493027, 0.9793994261835586, 0.9413213501290684, 0.9514935469509317, 0.9417311610744117, 0.9435971265339664, 0.9297590081080769, 0.9520400612399108, 0.9656985778098389, 0.9424113337300728, 0.9718395833526075, 0.970889618936789, 0.9365603713727398, 0.9458532613105386, 0.9292754438757104, 0.9723980377252108, 0.9481056060076188, 0.9697462685916068, 0.9829961932499575, 0.92038541595363, 0.9751740766258807, 0.9363380859950848, 0.9651931017225507, 0.941167685601158, 0.9620483503649684, 0.9736212392162796, 0.9148376974487824, 0.9786924989568735, 0.9544258585002997, 0.9496840621165692, 0.9599765438000089, 0.9560265983705151, 0.9530389294019792, 0.9408799289774606, 0.9674762920506842, 0.9500180876526789, 0.9733485580688364, 0.9209656957280273, 0.9452693719343684, 0.9688528026728129, 0.9503032615184578, 0.9495522206934166, 0.959240646463789, 0.9413449365093733, 0.9419860894389095, 0.9786344269229899, 0.9491130017196494, 0.9755191886381793, 0.9362995079384383, 0.9787484157358196, 0.9767197608327827, 0.9422819841663064, 0.9743242984488215, 0.9383612096099335, 0.9403999692750545, 0.9555672151196254, 0.9823281278708452, 0.9709910969743297, 0.9574289482522197, 0.9706738283498146, 0.9469844209394431, 0.9810958084817868, 0.9436581292822083, 0.9720086863492243, 0.9441322265162028, 0.9579024526963134, 0.9812417761286474, 0.934448851443905, 0.912645735169976, 0.9398969408366779, 0.9522177425673567, 0.9628344334161781, 0.9370008419545477, 0.9704836285776003, 0.9529531639698525, 0.9464214397426374, 0.9577176481503943, 0.9592257880566396, 0.9795710614829296, 0.948302945221727, 0.9718755186154642, 0.9583441588288564, 0.9391995031953191, 0.957459761953838, 0.944382491006153, 0.9629314194854987, 0.9399137861652396, 0.9808574067406299, 0.9571447358050367, 0.96919993855981, 0.9187321295470805, 0.9569128843382205, 0.9675514931062789, 0.9444044723200977, 0.954351042460262, 0.9307472235620854, 0.9812236267257436, 0.9232362145739246, 0.9704727079219228, 0.9041993083692415, 0.9612777766543417, 0.920807735424673, 0.9552332371192099, 0.96892982388902, 0.959596563306939, 0.94325891332005, 0.9532325222951276, 0.8890314462595709, 0.9415579810542704, 0.9368980497688898, 0.9787937216992545, 0.9846690112427519, 0.9599007603402897, 0.947875207276221, 0.9115359942216847, 0.9726449475781741, 0.9445422715690396, 0.9324341913377175, 0.9531439284632361, 0.9304257524233138, 0.9397768449217493, 0.9448002444060174, 0.980986658843979, 0.9551969711225043, 0.9261141445081348, 0.9556352507327206, 0.9370105523021758, 0.9422784552992932, 0.9597285995413426, 0.9409937918026982, 0.9430422022437374, 0.9729266689851946, 0.9376064234560678, 0.9385098479361141, 0.972742317987062, 0.9562687817890995, 0.9597513946611866, 0.9694703218027987, 0.9442173050562734, 0.9486630260878874, 0.97376302810085, 0.9503467600159983, 0.885072902100521, 0.9613823458164521, 0.9519704503217542, 0.938595787538515, 0.9360643915748393, 0.9527875968683944, 0.9783098796705361, 0.9861036525962128, 0.9707665945980265, 0.9610406530768419, 0.9617068973958238, 0.9694512583555546, 0.9640204318700778, 0.9338345603509658, 0.9780898361733653, 0.9807076141700967, 0.9723973206760735, 0.9704980067541465, 0.9444539524487713, 0.9495332418708252, 0.9647904422640553, 0.9288387189894454, 0.9602508588741879, 0.9642810817292462, 0.9102643942487264, 0.9677965821044912, 0.9415272435617219, 0.9452500314173, 0.9557481917726786, 0.9622215669227246, 0.9397410005043094, 0.9510570419169904, 0.9643168183579902, 0.9469507239945226, 0.9855377970645944, 0.9434311165685212, 0.9696892316201775, 0.9735821058729438, 0.9231927618013961, 0.9429397351655724, 0.9263784157914762, 0.9426510643977802, 0.9553082003491727, 0.9412791798823544, 0.9372650816538104, 0.9692097710148478, 0.9487192163808654, 0.9478501921600685, 0.9479763090872735, 0.9489753712658014, 0.9804004433204333, 0.9440525642884933, 0.9232794413457759, 0.9424240611577681, 0.9694435384857671, 0.9719554194768238, 0.982638414603783, 0.9541126975334294, 0.9518516289953841, 0.9532241716816224, 0.9644789064121694, 0.9578513118706482, 0.935784887472022, 0.9721315496987674, 0.9506650154187947, 0.9477505435650435, 0.9552700702046716, 0.9530462925050572, 0.9744233978676201, 0.9278338492594032, 0.9675393153039179, 0.9838757262155088, 0.9614684341574045, 0.948487881712784, 0.9146913795511075, 0.9606097567121511, 0.9350005839607947, 0.9525201426325011, 0.9403982975671046, 0.9276998535783677, 0.9817083218295902, 0.9352803575488943, 0.9586124832002085, 0.9485653853988892, 0.967106734687311, 0.9491009580523714, 0.9301630439679958, 0.9640381213927646, 0.9455251174508212, 0.9561437942674968, 0.9417899261903178, 0.9545123895175278, 0.9789039537476795, 0.9615910332018371, 0.9716147052054095, 0.9685356868524959, 0.9280724683424596, 0.9444462929960964, 0.965560926445523, 0.9537554654175353, 0.9364685832981261, 0.9671287613969957, 0.9524466280862393, 0.9681295809323319, 0.9846012719246037, 0.9635358204959508, 0.9717568061494423, 0.963780740616823, 0.9861720062356132, 0.9648640365384954, 0.9608055031698447, 0.9654714731681923, 0.934572914723759, 0.9320955566015268, 0.9620383414810681, 0.9624312222660449, 0.9332734583646887, 0.9604891049768616, 0.967207445742973, 0.9096786215404532, 0.9585761489267884, 0.9345741401973878, 0.9688690928198531, 0.9183821048104996, 0.9704936823683722, 0.9679866288133608, 0.9553319883366832, 0.9341905774023387, 0.927036556453476, 0.9774510214440402, 0.963745503564708, 0.97889118144507, 0.9398268941774836, 0.9446546917243605, 0.925951760624681, 0.9792107827784128, 0.9735327373821048, 0.9534235385059499, 0.9256361481780269, 0.94208379630896, 0.9695473560691712, 0.9286432832712935, 0.944813572903795, 0.9695436479179785, 0.9425895300624562, 0.9483575643130707, 0.9603132577891041, 0.9429043581948491, 0.9729360214331557, 0.9369003476341343, 0.9511022030783188, 0.9490502197073385, 0.9393868233485035, 0.892131625705104, 0.9644879656425307, 0.8760249069459376, 0.9828230314246555, 0.9583286155633418, 0.9788331535072031, 0.9474308016141326, 0.9334420700402919, 0.9305916187852061, 0.9441959671242016, 0.9272396402574122, 0.9132127387513163, 0.9246571789005206, 0.9237512705659634, 0.953074165975185, 0.950962215097583, 0.9386911329993253, 0.9408573793579826, 0.9706957678278081, 0.9693574204283985, 0.9704806775559379, 0.9516149623146306, 0.9480622542655052, 0.9749879017438585, 0.9485542409079177, 0.9654103022850012, 0.9709451881108899, 0.9714165953954568, 0.9855033032524159, 0.9550383816817924, 0.9359907483807943, 0.9551296962734992, 0.9340207212984937, 0.9056075783557078, 0.9443757775493683, 0.9610466866276275, 0.9512140994121521, 0.9828465776437312, 0.930886061621412, 0.9531390025658654, 0.9681206499305203, 0.9485551365438942, 0.9803114681193835, 0.9482395751350755, 0.9316605871649689, 0.9544821002978021, 0.9618598700914816, 0.9264330545970945, 0.931181524674521, 0.9477675755049072, 0.9611482757545063, 0.9542772315533493, 0.9654052287805415, 0.9548010892176848, 0.9312886777978456, 0.9632124716171813, 0.9671393407930643, 0.9724062276663924, 0.9519648555758987, 0.959071341391785, 0.9322940293698183, 0.9755471739995254, 0.9611233719955641, 0.9400912559549488, 0.953202196748025, 0.9670463895538931, 0.9574789441611209, 0.9637638417399509, 0.943098290894871, 0.9545054071716721, 0.9556303118314468, 0.9403305827718142, 0.9499251444248046, 0.9178110371837344, 0.9480872303046449, 0.9349554363530408, 0.9757127659647508, 0.934688607029891, 0.9601089843387232, 0.9480812109968743, 0.9668720151778804, 0.9380424157047584, 0.9513830641174662, 0.9646976880417901, 0.9680115794797621, 0.9595709839281712, 0.9646363442921873, 0.9535337965970518, 0.9609609895641632, 0.9648607458377098, 0.984733283211667, 0.9675675826952737, 0.9672125785684549, 0.9503010039664292, 0.9667522511904106, 0.965189607433403, 0.9341064967933727, 0.9413153323873662, 0.9800734878347109, 0.976270305858782, 0.9310139680173422, 0.963548977869549, 0.9694355929278324, 0.970448417897831, 0.9221636242869656, 0.9737229144965215, 0.9855313690423683, 0.9735042943324992, 0.9667519127055567, 0.9354760954319108, 0.9492387971888812, 0.9832414616052425, 0.9675089199177113, 0.9480927561916082, 0.9522153660808442, 0.9690499078805129, 0.9684198396401572, 0.922033178987107, 0.9418303276950509, 0.978707519255088, 0.9731924684975284, 0.9522074940998175, 0.9541867052875, 0.9696269073937553, 0.9439606964787136, 0.9538811453382949, 0.9748930944151265, 0.9607390321453394, 0.9722080254886567, 0.9553602699786344, 0.9369724816544495, 0.9523376325937926, 0.9809261568741914, 0.9466915277829245, 0.9638390182673154, 0.9761927140252225, 0.9662189638622728, 0.9518247200038338, 0.7571344235151922, 0.9327347556759101, 0.9377466619854016, 0.9703362000810585, 0.9430705481320857, 0.9100714088779647, 0.9543635522384596, 0.9612302469935532, 0.9473785257780067, 0.9753108304921989, 0.9637695956634155, 0.9519070233116057, 0.9834675827298512, 0.9426372433728084, 0.9582370399801904, 0.9333888470530689, 0.969272347442394, 0.9012105365568003, 0.9541020589823743, 0.9679855204792932, 0.9612135525785627, 0.9632990835990809, 0.9457474458360171, 0.9271415417140416, 0.9435486325697384, 0.9465534222630544, 0.9651356553468253, 0.9573288173036388, 0.9075371874254147, 0.9191972517284788, 0.9518990728420209, 0.9367337312107666, 0.9490404945421029, 0.9525763775369753, 0.9656909472063663, 0.9631230413021853, 0.9418935965378455, 0.9497742728888526, 0.9767809787339604, 0.9072271382182533, 0.9489556372749369, 0.9412844927604771, 0.9428803399742859, 0.965154357673681, 0.9342544426855188, 0.9143975898882346, 0.9493551594977409, 0.9427319140557209, 0.9457878856973989, 0.9367212317081384, 0.9465870216782979, 0.9570059324399335, 0.9556819519386762, 0.9125407510495498, 0.9434869087396615, 0.9641329694304082, 0.9654270961825016, 0.9401806099730066, 0.9631142574313257, 0.9341764345578986, 0.9490756722142079, 0.9340743701115991, 0.9497368833859285, 0.965961685941187, 0.9598092119250491, 0.9711961590755479, 0.9724205730752986, 0.963104965849217, 0.9529100362067806, 0.9481549478074884, 0.9094256538714086, 0.9385094200854729, 0.9578662304111873, 0.9360628368040511, 0.9531474147458523, 0.9546309124136794, 0.9369197693573394, 0.9461183637089109, 0.9765481090120376, 0.9475667628815285, 0.9539504231510694, 0.9411640402044958, 0.9626221849019383, 0.9324129090732918, 0.9399804454393521, 0.9694133019523218, 0.9336873660465143, 0.955527802905278, 0.9459538804236438, 0.9711121287608957, 0.9568935079121764, 0.9766103966455827, 0.9441033865742557, 0.9587546432579444, 0.9499051912007886, 0.9826097565803196, 0.9821976928383531, 0.9687981139885216, 0.9495653292148021, 0.9460411258379824, 0.9523359266509832, 0.9551522541915246, 0.9083740054692468, 0.9323659025023374, 0.9649361855041916, 0.9501967370983759, 0.9693867555605536, 0.9359335976882538, 0.9600479884375189, 0.9657736758942089, 0.9736868919889866, 0.9613686403129383, 0.9561081841676627, 0.9643793324463931, 0.9830457331400906, 0.9634613586332484, 0.9525044626105004, 0.9526749626739711, 0.9643499618291517, 0.9620232815254356, 0.9046565880612673, 0.9415672205662362, 0.9714054480109149, 0.9497257979229565, 0.9665262976896845, 0.9711201369640746, 0.9722849118258909, 0.9487470580751127, 0.9496107950438785, 0.9297543840901236, 0.9693741268027481, 0.9673141180249446, 0.980409284525173, 0.9593779665248302, 0.9123004609975078, 0.946796406116092, 0.9705882210448942, 0.9515169253069838, 0.9503595081430299, 0.9694322999315984, 0.943816145214101, 0.9542927657386574, 0.9511934327673542, 0.9585364992780523, 0.9424210473252649, 0.9687556342730299, 0.9747692447172144, 0.9181690120526993, 0.9533594833176758, 0.9189684862455867, 0.9372445465526744, 0.9687013532268839, 0.9819800061502113, 0.982509288481913, 0.9654122589083889, 0.9492244502282272, 0.9662655366946062, 0.9543309969027354, 0.9326178928023289, 0.9574630063598788, 0.9432351579694641, 0.950663471233593, 0.972051939853627, 0.9495626389979325, 0.9824637946674164, 0.9791345280095772, 0.9591691628789069, 0.9664512003593432, 0.9579529298678685, 0.9713454256997047, 0.9626087151378993, 0.9366871462344227, 0.976864032515074, 0.9622008040232841, 0.9526228748822665, 0.9446969320016915, 0.9722655059741829, 0.9685817697024847, 0.9403621002609761, 0.970677187457802, 0.9668183342988469, 0.9653533152960485, 0.9405625345449801, 0.983526597906683, 0.9731814363214324, 0.9574525210197076, 0.9123661881829966, 0.9586945700110275, 0.9482164887132968, 0.952530165637591, 0.9603770080335994, 0.9468048738556953, 0.9498042191626882, 0.9418116170675802, 0.9660445525782653, 0.9406730339401824, 0.9500534340644792, 0.9643595668333258, 0.9722759499162662, 0.9575822573681838, 0.923353672962942, 0.9574377288704804, 0.9552467023253789, 0.9715259969157469, 0.9554373484821177, 0.9611352906492289, 0.9217809616627316, 0.9199759054603037, 0.928813134337527, 0.9774202650718351, 0.9725961041595443, 0.9824691099752327, 0.984952616237569, 0.964736307134298, 0.9416828706312801, 0.9547625074375251, 0.943166193752308, 0.9425323317181196, 0.9537715081613177, 0.9553405464669451, 0.9765286973192695, 0.9807371956936751, 0.938999163818995, 0.954234931914969, 0.9512270596639044, 0.982369737922776, 0.9558783453293347, 0.9657970650053398, 0.9538323840208022, 0.975020831178949, 0.9381066432483594, 0.9266344426786415, 0.958280191911269, 0.979890075190604, 0.9764928688785519, 0.949510937265078, 0.9785893712150054, 0.964351464909397, 0.9519919943811072, 0.9387586452672186, 0.9465170317156393, 0.9658406581974406, 0.9542568414972319, 0.982124765777207, 0.9655696133394244, 0.9776455041680792, 0.9703080567183759, 0.9626999993182178, 0.9765961366373025, 0.9576902726122669, 0.9738166723793029, 0.9533968380307557, 0.9314666315890634, 0.9741545099103855, 0.957314382584842, 0.9462674172589518, 0.9397162600674869, 0.9326376783124789, 0.8700341724477781, 0.9323864941434693, 0.9494698904121739, 0.9174862206224621, 0.982689095832859, 0.9749562823413332, 0.9573572046369625, 0.941744476491549, 0.9727801691541045, 0.9084931739905383, 0.9301660344159064, 0.9681650681376953, 0.9594572402604312, 0.9499470243802743, 0.9383046956405363, 0.958002203383, 0.9417127137762615, 0.9601257566071284, 0.952441716472695, 0.9455874614180704, 0.9491939803806975, 0.9293104333680586, 0.9514900313873931, 0.9595376785285762, 0.9666387167219683, 0.9804138820077608, 0.946195950377578, 0.9447747040746519, 0.9567607241247471, 0.9787254336644899, 0.9540779982881593, 0.9574633818513619, 0.9679130144701819, 0.9727217331199681, 0.9739976948743624, 0.9511452356790842, 0.9698630831826028, 0.9552886131298787, 0.9395502618654609, 0.9315579268009567, 0.9812090997383736, 0.9212759875178823, 0.9129226806365391, 0.9346132470163231, 0.9801178242535179, 0.9373911340906679, 0.9659200213076048, 0.9365565671267901, 0.9574887539067942, 0.9496171623164672, 0.914003935892704, 0.957777360971098, 0.9459915441971555, 0.9542091576835366, 0.9633963341680848, 0.9284411099792866, 0.9714369649400317, 0.944748858421619, 0.9130435334630341, 0.9461482542503877, 0.952177347285912, 0.9650108115496867, 0.9312754045544294, 0.9490250727910321, 0.9485340635927318, 0.8962938326034869, 0.9478418026160279, 0.9573705801439744, 0.9249267977272939, 0.9391298116032802, 0.9431404309768202, 0.9823221027681234, 0.9088845370329471, 0.9807764805403789, 0.9803342808357725, 0.9479915062053982, 0.9463524744904718, 0.9412014784586337, 0.9532035648999019, 0.9678129544773514, 0.9632179801366842, 0.9545315417306016, 0.9043341685688899, 0.9440299658283888, 0.9653601833714075, 0.940512988126692, 0.9514876421274587, 0.9190680158750568, 0.9728019969615352, 0.9612189934168037, 0.9265103363961631, 0.9584596483815349, 0.9486329936597303, 0.9437940024134569, 0.9179736725942543, 0.9559103160966631, 0.9764616245027616, 0.9736381269056816, 0.947514461520994, 0.9277429756224704, 0.9674512255698823, 0.9318865724756603, 0.9685624536879949, 0.9774044365812247, 0.9596746768006783, 0.9547595323685772, 0.9583639040293815, 0.9391709782001587, 0.9539708730277047, 0.9633912010424946, 0.9449810528630886, 0.9511642991845607, 0.9621640618224127, 0.9563890138860264, 0.9701935691923668, 0.9513471053084356, 0.9583238185823381, 0.9621585150047615, 0.9730995228972732, 0.939098494188931, 0.9358298286794564, 0.9596346931331169, 0.9497125528368409, 0.9662337807239478, 0.9539484796302885, 0.9374516018993707, 0.961521930656397, 0.9516160137194857, 0.9725117109717748, 0.9570290018776705, 0.9418974691886998, 0.9557303552844968, 0.9450931438419503, 0.9520766118335918, 0.9557620066325548, 0.9822460054567381, 0.960359659673829, 0.9550995725211182, 0.9717051861991031, 0.939872937435888, 0.9563851836124295, 0.952539788969985, 0.9298342460320959, 0.953947816064307, 0.9366500013463116, 0.9436940940622912, 0.9667017015731043, 0.9758744559400631, 0.9448063918430495, 0.9577650091920836, 0.9362553228383952, 0.9624612838466998, 0.9585553170172402, 0.9550169977936234, 0.9839143783621445, 0.9269721719802649, 0.9634181491671465, 0.9714783803311455, 0.9740510149909952, 0.9434010291171101, 0.9750651995280653, 0.907765592234521, 0.9812577851424898, 0.9729488427885847, 0.9672886161698958, 0.9462471813985116, 0.92895069657604, 0.9501317503020478, 0.9334182095512105, 0.9510424427230982, 0.9626972401735052, 0.9544718063863523, 0.9383133893143195, 0.967830491674853, 0.9769460979622584, 0.9583361738334857, 0.975233799610639, 0.9468714478763436, 0.9720379198344514, 0.9479466854554501, 0.9713065751755892, 0.9666246351738322, 0.9685201792334548, 0.9640392474240294, 0.913761163511233, 0.9607892018248695, 0.953269078461813, 0.9503224192246267, 0.9766794821594633, 0.9590420193469624, 0.9377965817137309, 0.9581795920017346, 0.9535399984495342, 0.9444382680067936, 0.9587056908463004, 0.9477615809022392, 0.9659118719783348, 0.9543154693227643, 0.9706451762624829, 0.9776722798536184, 0.9301040861711364, 0.9490151440421201, 0.964965093159449, 0.9799443917692029, 0.9753739374436144, 0.9405417989605857, 0.9456004967005238, 0.9819124304257372, 0.9378633706029592, 0.9317785467670442, 0.9573873130455195, 0.9178223798443192, 0.956958643903819, 0.9724286661657802, 0.9442674985893912, 0.9615995833750415, 0.9463133300139974, 0.949801571174397, 0.8927618303735453, 0.9426723576726275, 0.9705882448060822, 0.9649224316110078, 0.9672570840335759, 0.9167178389632674, 0.9408740636822907, 0.9585986431405462, 0.9358101195645476, 0.9468890555024043, 0.9579690533521238, 0.9473408740210745, 0.9525385190103028, 0.9726745583089443, 0.9595997435222158, 0.9312531454283155, 0.960523657937075, 0.9762920314025048, 0.9435780247244915, 0.9479078846029514, 0.9450068518822168, 0.9686452757932521, 0.9274994436937686, 0.9750804393575063, 0.9342994145267509, 0.9495611852046252, 0.9526763123419998, 0.9376841605253905, 0.9562605487005503, 0.9719984949237636, 0.9611835037330654, 0.9765171902320074, 0.9225492452822631, 0.9724096499060694, 0.9633174558140507, 0.9722915796658744, 0.9693249674626503, 0.9621523322087663, 0.9329085908558119, 0.9525544317580984, 0.9254198386078973, 0.9429086404314002, 0.832325726882276, 0.9524426506149538, 0.9582813715267224, 0.9778526341593079, 0.903673490879799, 0.9616073440528237, 0.9508123439255433, 0.9391646047731913, 0.9372936520728186, 0.9373819445692879, 0.9283711192202982, 0.9812914036987818, 0.9357203132108597, 0.9195810291845609, 0.964872026888425, 0.9464871613558671, 0.940892475156205, 0.9694777652143367, 0.9751970590228657, 0.9288815954770704, 0.950095630465346, 0.9568002470136703, 0.9787906743479539, 0.9553954891036861, 0.9664495472509703, 0.9637784632724454, 0.9697702441530489, 0.9573272700144526, 0.9528008461054749, 0.9476039559950409, 0.9469751342657564, 0.9328448974491403, 0.9602633058268669, 0.9842994372603805, 0.9519511521634249, 0.9447486097280504, 0.9593119771340947, 0.9433169749510649, 0.958507163334897, 0.9390859066880415, 0.9681265491733253, 0.9477031869514989, 0.9404582304568554, 0.9631383091909798, 0.9414324387266643, 0.943323303310703, 0.9439152772656642, 0.942548541213552, 0.9687992289873446, 0.9557334932447047, 0.9571772650708119, 0.9643506172777484, 0.9479820161681185, 0.9550362586906241, 0.9838312460869404, 0.954256612712856, 0.9851746073027008, 0.9382182103366261, 0.9583036118353856, 0.9438305346252147, 0.9375746352546006, 0.9597748562543396, 0.9756530195468937, 0.9506473802741123, 0.947596079337931, 0.9671491173322392, 0.9627665246788079, 0.9214831141117705, 0.9578124841142611, 0.9689009872188222, 0.9390949896396721, 0.9669257227943906, 0.9466301426132087, 0.9730818883069429, 0.9343070629481984, 0.9844697121354724, 0.9465577334633287, 0.985005125981031, 0.9598314111991805, 0.9294415131064747, 0.9405962941910762, 0.9459756453254327, 0.9649378879977761, 0.9611985240474236, 0.9284332176418578, 0.9404732551405675, 0.9628271857710092, 0.9614324795126373, 0.95036159467635, 0.9347108509917872, 0.9758024083409379, 0.9606236913015497, 0.973349966134421, 0.9534194944025404, 0.9589312079135566, 0.9610802723049096, 0.9772140248354577, 0.9456654510840634, 0.9442531984175849, 0.9643477733889694, 0.952403896597824, 0.9698170733686011, 0.9759865672551403, 0.9502035038865058, 0.9166732007532442, 0.9341508865413353, 0.9513089841207111, 0.9240753021565248, 0.9790399334134128, 0.9578835370557729, 0.9670030980302564, 0.9042603853902449, 0.9656794910444895, 0.9716134028757641, 0.9444942822964184, 0.9630780464728793, 0.9582082280427953, 0.9803823798036861, 0.9753436916236413, 0.9585062282824504, 0.923723855588639, 0.9325835000118621, 0.9750543960614155, 0.9822664841516415, 0.9455053001902771, 0.9779012225982302, 0.9714209120464461, 0.9516695199674678, 0.960523800653082, 0.9498924044116904, 0.9768210602899603, 0.9649336276390127, 0.9404817938924109, 0.9271190296128818, 0.9815391304978887, 0.9457866103896595, 0.9672443205943225, 0.9718526181167211, 0.9551773979504142, 0.96164064498708, 0.9454491597792493, 0.9264810250505053, 0.9537107575956685, 0.9670087105068781, 0.974976546587894, 0.95915631190322, 0.9477831470752871, 0.8769547491470433, 0.9629741166059081, 0.9484908923062207, 0.9504506679740223, 0.961123908311857, 0.9752841404899503, 0.9612814584658871, 0.9780179281589609, 0.9831250926538928, 0.9252674933679581, 0.953094018198223, 0.9104724697222354, 0.9588169697569093, 0.9808285145218565, 0.9257729555422051, 0.9323499807591249, 0.9442921768142997, 0.9699343482835672, 0.9748669274189061, 0.9340122213389329, 0.9508927361169257, 0.9782362283912471, 0.9535159574163248, 0.9671433200229397, 0.9339523851482961, 0.9702313367017885, 0.9782095163423848, 0.9818837150774167, 0.9647163553317801, 0.949195758333318, 0.9465684652685212, 0.9681593348925188, 0.9535156768436033, 0.9503463244847286, 0.9705705378233913, 0.9419840530563706, 0.9589607910851118, 0.9340163306499425, 0.9388907381764154, 0.939624409198346, 0.9463541261167946, 0.9796232644709117, 0.9524134938980089, 0.9782431865629362, 0.9542909745802723, 0.9456080234620904, 0.9741628520876384, 0.9777265325335338, 0.9511252809634161, 0.97233644783236, 0.9681219134283886, 0.965528954596917, 0.9487800170616136, 0.9495396643352685, 0.980725910176301, 0.9664407859637766, 0.9609334732756167, 0.9528076691322565, 0.9475685356431802, 0.9744489187056304, 0.9432644923735135, 0.9733745561097302, 0.9855277621914612, 0.9237350862921229, 0.9216929128349871, 0.97028309434318, 0.9554216906930155, 0.9414112349005773, 0.9690411881143233, 0.9777493723323106, 0.9334653278503966, 0.9433591055237636, 0.9603071845588658, 0.9831893923180582, 0.9398315056164782, 0.9379616610423795, 0.97712189044141, 0.9828327277822256, 0.9696301987507485, 0.966867802566907, 0.9635913682093652, 0.9612388936312889, 0.960727095310548, 0.9452713175631995, 0.925871364887535, 0.97444235427709, 0.9815043429848044, 0.9564728620839497, 0.9278518938530443, 0.9243622335789109, 0.9411285523505789, 0.9368540508119727, 0.9587192266962944, 0.9284009204471985, 0.9227854332223361, 0.9711533945242444, 0.9645251929576774, 0.9572939881017397, 0.9311970552348219, 0.9539231240951003, 0.9660606862737372, 0.9259544892488375, 0.9598937398379336, 0.9751406250484917, 0.9279307879948321, 0.965659846960165, 0.9486635537247998, 0.9594525701694023, 0.9376235050761078, 0.949252716455483, 0.9681182704793443, 0.9451132216857573, 0.9539734725260496, 0.9632075405696373, 0.9744759550786362, 0.9694832503235795, 0.9463338230523223, 0.9464670494488977, 0.925740425306236, 0.9731369048130535, 0.9258505722580594, 0.9681405132283945, 0.9329436603367122, 0.9846523012842653, 0.9669212103193919, 0.926158271482238, 0.9664658723434707, 0.9564640559108128, 0.9563419493390959, 0.9422034826697242, 0.9682390410050666, 0.9359187532332818, 0.9304495339188082, 0.9704795979578571, 0.9495021734552483, 0.9803387591085938, 0.9766127673991896, 0.9623812954616475, 0.9478361881129529, 0.9781739873381572, 0.9480430026943866, 0.960830058269222, 0.9261810356312079, 0.9028997576838695, 0.9502431669253578, 0.9303715716833256, 0.9091342470031515, 0.9327313315088894, 0.979098151643219, 0.946764830855022, 0.929845325673625, 0.9282325829453363, 0.9834667649163102, 0.9579499029559686, 0.9651072678701484, 0.9803004255217618, 0.9664568291375976, 0.9391790241355578, 0.9707609893995496, 0.9624553787121654, 0.9359691611821737, 0.96118350785005, 0.9543857574152173, 0.9598218300466008, 0.9421036675139778, 0.9646683098692623, 0.9656984417871757, 0.9627505623949691, 0.9710746801094562, 0.94871472281423, 0.9660303615317631, 0.9557467048267986, 0.9425196818208204, 0.9282629444149684, 0.9521923627105404, 0.9606940009103625, 0.9430277260015133, 0.9516227499110057, 0.9558441653678027, 0.939884082012063, 0.9497629165186335, 0.9163367183045843, 0.9369665853748809, 0.9114969305197291, 0.9432202663747705, 0.9563893118659648, 0.9722132623956761, 0.9808960688634932, 0.9501521984091325, 0.9516226723732506, 0.9554889599534314, 0.9675458177648758, 0.9317070746832745, 0.9360576272332543, 0.9225008956571866, 0.9627989302910391, 0.9679039481707239, 0.9352379971960275, 0.9348508743499517, 0.9493294929292588, 0.9440719024494779, 0.9619038294112953, 0.952770704736696, 0.9572195098459133, 0.9453946393131821, 0.9774203614386946, 0.9437963046357717, 0.945836452667052, 0.9683548691001099, 0.9157848329060699, 0.9785651578691973, 0.9362758093914532, 0.9687724374892358, 0.9772485365361102, 0.9206935049593998, 0.9359859210817126, 0.9333825071182354, 0.938492215241927, 0.9416107484347248, 0.9727233574609607, 0.9361306913239565, 0.9553300985831266, 0.9410918976951984, 0.9756312151558598, 0.9538035611086308, 0.9357151972009257, 0.9728815747380127, 0.9576567809507174, 0.9276725706685128, 0.9322914827926525, 0.9095763685345029, 0.9646212558028355, 0.9863360253964234, 0.966141212347372, 0.9405477243702636, 0.9405331703312434, 0.9402107261220948, 0.9385248039222674, 0.9596832361874462, 0.930018829164493, 0.9564111489913908, 0.9654882572214815, 0.9423415048563548, 0.9727789327030981, 0.9428219879821136, 0.9442077052926277, 0.9593740332922998, 0.9276755823683328, 0.9481683162518283, 0.9555468980798605, 0.9579736697941085, 0.9477032151277347, 0.9598079503429181, 0.93746980413102, 0.9586459202209984, 0.9257127893046722, 0.9224204692012253, 0.9850347461012081, 0.9703129796409423, 0.9392508645315322, 0.9358989479281153, 0.9387769593779887, 0.9535607059125054, 0.9551324345164143, 0.957069174558975, 0.9405218928540849, 0.9520406979340956, 0.960992037469784, 0.9210896071815509, 0.9654900952105959, 0.9338013756092823, 0.9776916453681174, 0.9468167784656379, 0.9523680834825032, 0.9465177448210064, 0.9652514048325957, 0.964306874153157, 0.9707483619314254, 0.9155920533057171, 0.9509793784564838, 0.9657565563321485, 0.9765040484261709, 0.9480642957950459, 0.9366109642303396, 0.9848574334763935, 0.9539490689765323, 0.9858571772737394, 0.9531276313740168, 0.9485712842853338, 0.9520311297984004, 0.9597596979145119, 0.9567058954624107, 0.9430130696585498, 0.9498218593232469, 0.9375239596789782, 0.9604855047222473, 0.9446511725701925, 0.9342067552248559, 0.9304942356717283, 0.9541285431552414, 0.9449515900928044, 0.9684499879333236, 0.9458727696129381, 0.9401905689439126, 0.9620932438387296, 0.9718862818974556, 0.9397757325152303, 0.9474096235304209, 0.9609094255582348, 0.9417186265221754, 0.9413380217756229, 0.9404357689021408, 0.9733205179160279, 0.9476207223767344, 0.9475335819620805, 0.954715723033899, 0.9694185032809022, 0.9420291974714478, 0.9501554422989463, 0.9349818455826239, 0.9599441754710658, 0.9653814420448457, 0.9533767971916692, 0.9492934011610352, 0.9552365839417496, 0.9687191297116104, 0.9322610123256592, 0.9469614526243789, 0.9513357709446458, 0.9644032046296984, 0.9599223245295941, 0.9707587920416146, 0.910527924549192, 0.9688813318434634, 0.9366432481321035, 0.9553634732485798, 0.9037985078702903, 0.9572815625877541, 0.9667946699847833, 0.94956042142985, 0.9436017388322708, 0.9582213973714897, 0.9602990797227201, 0.9617883971584932, 0.9408641542225372, 0.987758529637995, 0.9755306941913681, 0.9703466931553629, 0.9849575214680606, 0.942295113105687, 0.9364869376388069, 0.9563920933289193, 0.9487749722243398, 0.9308647183998183, 0.9419595299942194, 0.9481848185050218, 0.9568253168500982, 0.9517780400688931, 0.9140918679594846, 0.9466497580176907, 0.9375711542154577, 0.9752936571720116, 0.9519212834930717, 0.9450552864939673, 0.976626395864984, 0.9671255981802372, 0.9575348784579832, 0.9725358630730958, 0.9627727879454747, 0.9417001766657151, 0.9724585183607279, 0.9570200361590839, 0.9242864965654962, 0.9362624254373412, 0.960480991369394, 0.9546003837848142, 0.9555704485625601, 0.9815084469318615, 0.9632055734526579, 0.9336129566268744, 0.9615808531577441, 0.9698674296403821, 0.9157577685022039, 0.9524414635936925, 0.935761413047314, 0.9439130203563559, 0.9542439070501282, 0.9754059864579145, 0.953365785194485, 0.9560012376345869, 0.9516307379861274, 0.9791510748997767, 0.9542447214253317, 0.922462650341442, 0.946544817989935, 0.9391721176292664, 0.9262648957564467, 0.9551871573263085, 0.959929461949558, 0.9412347310012835, 0.9428582348565252, 0.9243483890269261, 0.9356370050773198, 0.9737544011968969, 0.9458755270139895, 0.9550198369310922, 0.9711460241743219, 0.9388988077943443, 0.9203059064744336, 0.9502068571475143, 0.950006226192826, 0.9410868262155858, 0.9774165535666883, 0.9587684167298809, 0.9538408253496942, 0.9400230541302367, 0.9622078798911806, 0.9179959357569002, 0.9636395243857079, 0.9613565322346802, 0.9691113452478148, 0.9522812159856949, 0.9425907268880866, 0.9591360891586462, 0.9854409285118446, 0.9503043576455592, 0.9587807430660483, 0.9715352922915635, 0.9451306879295871, 0.961540417007893, 0.9624004080374535, 0.9787184286189934, 0.9174296858775536, 0.9239942166055748, 0.9258014737566063, 0.9538586405787072, 0.9785791963348568, 0.9433072189433754, 0.9796521078286919, 0.9433018666312409, 0.9583176270722683, 0.9431190859528069, 0.9789529503838427, 0.9080470996901945, 0.9386589777370867, 0.94527218926584, 0.9417076132191116, 0.9507110185551448, 0.9748700971315994, 0.9172559261423643, 0.9406268333869677, 0.9384217000100986, 0.963831800355166, 0.9321867145621346, 0.9442748148381459, 0.9682495321504742, 0.9577782727681999, 0.9255636802322168, 0.9504542970219283, 0.9302754082181212, 0.9471372264145215, 0.9402283066902747, 0.9550110302388256, 0.9740942560667345, 0.9345696040252691, 0.9601690309251263, 0.960726634439266, 0.9754356965525579, 0.9703509990154388, 0.9557104699199499, 0.9458349682208045, 0.9672103739123472, 0.9277901767197677, 0.9221261433277215, 0.9364400024546484, 0.979757493233153, 0.9774850821718021, 0.9719206356787475, 0.968973254505149, 0.9614758763217586, 0.9388706910782378, 0.9567684262417149, 0.9371897860293048, 0.9445799904289517, 0.9727259594042781, 0.9513009266500322, 0.9542551548621339, 0.9700451305241055, 0.9649897829768831, 0.9549731267829734, 0.9418293505762204, 0.9776494103531697, 0.9379758121842174, 0.9566065451539673, 0.9522660000507516, 0.9812440462441726, 0.9662753806632831, 0.9625325329869983, 0.9612844691105157, 0.9698954462897058, 0.943758977196309, 0.9685122900305444, 0.8994215739570235, 0.9757154566939197, 0.9825244147186016, 0.9591742150748723, 0.9367670938868615, 0.9689754995027029, 0.9393665043705792, 0.9585167781556706, 0.9830867371564671, 0.9615509250356005, 0.9761494448482378, 0.937679542307286, 0.9657743100317179, 0.982454173932483, 0.9712145042326855, 0.9218200678811642, 0.979500335920416, 0.9322367302371388, 0.9693878130540057, 0.9200868904011963, 0.9226258235583665, 0.9354380303328129, 0.9731003258940375, 0.9695814694257028, 0.9662834674361906, 0.971401156786279, 0.955134451631932, 0.9817879411246473, 0.9379691676695519, 0.9420578224525845, 0.9765445821278125, 0.9361512104665526, 0.955156426481254, 0.977945947010739, 0.9599308001025847, 0.9840186473367907, 0.9573353232545835, 0.9568027970994634, 0.9598056654019944, 0.9686259600683124, 0.9610119577014433, 0.9560297704330103, 0.9809943869942427, 0.9540931249203224, 0.945299552989801, 0.97038548021458, 0.9703468100881613, 0.9396823121550744, 0.9623416936137861, 0.9427138357057189, 0.9087769311245261, 0.9675649424401177, 0.9393219090207634, 0.9226749779523951, 0.9703917058866522, 0.9615087866396271, 0.962359428862772, 0.9482150198581272, 0.9481688492620007, 0.9499818265836069, 0.968160166290644, 0.9686783649794084, 0.9575294895427202, 0.9643433189515458, 0.9670210406268219, 0.9590751760283339, 0.9421510313767194, 0.9769272645411083, 0.9412548777486809, 0.9660073454197983, 0.9648786399317518, 0.9656468246072352, 0.9491246052372374, 0.9198457490853515, 0.9202758011902503, 0.9296528058909606, 0.9661536139969689, 0.9335717218716261, 0.9676108797810805, 0.95634397996633, 0.9354208750791606, 0.9400883531527213, 0.9644936765350279, 0.9617782797416542, 0.9702192145771715, 0.9565548734158603, 0.9341701618858954, 0.9689493070476211, 0.924466120233107, 0.9422254330720559, 0.9641205601739652, 0.9568585986443401, 0.9662462495994425, 0.9558443250218563, 0.9359235480008619, 0.9439769455388585, 0.937995235264959, 0.945361740713441, 0.9228282957350146, 0.9491703320356035, 0.959917641324625, 0.9338652357996741, 0.9599105211606309, 0.9681011260674082, 0.9634479658533794, 0.9478406769648343, 0.9605794120922989, 0.975817381270818, 0.9647900369533388, 0.9331572444351164, 0.9553782471446937, 0.9720541437938832, 0.9594959136003006, 0.9045736987004441, 0.9734881802017881, 0.9581541257770073, 0.9673484058118352, 0.9603737673108095, 0.984156003617854, 0.9489911781798279, 0.9674154302985559, 0.9507957952322208, 0.9795985159905778, 0.9576513217274989, 0.9808911687405235, 0.9569793018747497, 0.9732509727903799, 0.9447725038627987, 0.9586313610047461, 0.9447691748906494, 0.9702341207819803, 0.9370010514317789, 0.963956367373807, 0.907542573026712, 0.9431886058863228, 0.9448103434708581, 0.9203605916644466, 0.9165444181390758, 0.9657490309761658, 0.9735172389620346, 0.9365474970738051, 0.9715737960644741, 0.9811614597803164, 0.92684128875702, 0.9318654886039613, 0.9444938191319268, 0.9489551155442925, 0.9503077826575373, 0.9378821167489788, 0.9632582263412295, 0.966826396467499, 0.9454398363235809, 0.9794475594457123, 0.9767382487020377, 0.9559955176289316, 0.9385010352668377, 0.950118976402522, 0.9298491146742704, 0.9422926540415135, 0.9682440740902819, 0.9690555113564259, 0.9382155574651547, 0.9275593607605599, 0.9485523753042715, 0.9533548162165532, 0.9847427040173968, 0.9619272739255107, 0.940601592829978, 0.9747056530052547, 0.9405299732172918, 0.9343705478775338, 0.9329958219748938, 0.9419907195065984, 0.9420779662122244, 0.9490042575888048, 0.9829754141175381, 0.9505765740834936, 0.953224085928706, 0.9236249260282251, 0.9254706226438305, 0.946768844608504, 0.9589830629792995, 0.9347627083050746, 0.9456482699778662, 0.9726411407790426, 0.9854566999036539, 0.9165860267104239, 0.9548040935028316, 0.9506686008946661, 0.9531426631517639, 0.9533758565813639, 0.9475060544724767, 0.9577511091030115, 0.9383964491648639, 0.9657643802303029, 0.954110823956746, 0.966087279491568, 0.9503124394500206, 0.9517833613742227, 0.9080960216837461, 0.9431196767926545, 0.9647813736907837, 0.9380821067072264, 0.9469328951378426, 0.9533895240150502, 0.9447417004744852, 0.949840352557926, 0.9649253264703439, 0.9513747372187371, 0.9767880037164954, 0.9805336169943141, 0.9775279688033309, 0.9745855324183976, 0.9702765464728725, 0.9500336420572947, 0.9590955593642678, 0.9537169077581579, 0.9362845477124578, 0.9563104357021368, 0.9527187284076861, 0.9775426289282962, 0.9503833973089207, 0.9203347981083145, 0.9275706613367785, 0.978918840166429, 0.9736006522438587, 0.9519584603932674, 0.9403580231306404, 0.9516765864809912, 0.9542935914745491, 0.9443443559044035, 0.9773483630822364, 0.981772223565814, 0.9533988755269627, 0.941421650906812, 0.9292481810898622, 0.9137537144359332, 0.9709175605522479, 0.9576862849740634, 0.9205163707244891, 0.9574791433229124, 0.9791153570849489, 0.9694575394744739, 0.9488158884702993, 0.9333402156845498, 0.9494874913755804, 0.9326317772954955, 0.9521731305000865, 0.9425074756011826, 0.9629449297708468, 0.9426267202433448, 0.9254313927457227, 0.9653798593852214, 0.9450885221048131, 0.943283939649602, 0.9126875184726213, 0.9194690206911913, 0.9588525125850879, 0.978587247407466, 0.9313137165125567, 0.9812457753215132, 0.9577200912917708, 0.9534693462298383, 0.9327560164717527, 0.9358767603333157, 0.9703225886467777, 0.9611931565312386, 0.9342962894487851, 0.9550202924518618, 0.9630954315945027, 0.9528426583935634, 0.9339132030026631, 0.9820311395731404, 0.9715104475147082, 0.976359312460829, 0.9538870906387389, 0.9623532994093971, 0.9656010028644797, 0.9403556811949708, 0.9580336860191707, 0.9797375576017316, 0.9528840429569295, 0.9467358971417557, 0.9626196533527088, 0.9682376898209021, 0.9175288994153205, 0.9635667279218726, 0.9256175116137257, 0.9429884937013929, 0.9561006642879776, 0.9471093416789816, 0.9318817518106256, 0.982244572049552, 0.9239374811024855, 0.9736898011025786, 0.9590129569814321, 0.9811086849011984, 0.9841222630179933, 0.9772742525255118, 0.9578683242935369, 0.9630791697712987, 0.9442023038244126, 0.980186192622027, 0.9449407117575006, 0.9245894798058271, 0.943338710196552, 0.9669608980510953, 0.9614265160021264, 0.9488014938935082, 0.905704366614048, 0.9462404239402237, 0.9665574449891644, 0.9576831223921201, 0.9610173625238686, 0.947560942055459, 0.9484949433560214, 0.9752917309309476, 0.9428896225092991, 0.9728522752213932, 0.9304191142465331, 0.9550828212674265, 0.9582462869796555, 0.9688020132532114, 0.9812143924446598, 0.9481687134446009, 0.9154731667478724, 0.9313661521728703, 0.951136608604397, 0.9481168714425925, 0.9469559561876643, 0.9721209409559981, 0.96256984175484, 0.9067531611649927, 0.9265170771352105, 0.9560458724699665, 0.9587632999066947, 0.9859995330995157, 0.9599578627302738, 0.9543088837779581, 0.9540284465631028, 0.9331763416634454, 0.9676112711197812, 0.9399114272520984, 0.9356288280629842, 0.9772960906070246, 0.9635076933844604, 0.9472321527862236, 0.9555691037238488, 0.9642309287568849, 0.9728103981137475, 0.9843930664327687, 0.965133253650441, 0.9482569109523709, 0.9528747889605044, 0.9826710946931796, 0.9563684161264472, 0.9682071289817985, 0.9658511723028093, 0.9500779811604766, 0.9565457089860779, 0.9528833876021818, 0.9613341697105249, 0.9352278734652478, 0.9558223110093432, 0.9176991475172452, 0.9670815178459201, 0.9429464748652789, 0.9829162590693448, 0.9568906844048479, 0.9683526561354001, 0.9584218305604802, 0.9604123042835457, 0.9443133080158868, 0.9441754313387534, 0.9441100900761787, 0.9325669717719194, 0.9370000629644828, 0.9726165898647463, 0.9740766136815258, 0.9508855514281276, 0.9716790878010398, 0.9209150942338014, 0.9500850663204738, 0.9398243539152189, 0.969141833937935, 0.9468783677279939, 0.9567810282958455, 0.985699672427508, 0.9557399332491637, 0.9578499513440647, 0.9589652060488124, 0.9343315718268494, 0.9500073753059461, 0.9659746560881061, 0.9349819542528421, 0.9552262082594078, 0.967955569276663, 0.9659367194859552, 0.9745477046643323, 0.9588164118125365, 0.9709558151615764, 0.9628489039182947, 0.9133857233281103, 0.9432408259778762, 0.9638999503430067, 0.955272721253216, 0.9521069933206125, 0.964806050532475, 0.9680994558893194, 0.9419340333635122, 0.9405781400504184, 0.973103054506233, 0.9379786977101671, 0.9619814424228367, 0.9809717008115011, 0.9711753375625984, 0.9284622511744293, 0.9325744131634944, 0.9598234353356688, 0.9427447137683891, 0.9769949597911868, 0.9514196685262776, 0.9788256642357147, 0.9701285774981718, 0.9773347957530398, 0.9396828014974856, 0.944483764343937, 0.9747218372332437, 0.9391050673048005, 0.9603319467599901, 0.9660523593966659, 0.9458212080167836, 0.9452251177709947, 0.9738006762576504, 0.9852983781569477, 0.9742315805139505, 0.9768688400724166, 0.9613701684677294, 0.9439870820563925, 0.9824981129645926, 0.9161002621686047, 0.9490177455825841, 0.9013965051771272, 0.974896003930374, 0.9767279990851132, 0.9229252806243506, 0.9456772095632575, 0.9564247142519836, 0.9667567202348197, 0.9308966910286746, 0.9818814719255372, 0.9782873616260148, 0.9470900266740928, 0.97487346767469, 0.9534047392444797, 0.9627419419748946, 0.926827768405942, 0.9368047876615124, 0.9394186709794095, 0.9553088603633243, 0.957301278522711, 0.9529410338499918, 0.9482728155588226, 0.9600770886164318, 0.945192836425336, 0.9689543070197582, 0.9705245042183386, 0.9706285233996427, 0.9342989072184243, 0.9495812698440794, 0.9663518340801166, 0.9702437205208891, 0.9384526552176633, 0.9087181345034012, 0.9689105397457967, 0.9536796588270638, 0.9704579185953218, 0.9249668608688864, 0.9557411852277158, 0.9588552021212636, 0.9596520111875901, 0.9548264501089132, 0.979557842745035, 0.9208008465335067, 0.9395668120828875, 0.9555254901983045, 0.9307072418621943, 0.9708295586262361, 0.9564511549677821, 0.9532232879457343, 0.9462082053415753, 0.9711323623065542, 0.9606845504768655, 0.9623350981014283, 0.9531516228193957, 0.9326744217221286, 0.9237384243968652, 0.9403417841587965, 0.9628769857779633, 0.9226215019034032, 0.9639816341069133, 0.9620197996307782, 0.9551181787788517, 0.9364062999273707, 0.9392261434582543, 0.9542930897650681, 0.9231784613820723, 0.9733954585785183, 0.953675864530356, 0.9480197068302938, 0.906635158726466, 0.9621524080290812, 0.9705613385784293, 0.9642391907740597, 0.956082045451475, 0.9599372487354484, 0.9542120489723233, 0.9473362023741873, 0.9686761490558453, 0.9498181761265856, 0.9702303975632226, 0.9173885041895798, 0.9503393363534015, 0.9485215930250527, 0.9217455244483819, 0.951201794559571, 0.9495073041772792, 0.9304548911335145, 0.97268072521549, 0.9824062984597395, 0.9159252151190228, 0.9288256461688003, 0.9629066693383274, 0.9440841758305452, 0.9130638515614684, 0.9321053314553556, 0.9352013281009464, 0.9299319379431575, 0.9807304523965313, 0.948370076755913, 0.9357486936771052, 0.9717438385657039, 0.9400996409697284, 0.9763573482901876, 0.961605371737832, 0.9732922256712213, 0.9644448726105075, 0.9736685864065515, 0.8584748726308695, 0.9440943686864554, 0.9339670891086611, 0.9394876923043703, 0.9601243736689745, 0.9760884400803675, 0.9537230279228515, 0.965487041130332, 0.9568438154619718, 0.9270832258925562, 0.9527407602736245, 0.9714559323095996, 0.956021116761918, 0.9239811034262803, 0.927899863516876, 0.9842998604130085, 0.9564739136256446, 0.9483762973163602, 0.9505599252876216, 0.9668811794944391, 0.94119467613866, 0.9531369712693479, 0.9574606150531851, 0.9287274169662117, 0.9452559769285676, 0.9395745704688355, 0.9464116509710846, 0.9445067099381835, 0.9350523020612111, 0.948887997522814, 0.9413783281593593, 0.9717272871233403, 0.9391705571516239, 0.9643211774243458, 0.9409662146272884, 0.972414242210658, 0.9746450079833953, 0.9578117643404767, 0.9443816463415081, 0.9430874775700022, 0.9522968307095293, 0.93218184414737, 0.9407598246005833, 0.9464724764040652, 0.9558518693434901, 0.9530435962378783, 0.9582143710993161, 0.9722316124218311, 0.9479430103561387, 0.9432167761218095, 0.9231359374409988, 0.9381724544295446, 0.9550675998573736, 0.957903361790207, 0.9639068835632629, 0.9663792967990745, 0.9728124047230742, 0.9397585443674675, 0.9716418759652817, 0.8983533945413184, 0.93599493138588, 0.9469366717086433, 0.9534206291712526, 0.9471274313396426, 0.9651307249346591, 0.9825504083508515, 0.952109694996367, 0.9683001872840562, 0.9460873751616765, 0.976179571239286, 0.9211116168587252, 0.9183612677255879, 0.9641726487851355, 0.968299275228302, 0.971617046580181, 0.9449766025784071, 0.9567499945194479, 0.9436787354350988, 0.9401436088146014, 0.9389547001430956, 0.9741694667039379, 0.9394893983239528, 0.9616867836081577, 0.9336508597821263, 0.9827542132795125, 0.9291027135330867, 0.9868002885739358, 0.9336128268139319, 0.9660093531030738, 0.9671193219971244, 0.8990951013502959, 0.9807096494826856, 0.9291652662628661, 0.948842785178869, 0.9492842631001366, 0.970468436939401, 0.9237642968573244, 0.975787216940214, 0.9377414271890016, 0.9769234130166453, 0.9604130280658126, 0.9411001700584396, 0.9858860525349123, 0.9604644643878713, 0.9722263375459134, 0.9770314238958915, 0.932713512447005, 0.9455318248278148, 0.9284146740649641, 0.962879928653458, 0.9587806172461744, 0.9779682861410085, 0.9572043176781576, 0.9640800823573339, 0.9701444404135164, 0.9778440172849335, 0.9449173750186115, 0.9386601109219342, 0.9536080394036873, 0.9220910989713904, 0.9400631472603344, 0.9382490644659168, 0.9461175299364765, 0.9886734798987812, 0.9423575895097686, 0.9604697806057088, 0.9527533718081675, 0.9501277732712554, 0.9721182842611577, 0.9535855888763842, 0.8881714210183146, 0.9565353111246855, 0.9267957671387915, 0.9677353232993557, 0.9397170877290559, 0.9495800249003423, 0.9484593714561752, 0.9578502965782384, 0.9651628421937658, 0.9521911544817576, 0.9848616989363894, 0.9622693264846348, 0.940075708741643, 0.9499489965132192, 0.9519823130586762, 0.9307415618848822, 0.9617438647313752, 0.9752069780340336, 0.9448807119911244, 0.9353367052744931, 0.9397480425969119, 0.941688387071343, 0.9847759666480932, 0.9493193966175834, 0.9717477400448757, 0.9466526296916339, 0.9504897010761293, 0.9612276652407215, 0.9621447595369577, 0.9758483706705662, 0.9361147703134388, 0.9666007743805652, 0.9351551263452982, 0.9837993759563107, 0.982488478895691, 0.9531962986494216, 0.9395590952694522, 0.969625714917097, 0.9652865965694186, 0.939982709973543, 0.9252563387722513, 0.9279957409526354, 0.9621155753135212, 0.9222906744357096, 0.9713793083869364, 0.9412539961438363, 0.9514593841340551, 0.9660440821315762, 0.9726962756675178, 0.9675105197864705, 0.9643573271162285, 0.9646880958439047, 0.9672619494898802, 0.9742420649467086, 0.9783535665505906, 0.9636873450848588, 0.9844427378410973, 0.9595326632140129, 0.9652316095875216, 0.9643557845136537, 0.9167532761986344, 0.982767872888943, 0.9739412218024259, 0.9641305231378884, 0.9543904116487599, 0.9502651708506782, 0.9612867559738878, 0.9535403659482417, 0.9455921826943751, 0.9335964298768534, 0.9458542223638243, 0.9701041390844108, 0.9284089424512041, 0.9751556144563666, 0.9721127015332433, 0.9315067544959756, 0.9549442175477861, 0.9531419795912437, 0.9456778371770225, 0.9718552277878384, 0.9525762375047769, 0.9394566046905346, 0.9515243995138104, 0.9657702316245964, 0.9456653758422833, 0.957866728868881, 0.9447732546409752, 0.9803381414770648, 0.9536266987810197, 0.9560560544407717, 0.9464435311193521, 0.9379247780818413, 0.9754921022917785, 0.9341491580683663, 0.9775539200267359, 0.9404592536639877, 0.9401957795900178, 0.9771590832732979, 0.9577974917755507, 0.9329076392223573, 0.9408120702316, 0.9550342319285985, 0.9485449446836722, 0.898188146533662, 0.956229554367128, 0.9577055508439724, 0.9446599031228731, 0.9520886898025726, 0.9545096937613256, 0.9815514512212851, 0.9764124454730467, 0.9709422159763877, 0.9625406371331782, 0.9564468244094785, 0.9800835314195189, 0.9313674141786309, 0.9668400103241972, 0.9746589640990666, 0.965279302784379, 0.9138294358503793, 0.9730868357025454, 0.9717505060224703, 0.9581087050162105, 0.945741604272042, 0.9850312674964865, 0.9758671507315526, 0.9393789189289787, 0.9398024565135817, 0.9839891273108431, 0.9454203092731828, 0.9449123886257403, 0.9676333165775145, 0.9749354196696167, 0.9610553764724549, 0.9331315792256181, 0.954443409448847, 0.9445982917745264, 0.9470752588399398, 0.9806207168397431, 0.9413202496384991, 0.955560535170289, 0.945698242263149, 0.9557004125046833, 0.9575144154301595, 0.9445550369274933, 0.9438192351460034, 0.9559198321511051, 0.9611436765380764, 0.9719561624474135, 0.948741955550027, 0.9421193389478667, 0.9497106090825065, 0.9744286828362432, 0.9661625847709808, 0.9777813102700714, 0.9083249656171595, 0.9312994927940619, 0.9724741285295253, 0.9624390469718315, 0.9724449721634598, 0.9449343702358682, 0.9730426816140306, 0.9719291108217833, 0.9596419659906307, 0.9416357060728127, 0.9409878733094355, 0.9722216348414268, 0.9751333934618881, 0.9263832268154479, 0.9489698795515882, 0.9800832180425741, 0.9700126897748373, 0.9494519500128511, 0.9594115163337802, 0.9833999630899564, 0.9462702257005792, 0.9826373154905851, 0.9755625383983899, 0.9205695971450945, 0.946897132111981, 0.9586466905504964, 0.9528197537797558, 0.9543286729150372, 0.9458595584665185, 0.9339623128528328, 0.9295513391923044, 0.9516555921710499, 0.9728009033939429, 0.9526046385945293, 0.9796745844125908, 0.9748963241898427, 0.9767350794601489, 0.9410330914899541, 0.9057861236993113, 0.9650461751734738, 0.9561464475628347, 0.951694104675074, 0.9476296036580134, 0.9749580814034771, 0.9321290809763882, 0.9175148130328398, 0.9790402538931173, 0.9758121322668882, 0.9515468496048048, 0.9428406270616546, 0.9572984692065509, 0.9379021560524475, 0.9485673102035371, 0.9783596707099083, 0.9196858795792434, 0.9497135238676752, 0.9804886649948188, 0.9620423305997287, 0.9693907658255445, 0.9508872690695569, 0.9286810193773615, 0.9809905625683136, 0.9621477843001327, 0.9643915801770824, 0.9357523322342972, 0.9770868765270034, 0.9586691099966327, 0.940237283782209, 0.9591415866154485, 0.9421649127258609, 0.9468191205086772, 0.9474211332957366, 0.9417261232009863, 0.9376785759048211, 0.9382095110058906, 0.9727105806224784, 0.9683899033669129, 0.9463430284472029, 0.9302285305365202, 0.9558746182951083, 0.9648406393244031, 0.9615162262258615, 0.9570789569464274, 0.957610687894891, 0.9586370180336304, 0.9685734048484468, 0.9742582814141234, 0.959294482908929, 0.9746998167837234, 0.9475367852269919, 0.9660975582069125, 0.9816233804748584, 0.9389565752784053, 0.9552235224697005, 0.9547595117852248, 0.963769327198092, 0.9435812090591869, 0.9686724177882426, 0.917823687541903, 0.9406475398431887, 0.9615085721028569, 0.9672629017148314, 0.9581829455746118, 0.9656781242265409, 0.947601145292541, 0.9532206926787476, 0.9623639250175846, 0.9205205109973562, 0.9706681663515077, 0.96637618908006, 0.9387970139239594, 0.9378729722316685, 0.9187435676828473, 0.9168017936762924, 0.9702423210252915, 0.9646023069366837, 0.929869478370679, 0.9555882995937071, 0.9424933048178248, 0.8958153993591598, 0.9652178907227813, 0.9723480263097043, 0.9581026578635738, 0.9641718514751454, 0.9384661347166133, 0.9550854490170553, 0.965953628709149, 0.9415676881365859, 0.9617133545699742, 0.9559390751205996, 0.959971917573116, 0.9525094538953806, 0.9634254395436913, 0.9683485725142864, 0.9728883196536151, 0.9350386883860823, 0.9756926479163432, 0.9479470721674932, 0.8928712580538221, 0.9692333584088109, 0.9776273674015792, 0.9672866236615192, 0.9507076468128676, 0.9645954055511595, 0.9291359639246123, 0.941299447632684, 0.9689853022460987, 0.9554973621464032, 0.9623111504456041, 0.961872005294193, 0.9317280692750903, 0.9422057474196368, 0.9663209164260386, 0.9199746407938647, 0.9156629397387744, 0.9827796513837395, 0.9575798891639298, 0.9616321455541711, 0.9570057097147069, 0.9364797915810031, 0.9684210821293516, 0.9730777448341219, 0.9703060922066176, 0.9528831546000796, 0.9510111810742695, 0.9497256238459727, 0.9247950218322305, 0.9293064394310956, 0.9269918798053308, 0.9550161632117106, 0.9650449104041348, 0.9410382150131206, 0.9689753234296978, 0.949757712368186, 0.948642761925406, 0.9851327579989164, 0.9441215043873625, 0.9514070590988093, 0.9743977600119861, 0.9439104130869745, 0.9780557804906213, 0.9534003506768912, 0.9643370007691663, 0.951097645768265, 0.9641456574466396, 0.9753068011711257, 0.957025857890204, 0.9523273352619273, 0.9698346528002627, 0.9498177249107485, 0.9647859148571558, 0.9459503716481777, 0.9620756615881152, 0.9444955942130614, 0.9439871871360063, 0.92716198383757, 0.9702571950374282, 0.9440340317221219, 0.958554003067119, 0.9812819661747998, 0.9353893545695215, 0.9523857662837922, 0.9145738085753053, 0.939998098071406, 0.9134945734519883, 0.9499881301302875, 0.9357952369446758, 0.9594166453023105, 0.9612113350777266, 0.9777855151409279, 0.9590983451233793, 0.9455518784565915, 0.9471785898093066, 0.9584918802053516, 0.929355072405541, 0.981126021431706, 0.9630725928161311, 0.9662995872113812, 0.9526198025348904, 0.9454499991969083, 0.9441895404473715, 0.9658678695684971, 0.926972098837711, 0.9415840407334293, 0.9425919401909779, 0.950522776530519, 0.9399457951290089, 0.9565591659939613, 0.9584014994527816, 0.9572991024917857, 0.9611724674348716, 0.9580056481960421, 0.956571664472337, 0.9573953762620673, 0.9805944493167994, 0.9510540186172931, 0.9378738719676034, 0.9558192365841545, 0.9448047697297776, 0.9310292758200138, 0.9769908027027471, 0.9260466236298491, 0.9318583087880631, 0.9518905953274823, 0.9517658221293985, 0.953293668320957, 0.9720189027958002, 0.9558305469862, 0.9472694568242003, 0.9677879487629821, 0.9544975696056508, 0.9793623085630311, 0.9573565127952999, 0.9599755935551971, 0.9326233420588413, 0.9538120580513534, 0.9267008622298281, 0.9482251479522459, 0.9477851606616365, 0.9839602008206599, 0.945900636303385, 0.9796264521118413, 0.968836028059258, 0.9086750008479361, 0.9551202258176971, 0.9609867114853485, 0.9626211132631923, 0.9766546412600955, 0.9569109625322123, 0.9505077053938761, 0.9738245491534049, 0.9533427956800394, 0.9751409854756282, 0.9020077638575914, 0.9638273250052771, 0.9708939361820451, 0.9184105226654051, 0.9692865298198329, 0.9484150369301512, 0.9478085116715096, 0.9429174995233963, 0.9410271602955912, 0.9739008944893885, 0.952656563074447, 0.9802593088646585, 0.9612521648096864, 0.9828008165027693, 0.9589431841895977, 0.9729061917691256, 0.9291400344038724, 0.9587216856816319, 0.9695654938773005, 0.9644438112431467, 0.9268423866182004, 0.9473365219982646, 0.9767411626789467, 0.9600898478465721, 0.945957391070311, 0.9540696329691972, 0.9711226272797615, 0.9611445260368308, 0.980974592662884, 0.9260931165694075, 0.9713584838028381, 0.9571134186664044, 0.9221023494582704, 0.9522853582497466, 0.9793733234171308, 0.9479795459105851, 0.956041776235637, 0.9395899171898664, 0.9551902765261951, 0.9152091059859437, 0.9557029929588549, 0.9764401850696303, 0.9611657521727559, 0.9542032907966211, 0.9720417428069272, 0.9567008283179192, 0.947717890813197, 0.9418827825863711, 0.973011294175301, 0.9424456853265519, 0.9612671122836299, 0.9712720896533524, 0.9519262170951863, 0.9175951448980185, 0.9759702719898559, 0.9671241956832075, 0.9749608294423849, 0.932331857319509, 0.9281401232456766, 0.9653498761067627, 0.9551751364357399, 0.9507326710509593, 0.9367157157170045, 0.9756724133076654, 0.9501723885447543, 0.9629866620329786, 0.9640151976615635, 0.9351427451357183, 0.9539415840668064, 0.9208047919572765, 0.9492704562759157, 0.9578617803358395, 0.9407136603539651, 0.9485389635813156, 0.9707343770879618, 0.9259410617948065, 0.9379089638575656, 0.9707838183243693, 0.9819095439609005, 0.9518992590534614, 0.9461521606171774, 0.9642213145263429, 0.9617562665358049, 0.9457407025050847, 0.9776312099621878, 0.9403065500757318, 0.9530900543257338, 0.9224303563087657, 0.925480077733951, 0.9475856278404109, 0.9686776420305491, 0.9762829092225295, 0.9792393375176467, 0.9561267767722135, 0.9397826215437054, 0.9573271675244142, 0.9548271250797006, 0.9574164234337278, 0.9557780030362155, 0.9507210719076785, 0.9480468129419962, 0.9363234956947336, 0.9318868067092464, 0.9627737562722376, 0.9417812672923517, 0.9382066014606691, 0.9490351392377228, 0.9407290047315348, 0.9688340095874376, 0.9829519258177944, 0.958163524145921, 0.9781655079716514, 0.9337739523469856, 0.9648651424436625, 0.9708078220781311, 0.9316015351792741, 0.9577934413274735, 0.9410855819129245, 0.9539740585574523, 0.9271138301124727, 0.9807565879649401, 0.9335826008100391, 0.9555069503959437, 0.9634052575845001, 0.9697944389771257, 0.8979332662150998, 0.9336981641828698, 0.9196540345416827, 0.928641777297262, 0.9386940605038099, 0.9714259350441082, 0.9709250747130784, 0.9476325307759765, 0.9297110099594633, 0.9484363550995571, 0.969711783803028, 0.9811893067079072, 0.9655374465759319, 0.9399856863712798, 0.9517055604300748, 0.9813888103763633, 0.948584088190264, 0.9705397112389478, 0.9455083777351372, 0.9184009651376525, 0.9469115740850957, 0.9532258574647633, 0.9312992068591517, 0.9713778284886004, 0.9312494395064889, 0.9633458020702186, 0.9534285084636352, 0.9520365685837939, 0.9405349360030236, 0.9445090933899732, 0.9686140934534129, 0.9249522093000546, 0.9660031277546254, 0.9423554981413196, 0.942242847778388, 0.9737427875668362, 0.9515372339548316, 0.9447937044540963, 0.901005699552743, 0.9569398305186244, 0.9512021919512034, 0.9312207455343342, 0.9665463977857475, 0.9384755666682898, 0.9520568458954909, 0.9394764534110506, 0.9620608720233913, 0.9358350925214258, 0.9698067540711298, 0.9605400771366261, 0.9544203434967272, 0.9842844052995219, 0.9511372948922755, 0.976643430334592, 0.9543185882181711, 0.971102252207758, 0.9758541141276728, 0.9588490318204185, 0.9642861260725173, 0.9422698014536771, 0.9473785545517177, 0.9402494976506173, 0.9453570693280721, 0.964447558668946, 0.9141589166300209, 0.9650449806509459, 0.9618926919231018, 0.9537443616548175, 0.9158709532477695, 0.9637199498681548, 0.9569889460443726, 0.9483562080079657, 0.9499340128311015, 0.9642181434713988, 0.9247424377763838, 0.9629696074281657, 0.9501294302511405, 0.9414491640550906, 0.9395606111651799, 0.9108867201123523, 0.9538144593543332, 0.9262456608333223, 0.946760423330022, 0.9417975771491874, 0.9846881320564986, 0.9781936789509779, 0.9778203167389735, 0.9626351263475172, 0.9641034204942389, 0.9399514735966257, 0.9539467247966277, 0.9199967029836418, 0.9447208773485141, 0.9618148312593814, 0.9669477537175504, 0.9606460494181118, 0.9423718260736521, 0.9718104840063498, 0.9734519644649051, 0.9508954325876927, 0.9434997651426195, 0.9710001821407205, 0.9665649592829879, 0.9518584104067667, 0.9797190059488606, 0.9287779725533448, 0.972047520740802, 0.9448803250069623, 0.9566587608077447, 0.9566371858887369, 0.9346370308379818, 0.9302633834364646, 0.9730625505910293, 0.9249098773345323, 0.9559598425734788, 0.9107145789138699, 0.9753123328397353, 0.9382977458238436, 0.9245189397713606, 0.9418593706812523, 0.9708605270472986, 0.9335372167850596, 0.9764807644180452, 0.9527226044123064, 0.9300277220841837, 0.9721504305027783, 0.9531127821229777, 0.974217070400245, 0.9673333235491013, 0.9447629210334945, 0.9426681765184604, 0.9254623441948626, 0.9449645928369785, 0.9492853184454846, 0.9477439993153777, 0.9374154794555397, 0.9053467466793546, 0.9659339149266848, 0.9566362071532284, 0.9375735098547121, 0.9714159133816241, 0.950700289080332, 0.942627015486549, 0.9775154887092551, 0.9509968139886406, 0.9561323937776381, 0.9519277159507346, 0.9378081035533706, 0.9329390755362107, 0.9399529253707072, 0.9565495025869047, 0.9569528525887371, 0.9395074494304888, 0.9512614059270144, 0.9605961258484605, 0.9387992414196545, 0.969826306811972, 0.9253070051212776, 0.9491365206865481, 0.9437078515699823, 0.9530341542937961, 0.9692794887356085, 0.953360031557355, 0.9284367113523803, 0.9598901535860687, 0.9020280614365859, 0.9373504613910568, 0.9484188055972832, 0.9198115847304683, 0.9391790904426883, 0.9580325066786256, 0.9542206698430314, 0.9370396156101102, 0.9124986616220027, 0.9422121567889545, 0.9786262240465812, 0.9709621792757948, 0.9788010715338359, 0.9667790106882833, 0.9623193982289374, 0.957377186653653, 0.9490379131443175, 0.9698841671842426, 0.937810187201794, 0.9690643741132777, 0.9661590196951587, 0.9571331929020511, 0.953840441549381, 0.9588703273738347, 0.9081895619861937, 0.9607446231819307, 0.9653503841729626, 0.9536570522967079, 0.9283657678546635, 0.914249189889538, 0.9494092255833783, 0.9361314463252655, 0.9742896445396272, 0.9185923539796762, 0.9860492413594043, 0.9117228389492904, 0.9589678510237422, 0.9147520675058626, 0.9594801177790152, 0.9550438404970497, 0.9359713822262293, 0.9515157630877589, 0.9473808206671955, 0.96196800202653, 0.9508034269464083, 0.9577739433665051, 0.9436728640363995, 0.9475613237710127, 0.9631810376486317, 0.9498411498405863, 0.983413434198645, 0.979602697224285, 0.936207661004411, 0.9809176039438225, 0.9449522616027197, 0.963727559331818, 0.9245453437861179, 0.9510972857960435, 0.9628851295327235, 0.9640525407110573, 0.9678022718917086, 0.9763273080731856, 0.9594506084017074, 0.9674190270007103, 0.9783683027887006, 0.9342247669666769, 0.9452666598895918, 0.9598252758723115, 0.9367803560762352, 0.9508647086388319, 0.9508747995434634, 0.9568683918460812, 0.9618592637541281, 0.9702567856818134, 0.9576191612939648, 0.9587467577026269, 0.9481415266743016, 0.9755621484422994, 0.9824756388158277, 0.9497633568365048, 0.9523536585191585, 0.9462490048517387, 0.9314873152878166, 0.9704029454570785, 0.9757327711511292, 0.9770260523797719, 0.9398127229724452, 0.946963545269809, 0.9722388347588667, 0.9658521285908352, 0.9610836314840904, 0.9226260578553908, 0.9582876316161885, 0.9380443388214732, 0.969936660592126, 0.9734478715023075, 0.9598478913603535, 0.9851865649369294, 0.9603198528362207, 0.9337556497246995, 0.9537243633446081, 0.9577397663551805, 0.9753775841235096, 0.988931268001548, 0.9347733888960623, 0.9508718032259874, 0.9439996059901162, 0.9412774992488695, 0.9778975085488065, 0.9415622996153221, 0.9511053035042468, 0.9610911873081914, 0.9712365148973171, 0.9465326190691262, 0.9420470655404579, 0.9513322851437701, 0.9712011513621625, 0.9292708603903942, 0.9514894513820319, 0.913033307158329, 0.9606657070284447, 0.9593882974903105, 0.9838711375903284, 0.9695979424324017, 0.9483900680467484, 0.973584542785208, 0.9640268701025303, 0.9225043838979876, 0.9468200571508251, 0.9574842225060878, 0.9551043730632329, 0.9416791678504624, 0.9478643556420752, 0.9553095578634945, 0.9503499395890411, 0.9144747678598358, 0.9751460719521746, 0.9306648930015403, 0.9597567001308749, 0.9420059456588452, 0.9195220683452694, 0.9831239763065472, 0.9347530270144212, 0.9598831633070787, 0.9471372388284549, 0.9454439317447736, 0.9797008781610115, 0.928939483959305, 0.952646368869293, 0.9765099833904981, 0.9717157244405986, 0.9819746870404086, 0.9801819882700363, 0.955187825963761, 0.9444211200269845, 0.9312772554782955, 0.9601821541178762, 0.9335299635089883, 0.9563193581839045, 0.958592305092888, 0.9248686834668963, 0.9416474372959255, 0.9532049166074041, 0.9805495840918036, 0.9816891758487063, 0.9412305816492108, 0.949612407653782, 0.9605559571251489, 0.9799967079773264, 0.9739779540692161, 0.9739857487602547, 0.9634482816698816, 0.9406527906595524, 0.9633165918605769, 0.9727457370650961, 0.9768381805766049, 0.9655380921002947, 0.9388456160396005, 0.961624767942765, 0.9213108392599885, 0.9758465770323164, 0.9449250555480732, 0.9760857247678337, 0.9588919013434869, 0.9463957721007369, 0.9574976226716203, 0.95675338749665, 0.9862346776641475, 0.96396204361595, 0.8980178838032664, 0.9319784661968775, 0.9453136188716796, 0.9144199812511316, 0.9327485657276988, 0.9281829533256828, 0.9193875560016432, 0.9852698477796317, 0.9283996090063722, 0.9571167312805133, 0.9665434296369261, 0.9776582918685468, 0.9566402543757786, 0.9503887969191606, 0.9502124479854681, 0.9402040898996261, 0.9421761970267982, 0.9035772376049767, 0.9387465629293436, 0.9548255358158606, 0.9499021007738963, 0.9532419400274459, 0.9641432529878091, 0.9109114487534214, 0.9630445150107182, 0.9559817820678861, 0.9777136106274433, 0.925653175187662, 0.9647956760905199, 0.9531799091161223, 0.9200730183437785, 0.9806812145155146, 0.9837688482606457, 0.9645191890901132, 0.970095535321577, 0.9403374747467624, 0.9485224912104678, 0.931509349655733, 0.9552378864568533, 0.9395309410051095, 0.9297644459873592, 0.9767376111497427, 0.9641681231279253, 0.9722485039177359, 0.9497738823554908, 0.9600401851485055, 0.9741283394913951, 0.9595297321129795, 0.9044193504319147, 0.9602846138051466, 0.9274665611793755, 0.9295326713095644, 0.936570650671952, 0.9581649218628021, 0.9465633160373794, 0.9438511960974959, 0.9491160584434283, 0.9438795610436439, 0.9601810493975302, 0.9569819219264137, 0.9390926204337035, 0.948467195653382, 0.9537923092303765, 0.9235595541212641, 0.9740807396761707, 0.9462940865818878, 0.9492582920582286, 0.9470726853917618, 0.9723675785297438, 0.9150415701105075, 0.9369195718038492, 0.9356163262940927, 0.9132470645745447, 0.9670291836568942, 0.9343082537192782, 0.9245255064589147, 0.9537914849179587, 0.9589574417763227, 0.9242632762282923, 0.9552302218159272, 0.9510128471431367, 0.9307059728162114, 0.9398108314000018, 0.9445989011484174, 0.9589042125972586, 0.9437252077866499, 0.9610011388742162, 0.9495236805715662, 0.9557640342849044, 0.9598726504713371, 0.9586712465883199, 0.9826213853895812, 0.95891012170569, 0.9786205498378407, 0.9487208940540963, 0.949626666872407, 0.9672321891050623, 0.8951914051094095, 0.9691152013393872, 0.9343753512397608, 0.9263017559057007, 0.9848030376039565, 0.9608390384657907, 0.9157513193958486, 0.956087851268176, 0.9407758642600694, 0.9483982135425838, 0.941234604364066, 0.9552691386027228, 0.978332008830215, 0.956902404905816, 0.947636515197824, 0.966269941666949, 0.9483167592664107, 0.9469792374226436, 0.9741490900784817, 0.9675361160875392, 0.9285234877802356, 0.9750169953216463, 0.9740558904063933, 0.9545127740011776, 0.9256450598501119, 0.9794705337749069, 0.956607852428007, 0.9303789612682439, 0.9360808000574723, 0.928708759862361, 0.9463107502185897, 0.9573693253794133, 0.9596633483483447, 0.9665385927999188, 0.9558271990123318, 0.9687711290784127, 0.9490115298469204, 0.9581509504523132, 0.9542766755742841, 0.9322940085361836, 0.9500169913400772, 0.9422516510087589, 0.9692719270537851, 0.9772922785229629, 0.9594295128099231, 0.9749038846751376, 0.9800400905281463, 0.9570930069240229, 0.9562896003044095, 0.9406389077268016, 0.9653082004185968, 0.9402879224838353, 0.9444617517744875, 0.9726158095347432, 0.9488584508213845, 0.9688043952644071, 0.9468713357929306, 0.9693299228281813, 0.9654913765360553, 0.9446778294173588, 0.9029853538450912, 0.9629252007360797, 0.9507866477399336, 0.9798296535944787, 0.9282851192019937, 0.9572631070637125, 0.9688591287615642, 0.9643293175156663, 0.9559619577954358, 0.9750195236588513, 0.9359788361086159, 0.9638210878762952, 0.9649026673591617, 0.964770180870717, 0.9740329180354486, 0.9495039590218795, 0.9856627416238519, 0.9606070861562428, 0.9823579703428326, 0.9410395102068781, 0.9619717277987455, 0.9486956233946016, 0.9073428645529731, 0.9546686198478285, 0.9435831662542252, 0.9627341011800272, 0.9835783547159834, 0.9317158804283934, 0.9455259523000308, 0.9497673029854927, 0.950200130588408, 0.961185925346858, 0.9730791596931714, 0.9630646420424954, 0.9575658504599489, 0.9628261616517042, 0.9521147669138623, 0.9318007199235462, 0.9532633038914724, 0.9627206875013253, 0.9453278123547062, 0.9203727507190035, 0.9344302638324627, 0.9420804776396182, 0.9506720231301942, 0.9368666227623664, 0.9720644157819617, 0.9372191259509379, 0.9373624785898298, 0.9286569147897952, 0.9789452756562875, 0.9396737765822708, 0.9625201714050111, 0.9755582886578996, 0.9554388649058827, 0.9403701696517645, 0.9643556240353909, 0.9432477134979548, 0.9749765949957119, 0.979548351850342, 0.9591337640149965, 0.94390374919278, 0.962591737692835, 0.9357940780781483, 0.9395205574554024, 0.976221667964375, 0.9361188327197618, 0.9844863176237793, 0.9420430062991033, 0.9640385847365011, 0.9668029507223158, 0.9457513999255185, 0.94944770119957, 0.9557696516801706, 0.9173421359192555, 0.9282902999652456, 0.9376539272417586, 0.9537859164753786, 0.9361531402463662, 0.9485471197719355, 0.9457103585178414, 0.9559013242506011, 0.959270965036132, 0.9397814891863698, 0.9336528923356596, 0.9666788870974217, 0.9751403429545288, 0.975315781574866, 0.9332260066626515, 0.9721302098734402, 0.9525349011203528, 0.9503564018515916, 0.935365986049871, 0.9772499757167047, 0.9524222829846767, 0.9649222630145735, 0.9467776905918017, 0.9509931119784263, 0.9400986681992415, 0.9478369153595094, 0.9672981232509741, 0.9660060171181757, 0.9827693108807544, 0.9332914021200569, 0.9334938957137724, 0.946887912691475, 0.9186665574630969, 0.9462286884900691, 0.9646427130392597, 0.970564203902193, 0.9398399549393368, 0.9405157570646315, 0.975331062092471, 0.9531829019996296, 0.9344279787347372, 0.9455567487283674, 0.9645930314189551, 0.9610264341772149, 0.9691609801578667, 0.964641753379001, 0.9645224196636487, 0.9561095240175508, 0.9748704481705853, 0.9269371033335455, 0.9767178800944846, 0.9044892787301809, 0.9746773656706783, 0.961745268801715, 0.9621683446179755, 0.9179551949796069, 0.9444357614293767, 0.9715651977426911, 0.9593806567593081, 0.9792868416499572, 0.9587542749435665, 0.9489375986184372, 0.9683353347901322, 0.9595635645122754, 0.943290904274115, 0.9062466659438179, 0.9538401346410813, 0.950818451226631, 0.9483013890826923, 0.9064446706671218, 0.9091460932813828, 0.910481172229756, 0.943280648947447, 0.9251324714821381, 0.9540698775271174, 0.9547714301367631, 0.9577381302539696, 0.9719609034422345, 0.9618864977560194, 0.9664769757416931, 0.9363349808422711, 0.9300625170124166, 0.9734550348935156, 0.9679319877689989, 0.9404165214959224, 0.9547918780920698, 0.9412810524610543, 0.9649141468470118, 0.9685742527490616, 0.957715550485605, 0.964186577928685, 0.9569340312749924, 0.9616432223032091, 0.9801624628516905, 0.9424851270106279, 0.9673330719132835, 0.9426661212922156, 0.9680002593517778, 0.9421329117232632, 0.9490880689839807, 0.9657166371671119, 0.9600147554360486, 0.9614071642602754, 0.930470806824925, 0.9429815514850837, 0.9682679206668127, 0.9783379362274757, 0.9694270772978154, 0.9586641238315848, 0.9662583496326531, 0.9727484079234168, 0.9351156163293577, 0.9834446150134487, 0.964723594721307, 0.9412281979553837, 0.9625828680812757, 0.9389477191718928, 0.9589548776423465, 0.9528721961230703, 0.9536103645486644, 0.977279239338663, 0.9454510241496682, 0.9716299010707046, 0.9736967240896702, 0.9656870956264332, 0.9729905516524312, 0.9245076597894321, 0.9781667534150681, 0.9787212294569744, 0.9677255952586129, 0.9481855330722344, 0.9505257674961414, 0.9373550224611097, 0.9597496740260518, 0.9802434040488339, 0.956973191023622, 0.9781157424800365, 0.9637104082456845, 0.9504503865556561, 0.9606888534110383, 0.9471708720066735, 0.9199431731176605, 0.9448421176100227, 0.9662386771089623, 0.9631183060068605, 0.9434930694248432, 0.965769235743142, 0.9385403133633261, 0.9358219330995152, 0.9613595834116124, 0.9688743002236768, 0.9618848809182053, 0.9639732216062912, 0.9462969111124798, 0.9337704424102318, 0.9627763834589714, 0.9511455331990485, 0.9570191354245593, 0.9351484259160032, 0.9683863951088314, 0.902095546692709, 0.9659198432568384, 0.9864133129661662, 0.9574403958969334, 0.9719365280218908, 0.9551364444719184, 0.9587781636345527, 0.9874679526219707, 0.961136406364259, 0.9639945486348119, 0.9394700322444203, 0.9382177532358492, 0.9744270183812856, 0.952017442626434, 0.9401961265692832, 0.9675413711777722, 0.9712895766095265, 0.9689677183332613, 0.9253375387360591, 0.9777564494858579, 0.9435681339816668, 0.9255331722010636, 0.950902243697291, 0.962517420674937, 0.9499562379279676, 0.9552356996820818, 0.9449554422440448, 0.932273252390814, 0.962248595711706, 0.9295922148231328, 0.9210603438751601, 0.8979528993446673, 0.922923784104956, 0.9771460263734735, 0.9616944502269562, 0.9301195627036868, 0.9307238094388345, 0.9584745648274701, 0.9479474341584279, 0.942195966203127, 0.968100255684376, 0.9829978334701799, 0.9793841710692822, 0.9382747668440742, 0.9444541603521986, 0.9681780413353701, 0.9483593676180858, 0.9426580570637049, 0.9347209749718961, 0.9104532934733517, 0.9669593857594468, 0.9519511366104783, 0.959527379553509, 0.9563508315759061, 0.9500731724409601, 0.9294344149517189, 0.9194876939854337, 0.9509085246827027, 0.9364515003811098, 0.9470775584912849, 0.9398575743336093, 0.9665317274963594, 0.9492671747088538, 0.9241681551423627, 0.9532686707334753, 0.9504274636867095, 0.9465222918988092, 0.9551168627731527, 0.9598957413782624, 0.9449801849158603, 0.9738214408909152, 0.973423068099612, 0.967506690174154, 0.9516771455304459, 0.9520487573059732, 0.9523201158426229, 0.974667539654186, 0.953979051115224, 0.9203569220184884, 0.9628943482804203, 0.8868216425504758, 0.964580176157109, 0.9423684316513281, 0.9670460796100361, 0.9833247424156563, 0.9296154022357945, 0.9426776746893767, 0.9523769342149759, 0.9625134372621343, 0.9552129563487145, 0.9712662496444591, 0.9195879333526015, 0.9663449129994388, 0.9653081588125932, 0.9746056830933079, 0.9798617802223613, 0.9260186389602015, 0.9409448079460928, 0.9413873478570638, 0.9517332633534791, 0.9413137095810337, 0.9488699456435005, 0.943997511461918, 0.9732306521415905, 0.9565093811892229, 0.9287216092989762, 0.9614072769196121, 0.9571505843930048, 0.9632150173034891, 0.9343016837034464, 0.9624479053824445, 0.9475428427624341, 0.9473521339732445, 0.9569959424986103, 0.9639829715918906, 0.9352256123831793, 0.9680198109975924, 0.9536567528589668, 0.9383933371702037, 0.9506497224267931, 0.9502178291634445, 0.9355313747887799, 0.961253395054733, 0.9570567370571006, 0.9271603267443345, 0.9213948437733754, 0.9713088006549332, 0.9471500125756874, 0.9653074188361672, 0.9657946604150082, 0.9587679135056744, 0.9612037901967844, 0.9393745281768806, 0.9771968408498974, 0.9637791383425841, 0.9539910880625397, 0.9078595568954058, 0.9485101061291102, 0.973974383275709, 0.947603637456455, 0.9672458539959211, 0.9391128864333239, 0.9401249817002298, 0.9570635663392274, 0.98154403962617, 0.9571741479075452, 0.9449394480030646, 0.9338891795891564, 0.9661274697291845, 0.9151942340201973, 0.9698063056423124, 0.9566992657989566, 0.9457296863660366, 0.9509050640637284, 0.945920857452289, 0.9586965691722629, 0.9536414074860836, 0.9577703406923954, 0.9622319982388965, 0.9678805807688066, 0.9489908402638033, 0.9336639669384396, 0.962574657827638, 0.9201892227413574, 0.9487813176202766, 0.9547795563785969, 0.9580329434847977, 0.93219569682235, 0.9278438852535663, 0.9676557990672688, 0.9691681469050438, 0.9727479124932082, 0.9393403243233841, 0.9576977436889565, 0.9567007071672023, 0.9679095974119253, 0.9610675884752704, 0.9511850457945346, 0.9416476395354625, 0.935538903357279, 0.9311642246670783, 0.9662921214664836, 0.9525126506928981, 0.9758293126598325, 0.9673193211649287, 0.9657390920501489, 0.9625939599012772, 0.9518091100644087, 0.9544581918632183, 0.9441237944708324, 0.9361643727795406, 0.9302499697080229, 0.9363219503033865, 0.9396106724143517, 0.9038153345463132, 0.9719846325026469, 0.9766489867881898, 0.9431366377535922, 0.9667778540946808, 0.9307868460654085, 0.956414839767206, 0.9179742182642989, 0.9738767178571278, 0.9564070393896169, 0.9329308564367692, 0.9336796505595746, 0.9507273397670998, 0.9662588949471457, 0.9497177876010517, 0.9446432034064373, 0.9767566875854252, 0.922274482661668, 0.9279182947168331, 0.9258786045829168, 0.9701725565142169, 0.9419906339775741, 0.9587660337689327, 0.9590705292726923, 0.9726673927219993, 0.9670998686421682, 0.9758804649970738, 0.9480008264666772, 0.9786568482203457, 0.9449817764099208, 0.9358668436790641, 0.9535227918482543, 0.98376624537284, 0.9571983524172264, 0.975508477023785, 0.9675466233232018, 0.9499294861133666, 0.9848256390358292, 0.9777962468194473, 0.9795710062885118, 0.9662143061865216, 0.9581234146192836, 0.9373207814568808, 0.9652301020560166, 0.9821718901112244, 0.9183727884991826, 0.9526971248474752, 0.9740564397204096, 0.9474737251496254, 0.9757317749104145, 0.97029751292774, 0.9314152943765858, 0.951486784114793, 0.9492945938215577, 0.962989505791331, 0.9700586224331672, 0.960501144776062, 0.9481354868443111, 0.9180501303626107, 0.9314686739310937, 0.94815087384894, 0.9431352352098177, 0.9187248806330672, 0.9389624602404142, 0.9680127802931557, 0.9593411936146317, 0.9449647938494247, 0.9552456256822397, 0.9595985931411198, 0.9442590650377034, 0.952196900129384, 0.9366836920351611, 0.9625685482202929, 0.961684715048275, 0.9459529571603188, 0.9357389565449425, 0.9360925106287245, 0.938281178374255, 0.9477856766646924, 0.9568276899274685, 0.9670618069707115, 0.9415438730761145, 0.9620386496828773, 0.9504948035332488, 0.9444020626677889, 0.9313090784767559, 0.9420092191892007, 0.9741425107648033, 0.9672229191248592, 0.9854734213150915, 0.9617466596288435, 0.9691603644674036, 0.9486791290426665, 0.9525849926437308, 0.98611558854441, 0.9450579630160446, 0.9493779265600027, 0.9490182919430211, 0.9502606820241161, 0.920335321968112, 0.9271512843403357, 0.9304530663072532, 0.9817924541984777, 0.976234800990237, 0.9442162275664425, 0.9258537756748002, 0.9122958488646463, 0.9808960259927898, 0.9545909615688813, 0.9603691587633263, 0.9566931061040198, 0.9738222823785561, 0.9802794226198451, 0.9365802855696219, 0.9712920676920473, 0.9844130863325098, 0.9522129670676577, 0.8767430891756215, 0.9605860997016684, 0.9561617771706576, 0.951896826534295, 0.9651051267542683, 0.9359987865499189, 0.9669375251644965, 0.9374606227271951, 0.9145659203201735, 0.9439331716315671, 0.926878736138109, 0.9385167430345036, 0.93586090949405, 0.9587165417660685, 0.9373298523636036, 0.9669122265758219, 0.9674256280137814, 0.9545176640639499, 0.9630917667987455, 0.9188280008467018, 0.9646629576644979, 0.9609578710630912, 0.9723141973234267, 0.9615523380257438, 0.9249723444938749, 0.956428740225973, 0.9576275754927609, 0.9426435322793814, 0.9531459265229559, 0.9607647373710667, 0.9689598279339089, 0.9422355470279109, 0.9573353864508861, 0.943545188057616, 0.9667919013063799, 0.9780456631654407, 0.9390856027901238, 0.9649428648114143, 0.9655932986431149, 0.9181557593821652, 0.964142384938205, 0.9429103676929736, 0.9670821930339696, 0.9341219474871147, 0.9530785805499287, 0.9305540138168391, 0.9401313760468812, 0.9573692827419502, 0.9235345091858952, 0.9288062389214744, 0.9711335626035995, 0.9371712535995464, 0.9131843009293129, 0.9323280825914835, 0.952661065122532, 0.9397113666959291, 0.9633429483453976, 0.9786240969127107, 0.9430255130827806, 0.9654322038602178, 0.9602704964049896, 0.9655080421595187, 0.9641249509436216, 0.9049948694531676, 0.9602035819282255, 0.9438060058943428, 0.9708416568493072, 0.9267969171200213, 0.9219624489699481, 0.9759844527902102, 0.9554271694190394, 0.9645122332089142, 0.9520548106515089, 0.9612775726083388, 0.9226695498520479, 0.9465086618971071, 0.9591281322559345, 0.97065607193073, 0.9618279352926073, 0.9232129078697666, 0.9761057797662391, 0.9482255769247142, 0.9661012399010864, 0.9599815134178581, 0.9315135623891406, 0.9505089761456349, 0.9041889426705774, 0.9519171414705908, 0.954281613754351, 0.9445723627215373, 0.942942080076738, 0.9418761444781665, 0.9670594823037435, 0.9853439012387154, 0.9452462032754461, 0.9252714533316331, 0.9753454614748187, 0.9496092179269155, 0.9516184743831949, 0.9508001370934357, 0.9135188071893848, 0.9284946759460092, 0.9812634257052223, 0.9065804893108211, 0.9051799703091381, 0.9814164862918979, 0.9147277233924104, 0.9592472222534619, 0.9635503607004197, 0.9178206246512222, 0.9757003404701844, 0.9314037960270547, 0.9359844404780249, 0.9744984348602724, 0.9167944232392646, 0.9821839139851045, 0.9462123233689432, 0.9696231538828208, 0.9409969695357275, 0.9312948823835201, 0.9373909299475974, 0.933510698261999, 0.948184201326204, 0.9823707455980677, 0.9523692605729296, 0.9620352099210744, 0.9249417144493923, 0.9596925517099599, 0.9585090870090636, 0.9405369537125043, 0.9435652430734581, 0.9618738628994492, 0.9490872486600461, 0.9515590322941834, 0.9418155030949338, 0.9796960936611145, 0.8980576872972651, 0.9374676638839258, 0.9515103849083272, 0.9573339378702306, 0.9607651823862438, 0.965282051606307, 0.969073837019785, 0.968307178592057, 0.9286465838888787, 0.9515491254801028, 0.9415200564449795, 0.9712958808752057, 0.9489200808641002, 0.9557568132519767, 0.9371521734365006, 0.9627148062406027, 0.9475317193786736, 0.9458489655414404, 0.9662666125692435, 0.9756140779810272, 0.950353387100034, 0.9439508537762575, 0.9524979156409217, 0.9598565993199033, 0.963628170823042, 0.9412066879797921, 0.9518367044234827, 0.9696562299020569, 0.9633553946825116, 0.9708491545667411, 0.9402672755273331, 0.9218169034003196, 0.9393771321848164, 0.955104405980038, 0.9467744488848061, 0.9564432265186859, 0.9541463945290741, 0.9709700314918094, 0.9631706538727273, 0.9599532675755107, 0.9350241056966393, 0.9549477126468486, 0.9587907610709174, 0.959384966781699, 0.9688826303961626, 0.9773579985847529, 0.9717486616468546, 0.9673796671494131, 0.9563261132324878, 0.9289402995079707, 0.9435789922749162, 0.9489868419231229, 0.9433111892361595, 0.9265943836271376, 0.9738868632462804, 0.9604254774349698, 0.970754329150474, 0.9546288158306254, 0.9589406575423094, 0.9441739501896363, 0.9535916369213586, 0.9759372210996686, 0.9487966117336234, 0.9459523623986446, 0.9256171572305053, 0.943672899396813, 0.9567915028346593, 0.9502543318469877, 0.9443935010850524, 0.9760084037785501, 0.9517855682516251, 0.9710132700926027, 0.973967117123016, 0.9621953103140836, 0.9512678394616957, 0.9220750015609545, 0.9789246926282414, 0.9762181657813624, 0.9456501753699267, 0.9817671309427123, 0.9630578095212758, 0.9486246105321495, 0.955912225165251, 0.9390351558441149, 0.9439624512671327, 0.964374816777356, 0.9564836303839426, 0.9329870791888942, 0.9592677963129362, 0.9689656687058856, 0.9678023477451481, 0.9562114061132321, 0.9778956042032704, 0.9867837373251235, 0.9604162281215232, 0.9450503339372774, 0.9514212392959367, 0.9429960692461894, 0.9353738385935706, 0.9344359170993479, 0.9330670775198502, 0.948375217186236, 0.959074265337504, 0.9398179514557319, 0.9668989668351775, 0.967171391217985, 0.9513036015383513, 0.9705411689169728, 0.9625361249026808, 0.9531339598595883, 0.9743086175032308, 0.9596653078274998, 0.9616161347234806, 0.9635763777245703, 0.9304943196494389, 0.9241947213774547, 0.9813781752870987, 0.9415376551581821, 0.9524732950380495, 0.9629076582899414, 0.9172486680653797, 0.9605430345230954, 0.9225619278752878, 0.9643079879202299, 0.9541495682907978, 0.9639162432661174, 0.9478539639396999, 0.9655621840862495, 0.940195871478712, 0.9601231050289064, 0.948578433789488, 0.9728875664774351, 0.9591003958080458, 0.9587810920283419, 0.9398491510851876, 0.949534065092209, 0.9072274299685535, 0.9300880722672418, 0.9649086954003008, 0.9291185602669424, 0.9293482247633994, 0.9534661158314911, 0.9640471440766116, 0.9388248013017262, 0.9546752273935232, 0.9647640832602539, 0.9358088526556962, 0.9688610263034473, 0.9769999963671819, 0.9661678843028664, 0.973763145524529, 0.9737586486150904, 0.9675564226443181, 0.9361330961772556, 0.9430253140973072, 0.9406637878341079, 0.9562258695662643, 0.9630186648163556, 0.981816859617597, 0.9110716171677101, 0.9715964372119209, 0.9698810125269306, 0.9263822772928575, 0.9351261304277937, 0.9864129922304917, 0.9564502574728427, 0.97895827152338, 0.9694685231119339, 0.9491592228930974, 0.9527555491578532, 0.9630026544139957, 0.9704402218408573, 0.982495167408821, 0.934032754810453, 0.9450989486857139, 0.9520275303158363, 0.9741609587731317, 0.9561872716455634, 0.9526014547014503, 0.9668898901079144, 0.973564815805891, 0.9606883620430344, 0.9443056874137813, 0.977658761304616, 0.9699112353795025, 0.9694381440439794, 0.9652829730961245, 0.9871324028555886, 0.9362840286180796, 0.9726235863690458, 0.9538008981530005, 0.9364215184012216, 0.9579028087090883, 0.9640779652488314, 0.9441210850859829, 0.9743991744622367, 0.9213885157923576, 0.9553953531300786, 0.9563619492427098, 0.9634806735511092, 0.9567958539879144, 0.9385696079252068, 0.9591757856999229, 0.9442407221217793, 0.9611485373036562, 0.9483709231933731, 0.9592084868951292, 0.9483431391569866, 0.9819338131651949, 0.9635227207099208, 0.9706750266164729, 0.9444560075302473, 0.9801376063389801, 0.9771834325532254, 0.974040498759234, 0.9642043489616854, 0.9505400622155473, 0.9758153368239145, 0.9282939600769786, 0.9296268929808442, 0.972219835953176, 0.9308998768704162, 0.9067766520656217, 0.9453386248201242, 0.9304835810924457, 0.9589729444218976, 0.9361389856311361, 0.9570044850120557, 0.8970990529959343, 0.9276020102806802, 0.9076962957611432, 0.912773547693466, 0.976668368430185, 0.9620329817442064, 0.9547157249808653, 0.9795182933919595, 0.9558481174957454, 0.9520770762926177, 0.9497743002463862, 0.9485066609834149, 0.9642247102095387, 0.9396349393751406, 0.9673563203798488, 0.9653376928253485, 0.9865728655454914, 0.9463038487924916, 0.96977163613539, 0.9576369452251081, 0.9487650558797167, 0.9491459426574402, 0.917946412188383, 0.952917286013659, 0.9590800125687184, 0.9367282212700531, 0.9437279305475723, 0.9582462056715787, 0.9445731945946513, 0.9319840851833981, 0.9719828320398382, 0.9538166802681416, 0.9526403599013475, 0.9430076218499055, 0.9624117858676803, 0.9680099786308857, 0.9572160290744868, 0.9603601343193664, 0.94789199820505, 0.9370829927755653, 0.9719540150666122, 0.9605890367745996, 0.948752263256059, 0.9185866177010741, 0.9653215148081894, 0.9483791525231858, 0.937937910208899, 0.9169952475328914, 0.9384467074708078, 0.9667502643135952, 0.976009461864466, 0.9498956102431741, 0.9502112393035691, 0.9738300296928352, 0.9753743473233373, 0.9659831774966469, 0.9633700616498909, 0.935047207940965, 0.9786144065461002, 0.9692290014629404, 0.9659393789810796, 0.9637397655862495, 0.8912131237070073, 0.8803924333870784, 0.9695082931207051, 0.9756734078499736, 0.9624813429851488, 0.9504925105781007, 0.9634725372200462, 0.9685396761506812, 0.9645077190521082, 0.9574332204547626, 0.9711194748647098, 0.9352700973161274, 0.9572484534330536, 0.9287249954620461, 0.9527721797336037, 0.9492727927869419, 0.9668652582395227, 0.9686227257269814, 0.9652633676343165, 0.9316054367342147, 0.9829112946698421, 0.960652698310771, 0.9375324037312986, 0.9089222422965073, 0.9534493002858806, 0.930415748118586, 0.9660093618103971, 0.9652667952776811, 0.960689304475446, 0.9664309622494586, 0.9557173687009634, 0.9500023101581423, 0.9799687158675552, 0.9735000167941641, 0.9689494496963956, 0.9654030373794236, 0.9185815824166711, 0.9700818507070214, 0.9577659261235736, 0.9462655277693801, 0.9501638089580801, 0.952744823759625, 0.9797794565847633, 0.95067527668828, 0.9683469767342938, 0.9485126200455062, 0.9657769291904008, 0.9531063632800988, 0.9423732825678154, 0.9318741270819478, 0.9390295123850253, 0.9192560823263565, 0.9420440230495124, 0.9386928348555332, 0.9635673644411219, 0.9489008680920438, 0.9714991314425886, 0.9789370530431232, 0.9760109705461341, 0.9508142757028312, 0.913769837405662, 0.950502021319492, 0.937135583651688, 0.9527780253988277, 0.9664151269053531, 0.9842778001249086, 0.951257083712136, 0.973491646900748, 0.9663004717670443, 0.9604969522839254, 0.9837583431324316, 0.947350959948088, 0.9392777710504503, 0.940377387731507, 0.9742211181095303, 0.962208333013054, 0.9292078272703196, 0.9271536252508594, 0.9679498503552368, 0.9629393648490548, 0.9215047752898637, 0.9401524370182077, 0.9336857427103012, 0.9445368535041976, 0.9506199134544848, 0.9283846087721718, 0.9746907435274975, 0.9479918861799774, 0.9510059108000568, 0.9454514067252643, 0.9645731672324913, 0.9348622536601786, 0.9652203811104335, 0.9553611717274828, 0.9355713918990091, 0.9111879016528781, 0.9770095021582146, 0.9612688595172504, 0.9627257014565656, 0.9638593513581595, 0.9575989530444432, 0.9745284148348201, 0.947450923467235, 0.9394274534999194, 0.9402088707057814, 0.961834247994947, 0.9424029579766925, 0.9682487271306862, 0.8682333745472913, 0.9272208228279897, 0.9492121444083533, 0.9639205475011657, 0.9606484908987796, 0.9297644141588076, 0.9404844236253449, 0.9707815634312242, 0.9482683607190298, 0.9724937392869544, 0.9339019461023786, 0.9641665074233084, 0.9783063900628567, 0.9467106628369513, 0.9564060830765747, 0.9685793186188393, 0.9373140095172559, 0.9669956737925895, 0.982476085480026, 0.966475725903074, 0.9392719137405254, 0.9511212811678791, 0.9623360834304575, 0.9042837592410241, 0.9634788869415782, 0.9361185755756979, 0.9147086017463599, 0.9310099893453291, 0.9733389104765503, 0.9849263646637774, 0.9273385228858664, 0.9448223716417222, 0.924119159664523, 0.9787511777329272, 0.9664790197715117, 0.9456541586207314, 0.9508432260642737, 0.9415654497109357, 0.9409998471535006, 0.9690230969613637, 0.9349890402881827, 0.9454008699028098, 0.9637842493946082, 0.9498216861900486, 0.9269608600441364, 0.9652886059699998, 0.9411786536824127, 0.9479773376583186, 0.9523315165289095, 0.9499580222411296, 0.9469191904614579, 0.9481376960990281, 0.9662939381123641, 0.9640966055696787, 0.9666678790591021, 0.9460514613258885, 0.9548698495826459, 0.9764695464313008, 0.9628279489490508, 0.9592753515347657, 0.9734344100030182, 0.9734372450716229, 0.9437723622264533, 0.974923861196648, 0.9359362839186094, 0.949741792125012, 0.9461364073171087, 0.9649996936603589, 0.9557854835642081, 0.9501619356573149, 0.9209921007629357, 0.9473273970528092, 0.9819842345558003, 0.9658071975680181, 0.9377598618316476, 0.9634425609579821, 0.9877563788848426, 0.976644053352467, 0.9495257720291738, 0.9518546223928933, 0.972434509874093, 0.952827228318413, 0.9429165926129466, 0.9628498309618478, 0.9528297545857, 0.980866499747935, 0.9214657724899097, 0.9676985075671118, 0.9718603177331595, 0.9393179388369468, 0.9565140777605206, 0.9801783199542964, 0.9692477650514557, 0.9456030815151623, 0.9271896551462073, 0.977044227240983, 0.9487056618686356, 0.9387156198723541, 0.9534596853850706, 0.9396353725713874, 0.9480799828148557, 0.9611106328855472, 0.964605820668217, 0.938257880288834, 0.9381018203708085, 0.9466948745696467, 0.9618304515947561, 0.9598662118467202, 0.9793578575334513, 0.9102887462463695, 0.914966484857462, 0.9552249442823558, 0.9730890978438369, 0.9494903734081143, 0.9247467731555896, 0.9615912300211813, 0.9534477746661036, 0.9780403902151091, 0.947217309164831, 0.9671705074204089, 0.9676420458657375, 0.9788653688820487, 0.9590116963862843, 0.9786900968343603, 0.9675993936313302, 0.9572420824464154, 0.9459271780085007, 0.9715054060961522, 0.9615256886840738, 0.9763970297267922, 0.9681944048969243, 0.9369517667014085, 0.9765409598615208, 0.9322502842588699, 0.9375502797740628, 0.9558001980356544, 0.9262390956234968, 0.972289649709564, 0.9119224967503381, 0.9692021194971422, 0.935707459788112, 0.949843951530848, 0.9602049751896168, 0.9810639858367655, 0.9848672506423691, 0.9451121172445262, 0.9592818139303692, 0.9697967192045777, 0.9837091940897277, 0.9616572489950826, 0.970316803938004, 0.9357096689885058, 0.9769335263593272, 0.9752309400532782, 0.879533482460995, 0.9588007732134715, 0.9602363402625488, 0.9439428644404939, 0.9768619788914117, 0.9738671558904204, 0.9393348601754526, 0.9608499415304816, 0.9793111874854544, 0.9527781464562008, 0.910043228261517, 0.9072645180735188, 0.9793531621969909, 0.9290069282700688, 0.9652696624164521, 0.9340744733967153, 0.9513445512825524, 0.9497943580818154, 0.9719314113894304, 0.9701787487480632, 0.950798302819267, 0.9345026383599535, 0.9634259060916086, 0.9613631538571652, 0.9504583118018937, 0.9543086062661735, 0.9625831045661593, 0.9310266700504405, 0.9402527718464131, 0.9358211547427048, 0.9373765314315726, 0.929042107026875, 0.9508097970334181, 0.9695751062247637, 0.942925518376185, 0.973252500876835, 0.9303544157800233, 0.9723361604682065, 0.9571589585390864, 0.9641572815993418, 0.9601106105480397, 0.9374696669837491, 0.9422043780842846, 0.9528286143134896, 0.9561985645517392, 0.9519044949604903, 0.9607109827029503, 0.9273782288057973, 0.9258005753550589, 0.9262511490312748, 0.9732652572166051, 0.8952042245280093, 0.9447872454710924, 0.9341370637794518, 0.9603620216770176, 0.9257944726768994, 0.9516538514150468, 0.9659644613563768, 0.9474975722772487, 0.955944010290391, 0.9574070854434896, 0.9726803850803856, 0.9703164336625372, 0.958075554328349, 0.9382885620204889, 0.9554822179089395, 0.9705959170335974, 0.942770128249937, 0.9407313340323068, 0.9451643836653181, 0.9403558889284932, 0.9666296587978362, 0.9409271275792054, 0.9618925489005525, 0.9211869677137803, 0.9498634125517788, 0.9793374569422426, 0.9647525399553313, 0.9451085078560223, 0.9379564341328753, 0.9735381237151556, 0.9606790713370483, 0.9607006939376044, 0.9603287444996996, 0.9524402734741234, 0.9278659541412725, 0.9780392120761359, 0.9599152795819456, 0.9609465107288944, 0.9698673612705835, 0.9515265436354478, 0.9450597923744132, 0.9683717073484844, 0.9612991294501131, 0.9297425833461181, 0.9522868129951799, 0.9658331277224986, 0.9388543308675666, 0.9727951363912579, 0.9649739525965836, 0.9470019681049313, 0.961996558394413, 0.9781982098034263, 0.9486760002548884, 0.9361080776034264, 0.9692580475572319, 0.9446825718967495, 0.9629957161834602, 0.9629439184382222, 0.9698602601563013, 0.9474785752824285, 0.9721528986608474, 0.9526033268377795, 0.9434854469479796, 0.9411854118807701, 0.9308839492930747, 0.9724667290933278, 0.9243591500790788, 0.9450302788101936, 0.9254925173030621, 0.9470432124570811, 0.9580649117560077, 0.9483849624659526, 0.9732184150525441, 0.9498629756448239, 0.9124587475673386, 0.9785632850889412, 0.9640387209930685, 0.9728363248655171, 0.9644082400991042, 0.9528494452873647, 0.9494322423746173, 0.9528764763841044, 0.963062046491982, 0.9731487355030689, 0.9429923385791167, 0.9623095047750454, 0.9493347279884325, 0.9850107579569058, 0.9535363562096081, 0.9579370634485938, 0.9747176370548605, 0.9401073919794218, 0.9421289839695767, 0.9753249337154407, 0.9845891514962346, 0.9324372859736987, 0.9474503032470494, 0.9549592095683648, 0.9217134673695019, 0.9734405873645855, 0.9427205650614526, 0.9436509230647299, 0.9688032481281957, 0.9363883268942726, 0.9429078571952757, 0.9555642213166082, 0.96044047650784, 0.967525374093115, 0.9502644337694647, 0.9282805713437301, 0.9494513442642506, 0.9364751117435723, 0.9255948134272156, 0.9392512690060946, 0.9766766186865986, 0.9567054691445338, 0.9645484551266877, 0.9509348728153294, 0.9741786350738293, 0.9487229734627631, 0.9740765037428647, 0.9726670193568138, 0.9768083232886688, 0.959184347614445, 0.9539612977615544, 0.9418794895695964, 0.9408114770672155, 0.9694979972576919, 0.9399114549049743, 0.9418630022466307, 0.9494445571208924, 0.9549019951770278, 0.9733162840571089, 0.9736051767880244, 0.930682314041474, 0.9658097737828607, 0.9426745395536533, 0.935869043709241, 0.9097484822171789, 0.9613183730203859, 0.9417665040423815, 0.9532846035350419, 0.9321360126787189, 0.9404318402970073, 0.9435220647300782, 0.9621305164120206, 0.9503646116203626, 0.9396207307032659, 0.9490254639156184, 0.9547976837442513, 0.9450817146461704, 0.9442457063000657, 0.951980401539281, 0.9381346224802227, 0.9425042411147715, 0.9837667312412577, 0.9232860093347842, 0.9626397564825914, 0.9863108658963226, 0.9310291268671339, 0.9445602071174242, 0.9661687843154679, 0.9226152703431201, 0.9317396224197487, 0.9546274876272234, 0.9698480942037414, 0.960217058846527, 0.9644342187011566, 0.9295704965964671, 0.9740833462048332, 0.9730295503260099, 0.9723636347717598, 0.9609353994223064, 0.9739674951510071, 0.9763337336053214, 0.9721071140681558, 0.9600493903032734, 0.9582237931848854, 0.957068156298435, 0.9615488317615217, 0.9599356000515403, 0.9378880251075209, 0.9315656813080035, 0.9808603606888263, 0.9591758175589671, 0.9783603264884356, 0.9449277984031202, 0.9555387953388779, 0.9667853235927821, 0.9140613007241845, 0.9711417893610569, 0.92966358156129, 0.9736994881017383, 0.9440561558788128, 0.9515349082419214, 0.9472166233172454, 0.911971513616515, 0.9507972093837992, 0.9382069386214199, 0.9742527848999568, 0.9379661561822454, 0.962797108715028, 0.9570349609824, 0.9571609135975027, 0.9704130544929561, 0.9657567061716242, 0.9531810242305718, 0.9177158338884029, 0.976442474755284, 0.9338254411436524, 0.9707892891500166, 0.9576880326042546, 0.9531029266137362, 0.921019341835645, 0.9201168304545057, 0.9543475818410646, 0.9522179662867789, 0.9376677627846142, 0.9743244307526568, 0.9819885744109664, 0.9320799263556314, 0.9525890238135787, 0.9189566989056548, 0.9097844430396442, 0.9475113736300624, 0.9565968047722339, 0.952597948354965, 0.954033567128955, 0.9661857128450635, 0.9437242798715145, 0.9774196114520198, 0.9226330448067656, 0.9405287691578377, 0.9471132716844795, 0.917335708688923, 0.9353178674400197, 0.9387709603340381, 0.9375264271678267, 0.9765397197672709, 0.9683985293887533, 0.9709464312382109, 0.9687887416918745, 0.9386827678281866, 0.9635585606353265, 0.9553375933599706, 0.9750859086374926, 0.9299801865123337, 0.9459791459840292, 0.9638077313197392, 0.9296550466883061, 0.9526217798353944, 0.9763169204969346, 0.970739428980944, 0.9421122478332338, 0.9587952774767333, 0.9595869273160335, 0.9207381115243631, 0.9666325292273982, 0.9440425938926192, 0.9661166878799216, 0.9520206614574976, 0.9432259976491223, 0.9546448389940827, 0.9567326732026413, 0.9864647692008841, 0.9625142657994322, 0.967998650226623, 0.9537277215093043, 0.9304445894662674, 0.9539900480582978, 0.9674115672037324, 0.9503781485856964, 0.9433214935555904, 0.9508024394542345, 0.9601512078503369, 0.9488048168802754, 0.942918658800873, 0.9223841696634671, 0.9472260942525477, 0.9448185866954064, 0.9456691492751157, 0.9489439005252372, 0.9656308146838251, 0.9620447634124387, 0.9271383117371911, 0.9713200132020953, 0.956869594141335, 0.9397516462665632, 0.9495769876578777, 0.9720111237746952, 0.9551730261457249, 0.968757719181165, 0.977159831501929, 0.9405248442808184, 0.9629885475603801, 0.9783566820249968, 0.9741069602835972, 0.9701444374833761, 0.9728441583010179, 0.9484237661794652, 0.9042035014455132, 0.9519721650979062, 0.9750485309941749, 0.9241470984692759, 0.9543410420638075, 0.9358863534226864, 0.9608196612726534, 0.9611621049748998, 0.9673197910402831, 0.9790813440179758, 0.9623424412307542, 0.9698896444245125, 0.9516417202980324, 0.9338424273645181, 0.9783429358101308, 0.9572626804464835, 0.9787848038331516, 0.949845579204437, 0.9389277233177482, 0.9578268494153644, 0.9676473555505146, 0.9579590852670277, 0.9331241415987763, 0.9281597886054466, 0.947288749322733, 0.964070682376169, 0.9478776257428647, 0.9746595042946757, 0.9519058899565688, 0.9742704586022806, 0.9593221542059714, 0.9611366219098344, 0.9727203529328832, 0.9461762871188089, 0.9625252670230254, 0.9719806764768746, 0.9318234364712978, 0.9652559215688686, 0.9538539196194762, 0.9541245513989365, 0.9434180713117702, 0.9316345282208872, 0.9475558412673681, 0.948079420924158, 0.9448847168104948, 0.9562624498317726, 0.9706283336688047, 0.9238872903162592, 0.9707675217222672, 0.9617493462316975, 0.9528037873064981, 0.9487363843948109, 0.91175867826338, 0.9566832240132924, 0.962464608595816, 0.9676252719660572, 0.9394123965088459, 0.9536791320999308, 0.9655860484999753, 0.8949215495075248, 0.9278551107216961, 0.9748504406486209, 0.9481459791822442, 0.9362003278919965, 0.9689722538503447, 0.9622155974577644, 0.966082059266052, 0.9497257222854605, 0.9512406731397296, 0.980431286795444, 0.9724486474590023, 0.98076257374843, 0.9315112259683623, 0.9702187128704771, 0.9437552985928952, 0.9709516978632708, 0.955519469771877, 0.961395594626177, 0.9478672711167654, 0.9680425602268695, 0.9787471972983441, 0.9539125054064151, 0.9720483397329621, 0.9585582424428428, 0.9394829900691425, 0.9696011720648146, 0.9411018188550891, 0.9391388559284611, 0.9501017906529906, 0.945819888555742, 0.9531365990103433, 0.9700463158515417, 0.9692061841678814, 0.9714924061960807, 0.9186915786926615, 0.9387266209438903, 0.9830225443894416, 0.9401712358439983, 0.9470346967265773, 0.9639800990558461, 0.9695822775439514, 0.9331201276071431, 0.9402364916348119, 0.9710649823852155, 0.9488906304479848, 0.9376549856281756, 0.9561663594818667, 0.9687852666471314, 0.9651861534697521, 0.9503276416601818, 0.9591005240048748, 0.9711593222600644, 0.952022497780651, 0.9694290025775277, 0.9733493444180252, 0.9459177449464805, 0.9358207342538943, 0.9646573258271997, 0.9788532763385908, 0.9736032824423415, 0.9690743832331675, 0.9578843914277989, 0.917235356836802, 0.9706176201138383, 0.9460684814574677, 0.9585457003350314, 0.9571771285557354, 0.9579268041195043, 0.925002442618169, 0.9384661853260063, 0.9556978633763265, 0.9631514550565107, 0.9613165314269755, 0.9585586835441243, 0.9163065941655794, 0.9736992510951876, 0.9699688584180653, 0.965133420701623, 0.9280107004026966, 0.981002607159405, 0.9453462265195591, 0.9388433093803474, 0.9451120777151665, 0.9795764454218183, 0.9500004454666321, 0.955085393972179, 0.9116302037988064, 0.9354712251795019, 0.9402745198485072, 0.9538206225101609, 0.94955294721501, 0.9774618434752375, 0.970734315023185, 0.9422852504701938, 0.9086940145955998, 0.9693435864550662, 0.9794869289855785, 0.9509424969777484, 0.942438494688626, 0.9719623811451723, 0.9526691433942545, 0.953873802201898, 0.9526454089764116, 0.944187418090381, 0.9467738889379805, 0.9544198737856713, 0.9517344154224722, 0.941118679351896, 0.9647378823935163, 0.9562726402584693, 0.919284948520311, 0.9694878776172451, 0.9641584594218978, 0.9450136547966036, 0.9311345729508806, 0.968198919779732, 0.9336453488582429, 0.9218304146815064, 0.9469757070923804, 0.949934368306909, 0.942144596381066, 0.9412727568422463, 0.9511270511678734, 0.9557889213381272, 0.9376302444288569, 0.9640462680652734, 0.9610691434355392, 0.9689739753061423, 0.9356276522708463, 0.9468496606769308, 0.9318203607274246, 0.9421817836853345, 0.9791097513256406, 0.9462145672540047, 0.9494375384105179, 0.9521444053960757, 0.9361840552173902, 0.9440842255870231, 0.9330434418188297, 0.9214311199520822, 0.9740780347391991, 0.9356020648884974, 0.9636802636712785, 0.938645404269264, 0.9472448963937248, 0.9280115164051889, 0.9527474248217149, 0.9639787380693574, 0.9454438355423029, 0.9739156923697301, 0.9410217742902984, 0.9484931732288846, 0.9398595167126546, 0.9548634095135458, 0.9564790595774489, 0.9457949724364175, 0.9379328260773933, 0.9400848550344479, 0.9278071018245667, 0.9741199935105506, 0.9742301567496469, 0.9280897369916334, 0.9690717286972972, 0.9360525727139333, 0.9511616697584191, 0.9430073087795722, 0.9292430952846127, 0.9617924813551934, 0.9616138498929413, 0.9442606952244822, 0.960610777391655, 0.965460286859063, 0.9412394467494055, 0.9702515293136056, 0.9574461332735742, 0.9598324600707778, 0.8955543391975559, 0.9710706741057414, 0.9465394049005637, 0.9731442633979633, 0.9151201852574814, 0.9455250344564438, 0.9368151185996787, 0.9380337567803422, 0.9406940722646698, 0.9576841383598776, 0.9423622193130662, 0.9728423703042, 0.9352557279876249, 0.9437373150089152, 0.9492592011915261, 0.9095139375287374, 0.9794786561881279, 0.9750563841653678, 0.9217643361494121, 0.9388914465835015, 0.9284665215961434, 0.9551341984546243, 0.9804934579258122, 0.9198352495579396, 0.9633255207741107, 0.9729260583106557, 0.9188380877369805, 0.9400694297333004, 0.9495776343276037, 0.9374944456723869, 0.9643148353433385, 0.9590425961377032, 0.9346364436762303, 0.9749433324203478, 0.9445314594688525, 0.9587719576896956, 0.9672374886575661, 0.9563640210582913, 0.9352866387857776, 0.9401776136164084, 0.922546217339304, 0.9612057672264838, 0.9804271510784115, 0.9825992683562152, 0.942836509863633, 0.9601635123977765, 0.9281373330290893, 0.9323510960063477, 0.9536713786537596, 0.9806001210032564, 0.9590511850989724, 0.969266125684072, 0.9480600078287779, 0.983258071420515, 0.9687838100003339, 0.9512960678739706, 0.9492829744257255, 0.9300455991216383, 0.9569864744169388, 0.9656736701341476, 0.9611247542931941, 0.9329298799122825, 0.9444529883150837, 0.9394047758778129, 0.9397808256226914, 0.9370124985258647, 0.9505728017211197, 0.9650544892289792, 0.9487918613519531, 0.9760050646445931, 0.9833774723470938, 0.934612605864202, 0.934246396212056, 0.9137705853108892, 0.9704734578707032, 0.9694028179622705, 0.9260759258216106, 0.9487553319757794, 0.9550106685734371, 0.9213018352717528, 0.9760729050066805, 0.9552638080499373, 0.9448730921395629, 0.9703295878325605, 0.9580091012051403, 0.9572408531032741, 0.95189175183291, 0.9531710072061114, 0.9600129174432728, 0.9630991332004326, 0.9724314807264179, 0.9617231707284984, 0.9608458211237341, 0.9712072867301309, 0.9183836057226744, 0.9301130893340304, 0.9413821262129123, 0.9496289212896654, 0.9395732453504831, 0.9814680257551854, 0.9443037784475025, 0.9662863557360716, 0.9659062117142101, 0.9507088996626729, 0.9842360405319482, 0.9345654474857352, 0.9434193932565399, 0.9620555286477888, 0.9285677631745378, 0.9174885537138107, 0.9601482192641039, 0.9656318463251125, 0.9714968739825891, 0.9542781215924987, 0.9339005996512901, 0.9565409061963941, 0.9308058972160707, 0.9737428124441622, 0.9738834345720959, 0.9615382570243481, 0.9567946180216099, 0.9567300682659248, 0.9424707786730865, 0.9239651357963973, 0.9411292602685201, 0.9673300762819762, 0.9632968178700132, 0.911011337388676, 0.9199505335771841, 0.9549707167223167, 0.9428199194930346, 0.9379167661787218, 0.9645791751710845, 0.9515482449901426, 0.9488584075665798, 0.9666054378079312, 0.9513555749042627, 0.9465002041748269, 0.9442952599597464, 0.9588524534102811, 0.971316189884418, 0.9559979259784644, 0.9403431391741017, 0.9661280829643643, 0.9557965492053612, 0.9705156136285382, 0.9308589375487004, 0.960704643945635, 0.9176291854964352, 0.9293799719517296, 0.9513941134475487, 0.967592318612815, 0.9349207780395546, 0.9373272322828321, 0.9582631184924473, 0.980037943043331, 0.9622206039834911, 0.9539966399812148, 0.984508723634655, 0.9308516304601343, 0.9626596741603242, 0.9628867839110342, 0.9721453529614763, 0.9411426816444948, 0.9359444183997586, 0.9545699784227558, 0.9388414618696821, 0.9417496071805959, 0.9863065646158727, 0.9513607086141682, 0.9772719646964421, 0.977329813933524, 0.9408635804170483, 0.972815246023792, 0.9365600730495844, 0.9378686245985038, 0.9567014753679225, 0.962457649746879, 0.960676638588743, 0.9583384203971033, 0.9287586451386202, 0.9635172253259172, 0.9378231151749443, 0.9505411092206071, 0.9399727750276838, 0.9664427208005464, 0.951464345577022, 0.9642875106583191, 0.9484253665072988, 0.9845713862491421, 0.975583342166134, 0.9309759666441906, 0.9716442226820639, 0.9236515010189448, 0.9362885203873549, 0.9449015393437941, 0.9396380361703702, 0.9170499009389966, 0.9142616595861894, 0.9365309665329773, 0.9437590124980679, 0.9596228738040448, 0.9052767460275224, 0.9604471796643875, 0.9428434485601674, 0.9741750206939688, 0.9435660584572094, 0.951534608910217, 0.9615503859936948, 0.9790654701979715, 0.9424251320494584, 0.9668358089572109, 0.933346251139515, 0.9803053327567732, 0.9540686561266434, 0.9520507808968406, 0.9738507417097138, 0.9482685349230737, 0.9313620988960073, 0.9665743662708435, 0.9295638905816168, 0.9687099140692955, 0.940662434732021, 0.9114179581933993, 0.9715559289145296, 0.9256281751913793, 0.9801909724764765, 0.9664448349254969, 0.9607695203219353, 0.9462870275204346, 0.9301014339373516, 0.9344930569378681, 0.9795899450003988, 0.963228581066618, 0.975086905799861, 0.9568905762683364, 0.9832456195255471, 0.9467578469805539, 0.9623432210977438, 0.9678002410131121, 0.9800310439408976, 0.9304406233876261, 0.9335170559422717, 0.9668887325716143, 0.9557198315599684, 0.9503674989930543, 0.960289003998233, 0.9322772706910425, 0.929685483818057, 0.965533768999819, 0.9647578185877702, 0.9290778489551627, 0.9664586298940013, 0.9582615879390257, 0.9600684764681631, 0.9519453706369976, 0.9526206434124084, 0.9544641132254248, 0.9558543562423449, 0.9556399543349117, 0.9348389298897128, 0.964384851240901, 0.9386104956422342, 0.9783450618931068, 0.9685456467481952, 0.9745742759825841, 0.9504651789581527, 0.9213183618737015, 0.9658602998362579, 0.9599798717604241, 0.9515994510521686, 0.939955491005081, 0.9451196817123648, 0.9748542939217458, 0.964610821107772, 0.94457505998931, 0.9618549270781732, 0.9277851000736058, 0.9447047866859342, 0.9608241321997918, 0.9655377129616682, 0.9128340138130543, 0.9602779307251481, 0.9583207007806844, 0.9527204891185524, 0.9557780533411746, 0.9460085789577874, 0.9519415226127602, 0.9544404849723575, 0.9426792444509834, 0.9763672825994861, 0.9468575888115334, 0.9507135181507153, 0.9555088093566416, 0.9677845911715682, 0.9547859060235385, 0.9631638728526328, 0.9500448457831705, 0.9691621711448196, 0.9408838776399264, 0.9490925715769434, 0.9590255483859177, 0.9702758914098235, 0.973495392270841, 0.9659054591460042, 0.9403438241527461, 0.9605631789955199, 0.9481161416934317, 0.9652702559980006, 0.9684828017041155, 0.9589579596117166, 0.9669331818051133, 0.943309592116739, 0.9567532621479435, 0.9608155401598532, 0.9683375070344393, 0.9832592144504426, 0.9436755790763015, 0.9245662813159043, 0.9403871068519992, 0.9211099474265699, 0.948001046121136, 0.9640629531707615, 0.9580320254601085, 0.9656823999609836, 0.967141177769966, 0.9660410246026259, 0.9603199088025103, 0.9313896899101896, 0.9544830634321775, 0.9488144649566691, 0.9790122767469359, 0.9606529369372351, 0.9722286429728206, 0.9301250789426447, 0.9597244071564704, 0.9459981713471056, 0.9168895563435816, 0.9280043321826288, 0.9377493071524662, 0.9714007148202116, 0.969180141097978, 0.9511335211448791, 0.9617178939868437, 0.9651120601981538, 0.9758684116262653, 0.9685272513933939, 0.9465900933016866, 0.9375488232429907, 0.963897843454766, 0.958156391150439, 0.9226546303849769, 0.953363261107141, 0.976409582943693, 0.9708087457269744, 0.9588830246467923, 0.9654565397121241, 0.9672659844429133, 0.9650706703235504, 0.9204553807497283, 0.9415848101998061, 0.9438489292949018, 0.9576750688863132, 0.9540841670346525, 0.9674024048660421, 0.9428577214069328, 0.9426051327816835, 0.9623530693071107, 0.9755179111612426, 0.9880288447140801, 0.9113847352951092, 0.9245507879555332, 0.9320353934939702, 0.9622531039996757, 0.9575090096416576, 0.9757940180332302, 0.9158882516329867, 0.9011317479611678, 0.9794842481885864, 0.9462118892232402, 0.9677291961777744, 0.9413916479730663, 0.9523407963304568, 0.9508128463675712, 0.921283656473666, 0.9190117460506613, 0.9352719407365119, 0.9218603311412229, 0.9554066430410909, 0.9599687671205173, 0.9326651775588353, 0.9541158556426078, 0.9594807954187546, 0.9488248382750439, 0.9472235067517193, 0.9430814281584357, 0.9790345480720379, 0.9686305467824957, 0.9463829576147216, 0.9799533598055064, 0.9767351857823298, 0.9643220710564285, 0.9572372591116758, 0.952822457240983, 0.9501754956699656, 0.9653083109080826, 0.9541823001501508, 0.9847067315934311, 0.969029766564163, 0.9629771625562467, 0.9414628896197766, 0.9396009981807659, 0.9799163718619828, 0.9704026889986102, 0.9585814043543774, 0.966419605046618, 0.9608383494933708, 0.961347313988773, 0.9726083615428909, 0.9729805997124596, 0.9724637203701593, 0.9815850421101198, 0.9661331843750555, 0.9311457863916268, 0.9715858957270708, 0.9794701974074438, 0.8926034334995661, 0.9463715156882605, 0.9692317002896366, 0.9408215148545788, 0.9730084954393823, 0.9689646780852004, 0.9316501243860824, 0.9268053699931121, 0.9756530465873822, 0.9466380209918746, 0.9089627234866792, 0.979472576294244, 0.9640301196370527, 0.9477177970646331, 0.970362146123682, 0.974009823290806, 0.9179809379851065, 0.9369109556108784, 0.9430603259310087, 0.9470535360550806, 0.9708839744740061, 0.9732413716858265, 0.9772316495576678, 0.9499778504811809, 0.9469857950606175, 0.9425170472217745, 0.9511979271223145, 0.9399570324085024, 0.9531010709790164, 0.959817963098563, 0.9188451621470741, 0.9264022093574089, 0.9447807807871241, 0.9405372037278025, 0.9693956359360779, 0.9644834528976579, 0.9487267029408211, 0.9424195949218943, 0.9695300405687183, 0.9332681553170069, 0.948008903223846, 0.9751540534936642, 0.9619636797113207, 0.9548052196207709, 0.9730436214919769, 0.977456563416579, 0.9826417367583048, 0.902029624004611, 0.9328114496607254, 0.9829489574615983, 0.9475958441854393, 0.9498183570246758, 0.9695509723061452, 0.974939472680496, 0.9444448661400412, 0.971274056396122, 0.9511110148158772, 0.9542933182003996, 0.9740355953774479, 0.960677683401536, 0.9489410543310036, 0.9345400951615216, 0.9644019541696424, 0.9482924383239659, 0.9485268742386154, 0.9726607075165027, 0.9531693456380032, 0.9635612077995908, 0.9227189670907878, 0.947811396617253, 0.9423862823361687, 0.9692997627152219, 0.9440603519457367, 0.9435479168572702, 0.9816788010237337, 0.951362125110185, 0.9207750354821012, 0.9420228363113378, 0.9556854125815607, 0.9756961841464379, 0.9729232048927063, 0.9447923045538752, 0.9501241617407701, 0.9389015564705415, 0.9682421324362427, 0.9314304118201041, 0.9729716501773874, 0.9565328153919991, 0.960867282414799, 0.9327445839525765, 0.9677422682771919, 0.9533423335267834, 0.9171306822755757, 0.9413291984663414, 0.9508068538331874, 0.9380473099474808, 0.9752677390751557, 0.9432048885015079, 0.9470307688003097, 0.9561729165400717, 0.946227614783836, 0.9662794707444899, 0.970582336747003, 0.9514525966959622, 0.9480785324461242, 0.9565293330792032, 0.9168099621888377, 0.9601031085771535, 0.966241671502173, 0.9647584044533551, 0.9388920479250673, 0.9853825937785003, 0.9570123370894833, 0.9423003363126058, 0.9206633816368885, 0.9726078141207182, 0.9776762496856315, 0.9493348841190953, 0.9637506844099608, 0.9659809932158359, 0.9483267750889866, 0.9727703375594283, 0.9334765108131415, 0.9649274410537432, 0.9534925723744516, 0.9725529908176591, 0.970671726358433, 0.944950237102991, 0.9650514979824065, 0.9398229459330427, 0.9662665829110325, 0.9374509406715908, 0.9685784189819534, 0.9335500894369897, 0.9631769347307991, 0.9781121789293163, 0.9525412537430562, 0.9370733048695912, 0.9381864952389262, 0.9451255341236587, 0.9553495420543957, 0.9547178756325911, 0.9711003206556268, 0.9532954439025075, 0.9675031009418554, 0.9310496924248124, 0.9683821806706203, 0.9604113089665914, 0.9495204308372729, 0.9103156120941538, 0.9391003095248316, 0.9442992897491764, 0.9663684004243299, 0.9593383225869208, 0.9515571426119922, 0.9700149321455696, 0.9673772287247782, 0.9578860589026307, 0.9345413022725013, 0.9550851312209451, 0.9748214611788588, 0.9429737230076363, 0.9475737400938133, 0.9533555269491317, 0.8778596808199359, 0.9547814142623005, 0.9580864057990968, 0.9638616924497834, 0.9442639678050584, 0.9438656153781455, 0.9227391295932418, 0.9533920603089601, 0.943010302317059, 0.9260416265234632, 0.9780049632631268, 0.9508642939311696, 0.8696073393645172, 0.9422940474712157, 0.9249930068032625, 0.9371191296768651, 0.968805602078774, 0.966287021819458, 0.9474472518711669, 0.9557424571026343, 0.9536762239928509, 0.9799685368473382, 0.9721087347909002, 0.9763569289626743, 0.9795735613793614, 0.9518783981840626, 0.9828324776494185, 0.9608300558586408, 0.9668762495440154, 0.945996776538525, 0.9474130687982193, 0.977280225064873, 0.9461652693598526, 0.9626356144434969, 0.936795086547388, 0.9656572635091796, 0.9596693628563575, 0.9737562896688846, 0.9384584515559742, 0.9458564997768272, 0.962171058168344, 0.9750298623412046, 0.9791133509932429, 0.940728566185763, 0.9365920010126136, 0.9794348754504083, 0.9571405110284565, 0.9558464147570808, 0.9489326952399854, 0.9795702530838486, 0.9509924696961939, 0.9675017090618341, 0.9616912532637842, 0.9627675912973919, 0.9595683880070915, 0.9737855023695317, 0.9615555414630517, 0.9543022580773105, 0.937030557919737, 0.9235486121597182, 0.944415755105289, 0.9398211862753443, 0.9516906505003083, 0.954553175351167, 0.962880115291602, 0.9490530766652444, 0.9449846544335847, 0.9485699309115178, 0.9307835584125189, 0.9789266603164788, 0.9402510493494013, 0.9433217933772401, 0.9567167582267205, 0.9480392490090902, 0.9705317756086511, 0.9394098823346658, 0.9784782877410765, 0.977804356725419, 0.9660579048950015, 0.95916673721062, 0.9667929545764979, 0.9714726033952424, 0.9306426624900297, 0.9395429811943449, 0.9336746208465305, 0.966560704359749, 0.9322428298241328, 0.9634821527934191, 0.9540971879075674, 0.9559304795174185, 0.9277044500646612, 0.9246439203995341, 0.9530519179156727, 0.8765769881733639, 0.9189341006345101, 0.9615342408414098, 0.9680969481351771, 0.9548486613751574, 0.9441455405990271, 0.9433773095374655, 0.9727550322836873, 0.9709687278010821, 0.9547933312353611, 0.9415098772771168, 0.9371383269353275, 0.9787460377415163, 0.9705723304814606, 0.9820082126749724, 0.923532841875784, 0.9653434997036613, 0.9627105520320136, 0.9725639404370806, 0.9378388393472449, 0.9127243491424792, 0.9608163800710655, 0.9803291437831285, 0.9441654163048043, 0.9419640432263439, 0.9724897754855921, 0.9305440228790711, 0.966022165995289, 0.9589341143370141, 0.938330819774348, 0.9219539711971029, 0.950110047811856, 0.9421515782808888, 0.9476829400120285, 0.9712580440204954, 0.9559213131247967, 0.9331357833325024, 0.9642252303846052, 0.977483994558144, 0.9427913967371769, 0.9631249371998304, 0.9566207370574297, 0.9658802387997081, 0.9644414984609876, 0.9510733222266886, 0.9504635016649009, 0.9567955011633895, 0.9452520975503128, 0.9463884366891098, 0.9750609138012879, 0.9551494341141809, 0.9501976178342013, 0.9635251910271679, 0.9496724166418218, 0.9681546214136685, 0.968880061839069, 0.9297386889201165, 0.977561056598026, 0.9651612035798292, 0.9662432131276538, 0.9820323443424023, 0.9133687388999534, 0.9597155132449416, 0.9439081215743257, 0.9724310279831917, 0.970560878486725, 0.9694154061381489, 0.924877120289561, 0.9505290236441154, 0.9772696330863613, 0.9090676314002537, 0.9700496187200671, 0.9518697057557861, 0.9448941961408113, 0.979817792716301, 0.9723758378859302, 0.9719448733251413, 0.949024705961414, 0.9589923428142396, 0.9390474371457305, 0.9546993253369938, 0.9618074454452643, 0.9651467788965912, 0.9545087125135633, 0.9517387238172942, 0.967662034593455, 0.9784082167584338, 0.9716820539260254, 0.9447983840109636, 0.9537651117235156, 0.9628053332468193, 0.9724084467389817, 0.9248698325122005, 0.9571410781443918, 0.9634923457057624, 0.963391162579704, 0.9746733978242501, 0.9469010363750943, 0.9437739801043007, 0.9730145547853466, 0.940723864667854, 0.9608561832963959, 0.9587509479276484, 0.944277953842536, 0.9458834351483797, 0.9429890084579565, 0.9677986769922522, 0.9634816170243798, 0.9384931030830664, 0.9454985022677279, 0.973249749247859, 0.9663455477257958, 0.9317465735500513, 0.9568735738826997, 0.9668778787082958, 0.9472394829371191, 0.932835970136523, 0.9662749718967824, 0.9525731697509143, 0.9448499638303479, 0.9653114821230457, 0.9544452508170446, 0.9468541251845767, 0.974153999475903, 0.9856560869692608, 0.9288627128669756, 0.9604443518575227, 0.9567080984540435, 0.946517888431331, 0.9567953331628009, 0.9815313567646232, 0.9487003217403644, 0.9463637634652554, 0.9825489492113163, 0.9550398135732594, 0.9772385112032259, 0.965966931683591, 0.9491442897164825, 0.9483871454447451, 0.9661044659770998, 0.9688384717684555, 0.9735688519116419, 0.9721658085024406, 0.9413737000799525, 0.9648552348748956, 0.9435782931772407, 0.9451998449603074, 0.9462243861647877, 0.8952766208672369, 0.9460273542132367, 0.9529005828980311, 0.888923912893915, 0.9380446730819545, 0.9758171563625663, 0.9607076767201609, 0.9549661974487794, 0.9647759566551728, 0.9542707386179851, 0.933874205410089, 0.9554160749907572, 0.9252348778489972, 0.9685265697354105, 0.920339914364575, 0.939426275227689, 0.9068493600599898, 0.9671285207947902, 0.9733358164947398, 0.9256183320725787, 0.935681604447698, 0.9095074781312632, 0.9409113172520854, 0.9657113981830744, 0.9453968662339527, 0.934267785906884, 0.9607818874590859, 0.9459307165117298, 0.9669131248853614, 0.9751899106202606, 0.9124938393872449, 0.920002598394306, 0.9413912341707696, 0.9522318720228935, 0.9823830827951373, 0.9638919637717124, 0.9662623870495979, 0.9548227577965058, 0.934576628569255, 0.9524326287495023, 0.9619221482582528, 0.9627011059106462, 0.95551314673321, 0.9662939268231487, 0.9576557344998549, 0.9363321554158534, 0.9485344452030026, 0.9141538147016213, 0.9450561735283884, 0.944426080788728, 0.9751642397991767, 0.922079622845835, 0.9394681880392842, 0.9620880211283389, 0.9348727030599497, 0.9580297390337547, 0.9709121321792302, 0.9360106039839808, 0.9462776874835802, 0.9260296469447513, 0.9536561452988153, 0.9678305698582281, 0.9575982200000701, 0.9573683586449445, 0.9228819927618982, 0.9661881673085123, 0.950780100433682, 0.9512992890131932, 0.9534463164518748, 0.9519226244250674, 0.97280740847358, 0.9706488952204195, 0.9611202729110491, 0.9563519780331972, 0.9726090597647115, 0.9628343907117208, 0.9400030384109354, 0.940912655257285, 0.923671949669976, 0.9811448851649291, 0.9547977463467773, 0.9758798609342844, 0.9520728466917487, 0.9150285822636721, 0.9414713712289678, 0.9837770262044647, 0.9471382884357266, 0.9537055930292034, 0.9504083253706495, 0.9480104753759183, 0.9496160414030812, 0.9253664309601675, 0.9495761847914989, 0.925803285039488, 0.9524219411635586, 0.9320732508311529, 0.9514434779681259, 0.9462404870375227, 0.9543134898776017, 0.9541121198793526, 0.9458163407590725, 0.9559339965819664, 0.9550079056774124, 0.9656523786673699, 0.9661069104313309, 0.9427164934094716, 0.9335774668208283, 0.9500102371559639, 0.9145995929887377, 0.9693037212455258, 0.9401861255347363, 0.9470836722453613, 0.9427366946856838, 0.9449751497879797, 0.9336348849030603, 0.9819670703497688, 0.9299006765756348, 0.961563750524094, 0.9701674336743429, 0.9613777587414214, 0.9575037896130353, 0.9402439692608193, 0.9640583020440092, 0.9653500488931267, 0.9759581189234079, 0.9527400583030159, 0.9542271386416612, 0.9281128015184646, 0.9586085207722037, 0.910719941980316, 0.9673885336810405, 0.9417382044429652, 0.9618320459664805, 0.9376093925204253, 0.9258150596884793, 0.9643112819138894, 0.9720521240850872, 0.9587007435178533, 0.9393788859683764, 0.9621311358843672, 0.9513043451949953, 0.9607221852919109, 0.9356845788687358, 0.9658292798344077, 0.9442578274049642, 0.9130795017606377, 0.9194352708020115, 0.9816004266527464, 0.9635879988368091, 0.976902844084073, 0.9502891940458872, 0.9469417494681839, 0.9375060608808005, 0.9447545430826494, 0.9483472144676119, 0.9039367746588426, 0.9076920483661414, 0.9660822667320447, 0.9465882600210597, 0.9617576395843226, 0.9374470001767307, 0.9705639484420819, 0.9628807018281582, 0.9413602934455219, 0.9388398858486727, 0.9695981310728037, 0.9635206003054324, 0.9306718618368888, 0.95439293981092, 0.9006174289940639, 0.9454925397766205, 0.9648931859790422, 0.9341302881987247, 0.9685755198649744, 0.9521413078568668, 0.9482755792651044, 0.949968130181036, 0.9571169464647037, 0.928575750300145, 0.9349180573846498, 0.9808976120995165, 0.9326955826094898, 0.9458201662823531, 0.952971114946199, 0.9764053134708996, 0.9642104211922806, 0.9417712483357726, 0.936333467748874, 0.9802156596411431, 0.9614427212721942, 0.9551937086806015, 0.9724241911991672, 0.9544987229816314, 0.9851965979556591, 0.941085492849063, 0.9382247985461865, 0.9289796496515697, 0.9772495909771018, 0.9499708490543306, 0.9699107154174332, 0.9561149113849294, 0.96843444812347, 0.9784645445740218, 0.92755813130017, 0.9613678680285258, 0.9580526798911991, 0.9558407353787017, 0.9724931355322988, 0.965817955298464, 0.9541609610519887, 0.9284023321384344, 0.9766458097503071, 0.9812589138921342, 0.9623511694784711, 0.9357535619694994, 0.960962211263469, 0.9758454665386108, 0.9495448998754845, 0.9600785917978042, 0.9784316244416361, 0.9598842300712992, 0.9727169558923892, 0.9813255473324337, 0.9666801376763098, 0.9491382021095159, 0.9496714364775839, 0.9714737562116037, 0.9489122351171564, 0.96212474355153, 0.940159754927421, 0.9646925857618717, 0.9339682939034771, 0.9687370369294364, 0.9607905408515255, 0.9521499988465364, 0.97085489585476, 0.9767242633321049, 0.9622198588570776, 0.958551653651816, 0.982794066854109, 0.967691020330229, 0.9882857995641068, 0.9711248300549674, 0.9677917598656689, 0.9761580065261872, 0.9836447319696725, 0.968459032936145, 0.9309451840936867, 0.955234084600943, 0.9510441851059136, 0.9782452470718035, 0.9517622511191138, 0.9711882372667762, 0.9492058918549034, 0.9734434838790161, 0.9495050521897661, 0.9636418879312849, 0.9391535610046716, 0.9476155847034748, 0.974012568318174, 0.9379908823433895, 0.937902180595971, 0.9509555393668259, 0.9448661743740586, 0.9390178002730852, 0.9808299707891625, 0.9667887062677588, 0.965161377113607, 0.9492516811148051, 0.9520521330232163, 0.956122175605569, 0.9315859064734846, 0.9490647327740658, 0.9207196739638219, 0.9589875042082684, 0.9663525941255364, 0.9666600921916388, 0.94713732837837, 0.9826497297941227, 0.9751339610396867, 0.9403235237497141, 0.9591891103188145, 0.9630745235639495, 0.9561488034919978, 0.9550965000506311, 0.9167059289362885, 0.9728111368150918, 0.9496258839900038, 0.9502753061198107, 0.9733527443936636, 0.9631354701334524, 0.9690369868733213, 0.9625133626439922, 0.9476462154572113, 0.9598458610628389, 0.9286844754593876, 0.9672312041574114, 0.9667625866808444, 0.9705035475592039, 0.9361983677027182, 0.9530373992749532, 0.9333463463026118, 0.9204586104138094, 0.945488463076394, 0.9434002653302153, 0.9334736606130852, 0.9440946292964104, 0.9426925237747794, 0.9585621160202368, 0.949874245904021, 0.9557716153493291, 0.941877215768892, 0.9337475343891174, 0.9453466623613617, 0.9420451944496951, 0.9637871424556965, 0.9247324592827193, 0.9668095924909187, 0.9434786683659875, 0.9544212665050079, 0.9699992034830754, 0.9551157041113618, 0.9697654285119389, 0.9609316687650511, 0.945544087070171, 0.9609786034551793, 0.9338702883459585, 0.9591411671313356, 0.9526589504425986, 0.9763764790291366, 0.979129228839925, 0.9575822284656634, 0.9606095357535855, 0.9807524701567736, 0.9453078414938717, 0.9724827732928909, 0.9326706457803083, 0.969179803395735, 0.9387493509019955, 0.9822072057387475, 0.929736966484901, 0.9492455337859639, 0.9531275004193026, 0.9464579261054735, 0.9507853507635616, 0.9769377824885455, 0.919632022641936, 0.9766841267948807, 0.9638493765738956, 0.9494765422707064, 0.9302407489764959, 0.9382359414582055, 0.9779804421754852, 0.9606489291190765, 0.9668709716406949, 0.9394211660611137, 0.9505328456392393, 0.9471042973978546, 0.9513447983821729, 0.9427200645602409, 0.9502835217005339, 0.9508015811457702, 0.955918927498124, 0.9578841230130748, 0.9454174099822705, 0.9400710838536925, 0.9274108130220792, 0.9541037164665859, 0.9533605116686467, 0.9444620936456263, 0.9777182562597427, 0.9188827303728319, 0.9610316254251331, 0.9444436079732585, 0.9525367095923869, 0.9512998820366656, 0.9605718670965789, 0.9315405900413324, 0.9760075000242815, 0.9341566984902336, 0.9687956436082277, 0.9527511997852927, 0.9640912228417267, 0.9398976641878222, 0.9669858979590606, 0.9761806490633655, 0.9736047947196431, 0.9676215666198309, 0.9449613768541179, 0.9478422885173483, 0.9120204779728163, 0.9571832835917815, 0.9186556373500531, 0.9720150368259758, 0.9305756657548422, 0.9180241718732158, 0.965021185683448, 0.9515173350040389, 0.9496098081537951, 0.954838905333643, 0.9593593927906119, 0.9604457131410306, 0.9435572242426594, 0.9628282851715125, 0.9598664213356625, 0.9548684552552282, 0.9666405078519593, 0.9384296759637077, 0.9611024612343424, 0.938314426699348, 0.9425332373919358, 0.9685497681770953, 0.9739721822492151, 0.9663887315055698, 0.978189297280944, 0.9380194273210513, 0.9175924881880066, 0.9428900667914996, 0.9149856688113105, 0.9521991499924067, 0.9353343146207038, 0.9274651779492771, 0.908767954761366, 0.9755224554753948, 0.9574545954004327, 0.9573374503741616, 0.9449878934330997, 0.9538231512045626, 0.9707081448363816, 0.9765840613813581, 0.9638595242762105, 0.9625780756178899, 0.9690634946633496, 0.9543232854462359, 0.9369105834969526, 0.9544427282339398, 0.9675931962788823, 0.961266936850429, 0.9622239744891844, 0.973541259337067, 0.9584671039773028, 0.9733144416871644, 0.9737499708918367, 0.9675545788254175, 0.9471149781976422, 0.9532722816745383, 0.9751672468245299, 0.9675844503377562, 0.9576627073803194, 0.9768515341582045, 0.9290798414023469, 0.9758341353279172, 0.9447152617808459, 0.9672100992730022, 0.9677750589553387, 0.9432201001301894, 0.9648638193058883, 0.9216050603090251, 0.932881663258072, 0.9837428806036753, 0.962965941530921, 0.9744854916080953, 0.935583784995746, 0.9526084872055995, 0.9519212507603272, 0.9850027496622765, 0.9736662639321605, 0.9805863507463104, 0.9620275276965636, 0.9831795050194558, 0.9730317459945947, 0.9308710981455958, 0.9548430237016499, 0.9662963551708912, 0.9528212878686451, 0.9817134602296722, 0.9420277533070198, 0.9742350450962769, 0.9543317131664083, 0.9385388000319544, 0.9504340608319611, 0.9391811864695276, 0.9495317531629124, 0.9470295177956052, 0.9619368581605301, 0.9561398560807285, 0.9694836581785371, 0.9433060039751097, 0.9450888159708457, 0.9549562735906935, 0.9413259359361559, 0.9641549640797673, 0.9653764108944621, 0.9461098452581906, 0.9438420240547104, 0.9348399694675102, 0.9517326135759712, 0.9494266132526086, 0.9272339018057321, 0.9572173986798718, 0.934733777453426, 0.9707159529741443, 0.9698027501000753, 0.9562365035346785, 0.9643717594838966, 0.9589629685336855, 0.962736499030544, 0.9542848415300822, 0.9855069726928863, 0.9739628586165775, 0.9244938851394269, 0.9565245385173726, 0.9802923209300857, 0.9516953802264934, 0.9323893294615152, 0.9794812972341783, 0.9367878053054991, 0.950317388453986, 0.9380200368316121, 0.9399083803250584, 0.8808328431190945, 0.9656047408248105, 0.9695499235964092, 0.945758600011585, 0.9404454191999075, 0.9494248981775295, 0.9758295359179409, 0.9079897297403157, 0.9679716945854349, 0.9810499877015947, 0.9438090333800422, 0.9395052075170767, 0.9799797206469151, 0.9782728393189212, 0.9642451476864529, 0.9812761345821794, 0.9541140794923563, 0.9555140494216134, 0.9351465474019799, 0.9731203598397686, 0.9299336235168365, 0.9842119654475808, 0.9800617905125503, 0.9824356840260255, 0.9599489778584583, 0.9362651283588489, 0.9444932288325715, 0.961566784167489, 0.9556998524632685, 0.9704347528537713, 0.9362896410237831, 0.9608201322294345, 0.9457601409116575, 0.9321688559163089, 0.9659841203281646, 0.9351255466169588, 0.945702075925099, 0.951326612050587, 0.9371341244014773, 0.929962602013808, 0.9169605129342836, 0.9492677282517531, 0.9844253844541205, 0.9545239458214887, 0.977298238653003, 0.9552701658047319, 0.9729207200088321, 0.9301207220735931, 0.9836180471885765, 0.9172243251686392, 0.9340238733295144, 0.9576318711318349, 0.9391076398905023, 0.9379203571334033, 0.9336343920400751, 0.9627609816541199, 0.9488994783556027, 0.9501444018614869, 0.9550468920218889, 0.9564179241871998, 0.9288979487661492, 0.9626572339065365, 0.9155330893816963, 0.9665794907760543, 0.9288218265685338, 0.9499037813198896, 0.9591743871731616, 0.9433285482847861, 0.968435155983516, 0.9373513146591641, 0.9380235857884721, 0.9436098702075078, 0.9589943530521552, 0.984518658701345, 0.9390236959737558, 0.9139386726461595, 0.977090875695641, 0.9817381352179511, 0.9016538462354607, 0.946175263282307, 0.9708965783142538, 0.9313667634857726, 0.9327691939986044, 0.9529790779253474, 0.9569407712271298, 0.977976500032819, 0.929576246501426, 0.9692085727959544, 0.9503595060787892, 0.9718234111672529, 0.9846800118104279, 0.9611157506819519, 0.9736638470778609, 0.9692749118232903, 0.9387040308842589, 0.9746218502034563, 0.9620917416553187, 0.9745517943354832, 0.9615932643715179, 0.9449277677706621, 0.9111960766667551, 0.9433598786489295, 0.950339859294109, 0.9578788385705402, 0.9292417262571678, 0.9312500580281995, 0.9645473830713773, 0.9484280430250758, 0.9702565441665755, 0.9319901963256413, 0.9534012571395231, 0.9464540944725435, 0.9540737947529114, 0.9435411858208438, 0.9146865395386836, 0.9257917235682036, 0.9793188647221277, 0.9553897932181232, 0.9836042508652133, 0.9512298021933462, 0.9647354745571384, 0.9324445770357822, 0.9620142609381209, 0.9640758686946609, 0.9530689023869225, 0.9367080993994495, 0.9636299224989476, 0.9459714373008252, 0.9787756449085694, 0.9445453877515653, 0.9309500566702463, 0.9750606105915786, 0.9271940592951958, 0.9798254602654485, 0.9286874386677516, 0.9406401171197252, 0.9715635968389534, 0.9789185224592293, 0.9685868673512971, 0.9600933608182981, 0.9382097308979779, 0.9679919690110022, 0.9804830810511472, 0.9669215482041119, 0.9517886921907739, 0.9176376877973139, 0.9732908547395803, 0.9578926211863232, 0.9680453823473921, 0.9681066048550592, 0.9788547304096724, 0.9519261447296246, 0.9376106846555279, 0.9478464530097218, 0.9552719921194941, 0.9436942820639588, 0.9306885102231792, 0.9629147951795356, 0.9386821288444454, 0.9708127695318082, 0.9520198321173824, 0.9715273928278938, 0.976475442401134, 0.9675663159861851, 0.9469713301597169, 0.9264058872641231, 0.9534875219261978, 0.9444407026889949, 0.9567794216006155, 0.9795002865071036, 0.9381935144552581, 0.940765902735193, 0.9558387982682139, 0.9560787745061201, 0.9381970061515111, 0.9852155359495625, 0.9534079582920784, 0.9411399468018551, 0.9252619851049612, 0.9792408801585474, 0.9248623373473452, 0.9592262760347203, 0.9729346234188517, 0.976137095271618, 0.9772521773819568, 0.9826513878354567, 0.9743366773072215, 0.9368186453893995, 0.955677104035158, 0.9573894297639738, 0.9455436328699922, 0.9364722886576846, 0.9439813676506862, 0.9669097120681883, 0.9292534229922592, 0.9248843042673193, 0.9543209797830052, 0.983307050978614, 0.9374543002225741, 0.963455107809244, 0.9640244165279086, 0.9369177702094869, 0.9503203362810083, 0.9719362682627117, 0.9275002240986192, 0.9400307179140928, 0.9531889427070964, 0.9436133030609508, 0.9645111121328169, 0.9402876296821088, 0.9473152116872902, 0.9457050469846494, 0.9325988708840565, 0.9667602381917186, 0.9397746431662686, 0.9488648351132937, 0.9717431175637367, 0.9420528128175887, 0.9851150738163694, 0.9289946761517428, 0.9235954530856575, 0.962739299474354, 0.9648384741149373, 0.9452674608543913, 0.9536380159892968, 0.9395687536814882, 0.9270482053994898, 0.9016783825738787, 0.9556934245968746, 0.9621009541626682, 0.9411755677933069, 0.9626071003348238, 0.9856563256591306, 0.9398564200733355, 0.9287114100509904, 0.9628273054597105, 0.9509544036777887, 0.961223721703051, 0.9583922245605276, 0.9491913348660858, 0.9490564210770447, 0.9778652985358603, 0.956270276783999, 0.9599167483579838, 0.9759090820905068, 0.9607896406137052, 0.9494555582960275, 0.8900932198171235, 0.8659356517817578, 0.8779670770911934, 0.9013453730393267, 0.8738063661216122, 0.8420520120135224, 0.904701554255679, 0.865365410280523, 0.9062092762795678, 0.8912661659133467, 0.8269409599526398, 0.8930428806803691, 0.8829861811577349, 0.9062801707240591, 0.8796875969136339, 0.8489617737806691, 0.8509387861186927, 0.8836528979617732, 0.8597194629413313, 0.8840204912944958, 0.881344832025203, 0.8270319532566635, 0.8529506238467394, 0.8597672166165041, 0.8850306924859555, 0.9054222887502836, 0.8499059621783133, 0.8461932586268878, 0.8931112874069344, 0.883161863995919, 0.9027852685834453, 0.8964849629241646, 0.8634643452219808, 0.8967553441683775, 0.8969082473328416, 0.8737834577590169, 0.8462484126583855, 0.8436185158703603, 0.911865440919494, 0.912345579621658, 0.8707726436435711, 0.9126821857227415, 0.8780240721323519, 0.8573037189376815, 0.9005982157802028, 0.9070153082634076, 0.924675872648565, 0.846281442882529, 0.8251846477132966, 0.8568214148054322, 0.8752264188416745, 0.893484485002781, 0.9058261270614396, 0.8987668910598653, 0.8813484048091281, 0.8562435085999783, 0.8402710839960855, 0.8242471769481137, 0.8732942163316434, 0.8594062247470684, 0.8319376742864234, 0.8633138422044699, 0.8755210874420724, 0.8823385120285028, 0.9156896203516144, 0.8187411365660214, 0.8690162802864062, 0.8713486448894124, 0.9094303685660526, 0.8833662570715946, 0.8776380361479844, 0.879708106150049, 0.8524431046782929, 0.8731263931797504, 0.8917085141554745, 0.8955006700498728, 0.8641731231556447, 0.8421933841093263, 0.8361115126273493, 0.8425772930169299, 0.8753990994115095, 0.8936942703428907, 0.8946999939580708, 0.8169109133623832, 0.8495858709579219, 0.8696103953449598, 0.8534543964820968, 0.8897929861559012, 0.8637532991457281, 0.8930405621007066, 0.8322545061335804, 0.7098675027307141, 0.8886802483759835, 0.8572851788092731, 0.857960640068474, 0.8286738789229854, 0.8724007371658774, 0.8798224720046401, 0.9243281902374268, 0.8452410342201523, 0.8559334716223888, 0.9110640411386767, 0.8528701037499642, 0.9184777617959985, 0.8743910654139384, 0.8553889583171084, 0.8763568226114224, 0.8728815701162785, 0.9121459988816109, 0.8768629593073616, 0.8459580717875952, 0.8857800469402389, 0.8763104945829104, 0.893140971222175, 0.9043199597556859, 0.8619716696113171, 0.9138535790014011, 0.8896697788593438, 0.8411295403046616, 0.8529553435785332, 0.9240383219207217, 0.9081644710000987, 0.8675051038395077, 0.8489978282167174, 0.9029603479823344, 0.8633511516611488, 0.8825303290560752, 0.8860482429381007, 0.8940831510499093, 0.8217234870589298, 0.8571533570137855, 0.8619161844050889, 0.8656239883497455, 0.8277759956432781, 0.9066122068349066, 0.8857764988646378, 0.8802730661758879, 0.8851002024640535, 0.8650705280953084, 0.8772621079366639, 0.8130309053356046, 0.8711877065854413, 0.8913843903361365, 0.87767993014273, 0.9083176601002085, 0.9109049696116054, 0.8458306020699919, 0.8352071517086815, 0.8613197369409872, 0.888934824495807, 0.8856298530734735, 0.8455230576989715, 0.8963736492415824, 0.8991020745002404, 0.8357567144836161, 0.838985040273789, 0.8697728715649236, 0.8344534974157414, 0.9196439411698843, 0.8828851689504723, 0.8433845822091048, 0.808021077640871, 0.8881039969359711, 0.853837436704991, 0.890474852709249, 0.8921377029551478, 0.8367168533862406, 0.8907303936581764, 0.8409628370666024, 0.8741378071538666, 0.8497477172189969, 0.8644671857920856, 0.8559839980825178, 0.9187360285491191, 0.9029806778484983, 0.8682450416924725, 0.8699414558907516, 0.8492323678107018, 0.8911942177537934, 0.8556300998175417, 0.8728718283273745, 0.9124479364082312, 0.8654480085065623, 0.8453302959729254, 0.8041650173653578, 0.8670520907169065, 0.8647209591463385, 0.8975999656935378, 0.8835875237817014, 0.8603033154358303, 0.8665592578462402, 0.8799353268585293, 0.8957187925395025, 0.8905452266692908, 0.9045771130604484, 0.8739806980912769, 0.8693306413850885, 0.8665990262593459, 0.8497699225042243, 0.8510246306638578, 0.9050065938888858, 0.8663401138823954, 0.8483906680126136, 0.834215479014105, 0.8242807047103697, 0.875485413005296, 0.853726727348937, 0.8449085250200492, 0.8804491709570946, 0.8657229024646074, 0.894793411396712, 0.8613621063315464, 0.8275314514768182, 0.841090565835436, 0.8779411038686034, 0.8530865479054247, 0.9234504692170512, 0.8414693389889308, 0.857716183117319, 0.8603718561813242, 0.8467467789073482, 0.8705685641731441, 0.8719207628967415, 0.8756292070325877, 0.8619527865594483, 0.8397705653454455, 0.8297139221074192, 0.8059127572497133, 0.8908817815627027, 0.8965005251108427, 0.8199889506553241, 0.8875669754313457, 0.9083757468269585, 0.8776467431332191, 0.8606823317275152, 0.9055711572022749, 0.8494269659825343, 0.901974248314914, 0.8800603166327716, 0.8594937686035125, 0.8906941499596391, 0.8646458656095578, 0.8611690096145231, 0.8678758364002961, 0.8311842386384508, 0.8526552002887107, 0.8655172300907472, 0.8430833749660499, 0.8033763407878481, 0.8984149463609106, 0.8734087010440473, 0.8977789758840152, 0.9149000134377208, 0.8482616321714345, 0.860116799173712, 0.8637728364711624, 0.9079603002123449, 0.8735332527928731, 0.8873134267767381, 0.8229063682748877, 0.8473309493356568, 0.8810241495982035, 0.8608424056739855, 0.8020896854326143, 0.8554787707182235, 0.9141601166086503, 0.8422816943989402, 0.8708909153496058, 0.8949754023964934, 0.9153052467953441, 0.8655650413298746, 0.8578930886343443, 0.8997172863050537, 0.9070003721621906, 0.8464046559582994, 0.8520357895670481, 0.8801778341669462, 0.8650723974146775, 0.9111639690807438, 0.8706416254527147, 0.8896389908999109, 0.8448021544563143, 0.8582940615572143, 0.8457147570046116, 0.9035306444332958, 0.814131261141724, 0.8330515386568402, 0.8831078242716184, 0.8891204075808925, 0.8323089452426532, 0.9048501107272477, 0.8965736364344911, 0.8986771659380279, 0.8687544005827474, 0.8625432867072825, 0.874817024902513, 0.9038357781798416, 0.8572843489011761, 0.8686972667320275, 0.8774060187824608, 0.8700832790547551, 0.8475390589777395, 0.8132439657351902, 0.8741161999427054, 0.8881412250131447, 0.8431363795855471, 0.8930374338860034, 0.8739073261245187, 0.889210993103369, 0.8675474530922171, 0.8379200631606603, 0.856846046849322, 0.8439802984244426, 0.8546520071916107, 0.8751137579481153, 0.8842243494051999, 0.8988419571417829, 0.9029085033002486, 0.9190376593414961, 0.8850142412761541, 0.8870912521972097, 0.8221155718618933, 0.8592521814503699, 0.9003617510112825, 0.8459505965171178, 0.8270644619569577, 0.8462588923708089, 0.84438405336602, 0.906976720666286, 0.8334207471088729, 0.8958528424490128, 0.8724137938795317, 0.8769190616856216, 0.8715862096065072, 0.9076683694987897, 0.9056141305625337, 0.8771088080390465, 0.86380056959377, 0.9112961544933924, 0.9065901801602875, 0.8816533515427138, 0.9044187095956574, 0.9189728436889095, 0.892218098799295, 0.8856876319433467, 0.8779452250522007, 0.8699020858483029, 0.9129312564972558, 0.8570510863366085, 0.8892310885095075, 0.8682546836432048, 0.8876396236606114, 0.7984093156293254, 0.8861427306727487, 0.9097282749493968, 0.8761307837800675, 0.9143918100266909, 0.8798257039480413, 0.8535667975010123, 0.8416720919852644, 0.9127843748811951, 0.8983452658795041, 0.8708883400391528, 0.8479909368049433, 0.849083650691357, 0.858805644087397, 0.8550308694396963, 0.9066275558340603, 0.9072076071669273, 0.8660611637979748, 0.8073889616186374, 0.9126238710324068, 0.8959425629210747, 0.8992412207915864, 0.8477934794176076, 0.8530656067650576, 0.8843136755622826, 0.8764115405030733, 0.86284401698121, 0.8408364865847745, 0.8721437493688468, 0.8624569759391051, 0.9229885218617643, 0.8644734345926914, 0.8680326645490579, 0.867299809613315, 0.833068601085211, 0.8730418397560499, 0.8227902266858432, 0.872400857952454, 0.8902620912400764, 0.8834435691267707, 0.8774602446264799, 0.9206241566815385, 0.8267170213229996, 0.8338844630906115, 0.8536198980122666, 0.8617321458998372, 0.8808320445486841, 0.9080157048972832, 0.8750277465311123, 0.8633563298737591, 0.8629582812169252, 0.8789822220607681, 0.8825811818514209, 0.8850354428204473, 0.832054103958264, 0.8754376450081394, 0.8575633246148936, 0.8790830053075427, 0.8974114736690132, 0.8979244402204556, 0.8539386947033234, 0.8733058172067827, 0.8775995280529204, 0.8622015560295869, 0.8450940309137039, 0.8797756139812446, 0.8812091142108898, 0.9235431031076736, 0.8546693409544193, 0.8428676170200577, 0.8949660978857568, 0.8837050781599554, 0.8483141413595288, 0.8573284282188725, 0.871374728579485, 0.8636250557892182, 0.8927129592772283, 0.8665412734591668, 0.9066899218269234, 0.8591962063597459, 0.849167369794752, 0.8625569657532015, 0.9043783890697766, 0.9246014987935555, 0.8175652405473488, 0.9002711641432506, 0.8939112045351288, 0.8921906372285241, 0.8642389666098859, 0.9021143738844165, 0.8852518183355774, 0.8835803921739515, 0.9041183843862298, 0.8969915847217207, 0.8776045767958143, 0.8630017751500495, 0.900540030455845, 0.8812504069115711, 0.8929022630996695, 0.9077296268539362, 0.8929024265582446, 0.8669277886100729, 0.8521501996583062, 0.8810476388072758, 0.8862636947852038, 0.8474016918972629, 0.878877420502966, 0.8990621348112465, 0.8981840019942728, 0.862779305804919, 0.8311690981677331, 0.8154707303450359, 0.8987687049818613, 0.8416389293398625, 0.8617595361766005, 0.891106863913262, 0.8890860180373181, 0.8971726330230501, 0.8257360326077405, 0.8895113785361579, 0.8291758801688052, 0.8719068808980119, 0.8270722057889728, 0.8649856529811342, 0.9090472953157818, 0.8762357178294022, 0.8452409944990738, 0.8464529245100038, 0.9062088687873493, 0.8201685578280492, 0.9015074422218257, 0.8599184577540645, 0.8477848141810912, 0.8816397994586767, 0.9009469857400964, 0.8108576693941015, 0.9015905117272077, 0.878033883175226, 0.8408006077087983, 0.9083826834787811, 0.8890225645438187, 0.8625750587439927, 0.8337483300436368, 0.8656653768526318, 0.8975849798311665, 0.9035609852205406, 0.8294543705849746, 0.894172872749294, 0.8870250115791881, 0.9158036719104811, 0.8269868847420222, 0.8066525309081214, 0.8433181804847921, 0.8408603362920025, 0.8353052437797044, 0.8853022880088485, 0.8745704316946047, 0.8360407972330195, 0.8669981239679403, 0.8289035868523896, 0.8752578392678556, 0.884246225983508, 0.8969061094329304, 0.8681418349133083, 0.8301349107422689, 0.8410530803632907, 0.9018786838673569, 0.8229626489872269, 0.8867199079244341, 0.8546470823088084, 0.8073900089463281, 0.8516008089414845, 0.8489389470585414, 0.8449698451449086, 0.8928756827662141, 0.8639369657377302, 0.9018459820361188, 0.8953796719971768, 0.9011185638745731, 0.8717099811247532, 0.8390257904405293, 0.8447728448390045, 0.898601619230492, 0.8731781763882484, 0.9011235827124996, 0.84523387186735, 0.9136039286363091, 0.8810030913239196, 0.8772743064931732, 0.8816991813527804, 0.9082455679138154, 0.9001697636351972, 0.8330484332491511, 0.9158463196616959, 0.8529670013999137, 0.921483201123356, 0.8670457347129348, 0.8731585244615231, 0.8566929045637248, 0.9076611071751284, 0.8884507347437435, 0.8828133903138793, 0.8494174709907174, 0.8421664835387235, 0.8116390496510036, 0.8401431038632721, 0.8773711549486227, 0.8214465157273121, 0.8464169349324914, 0.8519530602840664, 0.8191665179156385, 0.9074633698639146, 0.8415492489722409, 0.8529781023256282, 0.9129095361946272, 0.8195519913976896, 0.7890168075037566, 0.8259742912939958, 0.8915021842871595, 0.8721178437633015, 0.8225855564675325, 0.8347230967745057, 0.8389152463399553, 0.8993895864225089, 0.9269671365892806, 0.8566222734324996, 0.9059459523012465, 0.8306225207027214, 0.8791817526914513, 0.8650532367164936, 0.8548011834976205, 0.8769443436590468, 0.796339445306941, 0.9113899724991282, 0.9106670252061414, 0.8344306113031376, 0.8803169003015602, 0.850007372974282, 0.8080575377931671, 0.8685961498481013, 0.8350886990727928, 0.8572715775389432, 0.8744960029878216, 0.9197981719764458, 0.8919381858631147, 0.8868250633112065, 0.8437883935642969, 0.9067044708397691, 0.8806902701830235, 0.874865847018251, 0.875943739376858, 0.8517222570200572, 0.8720768573608845, 0.8589651473896448, 0.851301730563304, 0.8757024088579207, 0.8922790442737003, 0.8564225927762049, 0.8838540676805808, 0.8727091601990787, 0.8566124993995669, 0.8288382721044567, 0.8789777449678712, 0.8872361986602602, 0.9118225075192465, 0.846714114229977, 0.8494646170230385, 0.869115191150894, 0.8999572756248426, 0.869331503476723, 0.8882964916815372, 0.87503682951672, 0.8583802721191116, 0.9053605011027932, 0.8627651078993901, 0.8785431487651706, 0.8498234747592958, 0.8672222381965417, 0.8541080194499163, 0.8882968295517939, 0.9050057307363127, 0.85270973090513, 0.8854777028546096, 0.8992042449296205, 0.8941071196109102, 0.8565307766236196, 0.8244908547959747, 0.9074566077163504, 0.8429611573891602, 0.8636122662286444, 0.8756865786384924, 0.88046213343148, 0.8520063582504999, 0.9038656386298287, 0.879026271031384, 0.872793280955578, 0.9151608742010753, 0.9107766677956961, 0.8795582056209974, 0.8695380922466178, 0.9179090925348564, 0.8519078306375376, 0.8499947228268335, 0.9005272152805093, 0.8616816175351415, 0.8559463768403152, 0.872990588839487, 0.8509754931851519, 0.8555187565193447, 0.883834012150208, 0.8114614361541734, 0.9002375595413878, 0.9026715683432716, 0.8901285594016426, 0.8760179111579305, 0.8831878680643804, 0.9208810727570514, 0.8574553402568271, 0.8333726593238701, 0.9181508208706247, 0.8958850655922317, 0.8448649908682232, 0.8432858596058855, 0.8820255406456265, 0.8424866955222298, 0.8435155662856195, 0.8484051820960693, 0.8754151224782921, 0.8637771672199374, 0.9182387193760164, 0.9179530517011236, 0.8226178586989968, 0.9101633621147212, 0.8359847631855974, 0.9124040161428116, 0.8899215008536521, 0.8730374812609132, 0.8489689392553584, 0.8707382650379386, 0.8933588524916819, 0.8613142013964175, 0.9007393217605232, 0.8504657245631043, 0.8600820575637104, 0.8943329457442994, 0.8166252383044792, 0.8626022628278261, 0.8775489395873597, 0.9073511976250238, 0.8354251216401588, 0.8551828490773783, 0.8615313790430212, 0.807788609124636, 0.8964828545179677, 0.8955905436350067, 0.8307727392584856, 0.922581631937261, 0.8552624553169696, 0.8759957708758723, 0.8791840204527787, 0.8777376255515114, 0.8226334420252909, 0.8658538896935932, 0.8506239482310066, 0.8409391350871952, 0.9009697558244727, 0.8433028712219519, 0.8621228735676577, 0.8758478424362367, 0.9100991929750089, 0.8954949306616329, 0.8834539587067263, 0.8363956919928942, 0.882837923280719, 0.9011942922616143, 0.8974251711544732, 0.8256519771254462, 0.8949948478264187, 0.8905581581387604, 0.8620968951177399, 0.8484567311496932, 0.8706342421693499, 0.9090842101968302, 0.8222460353030226, 0.9068138021656332, 0.9035140455380845, 0.9008423048266481, 0.8730665321741051, 0.8611606128046739, 0.8583327590671801, 0.8764418344201742, 0.8624809377426464, 0.8717513775527647, 0.8792440566766055, 0.8530567923851708, 0.8878650024581743, 0.8669246376226778, 0.9173462747857332, 0.8713498506695406, 0.8672954915969068, 0.8782517604242509, 0.8859411907945943, 0.8458788169297198, 0.9102553198545895, 0.8643544351361072, 0.8464635029870764, 0.8959401281206741, 0.8475608511060239, 0.9028649404185309, 0.8900365216773064, 0.8997892186643695, 0.833892884896908, 0.8802193099032258, 0.8700397863967908, 0.8564050074094393, 0.8748717527505538, 0.8680851629415381, 0.8526164726574628, 0.8886887770475307, 0.8388777838985344, 0.9245767709307537, 0.8249187972328947, 0.860626410002768, 0.8775679696830663, 0.859409388565826, 0.8788873858947059, 0.8592609154654475, 0.8386342949520291, 0.8398665964653875, 0.9016832799715099, 0.7827883329081491, 0.8757543289680687, 0.8425875964945737, 0.8926796139215968, 0.909550235286635, 0.837505848675747, 0.8351652144645065, 0.8516374244879158, 0.86095040564034, 0.8907404963425011, 0.868223568843429, 0.8423494490868236, 0.8498156432587018, 0.8087294592700124, 0.869747650369566, 0.8504500541234851, 0.8772919000459959, 0.8740829650339991, 0.8504703383264131, 0.842297799377883, 0.9024936077186585, 0.8546825448180967, 0.9040230152645772, 0.9021771265426334, 0.8570229209544264, 0.9038580653889147, 0.854615695933826, 0.8932606283360859, 0.8642126746218061, 0.8114213606101258, 0.8259254453395911, 0.8318937688287886, 0.9118297755163259, 0.8747979037931024, 0.8902770157368638, 0.867466692179084, 0.8935837640949867, 0.8641058620293476, 0.8811185644715325, 0.8777102806151386, 0.8418659521151537, 0.8673041986434337, 0.9072642036511235, 0.8293634769410452, 0.8589784171260698, 0.8325815733849729, 0.8642287099450462, 0.8303569389508451, 0.8794604002976205, 0.8579786681413851, 0.8577224984177464, 0.835316913031385, 0.8861658582605025, 0.8861811540888378, 0.8929412890896536, 0.8881906190980056, 0.8653773723231951, 0.8413962795934089, 0.8778242234018023, 0.8834890690213203, 0.8760671083785804, 0.8590500909440838, 0.8753075541743691, 0.8518341441546112, 0.8836066634745733, 0.8614454773648614, 0.8498391362860312, 0.895501005926448, 0.8821983594015799, 0.9016503679771429, 0.8906279259555537, 0.8568614797297308, 0.8359045259904152, 0.9040469635872297, 0.9062992129746715, 0.8860024397934348, 0.8226540184125797, 0.8719692950843064, 0.8448691545219275, 0.8415980664402148, 0.8686592811646856, 0.8780079876264485, 0.8666239125122843, 0.8987337219437376, 0.9294959270994376, 0.8288977108446373, 0.8617632435097775, 0.8856045549488398, 0.9023274396060076, 0.8707396553757887, 0.8451510188144786, 0.8475554524486026, 0.8683430712999578, 0.8238746266196291, 0.8473311665229964, 0.8602604743455353, 0.8604058069047905, 0.888579146439056, 0.8883251099093742, 0.8711904121531513, 0.8877131709948733, 0.8611545140590791, 0.8398071696039419, 0.9030913850681516, 0.88888376168869, 0.8394092771970639, 0.8886456239773763, 0.8974078858857881, 0.8968983545875485, 0.8989572383636645, 0.8862577169665774, 0.8565848048725856, 0.8796784959439575, 0.8757315278889317, 0.8392996613531762, 0.8500847299037497, 0.8505059252217483, 0.8983690450413298, 0.8358174081338308, 0.8583189881732405, 0.8271231574296964, 0.8226994438822769, 0.8457798315905312, 0.8496604271316122, 0.9082507487983706, 0.8115316215885712, 0.8551068127460646, 0.8908499716959168, 0.8760542355025209, 0.9069958490987114, 0.9029959740765238, 0.9116706745026655, 0.8339601979405856, 0.8721207007536029, 0.9015044793024738, 0.8455273195640737, 0.8319414148319265, 0.8669375452707886, 0.8901044699527567, 0.8820825914153307, 0.8700942597240148, 0.8711243519648882, 0.8464055885013124, 0.8171347223870283, 0.8764124344495062, 0.8803004109128454, 0.8468354870310223, 0.8448262716103659, 0.8693160400638399, 0.9156074363171243, 0.8938574645236451, 0.8248784397729962, 0.8991196120105367, 0.8648095444942225, 0.8824060036578713, 0.8586309724442324, 0.8717070018648274, 0.8584195760795984, 0.8404308249075153, 0.8992154267596988, 0.8705280665466003, 0.9143987593187575, 0.8656418411587166, 0.8863739893041345, 0.8871071050144228, 0.8478299923839631, 0.8689112708045049, 0.8403069151514868, 0.8808559930096854, 0.8492626985072319, 0.872803580542773, 0.8578442160250219, 0.8794156839854117, 0.8902097572011034, 0.9208824293933388, 0.9078438379206395, 0.8826106945573955, 0.8923909324266425, 0.8417421195605598, 0.8427400518809605, 0.8710715434176843, 0.904319424257618, 0.9042675239096056, 0.8424585390042006, 0.862939384608934, 0.9029682954668046, 0.8413894456171572, 0.8869642698366734, 0.8816542229501894, 0.9193169170390768, 0.8815513021642362, 0.8773236843095311, 0.8929163494028827, 0.8592002078316494, 0.8060337286700548, 0.8529738217771321, 0.8572880628321611, 0.906370728343036, 0.8772476199637715, 0.8345497317731476, 0.8705778567701673, 0.8454339576880323, 0.8684104077216754, 0.7994759168390647, 0.8582986824473748, 0.8825952276253836, 0.8678285798585217, 0.8559986080415444, 0.8365711851294724, 0.9015563847586104, 0.86908979686997, 0.8436947504907257, 0.8721940195237715, 0.8917789935413567, 0.8815773426615819, 0.9035806205075294, 0.9166905653017136, 0.7044552063876904, 0.8766371497800096, 0.8576371893214264, 0.8284133607546104, 0.8587356856820757, 0.8601805426670538, 0.8494215129648457, 0.8374648864562081, 0.8216247017238151, 0.8531271669388176, 0.8995701819906972, 0.8236806758845484, 0.9074723660304338, 0.8760822238508452, 0.8349442869450621, 0.8651430870265331, 0.8983114258960234, 0.8394285953056816, 0.8387072354517049, 0.8484459628489861, 0.8659688655945788, 0.8733542559491531, 0.9147251089869912, 0.8592769154599824, 0.8844704216861778, 0.8704583041887525, 0.84060526611194, 0.8293294618523902, 0.8277278045978996, 0.8224662221895718, 0.8811309729094573, 0.8673643783666439, 0.8204038276372136, 0.8467891718635212, 0.8674439559518623, 0.8867617025451048, 0.884613637114027, 0.9081551752554203, 0.8562353511255738, 0.8698001533476843, 0.9080887183938771, 0.8465224214823704, 0.8644596954962662, 0.8796646071421438, 0.8828413840091713, 0.865959414110046, 0.8212510530293445, 0.8781430072559783, 0.8468394858933052, 0.8946559976372249, 0.8313322772369683, 0.888838297682158, 0.8544237709305574, 0.8417508786937142, 0.833785057569336, 0.853918234268137, 0.8435482155912569, 0.8219862811833474, 0.8784070493748783, 0.8899519623158368, 0.8608367503427253, 0.8717457632886122, 0.890068671135242, 0.8367451026050995, 0.9011332927743239, 0.8964517944755761, 0.8775782712272719, 0.8887136796489254, 0.8977000850043121, 0.8864781083461815, 0.8201318934442859, 0.8455967770343151, 0.862738574020081, 0.8452657678243499, 0.8499403295046919, 0.9035364314917672, 0.9138577941862837, 0.858173364635953, 0.8362835153277774, 0.8805917687996639, 0.8813810919914017, 0.8572661090997241, 0.8694691789358472, 0.8520756535760446, 0.9083638385134052, 0.8568278015980639, 0.8662245225339611, 0.8587837154987626, 0.8428872683652212, 0.8973278062664799, 0.9047781325320647, 0.8817968205242671, 0.8410012772935863, 0.8894271512424274, 0.8481988887763231, 0.8501698429183189, 0.9087018689107719, 0.9104133906510338, 0.9157736606070326, 0.8750343514542492, 0.8670262982138945, 0.8640327803844877, 0.8640823110408885, 0.8924638112815693, 0.8796113962513219, 0.873515238670381, 0.8511964817647636]\n"
     ]
    }
   ],
   "source": [
    "compress_data = model_a_compression\n",
    "full_data = rnaseq_df\n",
    "\n",
    "reconstructed_data = pd.DataFrame(model_a.predict(compress_data))\n",
    "\n",
    "full_data_check = full_data\n",
    "\n",
    "r = [pearsonr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "\n",
    "s = [spearmanr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "print(r)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997658655046805\n",
      "0.9447158374543674\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(r))\n",
    "\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_keras_binary_cross_entropy(x, z, p, epsilon=1e-07):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x - Reconstructed input RNAseq data\n",
    "    z - Input RNAseq data\n",
    "    p - number of features\n",
    "    epsilon - the clipping value to stabilize results (same Keras default)\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays\n",
    "    x = np.array(x)\n",
    "    z = np.array(z)\n",
    "\n",
    "    # Add clip to value\n",
    "    x[x < epsilon] = epsilon\n",
    "    x[x > (1 - epsilon)] = (1 - epsilon)\n",
    "\n",
    "    # Perform logit\n",
    "    x = np.log(x / (1 - x))\n",
    "\n",
    "    # Return approximate binary cross entropy\n",
    "    return np.mean(p * np.mean(- x * z + np.log(1 + np.exp(x)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.34773301264385\n",
      "21.413660140934013\n"
     ]
    }
   ],
   "source": [
    "mse = np.sum((full_data_check - reconstructed_data) ** 2, axis=1).mean()\n",
    "bce = approx_keras_binary_cross_entropy(full_data_check, reconstructed_data, 100)\n",
    "\n",
    "print(mse)\n",
    "print(bce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-VS-ALL LR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLR(df2, test2):\n",
    "    time_laps = []\n",
    "    for i in range(4):\n",
    "        start_time = time.time()\n",
    "        clf = LogisticRegression(random_state=0).fit(df2.iloc[:,0:df2.shape[1]],df2[\"cancer_type\"])\n",
    "        pred = clf.predict(test2.iloc[:,0:test2.shape[1]])\n",
    "        accuracy = accuracy_score(test2.cancer_type,pred)\n",
    "        laps = time.time() - start_time\n",
    "        time_laps.append(laps)\n",
    "    avg_time_laps = np.mean(time_laps)\n",
    "    SVM_accuracy = accuracy\n",
    "    SVM_computation_time = avg_time_laps\n",
    "    return SVM_accuracy, SVM_computation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnDf2(c_type, df2):\n",
    "    fraction = collections.Counter(merge_train)[c_type]/len(merge_train)\n",
    "\n",
    "    df2_0 = df2[df2.cancer_type!=c_type]\n",
    "    df2_0.loc[:,\"cancer_type\"] = 0\n",
    "    df2_0 = df2_0.sample(frac = fraction)\n",
    "\n",
    "    df2_1 = df2[df2.cancer_type==c_type]\n",
    "    df2_1.loc[:,\"cancer_type\"] = 1\n",
    "    \n",
    "    #print(df2_0)\n",
    "    #print(df2_1)\n",
    "    \n",
    "    df2 = pd.concat([df2_0, df2_1])\n",
    "    df2[\"cancer_type\"] = df2[\"cancer_type\"].astype('int')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train_tcga_df_normalized['sample_id']\n",
    "test_id = test_tcga_df_normalized['sample_id']\n",
    "label_id = labels_tcga_df['sample_id']\n",
    "\n",
    "merge_train = []\n",
    "merge_test = []\n",
    "\n",
    "for i in train_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_train.append(str(val['cancer_type']).split()[1])\n",
    "    \n",
    "for i in test_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_test.append(str(val['cancer_type']).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.DataFrame(np.concatenate((merge_train, merge_test), axis=0), columns=['cancer_type'])\n",
    "reconstructed_data_label = pd.concat([reconstructed_data, all_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_data = pd.DataFrame(np.array(compress_data))\n",
    "compressed_data_label = pd.concat([compress_data, all_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame(np.array(full_data))\n",
    "\n",
    "full_data_label = pd.concat([full_data, all_labels], axis=1)#.drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, test_full = train_test_split(full_data_label, test_size=0.1)\n",
    "train_compress, test_compress = train_test_split(compressed_data_label, test_size=0.1)\n",
    "train_reconstructed, test_reconstructed = train_test_split(reconstructed_data_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "c_type_list = collections.Counter(merge_train)\n",
    "#c_type_list = ['LUAD', 'LGG', 'PRAD', 'STAD']\n",
    "#c_type_list = ['DLBC']\n",
    "\n",
    "cols = ['cancer_type', 'Full-data acc.', 'Full-data comp. time','compress acc.','compress comp. time', 'VAE-reconst. acc.', 'VAE-reconst. time.']\n",
    "results_df = pd.DataFrame(columns = cols)\n",
    "i = 0\n",
    "for c_type in c_type_list:\n",
    "    train_full_ova = returnDf2(c_type, train_full)\n",
    "    test_full_ova = returnDf2(c_type, test_full)\n",
    "    train_compress_ova = returnDf2(c_type, train_compress)\n",
    "    test_compress_ova = returnDf2(c_type, test_compress)\n",
    "    train_reconstructed_ova = returnDf2(c_type, train_reconstructed)\n",
    "    test_reconstructed_ova = returnDf2(c_type, test_reconstructed)\n",
    "    full_acc, full_time = runLR(train_full_ova, test_full_ova)\n",
    "    compress_acc, compress_time = runLR(train_compress_ova, test_compress_ova)\n",
    "    full_reconstructed_acc, full_reconstructed_time = runLR(train_reconstructed_ova, test_reconstructed_ova)\n",
    "    results_df.loc[i] = [c_type, full_acc,full_time,compress_acc,compress_time, full_reconstructed_acc,full_reconstructed_time]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>Full-data accuracy</th>\n",
       "      <th>Full-data computation time(sec)</th>\n",
       "      <th>VAE accuracy</th>\n",
       "      <th>VAE computation time(sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.995392</td>\n",
       "      <td>4.200271</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.072058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>2.186904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DLBC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCEC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.339745</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKCM</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>1.823625</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.065575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRAD</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.687988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.954026</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.047374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KIRP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.573793</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.044630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CESC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.539634</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.045379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THCA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.620418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancer_type  Full-data accuracy  Full-data computation time(sec)  \\\n",
       "0        BRCA            0.995392                         4.200271   \n",
       "1        LUAD            0.990909                         2.186904   \n",
       "2        DLBC            1.000000                         0.481713   \n",
       "3        UCEC            1.000000                         2.339745   \n",
       "4        SKCM            0.977528                         1.823625   \n",
       "5        PRAD            1.000000                         1.687988   \n",
       "6        HNSC            1.000000                         1.954026   \n",
       "7        KIRP            1.000000                         1.573793   \n",
       "8        CESC            1.000000                         1.539634   \n",
       "9        THCA            1.000000                         1.620418   \n",
       "\n",
       "   VAE accuracy  VAE computation time(sec)  \n",
       "0      0.986957                   0.072058  \n",
       "1      1.000000                   0.048122  \n",
       "2      1.000000                   0.019697  \n",
       "3      0.982609                   0.046875  \n",
       "4      0.989583                   0.065575  \n",
       "5      1.000000                   0.037151  \n",
       "6      0.981982                   0.047374  \n",
       "7      0.954545                   0.044630  \n",
       "8      0.983871                   0.045379  \n",
       "9      1.000000                   0.035904  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_res = results_df.copy()\n",
    "my_res = my_res.drop(['VAE-reconst. acc.', 'VAE-reconst. time.'], axis=1)\n",
    "my_res.columns = ['cancer_type', 'Full-data accuracy', 'Full-data computation time(sec)', 'VAE accuracy', 'VAE computation time(sec)']\n",
    "my_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEARSON, SPEARMAN, MSE AND BCE OVER K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_7\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_7\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 21s - loss: 7029.8871 - val_loss: 6676.9750\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 28s - loss: 4021.4348 - val_loss: 5659.1588\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: 3753.8380 - val_loss: 5356.8611\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3652.2201 - val_loss: 5354.6729\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3601.2556 - val_loss: 5302.1283\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3573.7334 - val_loss: 5293.4227\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3558.9386 - val_loss: 5292.3840\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3550.8204 - val_loss: 5290.2942\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3545.3195 - val_loss: 5290.5623\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3541.0174 - val_loss: 5288.1673\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3537.0420 - val_loss: 5287.3948\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3534.1224 - val_loss: 5288.7306\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3530.2684 - val_loss: 5282.4891\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3527.7959 - val_loss: 5274.1585\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3525.7824 - val_loss: 5273.8768\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: 3524.3822 - val_loss: 5264.5720\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3523.0811 - val_loss: 5264.9961\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3521.5864 - val_loss: 5262.1462\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3520.2845 - val_loss: 5261.9113\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: 3519.8842 - val_loss: 5258.2342\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3518.8095 - val_loss: 5262.2200\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3518.1403 - val_loss: 5260.7884\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 17s - loss: 3517.1679 - val_loss: 5258.2522\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 17s - loss: 3516.3463 - val_loss: 5253.0281\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: 3515.2652 - val_loss: 5252.5185\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: 3514.4947 - val_loss: 5248.5928\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: 3513.5320 - val_loss: 5252.8056\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: 3513.0061 - val_loss: 5251.4385\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: 3512.1300 - val_loss: 5255.3853\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 17s - loss: 3511.5773 - val_loss: 5255.2046\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 17s - loss: 3510.6837 - val_loss: 5246.3468\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 17s - loss: 3509.6138 - val_loss: 5252.6429\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 17s - loss: 3509.0206 - val_loss: 5246.2533\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 17s - loss: 3507.7665 - val_loss: 5253.9224\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 17s - loss: 3507.0818 - val_loss: 5236.0269\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 17s - loss: 3505.7692 - val_loss: 5240.8414\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 17s - loss: 3504.6428 - val_loss: 5243.6649\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 17s - loss: 3503.8235 - val_loss: 5235.8480\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 17s - loss: 3502.4643 - val_loss: 5239.4466\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 17s - loss: 3501.4783 - val_loss: 5236.6089\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 17s - loss: 3500.3175 - val_loss: 5239.4413\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: 3499.0101 - val_loss: 5239.7369\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: 3498.0476 - val_loss: 5219.3788\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: 3496.7244 - val_loss: 5227.0989\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 17s - loss: 3496.0682 - val_loss: 5223.6228\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 17s - loss: 3494.9074 - val_loss: 5218.5519\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 17s - loss: 3493.9099 - val_loss: 5232.3251\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 17s - loss: 3493.2284 - val_loss: 5214.7518\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 17s - loss: 3492.1652 - val_loss: 5218.8410\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 17s - loss: 3491.0332 - val_loss: 5234.8379\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 17s - loss: 3490.9845 - val_loss: 5216.2761\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 17s - loss: 3489.5489 - val_loss: 5203.2720\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 17s - loss: 3488.9481 - val_loss: 5218.2209\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 17s - loss: 3488.0672 - val_loss: 5207.9689\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 17s - loss: 3487.0486 - val_loss: 5212.5933\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 17s - loss: 3486.4385 - val_loss: 5215.1959\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 17s - loss: 3485.9436 - val_loss: 5220.0010\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 17s - loss: 3484.7940 - val_loss: 5207.2409\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 17s - loss: 3484.4150 - val_loss: 5199.2136\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 17s - loss: 3483.7051 - val_loss: 5216.4399\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 17s - loss: 3483.3516 - val_loss: 5200.1459\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 17s - loss: 3482.6870 - val_loss: 5194.6128\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 17s - loss: 3481.3674 - val_loss: 5198.6762\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 17s - loss: 3480.6957 - val_loss: 5201.8456\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 17s - loss: 3480.4941 - val_loss: 5221.9313\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 17s - loss: 3479.6204 - val_loss: 5193.9568\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 17s - loss: 3478.5369 - val_loss: 5197.3447\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 17s - loss: 3477.6608 - val_loss: 5208.7175\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 17s - loss: 3476.8445 - val_loss: 5191.9022\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 17s - loss: 3476.4701 - val_loss: 5200.2137\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 17s - loss: 3475.7428 - val_loss: 5183.0047\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 17s - loss: 3475.2283 - val_loss: 5187.0807\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 17s - loss: 3474.8914 - val_loss: 5190.6353\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 17s - loss: 3473.9906 - val_loss: 5203.2562\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 17s - loss: 3473.1942 - val_loss: 5196.5256\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 17s - loss: 3472.3046 - val_loss: 5191.8940\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 17s - loss: 3472.1325 - val_loss: 5164.9922\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 17s - loss: 3471.0548 - val_loss: 5174.6832\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 17s - loss: 3470.9045 - val_loss: 5179.0452\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 17s - loss: 3470.0452 - val_loss: 5183.2914\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 17s - loss: 3469.5026 - val_loss: 5174.4715\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 17s - loss: 3469.0586 - val_loss: 5183.6753\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 17s - loss: 3468.2791 - val_loss: 5183.5058\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 17s - loss: 3467.6219 - val_loss: 5169.0759\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 17s - loss: 3467.7151 - val_loss: 5219.7258\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 17s - loss: 3466.8596 - val_loss: 5191.5981\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 17s - loss: 3466.2008 - val_loss: 5174.9072\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: 3465.9815 - val_loss: 5178.0169\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 17s - loss: 3465.8487 - val_loss: 5174.7058\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 17s - loss: 3465.0306 - val_loss: 5169.0970\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 17s - loss: 3464.5417 - val_loss: 5180.6044\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: 3464.3310 - val_loss: 5164.7561\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: 3463.4221 - val_loss: 5175.5851\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: 3463.3393 - val_loss: 5151.0545\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: 3462.3773 - val_loss: 5189.7312\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: 3462.1306 - val_loss: 5152.9341\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: 3462.3148 - val_loss: 5167.9527\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3461.2172 - val_loss: 5158.7385\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: 3461.1946 - val_loss: 5168.5240\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3460.5457 - val_loss: 5163.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_8\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_8\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 6141.2653 - val_loss: 6265.3848\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3813.1930 - val_loss: 5527.4706\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3697.0500 - val_loss: 5363.4504\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3660.9209 - val_loss: 5386.8974\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3635.1032 - val_loss: 5313.4074\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3614.2244 - val_loss: 5269.3583\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3591.9934 - val_loss: 5243.8845\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3577.4831 - val_loss: 5234.7575\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3559.6283 - val_loss: 5225.9264\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3543.4043 - val_loss: 5214.9307\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3531.3341 - val_loss: 5208.4488\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3520.3789 - val_loss: 5214.2846\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3512.6267 - val_loss: 5210.4632\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3506.2047 - val_loss: 5216.6969\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3501.8873 - val_loss: 5213.7752\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: 3497.2957 - val_loss: 5211.4946\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3493.9127 - val_loss: 5209.7200\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3490.0368 - val_loss: 5204.4027\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3486.7833 - val_loss: 5203.2119\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 16s - loss: 3484.3066 - val_loss: 5195.2327\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3481.7608 - val_loss: 5193.8921\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3478.5571 - val_loss: 5187.3286\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 17s - loss: 3476.4114 - val_loss: 5190.2939\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 17s - loss: 3473.9655 - val_loss: 5174.5347\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: 3471.7259 - val_loss: 5175.1163\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: 3469.7813 - val_loss: 5174.7278\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: 3467.4021 - val_loss: 5173.2370\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: 3465.0248 - val_loss: 5166.7541\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: 3462.9079 - val_loss: 5162.2550\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 17s - loss: 3460.7180 - val_loss: 5167.6500\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 17s - loss: 3458.6656 - val_loss: 5161.6636\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 17s - loss: 3456.8197 - val_loss: 5145.4238\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 17s - loss: 3454.9293 - val_loss: 5154.6459\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 17s - loss: 3452.8528 - val_loss: 5149.5080\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 17s - loss: 3451.2988 - val_loss: 5138.8651\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 17s - loss: 3449.8150 - val_loss: 5127.6121\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 17s - loss: 3447.5616 - val_loss: 5145.7359\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 17s - loss: 3446.2462 - val_loss: 5135.7428\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 17s - loss: 3444.7094 - val_loss: 5129.6748\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 17s - loss: 3442.7745 - val_loss: 5134.6375\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 17s - loss: 3441.4633 - val_loss: 5122.0595\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: 3439.6153 - val_loss: 5119.1980\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: 3438.5566 - val_loss: 5127.0774\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: 3436.7749 - val_loss: 5128.7205\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 17s - loss: 3436.1407 - val_loss: 5124.5733\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 17s - loss: 3433.9763 - val_loss: 5110.1638\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 17s - loss: 3433.0187 - val_loss: 5096.5248\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 17s - loss: 3432.2229 - val_loss: 5117.9609\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 17s - loss: 3430.5799 - val_loss: 5100.2041\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3429.3192 - val_loss: 5113.9444\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: 3428.3792 - val_loss: 5099.6837\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: 3427.0027 - val_loss: 5104.0392\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3426.2687 - val_loss: 5087.8008\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3425.1073 - val_loss: 5096.1203\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3423.8096 - val_loss: 5110.4508423.\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3422.5716 - val_loss: 5098.3210\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3421.5165 - val_loss: 5090.8380\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3420.5418 - val_loss: 5098.4802\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3420.8405 - val_loss: 5081.8058\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3419.2193 - val_loss: 5091.6564\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: 3418.1140 - val_loss: 5071.1430\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3417.7307 - val_loss: 5085.9458\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: 3416.1229 - val_loss: 5103.4217\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3415.0595 - val_loss: 5069.9187\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3414.8668 - val_loss: 5076.5504\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3413.9096 - val_loss: 5082.7725\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: 3413.2166 - val_loss: 5072.2917\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3412.2335 - val_loss: 5065.0377\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3411.1443 - val_loss: 5062.8419411.\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3410.4425 - val_loss: 5053.9385\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: 3409.7757 - val_loss: 5059.2852\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3408.4802 - val_loss: 5074.9052\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3408.0701 - val_loss: 5063.5009\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3407.0588 - val_loss: 5061.7273\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3406.8072 - val_loss: 5059.3074\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3405.5902 - val_loss: 5078.0816\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3405.3029 - val_loss: 5083.0763 - loss: 3405.\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3404.6808 - val_loss: 5055.6091\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3403.9894 - val_loss: 5062.7653\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 19s - loss: 3403.1592 - val_loss: 5075.8706\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: 3402.7540 - val_loss: 5051.2077\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: 3402.2754 - val_loss: 5074.1098\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: 3401.8750 - val_loss: 5048.1368\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: 3400.6452 - val_loss: 5061.4624\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: 3400.4171 - val_loss: 5051.3337\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: 3400.4890 - val_loss: 5076.4324\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: 3399.7912 - val_loss: 5069.8016\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: 3399.3416 - val_loss: 5068.4978\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: 3398.8858 - val_loss: 5051.7598\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3398.0972 - val_loss: 5063.0685\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: 3398.1012 - val_loss: 5063.4163\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: 3397.5286 - val_loss: 5064.2721\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: 3397.6110 - val_loss: 5046.3210\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: 3396.4581 - val_loss: 5065.9479\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: 3396.5923 - val_loss: 5038.6772 -\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: 3396.3061 - val_loss: 5069.8429 ETA: 3s - - ETA\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: 3395.4132 - val_loss: 5055.1664\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: 3395.5800 - val_loss: 5054.9846\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: 3394.8360 - val_loss: 5059.7130\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: 3393.8398 - val_loss: 5041.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_9\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_9\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 5568.1648 - val_loss: 5654.4008\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3716.9419 - val_loss: 5328.9367\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3637.9564 - val_loss: 5260.4279\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3604.4531 - val_loss: 5264.8811\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3583.3067 - val_loss: 5238.4118\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3567.6668 - val_loss: 5230.4049\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3554.8030 - val_loss: 5218.8891\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3541.8481 - val_loss: 5195.6260\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3533.6338 - val_loss: 5183.0145\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3524.0200 - val_loss: 5155.7578\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3516.8982 - val_loss: 5159.0532\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3506.7327 - val_loss: 5141.1127\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3501.0532 - val_loss: 5128.8368\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3492.6609 - val_loss: 5134.7783\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3484.4799 - val_loss: 5119.0526\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: 3478.8505 - val_loss: 5112.7533\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3472.6292 - val_loss: 5116.2368\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3466.3244 - val_loss: 5107.7683\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3460.8461 - val_loss: 5102.4961\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: 3455.4383 - val_loss: 5100.4456\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3450.1156 - val_loss: 5114.5891\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3446.1096 - val_loss: 5113.2802\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 17s - loss: 3442.1857 - val_loss: 5101.8104\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 17s - loss: 3438.6117 - val_loss: 5111.0247\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: 3435.2705 - val_loss: 5104.3295\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: 3432.5404 - val_loss: 5112.2437\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: 3429.9296 - val_loss: 5101.9847\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: 3427.5346 - val_loss: 5086.904442\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: 3425.2965 - val_loss: 5101.5528\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 17s - loss: 3423.2197 - val_loss: 5094.2581\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 17s - loss: 3420.7444 - val_loss: 5094.1064\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 17s - loss: 3418.6207 - val_loss: 5091.7525\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 17s - loss: 3416.7949 - val_loss: 5078.7443\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 17s - loss: 3414.8493 - val_loss: 5067.6357\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 17s - loss: 3412.5651 - val_loss: 5072.5087\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 17s - loss: 3410.6271 - val_loss: 5063.0798\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 17s - loss: 3409.7113 - val_loss: 5058.8466\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 17s - loss: 3407.9275 - val_loss: 5061.4797\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 17s - loss: 3406.2799 - val_loss: 5061.7540\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 17s - loss: 3404.7236 - val_loss: 5062.2210\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 17s - loss: 3403.2487 - val_loss: 5047.0430\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: 3401.6680 - val_loss: 5063.961940 - E -\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: 3399.9977 - val_loss: 5037.1278\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: 3399.1787 - val_loss: 5044.7606\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: 3397.5504 - val_loss: 5034.8169\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: 3396.2332 - val_loss: 5040.7909\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: 3394.8125 - val_loss: 5026.4691\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: 3393.2992 - val_loss: 5040.5570393. - ETA: 1s - l\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: 3392.6190 - val_loss: 5027.3718\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3391.7948 - val_loss: 5021.0157\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: 3390.5920 - val_loss: 5037.8940 339\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: 3389.6061 - val_loss: 5019.6766\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3388.1728 - val_loss: 5026.2037\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3387.6231 - val_loss: 5003.8256\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3386.8906 - val_loss: 5009.9231\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3385.7290 - val_loss: 5005.1937\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3384.8654 - val_loss: 5001.7309\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3384.1943 - val_loss: 5004.9962384.20\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3383.5541 - val_loss: 5011.2322\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3382.2201 - val_loss: 4998.3018\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: 3381.6809 - val_loss: 5009.6061\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3381.3842 - val_loss: 5002.2953\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: 3380.0072 - val_loss: 5010.1302\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3380.3124 - val_loss: 4993.2482\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3379.1812 - val_loss: 4994.7146\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3377.9889 - val_loss: 4999.8007\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: 3377.8236 - val_loss: 4999.4042\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3377.2985 - val_loss: 5023.9613\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3376.9043 - val_loss: 5011.7596\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3376.4611 - val_loss: 4989.3741\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: 3375.8922 - val_loss: 5003.9240375.77\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3374.7686 - val_loss: 5000.1531\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3374.7096 - val_loss: 5012.9938\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3374.2134 - val_loss: 4997.503937\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.7185 - val_loss: 4990.4553\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.3694 - val_loss: 4988.7968\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3372.5261 - val_loss: 4998.9437\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3372.2566 - val_loss: 4999.6121\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3372.2129 - val_loss: 5010.7589\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: 3371.3904 - val_loss: 4985.6055\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: 3371.0060 - val_loss: 4993.3594\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.5348 - val_loss: 4991.4835\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.2577 - val_loss: 4988.7008\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.1346 - val_loss: 4995.1825\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: 3369.4699 - val_loss: 4980.2080\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: 3369.4397 - val_loss: 4974.7099\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: 3369.2348 - val_loss: 4991.5891\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: 3368.3522 - val_loss: 5000.2165\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: 3368.3025 - val_loss: 5005.2439\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3367.8967 - val_loss: 5023.6153\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: 3367.3240 - val_loss: 4993.3435\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: 3367.3879 - val_loss: 4992.4043\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.9351 - val_loss: 4987.3035\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.5043 - val_loss: 4979.7755\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.2369 - val_loss: 4977.8650\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.2627 - val_loss: 4981.2580\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: 3365.9085 - val_loss: 4989.6721\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3365.4106 - val_loss: 4992.6993\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: 3365.2597 - val_loss: 4983.9690\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3364.9887 - val_loss: 5013.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_10\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_10\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 5172.5641 - val_loss: 6089.9974\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3643.6132 - val_loss: 5334.7951\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3582.1544 - val_loss: 5234.2009\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3553.3504 - val_loss: 5167.5117\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3534.7666 - val_loss: 5167.5987\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3520.5784 - val_loss: 5129.0101\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3508.3573 - val_loss: 5119.9229\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3497.1738 - val_loss: 5103.9687\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3488.7389 - val_loss: 5099.3502\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3480.0558 - val_loss: 5092.8812\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3473.2506 - val_loss: 5076.9229\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3467.6995 - val_loss: 5095.7485\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3461.3805 - val_loss: 5075.4555\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3454.4636 - val_loss: 5089.9132\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3450.5386 - val_loss: 5080.8297\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: 3446.2708 - val_loss: 5038.2975\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3441.8646 - val_loss: 5050.6233\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3436.1163 - val_loss: 5047.7572\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3433.1915 - val_loss: 5028.0826\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: 3429.0291 - val_loss: 5031.4045\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3425.7902 - val_loss: 5029.4261\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3421.8856 - val_loss: 5024.4424\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 17s - loss: 3419.0411 - val_loss: 5025.4153\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 17s - loss: 3415.2711 - val_loss: 5011.1716\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: 3413.1647 - val_loss: 5012.0661\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: 3409.0869 - val_loss: 5019.4668\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: 3406.5377 - val_loss: 5003.9762\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: 3404.2424 - val_loss: 5007.2470\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: 3401.3261 - val_loss: 4999.5810\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 17s - loss: 3399.1819 - val_loss: 4989.1860\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 17s - loss: 3396.6659 - val_loss: 4997.2220\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 17s - loss: 3394.5883 - val_loss: 4987.8463\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: 3391.9095 - val_loss: 4992.0437\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: 3390.3254 - val_loss: 5016.0583\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: 3388.7899 - val_loss: 5002.7792\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: 3386.2884 - val_loss: 4997.5980\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: 3385.0048 - val_loss: 5001.0355\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: 3383.3152 - val_loss: 4999.6108\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: 3381.3302 - val_loss: 5006.7626\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: 3380.0467 - val_loss: 4997.9256\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: 3378.5251 - val_loss: 5006.3265\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: 3377.3260 - val_loss: 5018.5296\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: 3376.1282 - val_loss: 5004.4385\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: 3374.9211 - val_loss: 5001.6532374.90\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.9662 - val_loss: 5002.2675\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.0713 - val_loss: 4988.9577\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: 3372.1704 - val_loss: 5002.4209\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: 3371.0304 - val_loss: 4996.9141\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.0938 - val_loss: 4983.3970\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3369.5842 - val_loss: 5013.2578\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: 3368.3139 - val_loss: 4993.2521\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: 3367.7083 - val_loss: 4992.0351\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.3918 - val_loss: 4990.5157\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.0027 - val_loss: 4988.6059\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3365.1399 - val_loss: 4984.1598\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3364.9427 - val_loss: 4974.0076\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3363.9025 - val_loss: 4982.0331\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3363.1923 - val_loss: 4975.5519\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3362.4517 - val_loss: 4978.6518\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3362.0384 - val_loss: 4969.5896\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: 3361.8070 - val_loss: 4969.0264\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3360.8500 - val_loss: 4972.5801\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: 3360.5842 - val_loss: 4987.9857\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3359.9541 - val_loss: 4983.6411\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3359.1874 - val_loss: 4992.1147\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3358.7099 - val_loss: 4979.4817\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: 3358.1718 - val_loss: 4977.7509\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3357.6062 - val_loss: 4978.0029\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3357.1794 - val_loss: 4975.5386\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3356.7224 - val_loss: 4977.8197\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: 3356.5437 - val_loss: 4983.049235\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3356.0264 - val_loss: 4958.5324\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3355.4497 - val_loss: 4976.5878\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3355.0496 - val_loss: 4951.6067\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3354.8297 - val_loss: 4977.3545\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3354.2534 - val_loss: 4969.0761\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.8012 - val_loss: 4971.2132\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.5289 - val_loss: 4950.8785\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3352.9499 - val_loss: 4955.4140\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: 3352.8785 - val_loss: 4947.2781\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: 3352.1696 - val_loss: 4961.0017\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.9324 - val_loss: 4959.9701\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.7305 - val_loss: 4948.0993\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.4200 - val_loss: 4967.3799\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.4703 - val_loss: 4964.7644\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.0185 - val_loss: 4948.6726\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: 3350.5691 - val_loss: 4964.2213\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: 3350.1673 - val_loss: 4964.0156\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.9406 - val_loss: 4947.3857\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.4372 - val_loss: 4969.5890\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.6759 - val_loss: 4966.970034\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.2967 - val_loss: 4976.7649\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: 3349.0112 - val_loss: 4953.8384\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: 3348.5275 - val_loss: 4945.3322\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: 3348.4916 - val_loss: 4971.2722\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.8543 - val_loss: 4957.7757\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.9307 - val_loss: 4968.9417\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.6833 - val_loss: 4960.0998\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.2288 - val_loss: 4962.0875\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3347.1803 - val_loss: 4961.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_11\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_11\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 4729.9600 - val_loss: 5385.4071\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3590.2958 - val_loss: 5259.8097\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3535.1239 - val_loss: 5218.6290\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3508.9237 - val_loss: 5168.7014\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3490.2557 - val_loss: 5153.0752\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3475.9136 - val_loss: 5114.0490\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3466.2898 - val_loss: 5118.7430\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3457.2543 - val_loss: 5107.1438\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3448.5648 - val_loss: 5095.9574\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3442.3266 - val_loss: 5086.4422\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: 3436.7569 - val_loss: 5100.3681\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3431.5475 - val_loss: 5055.8622\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: 3426.1747 - val_loss: 5049.6285\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: 3421.2981 - val_loss: 5062.2425\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: 3417.0917 - val_loss: 5043.1898\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: 3413.6104 - val_loss: 5034.4155\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: 3408.9601 - val_loss: 5047.4657\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: 3405.5222 - val_loss: 5017.3555\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: 3402.0526 - val_loss: 5015.1200\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: 3399.1636 - val_loss: 4994.9055\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: 3396.3967 - val_loss: 4979.8407\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: 3394.0087 - val_loss: 4979.2631\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: 3391.6461 - val_loss: 4989.4040\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: 3388.9111 - val_loss: 4984.0420\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: 3386.2749 - val_loss: 4972.4816\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: 3383.9375 - val_loss: 4951.3791\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: 3381.8394 - val_loss: 4950.0191\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: 3380.0854 - val_loss: 4965.4811\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: 3378.1752 - val_loss: 4949.2748\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: 3376.4980 - val_loss: 4947.6529\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: 3375.0511 - val_loss: 4950.9891\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.2863 - val_loss: 4929.9813\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: 3371.6919 - val_loss: 4953.9288\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.3062 - val_loss: 4949.2934\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: 3368.6701 - val_loss: 4949.5361\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: 3367.6211 - val_loss: 4945.5204\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.1190 - val_loss: 4949.3713\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: 3365.2523 - val_loss: 4949.4064\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: 3363.7793 - val_loss: 4929.2985\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: 3362.3318 - val_loss: 4944.5878\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: 3361.4558 - val_loss: 4945.3086\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: 3360.2034 - val_loss: 4957.9391\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: 3359.1563 - val_loss: 4950.4824\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: 3358.3035 - val_loss: 4957.1603\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: 3357.0989 - val_loss: 4949.9631\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: 3356.2944 - val_loss: 4936.3803\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: 3355.3454 - val_loss: 4937.5826\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: 3354.5349 - val_loss: 4940.6160\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.6501 - val_loss: 4933.4896\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.0988 - val_loss: 4934.5419\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: 3352.2061 - val_loss: 4946.4927\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: 3351.3112 - val_loss: 4954.4313351.\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3350.5276 - val_loss: 4939.2320\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.9175 - val_loss: 4937.1548\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.2935 - val_loss: 4940.0872\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3348.6495 - val_loss: 4940.4703\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3348.1968 - val_loss: 4937.2019\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3347.2599 - val_loss: 4942.1048\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3347.0138 - val_loss: 4947.5879\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3346.0299 - val_loss: 4931.9119\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: 3345.3367 - val_loss: 4927.2745\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3344.7039 - val_loss: 4937.3528\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 19s - loss: 3344.0979 - val_loss: 4945.8962\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.8080 - val_loss: 4944.6779\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.2127 - val_loss: 4958.3253\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3342.7633 - val_loss: 4943.8314\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 19s - loss: 3342.0899 - val_loss: 4953.9897\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3341.5289 - val_loss: 4935.7228\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3341.4100 - val_loss: 4953.0011\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3340.7721 - val_loss: 4955.5796\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 19s - loss: 3340.1603 - val_loss: 4938.6167\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3339.5974 - val_loss: 4932.9599\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 19s - loss: 3339.8087 - val_loss: 4958.8530\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 19s - loss: 3339.0968 - val_loss: 4935.8103oss: 333 - ETA:  - ETA: 0s - loss: 3339.\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.9650 - val_loss: 4946.0418\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 19s - loss: 3338.3487 - val_loss: 4945.8634\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.0318 - val_loss: 4947.0873: 0s - loss:\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3337.6396 - val_loss: 4942.4615\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 17s - loss: 3337.2399 - val_loss: 4953.2559\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 17s - loss: 3336.7713 - val_loss: 4941.0599\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 17s - loss: 3336.4667 - val_loss: 4939.8927\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 17s - loss: 3336.3072 - val_loss: 4952.3681\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 17s - loss: 3335.9979 - val_loss: 4947.0706\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 17s - loss: 3335.2995 - val_loss: 4929.9708\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 17s - loss: 3335.4044 - val_loss: 4942.8550\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 17s - loss: 3334.8586 - val_loss: 4959.3654\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 17s - loss: 3334.7342 - val_loss: 4952.1825\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: 3334.3037 - val_loss: 4941.9633\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 17s - loss: 3334.1165 - val_loss: 4940.0554\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 17s - loss: 3333.9628 - val_loss: 4936.6264\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 17s - loss: 3333.4946 - val_loss: 4951.7538\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: 3333.0578 - val_loss: 4957.1016\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: 3332.8878 - val_loss: 4982.7766\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: 3332.6605 - val_loss: 4936.4680\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: 3332.7283 - val_loss: 4947.5224\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: 3332.2878 - val_loss: 4950.5550\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: 3332.1541 - val_loss: 4935.8636\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3331.4873 - val_loss: 4949.0168\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: 3331.3954 - val_loss: 4952.0170\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3331.2793 - val_loss: 4951.6016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_12\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_12\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 19s - loss: 4469.8346 - val_loss: 5350.4455\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: 3561.3782 - val_loss: 5284.8668\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: 3510.0591 - val_loss: 5210.2987\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: 3481.7214 - val_loss: 5137.6197\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: 3464.7671 - val_loss: 5126.6243\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: 3452.5802 - val_loss: 5095.5878\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: 3441.4302 - val_loss: 5074.5825\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: 3433.5658 - val_loss: 5057.7509\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: 3426.9232 - val_loss: 5033.6219\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: 3419.9496 - val_loss: 5038.2093\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: 3414.7617 - val_loss: 5036.1697\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: 3409.2102 - val_loss: 5028.4095\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: 3404.8240 - val_loss: 5014.3461\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: 3401.6037 - val_loss: 4991.5936\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: 3397.4045 - val_loss: 4985.8719\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: 3394.1151 - val_loss: 5012.8154\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: 3390.7781 - val_loss: 4998.2631\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: 3388.4484 - val_loss: 4960.1789\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: 3385.8139 - val_loss: 4987.1692\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: 3383.4768 - val_loss: 4956.0293\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: 3380.7291 - val_loss: 4976.9720\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: 3378.6151 - val_loss: 4974.2530\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: 3376.2701 - val_loss: 4965.2983\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: 3374.6606 - val_loss: 4958.5175\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: 3373.0073 - val_loss: 4966.3192\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: 3370.9582 - val_loss: 4967.2341\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: 3369.2759 - val_loss: 4977.6740\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: 3368.1900 - val_loss: 4957.5170\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: 3366.5069 - val_loss: 4952.7363\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: 3365.2458 - val_loss: 4962.5602\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: 3363.5657 - val_loss: 4964.584036\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: 3362.5590 - val_loss: 4964.0144\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: 3361.2107 - val_loss: 4961.8441\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: 3360.2910 - val_loss: 4968.4927\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: 3358.7816 - val_loss: 4937.8332\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 19s - loss: 3358.2450 - val_loss: 4959.4050\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 19s - loss: 3356.6481 - val_loss: 4943.4020\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: 3355.6217 - val_loss: 4925.7833\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 19s - loss: 3355.5813 - val_loss: 4957.8081\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 19s - loss: 3353.9480 - val_loss: 4939.0448\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 19s - loss: 3352.9886 - val_loss: 4922.5544\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: 3352.3497 - val_loss: 4952.7045\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 19s - loss: 3351.7030 - val_loss: 4936.3935\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 19s - loss: 3351.0661 - val_loss: 4936.9731\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 19s - loss: 3349.8981 - val_loss: 4901.1537\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 19s - loss: 3349.2792 - val_loss: 4925.0530\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 19s - loss: 3348.8132 - val_loss: 4914.8008\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: 3347.5719 - val_loss: 4914.6030\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 19s - loss: 3346.8701 - val_loss: 4946.8982\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3346.0925 - val_loss: 4924.9723\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 19s - loss: 3345.5761 - val_loss: 4920.9552\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 19s - loss: 3344.9216 - val_loss: 4922.8104\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3344.3743 - val_loss: 4897.3569\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.4370 - val_loss: 4899.6553\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 19s - loss: 3343.0433 - val_loss: 4898.1299\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 19s - loss: 3342.5714 - val_loss: 4916.9454\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 19s - loss: 3342.1906 - val_loss: 4904.6254\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 19s - loss: 3341.2833 - val_loss: 4912.1989\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 19s - loss: 3340.5791 - val_loss: 4942.687034\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 19s - loss: 3340.1610 - val_loss: 4914.0567\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 19s - loss: 3339.6009 - val_loss: 4916.3288\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 19s - loss: 3339.2058 - val_loss: 4895.7450\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 19s - loss: 3338.9501 - val_loss: 4895.1632\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 19s - loss: 3338.1814 - val_loss: 4892.8402\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 19s - loss: 3337.8119 - val_loss: 4914.5022\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 19s - loss: 3337.1134 - val_loss: 4886.2445\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 19s - loss: 3336.7469 - val_loss: 4920.2455\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 19s - loss: 3336.2143 - val_loss: 4911.8452\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 19s - loss: 3336.0743 - val_loss: 4916.9092\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 19s - loss: 3335.4965 - val_loss: 4897.1731\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 19s - loss: 3334.8814 - val_loss: 4891.8329\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 19s - loss: 3334.6267 - val_loss: 4894.5421\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 19s - loss: 3334.0743 - val_loss: 4889.4932\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 19s - loss: 3333.6658 - val_loss: 4885.5516\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 19s - loss: 3333.1356 - val_loss: 4917.1283\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 19s - loss: 3332.9562 - val_loss: 4895.3855\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 19s - loss: 3332.3886 - val_loss: 4900.5786\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 19s - loss: 3332.3645 - val_loss: 4888.2090\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 19s - loss: 3331.7437 - val_loss: 4912.9020\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 19s - loss: 3331.5737 - val_loss: 4886.0187\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 19s - loss: 3331.3033 - val_loss: 4911.7096\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 19s - loss: 3330.7880 - val_loss: 4873.0213\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 19s - loss: 3330.5653 - val_loss: 4869.2993\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 19s - loss: 3330.3178 - val_loss: 4891.6754\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 20s - loss: 3329.8091 - val_loss: 4891.0483\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 19s - loss: 3329.5508 - val_loss: 4870.4622\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 19s - loss: 3329.4415 - val_loss: 4890.0806\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.2433 - val_loss: 4875.9901\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.6857 - val_loss: 4898.4107\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.3713 - val_loss: 4895.5786\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.0877 - val_loss: 4897.1526\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: 3327.8217 - val_loss: 4868.2553\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.5986 - val_loss: 4870.5157\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: 3327.2642 - val_loss: 4888.2231\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.3218 - val_loss: 4887.6988\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: 3327.0483 - val_loss: 4878.0423\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.7307 - val_loss: 4878.1594\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: 3326.4435 - val_loss: 4885.4630\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: 3326.4691 - val_loss: 4888.1854\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: 3326.0392 - val_loss: 4879.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_13\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_13\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 18s - loss: 4360.8259 - val_loss: 5296.4629\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: 3544.8106 - val_loss: 5245.4031\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: 3495.7199 - val_loss: 5169.9083\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: 3469.4103 - val_loss: 5113.9829\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: 3452.2058 - val_loss: 5112.3601\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: 3440.6989 - val_loss: 5065.0327\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: 3431.4245 - val_loss: 5094.0716\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: 3422.5702 - val_loss: 5049.5975\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: 3416.0906 - val_loss: 5012.6780\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: 3410.4682 - val_loss: 5007.2424\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: 3405.2176 - val_loss: 5001.5135\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: 3400.9343 - val_loss: 5022.1047\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: 3396.9932 - val_loss: 4973.4945\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: 3393.3025 - val_loss: 4983.9564\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: 3389.8163 - val_loss: 5010.8641\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: 3386.4071 - val_loss: 5011.5047\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: 3383.8030 - val_loss: 4980.4741 ETA: 7s - ETA: 5s - - E - E\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 19s - loss: 3380.6440 - val_loss: 4979.9953\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 19s - loss: 3378.5824 - val_loss: 4964.0355\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 19s - loss: 3375.9751 - val_loss: 4985.9065\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 19s - loss: 3374.2019 - val_loss: 4974.1045\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 19s - loss: 3372.3228 - val_loss: 4984.1226\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 19s - loss: 3370.7148 - val_loss: 4960.4755\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 19s - loss: 3368.7496 - val_loss: 4992.1536\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 19s - loss: 3367.2494 - val_loss: 4962.2904\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 19s - loss: 3365.9890 - val_loss: 4931.9874\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 19s - loss: 3364.5229 - val_loss: 4946.9263\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 19s - loss: 3362.6060 - val_loss: 4949.3130\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 19s - loss: 3361.1257 - val_loss: 4933.9819\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 19s - loss: 3360.3761 - val_loss: 4950.0013\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 19s - loss: 3358.8788 - val_loss: 4954.9899\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 19s - loss: 3357.6451 - val_loss: 4939.3953\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: 3357.1765 - val_loss: 4919.0198\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 19s - loss: 3355.7176 - val_loss: 4930.0862\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 19s - loss: 3354.6831 - val_loss: 4938.2509\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 19s - loss: 3353.7835 - val_loss: 4942.2304\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 19s - loss: 3352.6308 - val_loss: 4923.5360\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 19s - loss: 3351.5657 - val_loss: 4922.0485\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 19s - loss: 3350.6843 - val_loss: 4951.1351\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 19s - loss: 3349.9128 - val_loss: 4918.3890\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 19s - loss: 3348.9001 - val_loss: 4949.1470\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 19s - loss: 3348.1194 - val_loss: 4928.3153\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 19s - loss: 3347.5121 - val_loss: 4922.1926\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 19s - loss: 3346.4067 - val_loss: 4915.4541\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 19s - loss: 3346.0175 - val_loss: 4973.2207\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 19s - loss: 3345.2230 - val_loss: 4910.8694\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 19s - loss: 3344.0336 - val_loss: 4910.1940\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 19s - loss: 3343.8710 - val_loss: 4939.8258\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 19s - loss: 3343.1193 - val_loss: 4914.0326\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 19s - loss: 3342.5483 - val_loss: 4928.4348\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 19s - loss: 3341.8749 - val_loss: 4912.5569\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 19s - loss: 3341.2019 - val_loss: 4895.7794\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 19s - loss: 3340.3638 - val_loss: 4899.2776\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 19s - loss: 3339.7420 - val_loss: 4884.2638339. - ETA: 1s - los\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3339.2511 - val_loss: 4907.0722\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.7979 - val_loss: 4893.8029\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.2884 - val_loss: 4934.2092338.\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3337.9694 - val_loss: 4892.5338\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3336.9909 - val_loss: 4940.7419\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3336.3799 - val_loss: 4920.6772\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: 3336.0948 - val_loss: 4917.4713\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3335.6059 - val_loss: 4901.5301\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: 3335.1763 - val_loss: 4911.1965\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3334.7662 - val_loss: 4898.5317\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3334.2160 - val_loss: 4898.2524\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.8286 - val_loss: 4925.0258\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.6559 - val_loss: 4891.3664\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.0770 - val_loss: 4882.8369\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.3498 - val_loss: 4884.3835\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.0765 - val_loss: 4894.1164\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.9141 - val_loss: 4889.8462\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.4866 - val_loss: 4885.0960\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.7300 - val_loss: 4864.0023\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.9033 - val_loss: 4884.4154\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.3668 - val_loss: 4890.5551\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.1201 - val_loss: 4857.8284\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.7196 - val_loss: 4877.7553\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.1585 - val_loss: 4886.5374\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.8935 - val_loss: 4891.9314\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: 3328.9347 - val_loss: 4873.8337\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.2697 - val_loss: 4868.5846\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.1700 - val_loss: 4886.4256\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.7691 - val_loss: 4901.2821\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.3429 - val_loss: 4870.9706\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.3323 - val_loss: 4857.8620\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: 3327.1983 - val_loss: 4873.4368\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.8786 - val_loss: 4834.9355\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: 3326.4859 - val_loss: 4863.0031\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.1581 - val_loss: 4864.0620\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.0203 - val_loss: 4856.258832\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: 3326.1626 - val_loss: 4873.1360\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: 3325.5806 - val_loss: 4871.9036\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: 3325.5805 - val_loss: 4850.2489\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: 3324.9775 - val_loss: 4870.9841\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: 3324.7655 - val_loss: 4849.0070\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: 3324.5721 - val_loss: 4844.3739\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: 3324.8280 - val_loss: 4887.8714\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.1563 - val_loss: 4858.5615\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.0318 - val_loss: 4866.6962\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 19s - loss: 3323.9687 - val_loss: 4863.3066323. -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_14\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_14\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 20s - loss: 4307.3531 - val_loss: 5285.1205\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: 3531.9337 - val_loss: 5230.1505\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: 3482.9284 - val_loss: 5194.6327\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: 3457.8691 - val_loss: 5160.4914\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: 3442.1567 - val_loss: 5101.3404\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: 3430.3297 - val_loss: 5083.6306\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 19s - loss: 3420.1153 - val_loss: 5098.6224\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 19s - loss: 3412.6466 - val_loss: 5060.3022\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 19s - loss: 3406.7878 - val_loss: 5024.8909\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 19s - loss: 3401.0124 - val_loss: 5065.7218\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 19s - loss: 3396.6253 - val_loss: 4999.7195\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 19s - loss: 3392.9157 - val_loss: 5007.5394\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 19s - loss: 3389.4186 - val_loss: 5021.8221\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 19s - loss: 3386.1569 - val_loss: 5025.4221\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 19s - loss: 3382.6855 - val_loss: 4996.2574\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 19s - loss: 3379.8933 - val_loss: 4994.1309\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 19s - loss: 3377.4124 - val_loss: 4972.8899\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 19s - loss: 3374.7123 - val_loss: 4956.2224\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 19s - loss: 3373.1102 - val_loss: 4995.4077\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 19s - loss: 3371.3476 - val_loss: 5032.6361\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 19s - loss: 3369.8562 - val_loss: 4969.7908\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 19s - loss: 3367.5966 - val_loss: 4966.6978\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 19s - loss: 3365.7317 - val_loss: 5001.8732\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 19s - loss: 3364.5893 - val_loss: 4966.7278\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 19s - loss: 3362.9318 - val_loss: 5001.7877\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 19s - loss: 3361.5425 - val_loss: 4966.0613\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 19s - loss: 3360.6889 - val_loss: 4977.7422\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 19s - loss: 3359.2065 - val_loss: 4957.4757\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 19s - loss: 3358.3493 - val_loss: 4966.7802\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 19s - loss: 3357.4744 - val_loss: 4939.8761\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 19s - loss: 3355.8302 - val_loss: 4971.4844\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 19s - loss: 3354.8752 - val_loss: 4936.3249\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: 3353.9489 - val_loss: 4977.3348\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: 3353.0408 - val_loss: 4932.4625\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: 3352.0479 - val_loss: 4927.4845\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: 3350.9119 - val_loss: 4919.7467\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: 3350.3992 - val_loss: 4921.7278\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: 3349.8607 - val_loss: 4924.4118\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: 3348.3861 - val_loss: 4952.5913348.44\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: 3347.6544 - val_loss: 4948.1785\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: 3347.1838 - val_loss: 4927.5760\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: 3346.2395 - val_loss: 4936.3833\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: 3345.4517 - val_loss: 4907.4909\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: 3344.7085 - val_loss: 4914.8495\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: 3344.1567 - val_loss: 4927.7604\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.0249 - val_loss: 4924.3310\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: 3343.0031 - val_loss: 4931.4137\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: 3341.8812 - val_loss: 4901.2281\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: 3341.6069 - val_loss: 4919.6911\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: 3340.9317 - val_loss: 4921.9357\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: 3340.4593 - val_loss: 4903.9629\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: 3339.9336 - val_loss: 4925.7202\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: 3339.0545 - val_loss: 4910.2521\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.6305 - val_loss: 4927.7428\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: 3338.2472 - val_loss: 4920.1879\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: 3337.5939 - val_loss: 4886.5294\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 19s - loss: 3337.2406 - val_loss: 4873.7703\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: 3336.7331 - val_loss: 4915.7336\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: 3336.0820 - val_loss: 4890.8989\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: 3335.5437 - val_loss: 4902.3777\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 19s - loss: 3335.2215 - val_loss: 4910.0671\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: 3335.1198 - val_loss: 4877.7638\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: 3334.4519 - val_loss: 4938.5085\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.8895 - val_loss: 4919.6926\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: 3333.5419 - val_loss: 4897.1974\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.9391 - val_loss: 4912.6966\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.5290 - val_loss: 4906.3973\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: 3332.2332 - val_loss: 4877.4179\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.5871 - val_loss: 4891.9305\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.6357 - val_loss: 4869.8185\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: 3331.2033 - val_loss: 4865.8797\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.6630 - val_loss: 4914.5067 ETA: 2s - loss: 3331. -\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: 3330.7459 - val_loss: 4906.2439\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.6986 - val_loss: 4880.5611\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.6503 - val_loss: 4889.2665\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.1900 - val_loss: 4868.0690\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: 3329.2592 - val_loss: 4884.1758\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.6724 - val_loss: 4883.0521\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: 3328.6738 - val_loss: 4895.2497\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: 3328.0476 - val_loss: 4878.9082\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 19s - loss: 3327.8413 - val_loss: 4886.9408\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 19s - loss: 3327.5052 - val_loss: 4907.5013\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 19s - loss: 3327.5404 - val_loss: 4848.6393\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 19s - loss: 3327.1749 - val_loss: 4911.9193\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 19s - loss: 3326.8243 - val_loss: 4870.3381\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 19s - loss: 3326.7443 - val_loss: 4868.3045\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 19s - loss: 3326.4990 - val_loss: 4869.9153\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 19s - loss: 3325.9886 - val_loss: 4872.7033\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 19s - loss: 3326.0034 - val_loss: 4852.6858\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 19s - loss: 3325.8525 - val_loss: 4896.8731\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 19s - loss: 3325.9518 - val_loss: 4852.6192\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 19s - loss: 3325.5086 - val_loss: 4883.5688\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.9022 - val_loss: 4858.2191\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.6933 - val_loss: 4901.4821\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.8801 - val_loss: 4892.5932\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.3039 - val_loss: 4895.3516\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.1016 - val_loss: 4870.3733\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 19s - loss: 3324.2021 - val_loss: 4849.3667\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 19s - loss: 3323.9670 - val_loss: 4868.3096\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 19s - loss: 3323.7845 - val_loss: 4898.2046\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_k = [2, 5, 10, 20, 50, 100, 150, 200]\n",
    "\n",
    "list_pearson = []\n",
    "list_spearman = []\n",
    "list_mse = []\n",
    "list_bce = []\n",
    "\n",
    "for k in list_k:\n",
    "    # Set common hyper parameters\n",
    "    rnaseq_train_df = train_tcga_df_normalized.drop(['sample_id'], axis=1)\n",
    "    rnaseq_test_df = test_tcga_df_normalized.drop(['sample_id'], axis=1)\n",
    "\n",
    "    original_dim = rnaseq_train_df.shape[1]\n",
    "    latent_dim = k\n",
    "    beta = K.variable(0)\n",
    "    epsilon_std = 1.0\n",
    "\n",
    "    # Model A (100 hidden layer size)\n",
    "    model_a_latent_dim = 100\n",
    "    model_a_batch_size = 100\n",
    "    model_a_epochs = 100\n",
    "    model_a_learning_rate = 0.001\n",
    "    model_a_kappa = 1.0\n",
    "    \n",
    "    model_a = Tybalt(original_dim=original_dim,\n",
    "                 hidden_dim=model_a_latent_dim,\n",
    "                 latent_dim=latent_dim,\n",
    "                 batch_size=model_a_batch_size,\n",
    "                 epochs=model_a_epochs,\n",
    "                 learning_rate=model_a_learning_rate,\n",
    "                 kappa=model_a_kappa,\n",
    "                 beta=beta)\n",
    "    \n",
    "    # Compile Model A\n",
    "    model_a.build_encoder_layer()\n",
    "    model_a.build_decoder_layer()\n",
    "    model_a.compile_vae()\n",
    "    \n",
    "    model_a.train_vae()\n",
    "    \n",
    "    rnaseq_df = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "\n",
    "    model_a_compression = model_a.compress(rnaseq_df)\n",
    "    \n",
    "    learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/figure/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_learning.pdf'\n",
    "    compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/models/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_compress.tsv'\n",
    "    encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/models/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_encoder_twohidden100_vae.hdf5'\n",
    "    decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/models/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_decoder_twohidden100_vae.hdf5'\n",
    "    weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/models/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_enc_dec_weights.tsv'\n",
    "    \n",
    "    model_a.visualize_training(learning_path)\n",
    "    \n",
    "    model_a_weights = model_a.get_decoder_weights()\n",
    "    \n",
    "    model_a_compression.to_csv(compress_path, sep='\\t', compression='gzip')\n",
    "    model_a.save_models(encoder_path, decoder_path)\n",
    "    \n",
    "    extract_weights(model_a_weights, weight_path, k)\n",
    "    \n",
    "    compress_data = model_a_compression\n",
    "    full_data = rnaseq_df\n",
    "    \n",
    "    compress_data = model_a_compression\n",
    "    full_data = rnaseq_df\n",
    "\n",
    "    reconstructed_data = pd.DataFrame(model_a.predict(compress_data))\n",
    "\n",
    "    full_data_check = full_data\n",
    "\n",
    "    r = [pearsonr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "    s = [spearmanr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])] \n",
    "    mse = np.sum((full_data_check - reconstructed_data) ** 2, axis=1).mean()\n",
    "    bce = approx_keras_binary_cross_entropy(full_data_check, reconstructed_data, k)\n",
    "    \n",
    "    list_pearson.append(r)\n",
    "    list_spearman.append(s)\n",
    "    list_mse.append(mse)\n",
    "    list_bce.append(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_bce.append(bce)\n",
    "plt.title('MSE v/s K for VAE')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.plot(list_k, list_mse)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(list_k, list_mse)\n",
    "# naming the x axis\n",
    "plt.xlabel('K')\n",
    "# naming the y axis\n",
    "plt.ylabel('Reconstruction Loss')\n",
    "plt.title('Reconstruction Loss v/s Latent Space')\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.show()\n",
    "\n",
    "plt.title('BCE v/s K for VAE')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.plot(list_bce[:8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_pearson = np.array(list_pearson)\n",
    "list_spearman = np.array(list_spearman)\n",
    "# print(np.mean(list_pearson, axis=1))\n",
    "# print(np.mean(list_spearman, axis=1))\n",
    "\n",
    "plt.title('Box plot')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Pearson Corr.')\n",
    "plt.boxplot(list_pearson.transpose(), labels=list_k)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Box plot')\n",
    "\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Spearman Corr.')\n",
    "plt.boxplot(list_spearman.transpose(), labels=list_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specific cancer type selection\n",
    "list_label = np.array(all_labels)\n",
    "c_type_list = collections.Counter(merge_train)\n",
    "\n",
    "for c_type in c_type_list:\n",
    "    pearson_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/figure/c_type_vae/fig__pearson_'+c_type+'.png'\n",
    "    spearman_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/figure/c_type_vae/fig__spearman_'+c_type+'.png'\n",
    "    c_pearson = []\n",
    "    c_spearman = []\n",
    "    for i in range(len(list_label)):\n",
    "        if c_type == list_label[i]:\n",
    "            c_pearson.append(list_pearson[:,i])\n",
    "            c_spearman.append(list_spearman[:,i])\n",
    "\n",
    "    c_pearson = np.array(c_pearson)\n",
    "    c_spearman = np.array(c_spearman)\n",
    "\n",
    "    fig, ax = plt.subplots() \n",
    "    fig.suptitle('Box plot for '+str(c_type)) \n",
    "    ax.set_xlabel('Values of k') \n",
    "    ax.set_ylabel('Peason Corr.') \n",
    "    ax.boxplot(c_pearson, labels=list_k) \n",
    "    fig.savefig(pearson_path)\n",
    "    fig.clear(True) \n",
    "\n",
    "\n",
    "    fig2, ax2 = plt.subplots() \n",
    "    fig2.suptitle('Box plot for '+str(c_type)) \n",
    "    ax2.set_xlabel('Values of k') \n",
    "    ax2.set_ylabel('Spearman Corr.') \n",
    "    ax2.boxplot(c_spearman, labels=list_k) \n",
    "    fig2.savefig(spearman_path)\n",
    "    fig2.clear(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE COMPRESS DATA FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels(df):    \n",
    "    df = pd.concat([df, all_labels], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\keras\\models.py:258: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "list_k = [2, 5, 10, 20, 50, 100, 150, 200]\n",
    "for k in list_k:\n",
    "    compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/models/k_'+str(k)+'_epoch_'+str(model_a_epochs)+'_compress.tsv'\n",
    "    save_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/data/k_'+str(k)+'_compress_for_classifier.tsv'\n",
    "\n",
    "    enc_model = load_model(encoder_path)\n",
    "    dec_model = load_model(decoder_path)\n",
    "    \n",
    "    with open(compress_path, 'rb') as fd:\n",
    "        gzip_fd = gzip.GzipFile(fileobj=fd)\n",
    "        compress_data = pd.read_csv(gzip_fd, sep='\\t')\n",
    "    \n",
    "    compress_data = compress_data.drop(compress_data.columns[0], axis=1)\n",
    "    compress_data = align_labels(compress_data)\n",
    "    compress_data.to_csv(save_path, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPRESSED FEATURES ENSEMBLE LR MULTICLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "k=50\n",
    "\n",
    "# PCA calculation\n",
    "pca = PCA(n_components=k)\n",
    "\n",
    "# PCA Model Fitting\n",
    "pca_train = pca.fit_transform(rnaseq_train_df)\n",
    "pca_test = pca.fit_transform(rnaseq_test_df)\n",
    "\n",
    "# NMF calculation\n",
    "nmf = NMF(n_components=k)\n",
    "\n",
    "# NMF Model Fitting\n",
    "nmf_train = nmf.fit_transform(rnaseq_train_df)\n",
    "nmf_test = nmf.fit_transform(rnaseq_test_df)\n",
    "\n",
    "# ICA calculation\n",
    "ica = FastICA(n_components=k)\n",
    "\n",
    "# ICA Model Fitting for Train Set\n",
    "ica_train = ica.fit_transform(rnaseq_train_df)\n",
    "ica_test = ica.fit_transform(rnaseq_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE compress feature load for k=100\n",
    "k=100\n",
    "load_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/data/k_'+str(k)+'_compress_for_classifier.tsv'\n",
    "with open(load_path, 'rb') as fd:\n",
    "    gzip_fd = gzip.GzipFile(fileobj=fd)\n",
    "    vae_data = pd.read_csv(gzip_fd, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_all = vae_data.drop(vae_data.columns[0], axis=1)\n",
    "vae_train = vae_all[0:9954]\n",
    "vae_test = vae_all[9954:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_df = pd.DataFrame(pca_train)\n",
    "nmf_train_df = pd.DataFrame(nmf_train)\n",
    "ica_train_df = pd.DataFrame(ica_train)\n",
    "\n",
    "pca_test_df = pd.DataFrame(pca_test)\n",
    "nmf_test_df = pd.DataFrame(nmf_test)\n",
    "ica_test_df = pd.DataFrame(ica_test)\n",
    "vae_test = pd.DataFrame(np.array(vae_test))\n",
    "\n",
    "columns = [i+1 for i in range(250)]\n",
    "columns.append('cancer_type')\n",
    "\n",
    "ensemble_train = pd.concat([pca_train_df, nmf_train_df, ica_train_df, vae_train], axis=1)\n",
    "ensemble_train.columns = columns\n",
    "\n",
    "ensemble_test = pd.concat([pca_test_df, nmf_test_df, ica_test_df, vae_test], axis=1)\n",
    "ensemble_test.columns = columns\n",
    "\n",
    "train_label_df = pd.DataFrame(merge_train, columns=['cancer_type'])\n",
    "test_label_df = pd.DataFrame(merge_test, columns=['cancer_type'])\n",
    "\n",
    "full_train = pd.concat([rnaseq_train_df, train_label_df], axis=1)\n",
    "full_test = pd.concat([rnaseq_test_df, test_label_df], axis=1)\n",
    "\n",
    "only_pca_train = pd.concat([pca_train_df, train_label_df], axis=1)\n",
    "only_pca_test = pd.concat([pca_test_df, test_label_df], axis=1)\n",
    "\n",
    "only_nmf_train = pd.concat([nmf_train_df, train_label_df], axis=1)\n",
    "only_nmf_test = pd.concat([nmf_test_df, test_label_df], axis=1)\n",
    "\n",
    "only_ica_train = pd.concat([ica_train_df, train_label_df], axis=1)\n",
    "only_ica_test = pd.concat([ica_test_df, test_label_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_train = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/data/ensemble_train.tsv'\n",
    "save_path_test = 'D://GitHub/Gene-compression-and-Cancer-type-classification/normalize/data/ensemble_test.tsv'\n",
    "\n",
    "ensemble_train.to_csv(save_path_train, sep='\\t', compression='gzip')\n",
    "ensemble_test.to_csv(save_path_test, sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multiclass(c_type_list, df2):\n",
    "    df_main = df2[df2.cancer_type==c_type_list[0]]\n",
    "    df_main.loc[:,\"cancer_type\"] = 0\n",
    "    \n",
    "    for i in range(1,len(c_type_list)):\n",
    "        c_type = c_type_list[i]\n",
    "        df2_temp = df2[df2.cancer_type==c_type]\n",
    "        df2_temp.loc[:,\"cancer_type\"] = i\n",
    "        df_main = pd.concat([df_main, df2_temp])\n",
    "        \n",
    "    df2 = df_main\n",
    "    df2[\"cancer_type\"] = df2[\"cancer_type\"].astype('int')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLRMulticlass(df2, test2):\n",
    "    time_laps = []\n",
    "    for i in range(4):\n",
    "        start_time = time.time()\n",
    "        clf = LogisticRegression(random_state=0).fit(df2.iloc[:,0:df2.shape[1]],df2[\"cancer_type\"])\n",
    "        pred = clf.predict(test2.iloc[:,0:test2.shape[1]])\n",
    "        accuracy = accuracy_score(test2.cancer_type,pred)\n",
    "        precision, recall, f1score, _= precision_recall_fscore_support(pred, test2.cancer_type)\n",
    "        laps = time.time() - start_time\n",
    "        time_laps.append(laps)\n",
    "    avg_time_laps = np.mean(time_laps)\n",
    "    SVM_accuracy = accuracy\n",
    "    SVM_computation_time = avg_time_laps\n",
    "    return SVM_accuracy, SVM_computation_time, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i+1 for i in range(100)]\n",
    "columns.append('cancer_type')\n",
    "\n",
    "vae_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#multi_class_list = ['UCEC', 'HNSC', 'SARC', 'ACC', 'LUSC', 'KIRC', 'PCPG', 'LUAD', 'HNSC', 'COAD']\n",
    "multi_class_list = collections.Counter(merge_train)\n",
    "multi_class_list = [c_type for c_type in multi_class_list]\n",
    "\n",
    "cols = ['Accuracy', 'Precision','Recall','F1-score','Computation Time (sec.)', 'K-Dimension']\n",
    "index = ['Full Data','PCA Features', 'NMF Features','ICA Features','VAE Features','Ensemble Features']\n",
    "multiclass_result = pd.DataFrame(columns = cols, index=index)\n",
    "\n",
    "df2_train_full = prepare_multiclass(multi_class_list, full_train)\n",
    "df2_test_full = prepare_multiclass(multi_class_list, full_test)\n",
    "full_acc, full_time, precision, recall, f1score = runLRMulticlass(df2_train_full, df2_test_full)\n",
    "multiclass_result.loc['Full Data'] = [full_acc, precision, recall, f1score,full_time, 16147]\n",
    "\n",
    "df2_train_pca = prepare_multiclass(multi_class_list, only_pca_train)\n",
    "df2_test_pca = prepare_multiclass(multi_class_list, only_pca_test)\n",
    "pca_acc, pca_time, precision, recall, f1score = runLRMulticlass(df2_train_pca, df2_test_pca)\n",
    "multiclass_result.loc['PCA Features'] = [pca_acc, precision, recall, f1score, pca_time, 50]\n",
    "\n",
    "df2_train_nmf = prepare_multiclass(multi_class_list, only_nmf_train)\n",
    "df2_test_nmf = prepare_multiclass(multi_class_list, only_nmf_test)\n",
    "nmf_acc, nmf_time, precision, recall, f1score = runLRMulticlass(df2_train_nmf, df2_test_nmf)\n",
    "multiclass_result.loc['NMF Features'] = [nmf_acc, precision, recall, f1score, nmf_time, 50]\n",
    "\n",
    "df2_train_ica = prepare_multiclass(multi_class_list, only_ica_train)\n",
    "df2_test_ica = prepare_multiclass(multi_class_list, only_ica_test)\n",
    "ica_acc, ica_time, precision, recall, f1score = runLRMulticlass(df2_train_ica, df2_test_ica)\n",
    "multiclass_result.loc['ICA Features'] = [ica_acc, precision, recall, f1score, ica_time, 50]\n",
    "\n",
    "df2_train_vae = prepare_multiclass(multi_class_list, vae_train)\n",
    "df2_test_vae = prepare_multiclass(multi_class_list, vae_test)\n",
    "vae_acc, vae_time, precision, recall, f1score = runLRMulticlass(df2_train_vae, df2_test_vae)\n",
    "multiclass_result.loc['VAE Features'] = [vae_acc, precision, recall, f1score, vae_time, 100]\n",
    "\n",
    "df2_train_ensemble = prepare_multiclass(multi_class_list, ensemble_train)\n",
    "df2_test_ensemble = prepare_multiclass(multi_class_list, ensemble_test)\n",
    "ensemble_acc, ensemble_time, precision, recall, f1score = runLRMulticlass(df2_train_ensemble, df2_test_ensemble)\n",
    "multiclass_result.loc['Ensemble Features'] = [ensemble_acc, precision, recall, f1score, ensemble_time, 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Computation Time (sec.)</th>\n",
       "      <th>K-Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Data</th>\n",
       "      <td>0.947559</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9821428571428571, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.9827586206896551, 1.0, 0.9821428571428...</td>\n",
       "      <td>[1.0, 0.9913043478260869, 1.0, 0.9821428571428...</td>\n",
       "      <td>55.0593</td>\n",
       "      <td>16147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Features</th>\n",
       "      <td>0.289331</td>\n",
       "      <td>[0.7950819672131147, 0.45614035087719296, 0.0,...</td>\n",
       "      <td>[0.9897959183673469, 0.41935483870967744, 0.0,...</td>\n",
       "      <td>[0.8818181818181818, 0.43697478991596644, 0.0,...</td>\n",
       "      <td>2.82495</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF Features</th>\n",
       "      <td>0.331826</td>\n",
       "      <td>[0.9754098360655737, 1.0, 0.0, 0.0, 0.04255319...</td>\n",
       "      <td>[1.0, 0.47107438016528924, 0.0, 0.0, 0.1, 1.0,...</td>\n",
       "      <td>[0.9875518672199171, 0.6404494382022472, 0.0, ...</td>\n",
       "      <td>3.06057</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICA Features</th>\n",
       "      <td>0.509042</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.6595744680851063, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.7272727272727273, 0.36046511...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.8421052631578948, 0.46616541...</td>\n",
       "      <td>2.77658</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE Features</th>\n",
       "      <td>0.906872</td>\n",
       "      <td>[0.9672131147540983, 1.0, 1.0, 0.9107142857142...</td>\n",
       "      <td>[0.9833333333333333, 0.8636363636363636, 0.833...</td>\n",
       "      <td>[0.9752066115702478, 0.9268292682926829, 0.909...</td>\n",
       "      <td>2.90972</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Features</th>\n",
       "      <td>0.901447</td>\n",
       "      <td>[0.9672131147540983, 1.0, 1.0, 0.875, 1.0, 0.9...</td>\n",
       "      <td>[0.9915966386554622, 0.8636363636363636, 0.833...</td>\n",
       "      <td>[0.979253112033195, 0.9268292682926829, 0.9090...</td>\n",
       "      <td>3.63952</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  \\\n",
       "Full Data          0.947559   \n",
       "PCA Features       0.289331   \n",
       "NMF Features       0.331826   \n",
       "ICA Features       0.509042   \n",
       "VAE Features       0.906872   \n",
       "Ensemble Features  0.901447   \n",
       "\n",
       "                                                           Precision  \\\n",
       "Full Data          [1.0, 1.0, 1.0, 0.9821428571428571, 1.0, 1.0, ...   \n",
       "PCA Features       [0.7950819672131147, 0.45614035087719296, 0.0,...   \n",
       "NMF Features       [0.9754098360655737, 1.0, 0.0, 0.0, 0.04255319...   \n",
       "ICA Features       [1.0, 1.0, 0.0, 1.0, 0.6595744680851063, 0.0, ...   \n",
       "VAE Features       [0.9672131147540983, 1.0, 1.0, 0.9107142857142...   \n",
       "Ensemble Features  [0.9672131147540983, 1.0, 1.0, 0.875, 1.0, 0.9...   \n",
       "\n",
       "                                                              Recall  \\\n",
       "Full Data          [1.0, 0.9827586206896551, 1.0, 0.9821428571428...   \n",
       "PCA Features       [0.9897959183673469, 0.41935483870967744, 0.0,...   \n",
       "NMF Features       [1.0, 0.47107438016528924, 0.0, 0.0, 0.1, 1.0,...   \n",
       "ICA Features       [1.0, 1.0, 0.0, 0.7272727272727273, 0.36046511...   \n",
       "VAE Features       [0.9833333333333333, 0.8636363636363636, 0.833...   \n",
       "Ensemble Features  [0.9915966386554622, 0.8636363636363636, 0.833...   \n",
       "\n",
       "                                                            F1-score  \\\n",
       "Full Data          [1.0, 0.9913043478260869, 1.0, 0.9821428571428...   \n",
       "PCA Features       [0.8818181818181818, 0.43697478991596644, 0.0,...   \n",
       "NMF Features       [0.9875518672199171, 0.6404494382022472, 0.0, ...   \n",
       "ICA Features       [1.0, 1.0, 0.0, 0.8421052631578948, 0.46616541...   \n",
       "VAE Features       [0.9752066115702478, 0.9268292682926829, 0.909...   \n",
       "Ensemble Features  [0.979253112033195, 0.9268292682926829, 0.9090...   \n",
       "\n",
       "                  Computation Time (sec.) K-Dimension  \n",
       "Full Data                         55.0593       16147  \n",
       "PCA Features                      2.82495          50  \n",
       "NMF Features                      3.06057          50  \n",
       "ICA Features                      2.77658          50  \n",
       "VAE Features                      2.90972         100  \n",
       "Ensemble Features                 3.63952         250  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_result_df = multiclass_result.copy()\n",
    "\n",
    "for index, row in mean_result_df.iterrows():\n",
    "    row['Precision'] = np.mean(row['Precision'])\n",
    "    row['Recall'] = np.mean(row['Recall'])\n",
    "    row['F1-score'] = np.mean(row['F1-score'])\n",
    "\n",
    "mean_result_df.columns = cols = ['Accuracy', 'Mean Precision','Mean Recall','Mean F1-score','Computation Time (sec.)', 'K-Dimension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Mean F1-score</th>\n",
       "      <th>Computation Time (sec.)</th>\n",
       "      <th>K-Dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full Data</th>\n",
       "      <td>0.947559</td>\n",
       "      <td>0.878011</td>\n",
       "      <td>0.872873</td>\n",
       "      <td>0.873461</td>\n",
       "      <td>55.0593</td>\n",
       "      <td>16147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA Features</th>\n",
       "      <td>0.289331</td>\n",
       "      <td>0.196031</td>\n",
       "      <td>0.164082</td>\n",
       "      <td>0.170341</td>\n",
       "      <td>2.82495</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF Features</th>\n",
       "      <td>0.331826</td>\n",
       "      <td>0.210212</td>\n",
       "      <td>0.192597</td>\n",
       "      <td>0.194684</td>\n",
       "      <td>3.06057</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICA Features</th>\n",
       "      <td>0.509042</td>\n",
       "      <td>0.281059</td>\n",
       "      <td>0.190303</td>\n",
       "      <td>0.211253</td>\n",
       "      <td>2.77658</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE Features</th>\n",
       "      <td>0.906872</td>\n",
       "      <td>0.918027</td>\n",
       "      <td>0.889877</td>\n",
       "      <td>0.890345</td>\n",
       "      <td>2.90972</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Features</th>\n",
       "      <td>0.901447</td>\n",
       "      <td>0.917407</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.88334</td>\n",
       "      <td>3.63952</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy Mean Precision Mean Recall Mean F1-score  \\\n",
       "Full Data          0.947559       0.878011    0.872873      0.873461   \n",
       "PCA Features       0.289331       0.196031    0.164082      0.170341   \n",
       "NMF Features       0.331826       0.210212    0.192597      0.194684   \n",
       "ICA Features       0.509042       0.281059    0.190303      0.211253   \n",
       "VAE Features       0.906872       0.918027    0.889877      0.890345   \n",
       "Ensemble Features  0.901447       0.917407    0.882543       0.88334   \n",
       "\n",
       "                  Computation Time (sec.) K-Dimension  \n",
       "Full Data                         55.0593       16147  \n",
       "PCA Features                      2.82495          50  \n",
       "NMF Features                      3.06057          50  \n",
       "ICA Features                      2.77658          50  \n",
       "VAE Features                      2.90972         100  \n",
       "Ensemble Features                 3.63952         250  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
