{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,  f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/train_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "test_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/test_tcga_expression_matrix_processed.tsv', header=0, sep='\\t')\n",
    "\n",
    "labels_tcga_df = pd.read_csv('D://GitHub/Gene-compression-and-Cancer-type-classification/data/tcga_sample_identifiers.tsv', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train_tcga_df['sample_id']\n",
    "test_id = test_tcga_df['sample_id']\n",
    "label_id = labels_tcga_df['sample_id']\n",
    "\n",
    "merge_train = []\n",
    "merge_test = []\n",
    "\n",
    "for i in train_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_train.append(str(val['cancer_type']).split()[1])\n",
    "    \n",
    "for i in test_id:\n",
    "    val = labels_tcga_df.loc[labels_tcga_df['sample_id'] == i]\n",
    "    merge_test.append(str(val['cancer_type']).split()[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "      <th>10002</th>\n",
       "      <th>10003</th>\n",
       "      <th>100037417</th>\n",
       "      <th>...</th>\n",
       "      <th>9988</th>\n",
       "      <th>9989</th>\n",
       "      <th>999</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9997</th>\n",
       "      <th>cancer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-LL-A73Z-01</td>\n",
       "      <td>202.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>329.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>492.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>4.590</td>\n",
       "      <td>14.70</td>\n",
       "      <td>337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>BRCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-55-8207-01</td>\n",
       "      <td>77.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>784.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>2.540</td>\n",
       "      <td>176.00</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>923.0</td>\n",
       "      <td>2490.0</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>LUAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-FF-A7CR-01</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>486.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.47</td>\n",
       "      <td>348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>897.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>DLBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-BK-A13C-11</td>\n",
       "      <td>80.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.6</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1.200</td>\n",
       "      <td>91.40</td>\n",
       "      <td>231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UCEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-EB-A6L9-06</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2.36</td>\n",
       "      <td>585.0</td>\n",
       "      <td>...</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>7010.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>SKCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id      1    10     100   1000   10000  10001  10002   10003  \\\n",
       "0  TCGA-LL-A73Z-01  202.0  28.5   329.0   84.5   492.0  448.0  4.590   14.70   \n",
       "1  TCGA-55-8207-01   77.5  22.5    74.5   13.1   784.0  333.0  2.540  176.00   \n",
       "2  TCGA-FF-A7CR-01  152.0   0.0  3020.0   26.6   486.0  497.0  0.000    8.47   \n",
       "3  TCGA-BK-A13C-11   80.5  40.0    70.6  284.0  2420.0  325.0  1.200   91.40   \n",
       "4  TCGA-EB-A6L9-06  319.0   0.0   422.0  184.0   423.0  392.0  0.945    2.36   \n",
       "\n",
       "   100037417  ...   9988    9989      999    9990    9991   9992    9993  \\\n",
       "0      337.0  ...  717.0  1800.0   6360.0   299.0  2310.0  10.60  3190.0   \n",
       "1      153.0  ...  923.0  2490.0  11300.0  1150.0  4030.0   9.08  2890.0   \n",
       "2      348.0  ...  897.0   861.0     39.7   464.0  3320.0   0.00  1330.0   \n",
       "3      231.0  ...  737.0  1410.0     10.9  1120.0  1990.0   5.24  3090.0   \n",
       "4      585.0  ...  328.0  1340.0   7010.0   450.0   563.0  10.90  3780.0   \n",
       "\n",
       "    9994    9997  cancer_type  \n",
       "0  337.0   892.0         BRCA  \n",
       "1  316.0   301.0         LUAD  \n",
       "2  606.0   558.0         DLBC  \n",
       "3  673.0   263.0         UCEC  \n",
       "4   37.3  1120.0         SKCM  \n",
       "\n",
       "[5 rows x 16150 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tcga_df['cancer_type'] = merge_train\n",
    "train_label_df = train_tcga_df['cancer_type']\n",
    "train_tcga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "      <th>10002</th>\n",
       "      <th>10003</th>\n",
       "      <th>100037417</th>\n",
       "      <th>...</th>\n",
       "      <th>9988</th>\n",
       "      <th>9989</th>\n",
       "      <th>999</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9997</th>\n",
       "      <th>cancer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-CN-5365-01</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>73.9</td>\n",
       "      <td>757.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>10.50</td>\n",
       "      <td>414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>612.0</td>\n",
       "      <td>5780.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>HNSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-LP-A7HU-01</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.949</td>\n",
       "      <td>517.0</td>\n",
       "      <td>6.17</td>\n",
       "      <td>63.6</td>\n",
       "      <td>365.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>9.02</td>\n",
       "      <td>633.0</td>\n",
       "      <td>...</td>\n",
       "      <td>543.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>17.60</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>CESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-22-5491-11</td>\n",
       "      <td>87.6</td>\n",
       "      <td>3.760</td>\n",
       "      <td>88.3</td>\n",
       "      <td>14.40</td>\n",
       "      <td>642.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>59.90</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>4480.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5030.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>LUSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-CS-6667-01</td>\n",
       "      <td>75.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55.6</td>\n",
       "      <td>2720.00</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>9.57</td>\n",
       "      <td>251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>23.70</td>\n",
       "      <td>7530.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>LGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-20-1684-01</td>\n",
       "      <td>63.1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>75.2</td>\n",
       "      <td>4500.00</td>\n",
       "      <td>792.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.16</td>\n",
       "      <td>623.0</td>\n",
       "      <td>...</td>\n",
       "      <td>812.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>8410.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>14.80</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>OV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id     1     10     100     1000   10000  10001  10002  10003  \\\n",
       "0  TCGA-CN-5365-01  70.5  0.000  1310.0    18.70    73.9  757.0   1.82  10.50   \n",
       "1  TCGA-LP-A7HU-01  27.8  0.949   517.0     6.17    63.6  365.0   4.27   9.02   \n",
       "2  TCGA-22-5491-11  87.6  3.760    88.3    14.40   642.0  295.0   6.84  59.90   \n",
       "3  TCGA-CS-6667-01  75.8  0.000    55.6  2720.00  2170.0  281.0   3.90   9.57   \n",
       "4  TCGA-20-1684-01  63.1  0.703    75.2  4500.00   792.0  433.0   1.64   4.16   \n",
       "\n",
       "   100037417  ...    9988    9989      999    9990    9991   9992    9993  \\\n",
       "0      414.0  ...   612.0  5780.0  10400.0   879.0  3830.0   4.10  4220.0   \n",
       "1      633.0  ...   543.0  1360.0   4960.0   510.0  2220.0  17.60  2410.0   \n",
       "2      159.0  ...   479.0  2190.0   4480.0   870.0  2120.0   5.13  5030.0   \n",
       "3      251.0  ...  1550.0  1370.0     12.8  1430.0   601.0  23.70  7530.0   \n",
       "4      623.0  ...   812.0  1070.0   8410.0   505.0  1170.0  14.80  1910.0   \n",
       "\n",
       "    9994    9997  cancer_type  \n",
       "0  308.0  1300.0         HNSC  \n",
       "1  233.0   993.0         CESC  \n",
       "2  285.0   530.0         LUSC  \n",
       "3  473.0   258.0          LGG  \n",
       "4  281.0   221.0           OV  \n",
       "\n",
       "[5 rows x 16150 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tcga_df['cancer_type'] = merge_test\n",
    "test_label_df = test_tcga_df['cancer_type']\n",
    "test_tcga_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    \n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, var_layer, mean_layer, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        self.var_layer = var_layer\n",
    "        self.mean_layer = mean_layer\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.var_layer - K.square(self.mean_layer) - \n",
    "                                K.exp(self.var_layer), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tybalt():\n",
    "    \"\"\"\n",
    "    Facilitates the training and output of tybalt model trained on TCGA RNAseq gene expression data\n",
    "    \"\"\"\n",
    "    def __init__(self, original_dim, hidden_dim, latent_dim,\n",
    "                 batch_size, epochs, learning_rate, kappa, beta):\n",
    "        self.original_dim = original_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kappa = kappa\n",
    "        self.beta = beta\n",
    "\n",
    "    def build_encoder_layer(self):\n",
    "        # Input place holder for RNAseq data with specific input size\n",
    "        self.rnaseq_input = Input(shape=(self.original_dim, ))\n",
    "\n",
    "        # Input layer is compressed into a mean and log variance vector of size `latent_dim`\n",
    "        # Each layer is initialized with glorot uniform weights and each step (dense connections, batch norm,\n",
    "        # and relu activation) are funneled separately\n",
    "        # Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "        hidden_dense_linear = Dense(self.hidden_dim, kernel_initializer='glorot_uniform')(self.rnaseq_input)\n",
    "        hidden_dense_batchnorm = BatchNormalization()(hidden_dense_linear)\n",
    "        hidden_encoded = Activation('relu')(hidden_dense_batchnorm)\n",
    "\n",
    "        z_mean_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "        self.z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "        z_log_var_dense_linear = Dense(self.latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "        z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "        self.z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "        # return the encoded and randomly sampled z vector\n",
    "        # Takes two keras layers as input to the custom sampling function layer with a `latent_dim` output\n",
    "        self.z = Lambda(sampling, output_shape=(self.latent_dim, ))([self.z_mean_encoded, self.z_log_var_encoded])\n",
    "    \n",
    "    def build_decoder_layer(self):\n",
    "        # The decoding layer is much simpler with a single layer glorot uniform initialized and sigmoid activation\n",
    "        self.decoder_model = Sequential()\n",
    "        self.decoder_model.add(Dense(self.hidden_dim, activation='relu', input_dim=self.latent_dim))\n",
    "        self.decoder_model.add(Dense(self.original_dim, activation='sigmoid'))\n",
    "        self.rnaseq_reconstruct = self.decoder_model(self.z)\n",
    "        \n",
    "    def compile_vae(self):\n",
    "        adam = optimizers.Adam(lr=self.learning_rate)\n",
    "        vae_layer = CustomVariationalLayer(self.z_log_var_encoded,\n",
    "                                           self.z_mean_encoded)([self.rnaseq_input, self.rnaseq_reconstruct])\n",
    "        self.vae = Model(self.rnaseq_input, vae_layer)\n",
    "        self.vae.compile(optimizer=adam, loss=None, loss_weights=[self.beta])\n",
    "        \n",
    "    def get_summary(self):\n",
    "        self.vae.summary()\n",
    "  \n",
    "    def visualize_architecture(self, output_file):\n",
    "        # Visualize the connections of the custom VAE model\n",
    "        plot_model(self.vae, to_file=output_file)\n",
    "        SVG(model_to_dot(self.vae).create(prog='dot', format='svg'))\n",
    "        \n",
    "    def train_vae(self):\n",
    "        self.hist = self.vae.fit(np.array(rnaseq_train_df),\n",
    "               shuffle=True,\n",
    "               epochs=self.epochs,\n",
    "               batch_size=self.batch_size,\n",
    "               validation_data=(np.array(rnaseq_test_df), np.array(rnaseq_test_df)),\n",
    "               callbacks=[WarmUpCallback(self.beta, self.kappa)])\n",
    "    \n",
    "    def visualize_training(self, output_file):\n",
    "        # Visualize training performance\n",
    "        history_df = pd.DataFrame(self.hist.history)\n",
    "        ax = history_df.plot()\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('VAE Loss')\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(output_file)\n",
    "        \n",
    "    def compress(self, df):\n",
    "        # Model to compress input\n",
    "        self.encoder = Model(self.rnaseq_input, self.z_mean_encoded)\n",
    "        \n",
    "        # Encode rnaseq into the hidden/latent representation - and save output\n",
    "        encoded_df = self.encoder.predict_on_batch(df)\n",
    "        encoded_df = pd.DataFrame(encoded_df, columns=range(1, self.latent_dim + 1),\n",
    "                                  index=rnaseq_df.index)\n",
    "        return encoded_df\n",
    "    \n",
    "    def get_decoder_weights(self):\n",
    "        # build a generator that can sample from the learned distribution\n",
    "        decoder_input = Input(shape=(self.latent_dim, ))  # can generate from any sampled z vector\n",
    "        _x_decoded_mean = self.decoder_model(decoder_input)\n",
    "        self.decoder = Model(decoder_input, _x_decoded_mean)\n",
    "        weights = []\n",
    "        for layer in self.decoder.layers:\n",
    "            weights.append(layer.get_weights())\n",
    "        return(weights)\n",
    "    \n",
    "    def predict(self, df):\n",
    "        return self.decoder.predict(np.array(df))\n",
    "    \n",
    "    def save_models(self, encoder_file, decoder_file):\n",
    "        self.encoder.save(encoder_file)\n",
    "        self.decoder.save(decoder_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common hyper parameters\n",
    "rnaseq_train_df = train_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "rnaseq_test_df = test_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "\n",
    "original_dim = rnaseq_train_df.shape[1]\n",
    "latent_dim = 100\n",
    "beta = K.variable(0)\n",
    "epsilon_std = 1.0\n",
    "\n",
    "# Model A (100 hidden layer size)\n",
    "model_a_latent_dim = 100\n",
    "model_a_batch_size = 100\n",
    "model_a_epochs = 100\n",
    "model_a_learning_rate = 0.001\n",
    "model_a_kappa = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Tybalt(original_dim=original_dim,\n",
    "                 hidden_dim=model_a_latent_dim,\n",
    "                 latent_dim=latent_dim,\n",
    "                 batch_size=model_a_batch_size,\n",
    "                 epochs=model_a_epochs,\n",
    "                 learning_rate=model_a_learning_rate,\n",
    "                 kappa=model_a_kappa,\n",
    "                 beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 16148)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 100)           1614900     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 100)           400         dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 100)           0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 100)           10100       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 100)           10100       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 100)           400         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 100)           400         dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 100)           0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 100)           0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 100)           0           activation_5[0][0]               \n",
      "                                                                   activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 16148)         1641048     lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "custom_variational_layer_2 (Cust [(None, 16148), (None 0           input_3[0][0]                    \n",
      "                                                                   sequential_2[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 3,277,348\n",
      "Trainable params: 3,276,748\n",
      "Non-trainable params: 600\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_2\" during training.\n"
     ]
    }
   ],
   "source": [
    "# Compile Model A\n",
    "model_a.build_encoder_layer()\n",
    "model_a.build_decoder_layer()\n",
    "model_a.compile_vae()\n",
    "model_a.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 19s - loss: -184127256.0116 - val_loss: -288975562.0687\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 19s - loss: -313611034.2262 - val_loss: -311879839.8843\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 19s - loss: -314340222.2704 - val_loss: -314460064.6944\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 19s - loss: -314359820.1198 - val_loss: -314736265.3165\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 19s - loss: -314521814.8700 - val_loss: -314625035.9783\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 19s - loss: -314581886.8877 - val_loss: -314801550.2929\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 19s - loss: -314557361.4113 - val_loss: -314848673.4467\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 19s - loss: -314586555.3257 - val_loss: -314850717.9168\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 19s - loss: -314652372.0217 - val_loss: -314852391.5226\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 19s - loss: -314639619.7934 - val_loss: -314771130.0398\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 19s - loss: -314628579.3755 - val_loss: -314847938.3725\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 19s - loss: -314646680.3295 - val_loss: -314852298.9367\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 20s - loss: -314669744.0804 - val_loss: -314852449.2152\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 20s - loss: -314661038.2672 - val_loss: -314686488.8246\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 20s - loss: -314660316.5280 - val_loss: -314819575.6094\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 20s - loss: -314659919.9968 - val_loss: -314852509.8011\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 20s - loss: -314641613.3028 - val_loss: -314846237.2803\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 20s - loss: -314672967.0275 - val_loss: -314848488.2749\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 20s - loss: -314682437.4844 - val_loss: -314852515.7613\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 20s - loss: -314685804.0040 - val_loss: -314757016.1302\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687507.4430 - val_loss: -314852521.7215\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 20s - loss: -314668159.8328 - val_loss: -314852515.7613\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 20s - loss: -314676035.8835 - val_loss: -314845473.6203\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 20s - loss: -314677425.5013 - val_loss: -314719930.0398\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687564.6663 - val_loss: -314852515.9349\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 20s - loss: -314671898.7728 - val_loss: -314852449.3888\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 20s - loss: -314680434.1957 - val_loss: -314852521.5479\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 20s - loss: -314675127.4229 - val_loss: -314852495.6817\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 20s - loss: -314681012.8768 - val_loss: -314852495.6817\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687472.6140 - val_loss: -314852518.8282\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685851.1007 - val_loss: -314852518.6546\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687198.1997 - val_loss: -314852524.6148\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: -314680245.7255 - val_loss: -314852451.9349\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683770.3934 - val_loss: -314852165.6709\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 19s - loss: -314669952.0257 - val_loss: -314852504.3617\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687672.1816 - val_loss: -314852466.7486\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687584.1415 - val_loss: -314852417.5624\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687696.6397 - val_loss: -314852521.7215\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687737.8726 - val_loss: -314852530.4014\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687722.9881 - val_loss: -314849882.8499\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687742.5598 - val_loss: -314852518.6546\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683870.4762 - val_loss: -314852521.7215\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687732.7740 - val_loss: -314852524.7884\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 20s - loss: -314685847.7380 - val_loss: -314852452.1085\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687738.3420 - val_loss: -314851106.8933\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 20s - loss: -314684307.9188 - val_loss: -314843737.4611\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687734.4264 - val_loss: -314852524.6148\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 20s - loss: -314675013.1822 - val_loss: -314852458.0687\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 21s - loss: -314687702.2335 - val_loss: -314852513.0416\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687622.5453 - val_loss: -314852524.6148\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685841.7778 - val_loss: -314852524.6148\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 19s - loss: -314677768.0177 - val_loss: -314852533.2948791.59\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687745.4595 - val_loss: -314852527.5081\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 20s - loss: -314687718.7318 - val_loss: -314851306.5316\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.3464 - val_loss: -314852521.7215\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687743.7107 - val_loss: -314852533.2948\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687543.6737 - val_loss: -314852527.3345\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687633.3663 - val_loss: -314852521.7215\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.8286 - val_loss: -314852530.4014\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.6172 - val_loss: -314852524.6148\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.2110 - val_loss: -314852524.6148\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.4073 - val_loss: -314852527.5081\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.7159 - val_loss: -314852527.8553\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.5714 - val_loss: -314852527.5081\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687739.8079 - val_loss: -314852524.6148\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687745.7553 - val_loss: -314852527.5081\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685482.7760 - val_loss: -314852507.4286\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 19s - loss: -314644564.1246 - val_loss: -314825807.7975\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687729.3599 - val_loss: -314851856.2604\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687737.0046 - val_loss: -314852524.9620\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687734.6192 - val_loss: -314852524.9620\n",
      "Epoch 72/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687730.7422 - val_loss: -314852524.7884\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687690.7631 - val_loss: -314852515.9349\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 19s - loss: -314683862.7864 - val_loss: -314852437.8156\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 20s - loss: -314683551.2927 - val_loss: -314654526.7848\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 19s - loss: -314674888.3134 - val_loss: -314852478.1483\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685635.8513 - val_loss: -314852530.0542\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687746.7840 - val_loss: -314852524.6148\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687747.2727 - val_loss: -314852527.5081\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.5787 - val_loss: -314852524.6148\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687747.4527 - val_loss: -314840502.9150\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687739.3578 - val_loss: -314852541.9747\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687339.4061 - val_loss: -314852507.2550\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687689.2779 - val_loss: -314852530.4014\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686179.3369 - val_loss: -314852530.4014\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 19s - loss: -314678350.9809 - val_loss: -314813320.4485\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687744.9259 - val_loss: -314852521.7215\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685654.7607 - val_loss: -314852524.7884\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687748.6357 - val_loss: -314852530.4014\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.2329 - val_loss: -314852533.4684\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.6739 - val_loss: -314852539.0814\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686916.0635 - val_loss: -314852530.4014\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.4000 - val_loss: -314852539.2550\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 19s - loss: -314686987.0139 - val_loss: -314852527.5081\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687752.2877 - val_loss: -314852530.7486\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.6829 - val_loss: -314852536.3617\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687755.3289 - val_loss: -314852539.2550\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.6452 - val_loss: -314852536.5353\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687750.8989 - val_loss: -314852524.9620\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687754.6345 - val_loss: -314852542.3219\n"
     ]
    }
   ],
   "source": [
    "model_a.train_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaseq_df = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "\n",
    "model_a_compression = model_a.compress(rnaseq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/learning.pdf'\n",
    "compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/compress.tsv'\n",
    "encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/encoder_twohidden100_vae.hdf5'\n",
    "decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/decoder_twohidden100_vae.hdf5'\n",
    "weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/enc_dec_weights.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_a.visualize_training(learning_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_weights = model_a.get_decoder_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_compression.to_csv(compress_path, sep='\\t', compression='gzip')\n",
    "model_a.save_models(encoder_path, decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(weights, weight_file, k):\n",
    "    # Multiply hidden layers together to obtain a single representation of gene weights\n",
    "    intermediate_weight_df = pd.DataFrame(weights[1][0])\n",
    "    hidden_weight_df = pd.DataFrame(weights[1][2])\n",
    "    abstracted_weight_df = intermediate_weight_df.dot(hidden_weight_df)\n",
    "\n",
    "    abstracted_weight_df.index = range(1, k+1)\n",
    "    abstracted_weight_df.columns = rnaseq_df.columns\n",
    "    abstracted_weight_df.to_csv(weight_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weights(model_a_weights, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3         4         5         6         7    \\\n",
      "0     0.888610  1.226341  0.000000  0.343611  0.927614  1.464005  0.850590   \n",
      "1     0.356790  0.141183  0.000000  0.000000  3.369023  0.000000  0.376657   \n",
      "2     0.500942  0.540359  0.000000  0.876965  0.000000  1.495549  1.472865   \n",
      "3     0.000000  0.000000  0.655434  0.000000  1.728442  0.000000  0.000000   \n",
      "4     0.000000  0.000000  0.000000  1.489861  0.000000  1.665756  0.303859   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1101  1.561076  1.591578  0.183055  0.000000  0.686180  0.616508  0.814003   \n",
      "1102  0.391478  0.177123  1.314176  0.000000  1.144765  0.552964  0.000000   \n",
      "1103  0.000000  0.000000  0.000000  1.571521  0.000000  0.378635  0.000000   \n",
      "1104  0.000000  0.000000  1.502662  0.394030  0.835129  0.000000  0.000000   \n",
      "1105  1.324750  1.692472  0.351112  0.000000  0.135655  0.000000  0.915859   \n",
      "\n",
      "           8         9         10   ...       91        92        93   \\\n",
      "0     0.000000  0.288112  0.396398  ...  1.241807  0.460358  0.804538   \n",
      "1     0.000000  0.319461  1.431152  ...  1.724381  1.797290  0.000000   \n",
      "2     0.238378  0.832656  0.000000  ...  0.331049  0.189573  0.914678   \n",
      "3     0.000000  1.770285  1.872866  ...  0.698188  2.526497  0.000000   \n",
      "4     1.115770  0.808706  0.000000  ...  0.000000  0.654694  0.000000   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1101  0.000000  0.000000  0.000000  ...  1.630399  0.598437  1.287153   \n",
      "1102  0.969387  0.000000  0.247119  ...  0.084027  0.686966  0.000000   \n",
      "1103  0.279493  2.401577  0.871217  ...  0.000000  1.590999  0.000000   \n",
      "1104  0.000000  2.183143  2.202225  ...  0.000000  2.360591  0.000000   \n",
      "1105  0.000000  0.000000  0.152682  ...  1.651316  0.598679  1.703231   \n",
      "\n",
      "           94        95        96        97        98        99        100  \n",
      "0     0.136865  0.000000  0.750757  0.701395  0.238728  0.000000  1.045009  \n",
      "1     0.000000  1.276084  1.314787  1.871421  0.000000  0.000000  1.877850  \n",
      "2     0.422211  0.000000  0.000000  0.000000  1.614012  0.450391  0.027915  \n",
      "3     0.000000  1.614744  0.000000  1.491731  0.000000  0.862541  0.356696  \n",
      "4     1.648542  0.000000  0.000000  0.499485  1.672059  1.529152  0.000000  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1101  0.000000  0.676026  1.465590  0.000000  0.000000  0.000000  1.768444  \n",
      "1102  0.661727  0.686261  0.332307  1.114346  0.000000  0.627505  0.422349  \n",
      "1103  1.053558  0.328388  0.000000  1.126514  0.877252  0.901893  0.000000  \n",
      "1104  0.700341  2.004504  0.000000  1.951445  0.000000  1.115880  0.000000  \n",
      "1105  0.000000  0.326961  1.537751  0.000000  0.154927  0.036645  1.953951  \n",
      "\n",
      "[11060 rows x 100 columns]\n",
      "       index      1      10     100   1000   10000  10001  10002   10003  \\\n",
      "0          0  202.0  28.500   329.0   84.5   492.0  448.0  4.590   14.70   \n",
      "1          1   77.5  22.500    74.5   13.1   784.0  333.0  2.540  176.00   \n",
      "2          2  152.0   0.000  3020.0   26.6   486.0  497.0  0.000    8.47   \n",
      "3          3   80.5  40.000    70.6  284.0  2420.0  325.0  1.200   91.40   \n",
      "4          4  319.0   0.000   422.0  184.0   423.0  392.0  0.945    2.36   \n",
      "...      ...    ...     ...     ...    ...     ...    ...    ...     ...   \n",
      "11055  11055  204.0   2.400   131.0   32.1   105.0  247.0  6.230    6.23   \n",
      "11056  11056   89.8   0.532   121.0   22.3   884.0  329.0  2.660   14.90   \n",
      "11057  11057  168.0   0.000   173.0   51.5  5110.0  300.0  1.330    1.86   \n",
      "11058  11058   64.5   2.160   182.0   40.1  2290.0  351.0  2.770   57.30   \n",
      "11059  11059   58.7   0.186   172.0  101.0   399.0  445.0  2.610   28.10   \n",
      "\n",
      "       100037417  ...    9987    9988    9989      999    9990    9991   9992  \\\n",
      "0          337.0  ...  3430.0   717.0  1800.0   6360.0   299.0  2310.0  10.60   \n",
      "1          153.0  ...  6050.0   923.0  2490.0  11300.0  1150.0  4030.0   9.08   \n",
      "2          348.0  ...  4930.0   897.0   861.0     39.7   464.0  3320.0   0.00   \n",
      "3          231.0  ...  3890.0   737.0  1410.0     10.9  1120.0  1990.0   5.24   \n",
      "4          585.0  ...  1930.0   328.0  1340.0   7010.0   450.0   563.0  10.90   \n",
      "...          ...  ...     ...     ...     ...      ...     ...     ...    ...   \n",
      "11055      107.0  ...  3190.0   759.0  1810.0   9380.0    65.2  1930.0  29.20   \n",
      "11056      847.0  ...  2680.0   357.0   994.0   5550.0   264.0   900.0   7.44   \n",
      "11057      204.0  ...  2660.0   431.0  1300.0   2370.0   706.0  1340.0   3.45   \n",
      "11058      306.0  ...  5480.0   812.0  1670.0   4990.0   652.0  2710.0   4.62   \n",
      "11059      169.0  ...  4020.0  1780.0  4600.0   4120.0   369.0  4200.0  16.00   \n",
      "\n",
      "         9993    9994    9997  \n",
      "0      3190.0   337.0   892.0  \n",
      "1      2890.0   316.0   301.0  \n",
      "2      1330.0   606.0   558.0  \n",
      "3      3090.0   673.0   263.0  \n",
      "4      3780.0    37.3  1120.0  \n",
      "...       ...     ...     ...  \n",
      "11055  3840.0   392.0   338.0  \n",
      "11056  4500.0    45.7  1230.0  \n",
      "11057  1810.0    98.2   671.0  \n",
      "11058  4680.0   452.0   201.0  \n",
      "11059  1870.0  1290.0   167.0  \n",
      "\n",
      "[11060 rows x 16149 columns]\n"
     ]
    }
   ],
   "source": [
    "compress_data = model_a_compression\n",
    "full_data = rnaseq_df\n",
    "\n",
    "print(compress_data)\n",
    "print(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.007151864935536554, 0.0074135171681647075, 0.004365055550787185, 0.009082560852392913, 0.005954732115413856, 0.011034765652641547, 0.008192367216028087, 0.004916744108931889, 0.012292887295604474, 0.0077351988070477554, 0.009145686385356048, 0.010833493658387164, 0.005249681873855111, 0.006429108953404661, 0.013227188941730417, 0.0035066263575004447, 0.011675279571442349, 0.009316998487131932, 0.005411127908146138, 0.00676489453069681, 0.011051974226942377, 0.007311496937054261, 0.0074406567186755534, 0.007361796414018524, 0.0078007693427512535, 0.0046977216793658615, 0.004572300183668797, 0.00492734571681453, 0.007881804454476593, 0.003683317974045115, 0.00470531206990497, 0.005621892309909938, 0.003968114705705877, 0.0075456113503951875, 0.009208814191765224, 0.00458862126404957, 0.003789635097753626, 0.0031665985399701745, 0.005448067037560067, 0.011014041648244259, 0.006410215399966035, 0.011530194057197598, 0.005163450485690695, 0.005138859229666115, 0.003908330494441381, 0.005380873690858615, 0.006828733738021527, 0.004735930285128012, 0.006400093688415605, 0.005354040400459431, 0.004746576707882769, 0.0037684226049978075, 0.0070343247454505535, 0.009645145067197151, 0.006402114893731974, 0.010221776487292734, 0.006411967864137657, 0.002777495808345536, 0.014131175782407215, 0.007354260270597757, 0.00971711961080499, 0.006896842108349765, 0.009885985603959839, 0.008327422597397986, 0.011195845821245824, 0.0036456920383219514, 0.012804195655572333, 0.00578311481465168, 0.0013307873544051113, 0.007337785132473963, 0.006087991454786092, 0.005275670017823025, 0.01068478838416431, 0.007679609928467794, 0.010652106898993595, 0.012178144990358793, 0.0037240728917865254, 0.011227159254782907, 0.0075920899019774595, 0.0036910276819686508, 0.007023442707073611, 0.007208486586985471, 0.006671397103071154, 0.009020236984348201, 0.007712256403305836, 0.005957290409891194, 0.002252521667697906, 0.004648093218347024, 0.0070917947369563755, 0.0028225299001319246, 0.005867125743425412, 0.0050706498629525636, 0.007187189973031806, 0.0042865974574460095, 0.0050041343102718155, 0.0036349463912588712, 0.006296644859750152, 0.010001810587551611, 0.009017581851842003, 0.00904647120093717, 0.009907271345523222, 0.009972108280631293, 0.009753639141547924, 0.0048294407223053015, 0.010348089557022454, 0.005775517367739985, 0.004309278382838324, 0.009649866845874981, 0.006208883673574802, 0.012824555591532213, 0.013763175196826424, 0.006757826596562067, 0.008181504774776267, 0.009342629856328433, 0.011943284557611044, 0.005468017230446896, 0.004853256732408408, 0.009538982637744633, 0.00565475994699508, 0.010546157522830335, 0.005318068552934256, 0.0054015661292195994, 0.005890546443519843, 0.0068136494837155075, 0.00516337440370415, 0.008904350274847497, 0.011164141663926503, 0.005576783735314629, 0.007756666859722324, 0.004675165896663537, 0.005642456933051607, 0.006989469915983464, 0.012071642428548102, 0.006228561236464993, 0.005215982440951257, 0.003285830416455399, 0.005188876662849731, 0.009730779575557909, 0.012417011352343608, 0.009800446960097162, 0.002347371055448289, 0.00683770638213386, 0.005582053604968092, 0.0021208046660669616, 0.007154716689612596, 0.0045670842800153485, 0.005438445663204846, 0.005629005227888753, 0.007675271874607512, 0.0032585682407472068, 0.005279273048295845, 0.0072821524176567435, 0.008594472329450105, 0.008616587660382539, 0.004549189279617892, 0.0025269492558853525, 0.006993743910283491, 0.006763881775461627, 0.00650198960043379, 0.005207258555961309, 0.005605555147641962, 0.004166485683802776, 0.008863068463784492, 0.005717012336028322, 0.005805232245090466, 0.008501478475832313, 0.005623050557199803, 0.007517525565230654, 0.011204784131867236, 0.011884634145231453, 0.003446087686464811, 0.006116092990746859, 0.006548296239687302, 0.008794016070797097, 0.008499148712360191, 0.0062289715714485, 0.009102780042319483, 0.005250375931323685, 0.01364069977141832, 0.004853164404079162, 0.00917839893417538, 0.005191968351920078, 0.010341672306642598, 0.009319465232646481, 0.008701611825292156, 0.004409409299610513, 0.006971756422377297, 0.006824315434255594, 0.004246858099384335, 0.003494430598645782, 0.008919304563262474, 0.005926228642702052, 0.004174946855857114, 0.004536202986500538, 0.009372565572953519, 0.01238036894724472, 0.008136088593558157, 0.0061158821248669835, 0.010667478930345725, 0.0033353865937570852, 0.01193469712754389, 0.011179872766835715, 0.01246392665306047, 0.006321008847958009, 0.009777115945595823, 0.0022063249329716396, 0.006348112299298243, 0.005903757960246704, 0.008159143002374553, 0.0038994743632739005, 0.002656138357589497, 0.007610992096248333, 0.004532956371535869, 0.004493034114287017, 0.007768747669983133, 0.009793461896375179, 0.007440551746619785, 0.007430755067163956, 0.0130177012426438, 0.004632300821464213, 0.010156664999017503, 0.011263482858746829, 0.005574640873425583, 0.009344770695991454, 0.0015422811991529111, 0.004515459653160696, 0.004409381868060925, 0.004198652086833338, 0.004537413673347131, 0.009726349418817653, 0.0067206888923957145, 0.00912086196106977, 0.005370804541574166, 0.010086300670551118, 0.005276151392983038, 0.005815206180067839, 0.011228996761243679, 0.005982318909146938, 0.005742655059915339, 0.007043930393287682, 0.005736001416969922, 0.010952821025542776, 0.002779844130755759, 0.005994320284189362, 0.008653348489966451, 0.007563499373883387, 0.0026401552062233907, 0.004246024766094008, 0.005070696825566484, 0.0022733147314593586, 0.003562880377195907, 0.0034913561571324127, 0.0025702882743108757, 0.005036368178902943, 0.004051222380505315, 0.006405821105733404, 0.0045771385474427315, 0.003957501617500072, 0.003968096391121752, 0.00694320084031933, 0.008805113324914658, 0.004963413121987211, 0.005753070262809068, 0.0030885085477191845, 0.006048446633057564, 0.004857429104573031, 0.004736636175865783, 0.013680131892009447, 0.004031597712480469, 0.011803512266872422, 0.008993295040639738, 0.005768223292464829, 0.003505017614961363, 0.0054299697500202, 0.010525012370227417, 0.005486044257415865, 0.012035784121033677, 0.01106966081002464, 0.004450040625876569, 0.00621406384427973, 0.00878774877692473, 0.005121570505588062, 0.005148913530867832, 0.005025414211701916, 0.013114019572610828, 0.0085224782523722, 0.00627417509683001, 0.004463776008757353, 0.004665561929838788, 0.005991992854897588, 0.005176381322254415, 0.010155604253738239, 0.004584105327005034, 0.0055304160526186315, 0.011491590419701745, 0.004247425067231604, 0.008879270210286535, 0.004418378966980896, 0.005869665436481749, 0.007139067251579599, 0.0052075008045981, 0.005368266527005652, 0.007179001878682103, 0.005318168202601387, 0.0096593940975815, 0.004092211281246363, 0.009574525966320132, 0.011731179581693316, 0.006622956156180278, 0.0057606450356392554, 0.005768068915741053, 0.004768600055138296, 0.010283322843746046, 0.0049781909130375435, 0.009629594572014278, 0.006011744476401075, 0.0032713274147735984, 0.005840053846604747, 0.008219702080547625, 0.007942786999114722, 0.00851242623285193, 0.007362651042024958, 0.006472591909975678, 0.010584744988378744, 0.004180721529406652, 0.007903493968877134, 0.011266870002793646, 0.007557754896064585, 0.006103256523678331, 0.005221918654168146, 0.014715589330649762, 0.008368991046432538, 0.002231004544740549, 0.00947832439462805, 0.005073923209868844, 0.005389033460078224, 0.0033337181120964314, 0.006991446110467899, 0.0049512896901433845, 0.005006287017880803, 0.010927299396112528, 0.007281679264036821, 0.004899068317044378, 0.004080683889859426, 0.0017749061633493253, 0.0021012610799922733, 0.012130439922085314, 0.004512601012212452, 0.0077548355666927195, 0.0058915264369010486, 0.005899416468592755, 0.008964274277947671, 0.010900878929564432, 0.00292036411279341, 0.008039531662072193, 0.002073701096267919, 0.005909877054293229, 0.0028806896401226572, 0.013398496520798034, 0.003522702610688583, 0.006069968605597971, 0.004792757076580513, 0.00940256952142916, 0.005261853614510471, 0.011881316008361672, 0.004921547119261241, 0.002935749337611137, 0.01083535559545211, 0.008765445113830792, 0.005715249567749017, 0.0021412561369647393, 0.006260563578609555, 0.004918808559821582, 0.008769857480895198, 0.0029742778713874665, 0.006903379787395419, 0.006736010578809755, 0.011415071559953577, 0.008692464150692197, 0.007248262735746376, 0.007596316317036516, 0.005154342882456873, 0.0033738023693859025, 0.008248717309910725, 0.006524086954102106, 0.005175170295426234, 0.010206729522343099, 0.009644385563932618, 0.004177054210649561, 0.011315508725187308, 0.00756155011568564, 0.008873334589352343, 0.007131309926975103, 0.0053309458151735364, 0.008591185734739923, 0.0036602102462858755, 0.0027012281914292587, 0.006561950013174623, 0.005893236565081625, 0.008231101338304911, 0.009056408089539062, 0.007686415002022112, 0.00218191847631723, 0.007205832217269794, 0.012897762582997378, 0.009131604029565445, 0.006533428834378956, 0.006813250521739193, 0.0038836081949294695, 0.005902120010722284, 0.003972499495266795, 0.004813608068168285, 0.002562354879663747, 0.010745921587936993, 0.008145033881168193, 0.005238765848556747, 0.010405337185959065, 0.006965416127600795, 0.005172851787530288, 0.0063168382352226295, 0.006429524250287608, 0.0077410066779887545, 0.007547411109490294, 0.0101948732629604, 0.004516802835639776, 0.0033986139460934765, 0.008037513861042426, 0.003968450231645159, 0.0055082648001998835, 0.006191879557207014, 0.012800565638688177, 0.006665569807463374, 0.004510925071371844, 0.006729654965244677, 0.007321409856860823, 0.011971611214690078, 0.007960810683484316, 0.007024848433800894, 0.011983009156739718, 0.00824791219014737, 0.012237116238378264, 0.0034225274732115913, 0.010418498762023066, 0.007221160470305969, 0.011178846220987266, 0.006123223165867918, 0.0023240152376794027, 0.003709504828320093, 0.008176471592207663, 0.007736344673125381, 0.009096562636426693, 0.004340614364470299, 0.010251892037515729, 0.008036936094003161, 0.004641656490514491, 0.005802744063334229, 0.00215947314538461, 0.0057096010007584765, 0.008609050958206495, 0.006591165976207915, 0.010327997110309711, 0.006268445558581533, 0.00790641799903091, 0.010816182461574982, 0.013595169578867259, 0.0016472519691561112, 0.0063748836030487884, 0.0058484923631610085, 0.010512668046874861, 0.00719337615310541, 0.003976838933205036, 0.01408585798553499, 0.007471311913619985, 0.0031385656873618613, 0.005145856522350175, 0.00871524551648138, 0.006580249121815786, 0.005207506942822656, 0.01196447841681984, 0.006250270625026696, 0.009729239679454642, 0.01083574476747352, 0.003221216285100008, 0.004874455291445978, 0.006150153799821616, 0.0027074862512405976, 0.009394507450713045, 0.005719590940632514, 0.008340290592282328, 0.005478481786514612, 0.007839798683117674, 0.004161073242034773, 0.008071374550739863, 0.003946909960885043, 0.007459262954421163, 0.0056774176256327085, 0.0048952730088095316, 0.008690824459944646, 0.011351199533901391, 0.0045724360436028184, 0.014364028666385743, 0.005443618016810189, 0.009591264525208736, 0.007917824542858075, 0.007205431757619398, 0.0066555430575163405, 0.011814037155359582, 0.00440228710592585, 0.0022888876471614658, 0.005505813695416536, 0.005570500248572668, 0.009102205344557456, 0.002268289270998248, 0.006375255852081242, 0.008833861854080109, 0.007958824013978277, 0.007136347750142781, 0.005031167033700705, 0.0013424707254595769, 0.005162441248515521, 0.007711726554225818, 0.00394579943213608, 0.006273767311392139, 0.010184483291170362, 0.0033436239181888843, 0.005166443251411155, 0.00695295667925472, 0.004151342348256808, 0.011285930743461813, 0.00678187718674114, 0.013212920212439541, 0.0029229012186313876, 0.010992560990367467, 0.0038764017153442394, 0.0029431782521174184, 0.00855648370530675, 0.0045104124688829334, 0.005099172996196728, 0.004550075336623561, 0.00592620375876171, 0.004229675674486982, 0.01079213567065726, 0.00419210121545428, 0.005053169158984199, 0.00540178350464042, 0.008368290145806853, 0.00839702043095563, 0.007502475422132793, 0.004741476176704777, 0.003699661166180376, 0.00420278007307077, 0.012310309913541578, 0.004130567475216701, 0.0053447522298209595, 0.007572829487599058, 0.0016663693548652585, 0.006890621437081935, 0.009860483749330172, 0.01225484412600901, 0.00967010710494121, 0.0014864338141805694, 0.006959034360090959, 0.003611954770290031, 0.0026684407332840205, 0.008974648514917525, 0.008685947551139665, 0.0054012338723050035, 0.005136203033531697, 0.011427708565025941, 0.005595019087487852, 0.0057742034314696745, 0.0056058934871242, 0.007939116429521557, 0.005590680903399353, 0.00921277499437399, 0.002463336045139089, 0.007613894493052877, 0.006962107400102432, 0.0077985854810759085, 0.007002776316370737, 0.010896870407552581, 0.005724828693298182, 0.002772174567578639, 0.0036604762371912646, 0.006775083774895668, 0.006259842586095719, 0.009949356046429002, 0.006922586732880641, 0.012149758875057873, 0.009875073354601294, 0.005488515047027465, 0.004403574551071736, 0.011152337608650522, 0.006068230990243246, 0.008284840923074277, 0.010230599167835384, 0.00416932805445932, 0.0019339134430888505, 0.01246932843755845, 0.0041374971185219505, 0.012476001821458749, 0.013809111911182158, 0.0034495387770254217, 0.009119983408897761, 0.010146652385051653, 0.00591392087363978, 0.010055479355937579, 0.005118450104205489, 0.0064639180223667655, 0.006895095629543553, 0.011269197891798729, 0.0045785182105162305, 0.011597549114307937, 0.008682203028851714, 0.009209311610437945, 0.007898556985863638, 0.010368004270359032, 0.0056117019718957524, 0.003659518664488391, 0.0025192286476559073, 0.003439629337466612, 0.0048258710753237045, 0.007310766094708871, 0.009679229396722493, 0.006664936899917696, 0.0050094263476400495, 0.005969335190697539, 0.01175530639904009, 0.010540611618091278, 0.009225497171703987, 0.01004684374509828, 0.001138015481335554, 0.00510118102226081, 0.007779219072306971, 0.010236930011660875, 0.005927598636827499, 0.008165323303815305, 0.004820956807100153, 0.006076360378474912, 0.012977970127694824, 0.007984470083530723, 0.006344946474957317, 0.0016093468972833572, 0.011909093759167986, 0.00500611642039254, 0.007389854600384832, 0.010009566229041367, 0.00650261744830295, 0.010668537467566575, 0.003811834997182256, 0.010119129284308734, 0.009298551660575865, 0.012723257360261336, 0.009655021396227344, 0.0029670635962862233, 0.005100049464585726, 0.012341428839916393, 0.0035003760475542586, 0.008497510843006161, 0.004558921830752373, 0.006083439720403582, 0.00943749299585466, 0.006563648097457666, 0.011944243814024693, 0.005411716753105529, 0.004666125929496322, 0.003989095735666731, 0.011800768034677701, 0.011635979213275947, 0.01164763578169616, 0.0027341825303300845, 0.004080467638759826, 0.012066250530847271, 0.005305862335877496, 0.005303061514373305, 0.01009866141736893, 0.005380485401204263, 0.006488409233189272, 0.0056913504286448535, 0.013338351721877981, 0.004397940570702366, 0.005260591515213242, 0.003413061382644732, 0.009756879989410265, 0.011538172673317033, 0.008550762004165994, 0.0076432932443038695, 0.006531171526890886, 0.00676938588116512, 0.008406993186015703, 0.003956901128914292, 0.004631927227682791, 0.00513644447170526, 0.008063034708467628, 0.008437473542193732, 0.006626643868957081, 0.007263835630129946, 0.006697084222873088, 0.004601849224801055, 0.003624267905967714, 0.010604616404669722, 0.010782180331525518, 0.007218867331528961, 0.005287823497299419, 0.005366841439638901, 0.010654801038354573, 0.010191560641813202, 0.005612388705831374, 0.006196944055916699, 0.005693148065929631, 0.011422030769578024, 0.00541826662831263, 0.007042396788145676, 0.004550559085956971, 0.005249900630548144, 0.0029866585089797825, 0.011335272132938867, 0.0076653872445322, 0.010127761734169946, 0.004673205176610392, 0.006102647390596508, 0.004739452851078624, 0.010137170127391511, 0.005163215140714126, 0.0023746384730807127, 0.009379979158643817, 0.0077960413548170005, 0.004293153822974703, 0.005963380855485803, 0.007879557668623355, 0.00683705072957848, 0.005145721275954056, 0.006010412951850631, 0.0037397112463229956, 0.0031346582435578074, 0.005516368789727959, 0.003388668619053622, 0.012237930364494198, 0.013084118638703391, 0.00928164355197646, 0.006181937127985693, 0.0066247255649838225, 0.0046875804866053465, 0.006691359138525872, 0.0052657964064292484, 0.007231049297107986, 0.005287099091275749, 0.006536750451335853, 0.010918256861668635, 0.009652543284424725, 0.007269044504666134, 0.004227635300896258, 0.0069726353609325786, 0.007004670157385146, 0.012051810540324061, 0.007286483807176917, 0.003158071496426505, 0.007096560378011943, 0.0037236917823397302, 0.004534100828666988, 0.004712073944333832, 0.00720264554931149, 0.01211597904354799, 0.005275786561309694, 0.010108372482585701, 0.005666665054371222, 0.004477844613308461, 0.008710163000252416, 0.004895348171234776, 0.005349293379883326, 0.010618037814286909, 0.009613358953562159, 0.006138106605886824, 0.00884110858852221, 0.012859209054250465, 0.008198949480323172, 0.0022509509176146907, 0.008240431226658887, 0.011248421152493445, 0.008941212238328701, 0.004438341195155869, 0.004420458952487275, 0.0034173621006965233, 0.007326992115575119, 0.008051228482684337, 0.003998164565682357, 0.006675828937816526, 0.0060096961785258635, 0.002149498988621628, 0.010322985848109449, 0.006367359547201901, 0.004865415098978748, 0.0052970206070966815, 0.006208270218341061, 0.009118805867021495, 0.005043741381263619, 0.006587659880040956, 0.002566446456965316, 0.008335685467066384, 0.0128109496204431, 0.008347783585151413, 0.006875688304317734, 0.007216274208389498, 0.0064170272687715454, 0.005595159915071477, 0.008055638631114836, 0.012111526345550627, 0.010008058809948053, 0.0023530127979983677, 0.007827441056897338, 0.004938122690262298, 0.007123890665844587, 0.006545492815198863, 0.012809726526952493, 0.003342572558237318, 0.007925694114298965, 0.0027203316574377105, 0.004389270266460467, 0.00605089338733344, 0.011929349221018914, 0.006004416181939086, 0.00643251132483739, 0.011026850593137705, 0.0039222754157726865, 0.005287496437821161, 0.005483277182904945, 0.004929853697455032, 0.005178762150193283, 0.0018055787976411592, 0.005236133385674866, 0.010609922751983138, 0.006812110611214197, 0.0052759231763291215, 0.0066222958654159605, 0.006036378583753483, 0.010909127823496147, 0.006605632193881349, 0.011777059145264987, 0.009165720014377801, 0.00217201072647459, 0.012141760093415378, 0.008111478136737951, 0.006112527049836202, 0.0036704821177942384, 0.005858277142377202, 0.00722301973887758, 0.005543626113933032, 0.003171182603650209, 0.011985710970100545, 0.006557990971165253, 0.0015382558450337692, 0.0036066385711331556, 0.007994008425422226, 0.005595245089420179, 0.006902945754595324, 0.007572485392220496, 0.006564991238545004, 0.007006667628352093, 0.003885412526743348, 0.002637612332028498, 0.008660793098418319, 0.006209364615469694, 0.005973895641028846, 0.004643123873239601, 0.008062080018274211, 0.009733688332363207, 0.010736241055737634, 0.0025266634164210614, 0.007317906377159463, 0.0035956969274333, 0.0057003524476833545, 0.0032478726165401832, 0.0057998224429404435, 0.0038072119490408706, 0.0048568450250941935, 0.009389464267273148, 0.011025715084675619, 0.0078033011236053225, 0.006339527495118794, 0.0010809778323674563, 0.00474093418778092, 0.005916338459116929, 0.009555295537247991, 0.003416274723648339, 0.006894380192204334, 0.007535098860912059, 0.005326216582743735, 0.003492969717468369, 0.0059577662233396955, 0.0038887035550436897, 0.006357012457456676, 0.005480998304247762, 0.007536731429304933, 0.002236192679649956, 0.005308066787619448, 0.005973698359941217, 0.004991107978160821, 0.004334753168643294, 0.007469659078356984, 0.00409771913971055, 0.0028432627023209102, 0.010719438477290039, 0.006198125058330523, 0.006138026378171629, 0.004541377203311604, 0.0044879723605911435, 0.010987461939252013, 0.01175660047079068, 0.0063055730300960195, 0.005343834087461947, 0.007390471722941063, 0.0015026915758373516, 0.007874942773811844, 0.01156816583670927, 0.00877662744100743, 0.010724165220654284, 0.005666639919592089, 0.004291052566982011, 0.010371854101955938, 0.0029839608654670165, 0.003943075112123346, 0.011427465271729246, 0.006698980704166111, 0.0040881394626816735, 0.008015584923336441, 0.010278646954758145, 0.007996442126990362, 0.005272293382105176, 0.006898636788228161, 0.007713009669138786, 0.005883534815161564, 0.004800602052600652, 0.010684035807793266, 0.008027346458701222, 0.004208865910406285, 0.004297178698869432, 0.009704765990125909, 0.006387944075096847, 0.00857592874868503, 0.0039844334191835055, 0.006834469418388271, 0.005911576923845398, 0.004933752689889469, 0.004957523401036993, 0.007190278710674654, 0.006082542966209312, 0.01210757601205224, 0.007078289871923086, 0.0064842893394011815, 0.005029830935475279, 0.006265837040563292, 0.008324419649661359, 0.008900359913153959, 0.007411744003416041, 0.004687199945293033, 0.010131432835359918, 0.004719237137595685, 0.004543063893780245, 0.00856235842056935, 0.007450959916711744, 0.006779523220470083, 0.009017001436068598, 0.005652845707441775, 0.0026159043858039518, 0.01147403680985094, 0.004677533453671424, 0.006101801675626007, 0.004922983869037123, 0.0031802017942599743, 0.005886924188783147, 0.007880197796841211, 0.006877961778920447, 0.007310772897196371, 0.011935208214642517, 0.004050569834909919, 0.00661972181226512, 0.005935719962948211, 0.007605908060408056, 0.006498976091799294, 0.0072872595137633625, 0.007341990786758559, 0.00485769356757308, 0.0036092740668104773, 0.004651521523562364, 0.004163117152508654, 0.0039035886234107062, 0.005501674864805928, 0.007799337190899754, 0.01097082275425919, 0.004600298119924529, 0.010677729637578433, 0.00600038360638536, 0.00985656996602156, 0.004275090788796298, 0.006407717768182749, 0.005357606269386631, 0.01131958398642596, 0.0068293157019183, 0.005568858424865715, 0.00818373059635662, 0.005417243059704096, 0.0077442802171138175, 0.004400266612358918, 0.006741817801141057, 0.0060891883679991595, 0.010577392259620708, 0.004353546410100624, 0.007632604587780496, 0.0073173782464714, 0.005308734556182292, 0.005941948789127856, 0.004583683379639595, 0.0074935776894540515, 0.004660432183926733, 0.007376702437374524, 0.007186248574985923, 0.003388625889218271, 0.0076144535884715, 0.004177923301791454, 0.00440706963457791, 0.008694381769690776, 0.004874493428730557, 0.007499336101077685, 0.0037675491336840294, 0.0068691897241186595, 0.006198994792896432, 0.005145735745504739, 0.005310324472983848, 0.009993217753837047, 0.004080844960168847, 0.008426893146595608, 0.013315123673254678, 0.006987680722020227, 0.0059515307261932895, 0.0015992439018731347, 0.0038497433037465185, 0.005843105453389609, 0.010040666131026572, 0.003994294298291898, 0.010799327843066506, 0.001225047331202329, 0.00884787709359033, 0.010267646941655238, 0.01095380740278467, 0.006683457425510056, 0.00805380066178914, 0.006626160141016697, 0.004384060974527955, 0.004877497533691703, 0.004411246413461695, 0.005294868646514068, 0.005342692175747046, 0.005659206456904685, 0.0049897036775274056, 0.006688553592306043, 0.0029594108796011536, 0.004226561324449162, 0.005678056902551059, 0.0027934644305801027, 0.005358914071500778, 0.008014803777368013, 0.003925179335061091, 0.009753388980018127, 0.006674935082758265, 0.005909626815617951, 0.008568612779098386, 0.0031875816539776013, 0.0025030912626712734, 0.0014970872541917135, 0.010745002519493804, 0.00473156381068617, 0.004827328720804861, 0.0071697371498499265, 0.003369864487006236, 0.0031686226374340563, 0.009759087169458402, 0.004717004556798877, 0.0058110703630142296, 0.004498689674925047, 0.0033428776685171407, 0.0063461651095392075, 0.00445158883171603, 0.005198185513958069, 0.0018974961584863623, 0.011421791671065485, 0.010232648953023313, 0.01333965398140197, 0.003284452634296345, 0.009789883305649609, 0.011610558369140414, 0.00421997466446624, 0.010290014616668453, 0.006021757602752844, 0.0064482948030073475, 0.005437859800086465, 0.007339205444150922, 0.008752495161781617, 0.006564464782992577, 0.008074483361344581, 0.0034974534625818047, 0.00675665070966463, 0.004304205162373645, 0.01030249841465435, 0.006811819956936599, 0.0027494543666828457, 0.0038871865613168666, 0.008421717359742962, 0.010618649481089551, 0.008144965616273323, 0.007028515744669432, 0.01179051906971371, 0.005220218874744305, 0.003641513395363476, 0.00444370933681794, 0.003666596461419078, 0.007833369665234683, 0.004155779026960599, 0.0066157032169434395, 0.006677889754008001, 0.007070111942375822, 0.004679319527656478, 0.008488245386961867, 0.004778469286868526, 0.00535183629185451, 0.007174775332257715, 0.007833126855306112, 0.006924509166057983, 0.0038871176675762393, 0.006749708104952509, 0.00905987653325621, 0.011396014473756969, 0.008736954574595321, 0.002904272807352878, 0.008730782380881548, 0.006839958701830385, 0.005933358793735025, 0.004586217830191941, 0.003810055194589954, 0.004883851339713644, 0.012625456521098621, 0.00605983402816916, 0.005948379871771318, 0.008639863505889241, 0.00674935982882395, 0.003937089364955458, 0.005034981782193718, 0.00397236442536145, 0.0040274011283540695, 0.01080494820585923, 0.006280943724977265, 0.010107412231588018, 0.006170099585357164, 0.004732793489550132, 0.005995332724721619, 0.01019718165387785, 0.004798331063860723, 0.0037093083571506126, 0.0052418825893224465, 0.012567702780192638, 0.0012573180849128663, 0.0045972302510900835, 0.010112394332307994, 0.004744576826576569, 0.004950339989114688, 0.004607582703054519, 0.006267690299081168, 0.002760148774362191, 0.010604573580325398, 0.012311146549774181, 0.007122635336995693, 0.004062731109228877, 0.005640202644386539, 0.0051404765765980225, 0.004144058786052201, 0.006109409221026214, 0.010308525941238374, 0.004531103524795863, 0.006001371034156886, 0.006755761003388138, 0.0054738427435046, 0.00527373048607447, 0.01219932048570932, 0.005647899831693362, 0.01455342889835505, 0.0057942593330719576, 0.002890790960326735, 0.004589585273341734, 0.008145526853760661, 0.0032182743392013477, 0.005238092003572465, 0.0018057286426357245, 0.005767893274233701, 0.007760705123064502, 0.012964209501880018, 0.003072646271550079, 0.004987887657590437, 0.008674974502952796, 0.007591653700457732, 0.007809248915523868, 0.0011860656804021177, 0.007534161303722923, 0.007780659997281924, 0.004906396670393037, 0.004906079121373349, 0.00648772282100096, 0.004231514395585624, 0.0029060281281914446, 0.005103056106654432, 0.0035536287475348423, 0.007990098412542355, 0.009245389150205969, 0.001504547941507533, 0.009119258608124261, 0.005068290547586793, 0.004182470472171982, 0.004896784855546676, 0.004531638579104716, 0.006117159946730781, 0.004718764477745275, 0.005482603992849456, 0.009290040649982376, 0.009318204095789274, 0.004012882212722507, 0.004358801697646944, 0.00817006642594683, 0.00530524903907066, 0.001734396422023136, 0.00487264578624626, 0.0034473062345641388, 0.0019752301618973424, 0.0028812807233938816, 0.006235880293099256, 0.003108904930150102, 0.012525384399351214, 0.005280943346795918, 0.0023526656199845137, 0.0075411614061473885, 0.006785091610273977, 0.002963250808880964, 0.004314185385521252, 0.005350521464222244, 0.012330394442153603, 0.005683219924398127, 0.004951855292044961, 0.012457972244778176, 0.00699933951673597, 0.005728680218213329, 0.003957464198793171, 0.008604696939048914, 0.0037373805482619968, 0.0054587946431656625, 0.005157403982585613, 0.0031339791929904637, 0.009818382921213408, 0.0034395219749414614, 0.005242367795545412, 0.004122826398985312, 0.012687274027183962, 0.004257983072544691, 0.009370743344689653, 0.002859322213651847, 0.0032678857517783443, 0.00899869355049561, 0.006324958362863389, 0.003286029875294107, 0.005914248402717379, 0.005932815665158853, 0.003429798781748021, 0.005205998105824891, 0.007765001409079935, 0.002891438021059477, 0.0076675327330328535, 0.00850129221146424, 0.011522380969986274, 0.005833542822044851, 0.0038592952775032222, 0.005814580060491412, 0.008315549945386958, 0.009875402218552935, 0.002425415696186683, 0.0033925056002069263, 0.008057829378373188, 0.005380703603465042, 0.005103180122778674, 0.008010238920688148, 0.009919793916354974, 0.008725237237409762, 0.009114797271109778, 0.005993457065123076, 0.003637333289788538, 0.0017070166578117484, 0.0026176737611562006, 0.010458135909575105, 0.007657229867024124, 0.005255008730392352, 0.0038815262461619968, 0.006009424241463883, 0.006549434325105817, 0.004560565425966731, 0.006931514518334362, 0.004229328483833975, 0.005870364760443463, 0.005941912251859996, 0.0048137148697347774, 0.006241469648528182, 0.004762644477698957, 0.012884677363258597, 0.0053898261367164284, 0.013025670547371648, 0.00514256087984136, 0.0062130749878457, 0.006148233198749084, 0.005930964552886053, 0.007121287432150291, 0.0024624544311786416, 0.0027371351879313987, 0.00300224056607094, 0.006347040665916615, 0.00801218513797683, 0.006517697668138391, 0.004712961816322914, 0.0038869713668952667, 0.01053492118519369, 0.00562124883381045, 0.005829689139379465, 0.008442060979124923, 0.006068202464315085, 0.004159791874223799, 0.004077618211172161, 0.002812007767635646, 0.010185661761565986, 0.001940153620973566, 0.013371698989069456, 0.004692473154295888, 0.012073607639380379, 0.010213240810885576, 0.002935502786226656, 0.005879429216019304, 0.0023811793135238646, 0.006411777160960357, 0.0038536325319919974, 0.009646076350342887, 0.0047635251185437245, 0.004042426209735231, 0.006333911851534093, 0.0029611689526023474, 0.004934783470861801, 0.004317907596099622, 0.011559139111286374, 0.002588926314924015, 0.00858370688614736, 0.005905353866349982, 0.00654643300435339, 0.007987148293855741, 0.007806762412599038, 0.005376860630841056, 0.006345362939787061, 0.008226372238756108, 0.008068814562305017, 0.004367534686114116, 0.006582384584649756, 0.004296594599477569, 0.006850541950728667, 0.0034170167387295976, 0.004338137612485021, 0.009423345900125729, 0.002742365613192983, 0.006016791728445683, 0.006882358257577409, 0.0070619789003587615, 0.004493226674620606, 0.004345401014666099, 0.00443664434412098, 0.012255998572701952, 0.012514302588017532, 0.011578413620526709, 0.010426992716171247, 0.00497432519337407, 0.007751286002971818, 0.011359567177588036, 0.002460906750523571, 0.011403193680909475, 0.0034606588077021375, 0.004352356648651175, 0.009210610301268346, 0.007669722185776071, 0.0059771169562836055, 0.004536203601595658, 0.0025410665382314536, 0.007502863180988302, 0.004129695989165956, 0.006041934259774182, 0.008550217866897311, 0.0038217633494708764, 0.015277901973859127, 0.008110294926096849, 0.0036667836362325916, 0.0031547655387495427, 0.008600419500486454, 0.008561068060097694, 0.005245359149257705, 0.0036764489043224647, 0.007952275490471165, 0.0035996657414938855, 0.007494476815856903, 0.006069056146274829, 0.008055608190010725, 0.008462945731135343, 0.005580350819443061, 0.005045856400779925, 0.00351919250034526, 0.003371176266146825, 0.011717684295796034, 0.005432807239492677, 0.004155363135284739, 0.008407817734212134, 0.006880146870996416, 0.004024506668953847, 0.007625965996705708, 0.004527933053563995, 0.011081856338261458, 0.009624913507405403, 0.009269405707294905, 0.004298368830532423, 0.0068371392909406265, 0.0037904882949688847, 0.004973589176414952, 0.0037890350317672738, 0.0038918764075601114, 0.006397476828549228, 0.009267601508422789, 0.007558175064993062, 0.010432477935475186, 0.009042827893424817, 0.010831730124151185, 0.0071072467449590435, 0.004296814575151746, 0.006916984136739236, 0.007023711718638591, 0.0064683994293175335, 0.004816724309496272, 0.006157423793254028, 0.004957264349076959, 0.004018370816825087, 0.012013687253976855, 0.007813098803671373, 0.002414325017010664, 0.008468037850849196, 0.010994244933822615, 0.005274824867000711, 0.0056363497006313105, 0.0075163380036361496, 0.0035944203494984485, 0.007058009944849792, 0.003809334606548236, 0.003818840630954329, 0.004673225095894611, 0.011465853148185729, 0.0053693306413516405, 0.002887457537310942, 0.011315730892066035, 0.005318237606803394, 0.005545978943044276, 0.007724175323525607, 0.012042506652960885, 0.0068135832578064635, 0.003244213119646861, 0.007108691292166438, 0.005912034890786437, 0.010009489664189401, 0.007016815998408758, 0.010672915753115962, 0.004453989515732267, 0.007966212984034752, 0.0033534958370056585, 0.004864669146685934, 0.005777506663565978, 0.00698463129245638, 0.0076543395219333035, 0.012062453159663158, 0.007245937177817243, 0.0018957830161989903, 0.005109719993850943, 0.004853743021634034, 0.004264246207103009, 0.007894348568781767, 0.0083728111094486, 0.006913485797384589, 0.006542262807313241, 0.008650840809122297, 0.003961341152715167, 0.004158396783641139, 0.0059198706905127995, 0.007864553353660415, 0.004342874070274046, 0.005194107651667504, 0.009484195283079002, 0.011007249125079692, 0.004862989844042439, 0.011158020480909366, 0.005291811475011921, 0.009520523429869353, 0.006559806291343174, 0.00702218973636083, 0.011569602522861572, 0.009832394852698243, 0.006927961480210594, 0.004072909979755424, 0.0013097123277494745, 0.0032693249570437274, 0.0069672876682006085, 0.005544048679129072, 0.008329170915928174, 0.00894864505013105, 0.009098377488496671, 0.005762502410219522, 0.006176590949168494, 0.009139523331941395, 0.004053945350343126, 0.006418666701931448, 0.008453698695864374, 0.005967051449833204, 0.005333696023291497, 0.0048577070708914795, 0.004703767939826767, 0.004893541437879898, 0.00906598461404054, 0.009699193217805643, 0.0032997921934293383, 0.002332918289341166, 0.006642502272678728, 0.004152450409286919, 0.006491136282884058, 0.0032684273188995426, 0.003974852590631913, 0.004587418771780455, 0.004991193878566225, 0.010879461912204355, 0.002448423221177032, 0.007824582417165066, 0.0019192402514836315, 0.006189990376204079, 0.014469982722058104, 0.0033210937161835268, 0.004255986506765657, 0.010147003595730855, 0.007189338421878853, 0.004784758507910771, 0.005326125767747126, 0.005071272303999009, 0.011025970055998487, 0.0019235761121601516, 0.0035132131321127004, 0.004989045328776026, 0.00294645882998987, 0.006992759507566821, 0.008699835278031018, 0.005179308204334441, 0.004480111821804175, 0.004592458791427217, 0.006623899209602994, 0.008095316790862249, 0.003296642251876566, 0.004288152649852597, 0.004906669026767718, 0.007785873613093943, 0.004913127210333182, 0.006042517661873737, 0.00693196167957292, 0.004295980539867853, 0.002926232033839356, 0.008712953378657172, 0.006539539844117358, 0.0034585328511249963, 0.012042377701440956, 0.01243401119304491, 0.006423541855209505, 0.011417848221576871, 0.004945482538898287, 0.005021522892886158, 0.004600154464356723, 0.007251540066084512, 0.004280789615986918, 0.0036960387731504903, 0.004092029870147917, 0.0059921827150465, 0.0022832818876890376, 0.003594405972673796, 0.004782041014387589, 0.006300959510986491, 0.006930098854638257, 0.0038422069729936318, 0.007229914281738152, 0.009344153738306438, 0.00688730641882603, 0.007905518823176437, 0.007794749127688743, 0.010182632956910773, 0.008107062063822027, 0.00441648101245329, 0.0035281770458230536, 0.0069554271283766905, 0.0054650635437265265, 0.005711771513925063, 0.0036802759388847098, 0.012883003541240811, 0.008708307525095611, 0.0038837978621478965, 0.005111956634472364, 0.004012118850236052, 0.007781872929521854, 0.006898329808338127, 0.013120154118658486, 0.007499101388291899, 0.00534199671480449, 0.009792579650731601, 0.002659762321022112, 0.007134596766810658, 0.008107423416648083, 0.006365469375491103, 0.005774653172297724, 0.006642458664058323, 0.004386153972240845, 0.007100030825027113, 0.007011603975176873, 0.0054884597961914645, 0.005788952595746317, 0.011368881207690654, 0.006088266086183106, 0.011867375714826923, 0.005718332708600742, 0.0052058764889794905, 0.0042470649290705246, 0.011608965118260798, 0.006443873013176794, 0.0030594408209217443, 0.004873275109062124, 0.006315741268227874, 0.007191431764751396, 0.006311981004034331, 0.004267876902017777, 0.009786720185804492, 0.006126905180559744, 0.010144273031444027, 0.006926203803132929, 0.008260388959284375, 0.004146907130883521, 0.010947835117160402, 0.00854506517964934, 0.005018929626234876, 0.010097109992533045, 0.0036081737741587507, 0.010910572975893696, 0.0028922373120150403, 0.006165881252233936, 0.0046374427491957205, 0.004943317929016108, 0.003711507261649185, 0.009564991439872859, 0.010548932786026217, 0.008747293890078413, 0.00720133791125184, 0.007437277633958217, 0.004989037077464625, 0.0068972027618436176, 0.006673491168610667, 0.008591440397188968, 0.005703693356629774, 0.0027856728530187627, 0.006811024055350776, 0.006818415737544301, 0.009186113542073104, 0.0032131698364282492, 0.005095005825482969, 0.009746434070785386, 0.010860314874762215, 0.0025470965011849065, 0.004008914094212086, 0.01018875442923111, 0.009214876516409056, 0.003242491060900098, 0.006273072697000354, 0.009288632375199394, 0.011160656151357902, 0.0042760876708886056, 0.005263692765680049, 0.008123999783579021, 0.0047369956797973884, 0.008331679186669015, 0.00884554846032782, 0.007233114176070917, 0.004539340600659328, 0.004125841159778092, 0.01260125171341827, 0.00708184588992235, 0.005292767298663199, 0.006225891865088082, 0.011184357942663424, 0.006332775079879087, 0.012849936378591678, 0.01293378350642865, 0.0065347279575309345, 0.007763407191725042, 0.005319468151416047, 0.004932410877861845, 0.005291064198819369, 0.008989353211671186, 0.008950788423108272, 0.00953749681132804, 0.005326777239152534, 0.007201185890383599, 0.005686049708563125, 0.004650275537583725, 0.0074893585363521595, 0.007143577219275641, 0.00375120938043222, 0.00409397908154208, 0.009312063438610848, 0.0031628207528460748, 0.007628700857334934, 0.006729568200053039, 0.0062989415680992904, 0.006993631623237195, 0.007291268692996174, 0.008512279105467068, 0.004960446828253846, 0.006376381770732624, 0.004194375452183863, 0.003968899572292879, 0.006851307495691984, 0.012998404319793568, 0.0046720481939508075, 0.01173704842052339, 0.0036562890901186626, 0.005636740716444872, 0.010629185629820903, 0.007063449283931436, 0.010718478068296424, 0.011804676231528885, 0.008550874791506019, 0.009215629808080677, 0.003968983933793569, 0.007269392643035872, 0.0025445917170871407, 0.005953358902535585, 0.001908714421820442, 0.012992953761370302, 0.004878208641576173, 0.008114458804853385, 0.0066643464740694415, 0.011389653300748481, 0.008900697265815863, 0.004881367624859782, 0.010555699629292804, 0.007492349730321325, 0.007570906578030005, 0.007824712385862046, 0.006102461267339151, 0.007560377839616224, 0.0054736477701595124, 0.005395188687694655, 0.006573332800366054, 0.004233288348449446, 0.008614647996067894, 0.011222455118034262, 0.009610270715362322, 0.005425766975191942, 0.00801660568099757, 0.007605005588286927, 0.006760336013913899, 0.007032228108827622, 0.007329015180775018, 0.010913163295161767, 0.007850298730525722, 0.003929502133350596, 0.005371414222246576, 0.0057917253022656675, 0.007985258597910813, 0.005628784703527813, 0.009976079738884334, 0.006810812032270207, 0.005539097528430159, 0.009125616917566397, 0.011408393931611834, 0.008371969280568763, 0.006432673090840927, 0.013127350759035096, 0.002409087227067021, 0.005396407068368871, 0.008468344952434814, 0.0044276158049058375, 0.013162041064486475, 0.010147676925110038, 0.0034547213115549264, 0.008007911468773572, 0.0046351268580774475, 0.0044678851170805505, 0.0022312376057958745, 0.0024241325048270247, 0.005273613983995498, 0.006937596114854628, 0.0070797939051034375, 0.006625077598797944, 0.0070190941802446, 0.004033535840435079, 0.005689999150007587, 0.007526840927460676, 0.005980765494224761, 0.006934606375125352, 0.007103591004540617, 0.004549884591755495, 0.00688185781623985, 0.007602532180756443, 0.0055038817629523475, 0.005685299529162427, 0.007634676111232187, 0.009923433105735173, 0.005851786677331978, 0.0067942133140284555, 0.005703078081658418, 0.003637045000936479, 0.007809115036583037, 0.006372240696232056, 0.0025883879153992175, 0.006329406167063642, 0.004463978406245705, 0.013717075065527624, 0.005082692203643098, 0.00835825278426236, 0.007616428110752131, 0.007897666177679612, 0.007742220331342071, 0.008366747138059138, 0.005092644240810731, 0.010982348407229534, 0.00782536780438277, 0.005202003997562417, 0.003019014004667417, 0.010878702220809854, 0.004816298182104379, 0.006598230454612555, 0.0035414582441220983, 0.009321418308137125, 0.0058644224448437116, 0.00603051670089973, 0.009415439358927026, 0.007070208315785904, 0.004784685334849645, 0.005662140477123645, 0.008135956886218928, 0.00759636636809121, 0.009734248730527868, 0.0059122408768049195, 0.0037174437958931252, 0.010942308626723744, 0.003717551394608057, 0.011166570230798187, 0.005543821334599487, 0.004192304575270542, 0.006004838757566935, 0.0070908183302021595, 0.004435075925413786, 0.0043455565612832625, 0.004943574563324685, 0.0026677205913497905, 0.006140451219280879, 0.0064987895650701144, 0.005330863886847894, 0.006145287579386977, 0.003925291056618375, 0.003642429724093588, 0.006217173630757547, 0.008042209064259056, 0.004318350099805465, 0.006436103477768174, 0.00470433233350222, 0.005242983699439986, 0.008300676753288173, 0.006930088277691537, 0.006054757729611256, 0.006246478147001298, 0.004360618417592778, 0.006299552455299512, 0.0030332572111274334, 0.006251679781608, 0.008058586985067586, 0.004137014792029561, 0.009559504519346838, 0.008881596026258726, 0.00548115355070031, 0.009238197650248525, 0.004759031599685545, 0.002297403156299282, 0.005940498727650495, 0.003859733576872584, 0.005838935761207104, 0.005520157707892182, 0.0035384661144223766, 0.008157730015317667, 0.013174458492972054, 0.008468703120510046, 0.004335801832487387, 0.003976652736780446, 0.002648545384327152, 0.011307891313055499, 0.012299606696278614, 0.005623780246264184, 0.005176857679442231, 0.004778322454119736, 0.011182854274824738, 0.005485033841967064, 0.004472218200888217, 0.008085651884432459, 0.00604953003607067, 0.007620719536145895, 0.008507962184025284, 0.005795945329488916, 0.005912545406001856, 0.008056202882808576, 0.008341449525750683, 0.01184419757318679, 0.0052622763408961964, 0.005198285859001559, 0.003617030602181606, 0.008068423964757584, 0.007075871688381771, 0.0072371321839016425, 0.009433196557617946, 0.004900339608617165, 0.007927098025912353, 0.001439016119422887, 0.00995999452441805, 0.004787481823557142, 0.006383555095970753, 0.004994905895191458, 0.0041993857198881, 0.006847641020485045, 0.00476638748125403, 0.010867016210954275, 0.008148783727991105, 0.005057577577384084, 0.007973838105151518, 0.004806661875034692, 0.005682248592067753, 0.007732861347551909, 0.006533963109369692, 0.007844108224188859, 0.004910924495685527, 0.00417291186669847, 0.009587398934374497, 0.0054643366289283835, 0.008770000389342376, 0.011608328910365241, 0.009406104596502221, 0.006217794329572205, 0.006808560018727163, 0.011196050793441884, 0.004501727936277399, 0.005045749092254393, 0.005059374166346799, 0.004858917910975445, 0.008494574179910994, 0.0023851238579932167, 0.012404224180449109, 0.008182951357852495, 0.005646375832988246, 0.009237704215422627, 0.004287569358148441, 0.0020233445656914328, 0.008930249233622699, 0.0034171025245514786, 0.008982683991282742, 0.0069166963288769395, 0.006090099847572484, 0.004872225331645072, 0.0038546107996282365, 0.007179611476419856, 0.006004887969287571, 0.006649666732139135, 0.005085668291549434, 0.0034011071969512587, 0.009139224968059374, 0.00493743685409349, 0.004727073271064334, 0.005649793798067236, 0.0053143933351439705, 0.004942373873324151, 0.00789288262049058, 0.006863423280461335, 0.006941420783325907, 0.011587448910452942, 0.0062766128658677655, 0.006068143190345801, 0.004090357182892373, 0.007442266151555656, 0.005933301166027353, 0.007797261837846743, 0.005103755719814695, 0.004487643515187295, 0.005052170212258516, 0.008451501114430302, 0.004534063131440602, 0.009617009542453571, 0.004483704634551477, 0.010513853920019387, 0.006495352720357462, 0.0058165889652182275, 0.007981862133518586, 0.006538022879031738, 0.003023304350050521, 0.007009626828881772, 0.004890029411293557, 0.00753079016395417, 0.009241929655520884, 0.0063366664074422235, 0.011832251598294496, 0.0011815795941038417, 0.0061881766732044, 0.012593580201470691, 0.011346631733702862, 0.004586891719711269, 0.004675504083152022, 0.006848880597564401, 0.012611957901782817, 0.007480322264207552, 0.004628867084316762, 0.005072447416260365, 0.008673287877653788, 0.0070723031072992635, 0.007116271522244685, 0.00633948499579336, 0.00848713891091045, 0.011119809025394339, 0.005347536042637026, 0.008024185941442701, 0.005949971541217227, 0.010712313656365394, 0.007478425645310424, 0.009039969713286841, 0.004127923319367982, 0.00342798597480758, 0.00780056412917233, 0.005315628738218302, 0.012837067135268347, 0.007661540480573417, 0.006812446039051961, 0.007072714876057568, 0.0064685903855745, 0.0053178993068621954, 0.011231559807877697, 0.012125125807831651, 0.005471110841219728, 0.005581826746148876, 0.006225067800473685, 0.006704104873649552, 0.010353683970706077, 0.006419654900153077, 0.006302153640664796, 0.004516649332885189, 0.005105082459150647, 0.007259980681739561, 0.011002547351886171, 0.012327675419114099, 0.009005777546402544, 0.008188281469085566, 0.0036134599363416902, 0.003492248229220109, 0.0077102328273403724, 0.0072127662299132506, 0.006093297238239831, 0.009061916432236135, 0.001398947113293486, 0.005191373078771818, 0.006670896769411749, 0.005517734229007181, 0.006086578516340041, 0.007535459551068919, 0.01203817308073223, 0.005372355833332491, 0.0015101028287457202, 0.009331107477868828, 0.007049129646006288, 0.0052613381724392295, 0.01285011802871352, 0.007471519129016595, 0.003904688679350345, 0.005557860383351987, 0.003619722452468039, 0.00555781292571925, 0.00586276373395697, 0.003944130921967128, 0.0035158615092372343, 0.0067726205360583835, 0.008074849572239163, 0.004943151020485884, 0.006339885381104973, 0.0044140419027395225, 0.011575394833544202, 0.0037845157325009132, 0.012904607267938356, 0.004737451639423426, 0.0011710212379269142, 0.007015339160783092, 0.004068522340974195, 0.005330085426594255, 0.0051754897680033945, 0.0019019071296002684, 0.006435506861949868, 0.009763366966028132, 0.0041712203570182715, 0.007711950617545585, 0.00644055317660317, 0.005717757143006573, 0.011078600679811541, 0.010728012539927502, 0.004918906628789754, 0.004206307358892845, 0.0016263082444212635, 0.013253508515962596, 0.005262891245386931, 0.0018805951297245643, 0.005380855883512356, 0.0056744438022087226, 0.006822784060015812, 0.007358384940205793, 0.00871075307546245, 0.006169862123431985, 0.003664309420642697, 0.006780577935916436, 0.0019502990128936796, 0.007982108353631221, 0.0036392268158930386, 0.00906840343135015, 0.00532650085526102, 0.012258868364174717, 0.002368434003686159, 0.005467788554116541, 0.006103202027323208, 0.0054998971485326715, 0.004953854991576797, 0.0046528195182485195, 0.0024864221182735835, 0.010689210440923934, 0.010105477984848761, 0.005585397431865488, 0.005196640906257639, 0.008004538213520878, 0.0069798159948065595, 0.0016284593646131611, 0.0052588480130965586, 0.01134237580670234, 0.004771226554080713, 0.012111106178797723, 0.0054408328440382365, 0.004061086557305236, 0.011051935570831084, 0.008526163058780475, 0.0029749239838469206, 0.006861437411283901, 0.008424576223781108, 0.004275887925445691, 0.0016842976775300444, 0.007090191673851014, 0.006956964913863414, 0.013179777685810757, 0.00951646510632396, 0.01073365647634568, 0.0043275396777653855, 0.008532044936883193, 0.006000761395834241, 0.007754094095229658, 0.002238658893029606, 0.004255248448461984, 0.001523991403034552, 0.0038912822273216774, 0.0057106937106536845, 0.01348141644366397, 0.004219237925371838, 0.002257707026119004, 0.00861248615182182, 0.002972585178835566, 0.0036810601670717973, 0.013352994271538824, 0.005004502827410626, 0.007471739378280064, 0.007430904427220206, 0.007552584971522571, 0.0032806675772244363, 0.005115474803636715, 0.004814162333560327, 0.01129997584661283, 0.0049148678584898286, 0.008659725920788914, 0.0019111154900332901, 0.003446607855398311, 0.0039050570285881336, 0.004866486058031215, 0.008710741088483433, 0.0029454340971970666, 0.00480968324802665, 0.008118911846977286, 0.0044725321158661435, 0.007250405817201123, 0.013349127176910978, 0.011699149546264272, 0.00564352591162163, 0.004959104182235151, 0.011047241080592466, 0.004950840594518187, 0.0068375642564352315, 0.008568377118058204, 0.004738461423020765, 0.0018625850122935307, 0.008266432382664071, 0.005172389892325074, 0.005915770145304088, 0.00807132583098709, 0.009553965319369268, 0.0031793902234020883, 0.012453285120597648, 0.005276584005196136, 0.0054988040789216205, 0.0067071609539906705, 0.009898665330105003, 0.006220823319097056, 0.009061321891454456, 0.007732581547545374, 0.010696390043911607, 0.0036986536914394015, 0.008099021864263329, 0.0058359363560822495, 0.012201236435463607, 0.0050111210658097555, 0.006961090782737328, 0.006308825876016387, 0.005977029903468145, 0.008370437937684898, 0.00777024535162811, 0.005586740080039701, 0.008602575896876482, 0.004249611732437131, 0.005874957682060042, 0.004577453712994111, 0.007144191246093606, 0.007290846289906936, 0.0033352522452152165, 0.005268116804587357, 0.008789066713247997, 0.007340254178520323, 0.0018760157183987357, 0.0069509949774731435, 0.0057096630077256485, 0.007282799237479347, 0.006071082970952876, 0.005083619704314202, 0.01020604265987506, 0.00942289082494525, 0.008616976957401263, 0.004959659793089236, 0.003926795787092043, 0.005467340771692909, 0.007925147747872245, 0.006731862653691088, 0.007202815162858128, 0.004893635000515933, 0.009945755898813862, 0.0066301656333737505, 0.005962267951852196, 0.01119946418055127, 0.005596966378492314, 0.005073765625871423, 0.002585948949577756, 0.004742289726595416, 0.01091772745739219, 0.013046713615324841, 0.004525036741817234, 0.006145033889597079, 0.008126401016997943, 0.0067180160191334, 0.007763435402996554, 0.008962779485226557, 0.004517708603911885, 0.004613396112574348, 0.0056360593842612085, 0.004745403861885966, 0.01127489680595246, 0.0109635127307009, 0.007582684322165432, 0.004440072033889963, 0.003825481122156444, 0.005444812271087089, 0.00819670791242893, 0.011406074340759081, 0.012731113160710896, 0.009890815727098535, 0.005318223682470085, 0.007132258271460006, 0.004642617709182359, 0.005296852474304586, 0.01219807785140484, 0.0077408490960216925, 0.0041855410756587936, 0.0057237589567610565, 0.0039172712036811795, 0.003475382567159145, 0.002336186746384965, 0.0063937252544119805, 0.005067302490242832, 0.006624637679004446, 0.004404739610924196, 0.007661142420124333, 0.008834352765063442, 0.003768933344966006, 0.003604779822089817, 0.007813404392511762, 0.005393625315600474, 0.004589544739896294, 0.0044960222410320196, 0.010689819951737851, 0.012564901568234265, 0.008213265455552128, 0.010366289844460135, 0.004393420816526691, 0.004424609203435881, 0.0056221601988756175, 0.007105450226979561, 0.005629514266581305, 0.003170042464128899, 0.0026650076535110114, 0.011716178256889484, 0.004787489178635138, 0.00954801766717243, 0.007887309391614325, 0.004504368221292594, 0.011209230638968965, 0.007385010525398072, 0.014016387719299722, 0.005871008580533598, 0.006461044891193866, 0.0059112048979595554, 0.00551171583206481, 0.004994814086847852, 0.00457673370933104, 0.013613479382593819, 0.004905629123988653, 0.006342491339994669, 0.005388957755508669, 0.007855031240715798, 0.005334239667318098, 0.011809613187983986, 0.009264860366082327, 0.010634248887623224, 0.009167258282672112, 0.013532679937300254, 0.007849002463012815, 0.010212602755434567, 0.005194987695955867, 0.009813257391853264, 0.006937762445634598, 0.006775317632739813, 0.005836450588031101, 0.003923772583607651, 0.0032888258444842148, 0.007309863947595578, 0.005130762309064799, 0.012183367912498879, 0.005929713611034368, 0.008206745487001187, 0.00765688115250066, 0.009432427950108051, 0.01257049099559062, 0.004763319179453775, 0.0062775531576463005, 0.006937232195025192, 0.010047687372494209, 0.013176512466266239, 0.007763623571863195, 0.004955659199042813, 0.004213095627966372, 0.005238612168337797, 0.006486471542230625, 0.003920428443073056, 0.010100199139810756, 0.007915583252438504, 0.01031714469840117, 0.011351257758126178, 0.009166070978068208, 0.005919661812812782, 0.006147191010904119, 0.007023680082581695, 0.007795421286352184, 0.0019761585447474563, 0.005462780256309301, 0.003679565441303016, 0.004674037154914108, 0.006421928827732673, 0.008062360846557641, 0.0019186205295895421, 0.005992808022264233, 0.008209360488695859, 0.003535747431457942, 0.0061647498213491265, 0.007009745445609578, 0.006336128517587337, 0.004708130423937947, 0.009393306622270583, 0.006652800245522275, 0.008473480233959222, 0.003583407367329815, 0.003191102539355429, 0.004065626545890683, 0.0064387476488500656, 0.008684901695718944, 0.007650526567910501, 0.007813256665519444, 0.008973333157705692, 0.004013306842362542, 0.0098377277265515, 0.00972200335149424, 0.0034958919023289257, 0.001936191447569965, 0.00527999486836623, 0.007745751444976292, 0.005665092082894578, 0.004559619955002633, 0.006337416093337788, 0.010268088175861008, 0.006431143614049294, 0.009772364614513739, 0.007397507376527399, 0.00518636582660825, 0.005093516293989268, 0.005117346940726392, 0.005641872442830399, 0.012310424334352409, 0.003407284421877258, 0.004816855032673494, 0.005404795898473314, 0.006673818991416412, 0.0071253938754951346, 0.007506387630222459, 0.005766467085027075, 0.005108292606897958, 0.006880683207920927, 0.004292302988300045, 0.005067552634145234, 0.008049758803289852, 0.009880174083674337, 0.007904248853896935, 0.008001560900768308, 0.004617593048469144, 0.00683405698524988, 0.002378933246160818, 0.010709323435213344, 0.006210005002384259, 0.010331986572941885, 0.006085024532789507, 0.0062181961207791745, 0.005452836879745912, 0.006314309946443779, 0.003157684505341686, 0.006387115848422902, 0.007458582954927325, 0.00612701000073213, 0.007940107114516547, 0.007508433920421451, 0.004258005144701449, 0.006615224255019269, 0.007620181124462821, 0.005073733216261634, 0.006767510311041829, 0.010981614528804348, 0.007695936407073534, 0.010229940427160047, 0.004561326435229265, 0.006806996105522422, 0.003731344970794444, 0.00988457863265844, 0.004681861243298973, 0.007119598897240482, 0.008694003279391486, 0.005015484059310006, 0.004103353404968396, 0.004435231030441303, 0.006723186208240494, 0.00520048949201761, 0.00899465603127729, 0.003901090173689927, 0.00747204580369993, 0.009382747692255323, 0.011522027225326987, 0.007103732941472386, 0.007131495483645618, 0.001556814368499108, 0.005074838321518654, 0.006811254911933099, 0.009995182580034002, 0.0013030213639521333, 0.004517061699936667, 0.0024587214123018234, 0.0061375027585840805, 0.009006856499338325, 0.006265742503523224, 0.0033647529564557023, 0.005633607141031208, 0.004690585509465472, 0.005621924467427986, 0.004536964480637368, 0.005620557353079715, 0.010050705214657549, 0.006683453329604618, 0.0018967801427892572, 0.005054659687314965, 0.011445117447533456, 0.011956899273692078, 0.006243062559221141, 0.005204955859453598, 0.009758681343082859, 0.011909799837284948, 0.005216631995014091, 0.003633695160293921, 0.005803191504370872, 0.008385331828991581, 0.003920318985863251, 0.009658002534695332, 0.004784075416944175, 0.006796078775082579, 0.009894732392085624, 0.012827365354599995, 0.008640842053557694, 0.0015477228946304971, 0.005512935049369328, 0.004950350968700837, 0.004489399723995082, 0.00901183057625249, 0.015578755748178599, 0.0020901226914975205, 0.0032732768279670607, 0.012333017906094626, 0.008071551240562441, 0.00771895401821909, 0.004571316319084074, 0.007949203751631048, 0.01307893986452676, 0.0056667676014264985, 0.0040852662567309305, 0.0038603313762640627, 0.008543018962984074, 0.005119219355302693, 0.005682695784025204, 0.008730592411485839, 0.009652313773434762, 0.013103117329214497, 0.00409667707465878, 0.006952741492001253, 0.005841321273343915, 0.0036630917170915626, 0.012508991020115556, 0.005033762678056549, 0.006311499818626492, 0.004662227576586791, 0.004083196897569069, 0.0035187835359256265, 0.006820163718525238, 0.006671955881576316, 0.009750911348011895, 0.008588482968861553, 0.006704442032667982, 0.00370862806722285, 0.006821094904987671, 0.004762647978815255, 0.007271072217399989, 0.0063841218543646255, 0.006172938247344191, 0.005997735659310298, 0.011519498686295551, 0.007807498456657756, 0.0026769331855270966, 0.0090924031990136, 0.010058461961151023, 0.0061969542815054224, 0.004767354907244196, 0.00408938503729501, 0.0044409721540177565, 0.011856154056144232, 0.010421399950030148, 0.005739792055489098, 0.004663991992437848, 0.006221909597578167, 0.009502944728153186, 0.006458604193264437, 0.007326316166624387, 0.0014911465548742087, 0.00697041264566702, 0.008657150831056283, 0.012426442081672085, 0.010283150399585373, 0.003917274183026222, 0.004846202796516499, 0.0019206757250477455, 0.006958421132554029, 0.005634520881403837, 0.010550929690963634, 0.004736897243193891, 0.009593602832527519, 0.009133666195268612, 0.009879233459024542, 0.007603363427444822, 0.004266703100034978, 0.005321677929726598, 0.0052035048380826504, 0.004684571051882611, 0.0075956364281481, 0.0027301124328827195, 0.007194488373956176, 0.004448576633266176, 0.0062235375663272675, 0.002941507662202515, 0.0033992354994160498, 0.004171904795359935, 0.004205241134229303, 0.009303886575462637, 0.010501402315295248, 0.008496822508214662, 0.003986823978066134, 0.004650567752934767, 0.006798394072426722, 0.0040581580891760685, 0.006730463740341602, 0.004013410330212756, 0.005843302408067684, 0.011068875068042338, 0.006785007105999632, 0.007189328248357801, 0.006855536249187725, 0.006945058716308259, 0.006571677389896693, 0.00876635100313261, 0.00461156833718344, 0.004331503406436462, 0.003485832647646096, 0.007844984349935788, 0.005306382592087704, 0.00460580129079729, 0.006014174213617895, 0.005685253268260039, 0.009871232245450392, 0.0067175184143931045, 0.005815886144781231, 0.006783313005324041, 0.005092661247726173, 0.004109586163905589, 0.0044767288552644245, 0.007350499218061062, 0.01180887228789797, 0.004725747820871222, 0.010930535383648389, 0.0038867175543728216, 0.006191601019030844, 0.00768667410321305, 0.006601389272797428, 0.0047912303661912, 0.006098760516871178, 0.007667320069924139, 0.00838241789782916, 0.007518140611134209, 0.010534288532717387, 0.007728911264074524, 0.006887620444231657, 0.004282187271219058, 0.00412605868592746, 0.011148073520868343, 0.007377195714191044, 0.007778597895758753, 0.005725284848752819, 0.009783280931367343, 0.004858348817812777, 0.0027143332579132326, 0.007544766591899246, 0.005234124098932416, 0.009328107636576686, 0.006352078086959806, 0.004856087141105567, 0.009639234930107213, 0.009096759541231264, 0.005466606565501438, 0.0065891773983671065, 0.007309087719505829, 0.0067526006967013625, 0.010563857351897975, 0.005762872731057105, 0.0072002544784283, 0.003697585218527104, 0.012326388243516694, 0.005872061990426216, 0.008428227379841214, 0.0026931631094098485, 0.008684586788103164, 0.0033007549805061354, 0.0048140004130600815, 0.006209429125194572, 0.006513590457482905, 0.0070741361171295395, 0.007862710536209544, 0.013058523594735683, 0.006026854471321412, 0.011814139162829314, 0.0025336329789450275, 0.0059813990018659415, 0.003736691647048253, 0.006166516293769219, 0.00659139088373921, 0.01145304387407433, 0.01286045832900435, 0.011147518930439585, 0.006885188010233227, 0.0059648617827639675, 0.006025593487937171, 0.006360037511885119, 0.004167256093579792, 0.004563794752744753, 0.0049240079904729495, 0.007444711125189613, 0.005458879318816694, 0.011273757967984719, 0.004132384397048885, 0.006471430216333011, 0.0063039048695534, 0.012976919688079791, 0.0026040859477557085, 0.005736229584033623, 0.010931966598618156, 0.0026724997364178083, 0.013013810456745649, 0.007787956281308607, 0.008302470741884747, 0.00404939596155, 0.009659460255226198, 0.00952417633477828, 0.005568467710353508, 0.005958041130997462, 0.004782573412317494, 0.00731395027773388, 0.00175893810245157, 0.00546446666083799, 0.004599798833953185, 0.006292202418421511, 0.008157199149409648, 0.01056585249171964, 0.0030785463060993253, 0.009189637064435246, 0.0065692462286081905, 0.006433442729845769, 0.008273965075833854, 0.007205803839380506, 0.007628050620443015, 0.007315370574178156, 0.012555094487573746, 0.006804776589701188, 0.005654245308970916, 0.006813901059493484, 0.0067772398621670366, 0.005382616509066175, 0.006116702110569507, 0.003955808325445474, 0.010612232300365437, 0.009150784732745595, 0.008797824632602116, 0.004318845024084063, 0.00724088358457734, 0.010352592893438036, 0.011293755148266336, 0.003239470348089927, 0.004591936711322042, 0.004631381002077541, 0.004519221214631465, 0.012800960056147753, 0.006538562569684381, 0.005665608177168646, 0.007703102592730209, 0.0059036161481180955, 0.008324786885308695, 0.006179651107610702, 0.01026989095502301, 0.006797508731057887, 0.007020548861850422, 0.00713096702591633, 0.011139708910860524, 0.00464165601029588, 0.007911532448559144, 0.005951227661997007, 0.005509092042955995, 0.0025182617239595715, 0.008665855106320671, 0.012118298918165665, 0.0037232955988433015, 0.005573902680567048, 0.008129154516383616, 0.005271056064319766, 0.007318589304365221, 0.011852704797721084, 0.013743678161230987, 0.003283927696033499, 0.006821880559131868, 0.008018693441498288, 0.0037369959420732847, 0.008785415929837895, 0.013155169608932999, 0.008055023147179966, 0.005092161998899984, 0.005403675278765591, 0.002320632617749215, 0.00675694573590456, 0.008658032181234933, 0.004976420932818158, 0.005455940487705223, 0.004664825775972444, 0.005512787780685485, 0.012672777865132656, 0.0038074054482072723, 0.005955922307531454, 0.00999564077262142, 0.00886413612007904, 0.005229427634654747, 0.00377398594929688, 0.006473856645951661, 0.005275679239125757, 0.007375922144879306, 0.005777653440294491, 0.006984329563465296, 0.006736690544189057, 0.003589503185546491, 0.0058069546707754625, 0.011614360044921272, 0.010961206251370047, 0.006942993530104731, 0.008462556846149338, 0.005535926059443208, 0.007013758307266216, 0.008720267354592389, 0.006009414187557943, 0.0021639869172661234, 0.005767881025041714, 0.004696233501749658, 0.006267575831121516, 0.006908122166602072, 0.0047974113582076455, 0.0012329459846556355, 0.007951276778071281, 0.007044898126142351, 0.002703847995604667, 0.006114680354378976, 0.00504957616643055, 0.006744683131977947, 0.005589184106574977, 0.004468854627172141, 0.004754240188399719, 0.005047035367359416, 0.008221766909893314, 0.006204582692747152, 0.010780298586547186, 0.00250952486585079, 0.008052724586519837, 0.0047493758104008394, 0.00612773082003336, 0.008869411353008057, 0.004400745477964868, 0.0054587955665691525, 0.003880760533185127, 0.00498955642805511, 0.00922453510556308, 0.005845737878682172, 0.001795876496505968, 0.0065958410473736465, 0.012326614915418286, 0.010679450421178745, 0.0034109593724052758, 0.0040123348469524745, 0.005187912139306538, 0.004087520271973685, 0.007601119500892532, 0.013858926164351661, 0.012699087317717126, 0.00413078806711812, 0.006430795020562307, 0.005194212736542913, 0.009109709043719057, 0.006341721393008054, 0.004394842475416901, 0.003308206961036833, 0.007686194237619065, 0.004824187861707474, 0.00852753886314639, 0.006399116017517127, 0.005637220778086633, 0.006226533502910068, 0.002946708240565174, 0.006977891277160888, 0.004230024858381145, 0.008960320692188297, 0.006595907983425318, 0.010590325843506514, 0.012772727909807227, 0.00727710530269693, 0.006567995705840696, 0.0041777265210019374, 0.006378141617963946, 0.004706090992189653, 0.012562028922702233, 0.007529304613727474, 0.011479702352844616, 0.004225157750633731, 0.004316237076522645, 0.0021311724793341698, 0.009024221110700016, 0.01077563982997862, 0.01349913117544535, 0.006954348661649674, 0.005126787322030084, 0.006705864520669211, 0.010895620941505625, 0.0037246396209056083, 0.00634539317146955, 0.007450116943845686, 0.013167419955134404, 0.00973107885415524, 0.006255109044665115, 0.005658200527461367, 0.007144701949413173, 0.003367666132017378, 0.005238084743650791, 0.004893527351075651, 0.005915612668620741, 0.007292465014531348, 0.009573993034921787, 0.0029714841585369257, 0.010800921048644083, 0.004984275478878853, 0.011208331444589145, 0.008540642918087933, 0.004363624198193086, 0.005561249204161159, 0.005124663213689612, 0.009344449536611055, 0.010407418601259055, 0.0032116539888332038, 0.004232597636679799, 0.0054671069041661476, 0.0045222516897354716, 0.0088113228088692, 0.0027060523914020362, 0.004485462400999198, 0.0074056828460545695, 0.0051192988130881, 0.006692135314100631, 0.004384636456952307, 0.0028728674406349464, 0.004167788600105322, 0.005450102101506078, 0.004149987702854324, 0.006196837496889674, 0.005855643845060201, 0.007476627131928116, 0.006951236807754044, 0.0021076300181365752, 0.011071314647468097, 0.003913700821295911, 0.011736029331898296, 0.004681148906429429, 0.009088536418088187, 0.0038101563067734342, 0.008160602919658866, 0.00539342182499684, 0.004647088469410905, 0.007772705787524779, 0.004070713630665137, 0.005497648311609471, 0.006112882136343351, 0.010110907073801412, 0.004674457150161724, 0.006590746751813048, 0.0022760634570005104, 0.006638138341345618, 0.007507945881433595, 0.005542698020756638, 0.004993548517206557, 0.007650684696771975, 0.0017831963588262583, 0.013392199909065004, 0.007611859901220198, 0.012015402643653004, 0.0031235200733756977, 0.006755860551256198, 0.006448770406506185, 0.003489296045486566, 0.0024355931701597333, 0.006701676472230474, 0.0072857162976906285, 0.0033522357955052175, 0.005385293671791981, 0.004023768870588347, 0.006345021096768134, 0.01382015996274368, 0.006733623996058022, 0.005654709898658893, 0.0038378498225875744, 0.0036055405547908027, 0.009785837011131436, 0.0037029086725204915, 0.0061831813701132355, 0.004329646252642444, 0.003994265993456143, 0.004011184956179764, 0.005797559847538677, 0.01230369153511902, 0.005848281512939138, 0.011053348931184832, 0.008246017180831525, 0.010586275220840467, 0.007629778767129345, 0.009648255351482584, 0.00465586700403952, 0.004377366765390836, 0.010560739685604732, 0.005428675628274466, 0.006980820015678879, 0.006508463723851731, 0.004532817681993078, 0.009611765957512192, 0.0074478768143324235, 0.008157809761128494, 0.010537843579312839, 0.006837967600119703, 0.00625300935436755, 0.006344227380921694, 0.0094220294744869, 0.010055883678479285, 0.01201337485321985, 0.0059951282049056295, 0.004424643047052803, 0.004614380256347312, 0.0024354955291768557, 0.007497089057479593, 0.0013691994415484597, 0.005691490264993401, 0.00650671977264008, 0.00989927386431929, 0.004812586747590144, 0.005222847587051512, 0.009374246829290962, 0.006130994610048927, 0.010463092049841458, 0.010822613387766796, 0.007239100060571709, 0.006747589495859479, 0.004175769094449113, 0.006672811961725089, 0.0032647707010485558, 0.0032696054169085286, 0.005601172381200117, 0.00754165306329969, 0.011635058503423102, 0.007189941522897305, 0.015318993071450796, 0.006234454136086221, 0.00897014772002222, 0.007138931358465675, 0.012532364836770067, 0.011765985965953792, 0.006239681949009782, 0.005661979526283743, 0.005581032044909163, 0.001858411093273338, 0.009184084916833387, 0.011677422019160461, 0.01028277035144853, 0.006278782047384745, 0.005329904453288695, 0.006427849528050082, 0.012369105355133005, 0.010499015776627305, 0.01458222604128951, 0.012806013818471679, 0.00761290419637738, 0.004225980001219596, 0.005155282261012396, 0.007070114242885894, 0.00608615321113967, 0.001961469762451178, 0.008530820850007025, 0.004169840995155408, 0.006028883961239816, 0.006907206860086453, 0.004772642071632112, 0.012344831750266062, 0.007287930217085706, 0.006405656675148785, 0.005613897314240791, 0.007036221961669751, 0.00692984368700984, 0.0068636675536766795, 0.010700108092369168, 0.007948484737709375, 0.004757174405674315, 0.011007348906826277, 0.009218331995792656, 0.005360185956467336, 0.00823875292591813, 0.007226144008829911, 0.0063141611476697284, 0.00759052490779938, 0.007076846550314684, 0.005253891128083697, 0.011524975907675152, 0.004141065269637714, 0.01250409694862506, 0.004869835422443421, 0.006936937883031526, 0.008263349127443155, 0.007932742616613116, 0.006888004350300703, 0.007316916861104114, 0.008518222570761246, 0.007006815854124965, 0.007113102439744404, 0.005756923347096755, 0.006877989690358945, 0.005656026399822102, 0.007945405373533743, 0.0035659053712068954, 0.0037801219198940524, 0.0046528951739413, 0.010105637629131603, 0.006598737752925077, 0.0022134803644935064, 0.0036158566917647633, 0.004734576753700379, 0.004937512003762885, 0.008160181299495382, 0.011224750675185847, 0.004218952315685057, 0.010113617058610328, 0.0037289875950927334, 0.01050604452423768, 0.0052933269193532004, 0.008913505765119888, 0.006951223058245736, 0.01108957006791116, 0.009692690399048574, 0.00590811694821263, 0.009744102589172023, 0.004240901099120302, 0.003391019672599249, 0.002663094523469718, 0.0028719519694325388, 0.006174601122382421, 0.008141931562147896, 0.007996632026845824, 0.00526370609180569, 0.011844697401206108, 0.006333227784231957, 0.007823484212438576, 0.0061873330284049075, 0.009978523791654158, 0.013349153488840054, 0.006627712792018039, 0.0064828847298378164, 0.0037552315502203783, 0.005870018215456818, 0.006726769601766743, 0.005084191270156224, 0.002513793997154072, 0.008838794902327463, 0.0020063124997657723, 0.013773652531939039, 0.0058045229904525025, 0.005100244358471168, 0.009961043692314044, 0.013829408356279793, 0.010565275736155403, 0.006479178388183931, 0.005323970853251484, 0.00727157856459615, 0.003914294636516567, 0.004233816621924422, 0.012767449488770885, 0.0035523260417677483, 0.008909301058769255, 0.005108502020053984, 0.005000112180180338, 0.009059771129877884, 0.009489599466818504, 0.007320163030492088, 0.009013993468488593, 0.003945239302880642, 0.012995851582884927, 0.0052452389214849085, 0.004463323885276697, 0.0019892829447276635, 0.008502391220034856, 0.00866242187495267, 0.003637575839721059, 0.008759685276067922, 0.004274156601947451, 0.011312528728129677, 0.004724417323936563, 0.005742015085939767, 0.0043110241353491435, 0.0057368902610532855, 0.0052014109669835384, 0.010970769924307979, 0.0009777976265968854, 0.005435060949813731, 0.0051846085079065955, 0.014896735411258265, 0.0071023644589288185, 0.008381825322380732, 0.007381275622209188, 0.004531871582299267, 0.011886919510454863, 0.006029210625263398, 0.004668680336468884, 0.005035995195365321, 0.013699152269013514, 0.005844037186419153, 0.006038928787081783, 0.009549627836376823, 0.007861407891435421, 0.006582050460026776, 0.0063704296427431525, 0.006097383473096034, 0.006429956271186937, 0.0032750976376055676, 0.005546286334250533, 0.006868755270532219, 0.005535769584898962, 0.012841627224511735, 0.0065636227644913035, 0.0058072885953984795, 0.004697048131231953, 0.00748327696798739, 0.011605963216197016, 0.004969484469203346, 0.011427110952251917, 0.012091709395441155, 0.002760256286701348, 0.010864433880492472, 0.0049654099615373745, 0.0062364111241281365, 0.004907156357030543, 0.006614486552211644, 0.004493384288711765, 0.004867635055992763, 0.00857105458715047, 0.004236627678606455, 0.009258244118885027, 0.00196780662243119, 0.010370812234176845, 0.002807576656758253, 0.004564790642905095, 0.009487294683304824, 0.0072149817550746466, 0.004290773709140196, 0.0045875975332147064, 0.013183718682085295, 0.008093414931355795, 0.004907277673029369, 0.0028955112710694363, 0.007473419663957035, 0.004289536009520133, 0.011163365127439429, 0.004525324098447369, 0.0058372284800477636, 0.010614036812548019, 0.011923470517324957, 0.011971827902805425, 0.004266966632718656, 0.007265111833598935, 0.005518466939092815, 0.003125686013932346, 0.00809497482086578, 0.005436279630517226, 0.008374095278399649, 0.0039824339411675645, 0.005071688694726672, 0.0060445629228012545, 0.008119847016467521, 0.0070958596458949195, 0.0032233334045154004, 0.003373180518481397, 0.010953105293368497, 0.009567465094320169, 0.012063123108554457, 0.0075953614673405, 0.005846697373762419, 0.005607365077065749, 0.005159548443019657, 0.01160740009917599, 0.009303379696026511, 0.006558932770785026, 0.004333322150159735, 0.007066728505251408, 0.00613759667898172, 0.013548882586868965, 0.006340131277046449, 0.005182353882947372, 0.00799597101200821, 0.003013753928704486, 0.006361035243452691, 0.005910116050984869, 0.006514962092186178, 0.006190203581820304, 0.011811628121897164, 0.005738848296554395, 0.005849024756194121, 0.00592735707159949, 0.014060786547665592, 0.003938155970602186, 0.007440525118733969, 0.003964577948210687, 0.005869130604070492, 0.002962247023330813, 0.009333531935189834, 0.005533986294944276, 0.01143657594918953, 0.009496143729231694, 0.004604560593158259, 0.007031058259257036, 0.006675159989867085, 0.004007711855653177, 0.00607305253220706, 0.004779716586851441, 0.007561761174692513, 0.006049393695522736, 0.010550158078778935, 0.0076659415414452306, 0.005578718730795245, 0.007185080998413185, 0.004740068353596867, 0.004355798960053612, 0.004594364323103197, 0.004574183251985089, 0.010456119764107756, 0.011191533057033222, 0.003994459283462936, 0.002906926638158008, 0.0037325955569014724, 0.007150846376459546, 0.010283753910609403, 0.005289820597953064, 0.007299379579639421, 0.004967489993098543, 0.004992708615632967, 0.007057193924127314, 0.006980090969262991, 0.005025867986686968, 0.005030217439427187, 0.004099269241708608, 0.007650347210642217, 0.0063229341497327216, 0.004167595714225602, 0.008011864073668266, 0.0030288033615923117, 0.005251124940175061, 0.003016341838992227, 0.008525242358116823, 0.006513130880726978, 0.004396409733142526, 0.0052787542258280785, 0.004237200721709096, 0.005319344216594137, 0.004831366212503008, 0.0014028076198811844, 0.008099621087368001, 0.0044226813910811956, 0.0037825484570638513, 0.007529490063038038, 0.0029483200684519784, 0.005645821962712853, 0.005880807473681207, 0.004609857050164099, 0.004420783511322186, 0.005266524899583278, 0.0029447662845551626, 0.0051631249242213, 0.005126489411390585, 0.011820139067706438, 0.004373276359512606, 0.007526109885225181, 0.005532446184050567, 0.0111745896455199, 0.008545931158172149, 0.01108287735334456, 0.011910189778561002, 0.006088915413609425, 0.005270690126108157, 0.009105841932579701, 0.005286107778479816, 0.0057747334302776804, 0.007438847442508115, 0.009197251417069802, 0.004322827490704805, 0.005753243527354611, 0.004592997159265266, 0.002093458841490511, 0.0043278424643968805, 0.006951446232485161, 0.014396613042618642, 0.010276067268814209, 0.0053275041563221725, 0.007846885729352908, 0.010436553233735681, 0.005738271931402057, 0.008400327509485451, 0.0076404466285757335, 0.010460001301265297, 0.00226910214651141, 0.004932300823785931, 0.004342452180529529, 0.006412804552580639, 0.011487836533547785, 0.005587199515328291, 0.0057214368955885685, 0.004905412390031876, 0.007739257291747938, 0.004080247083999799, 0.009126831408581266, 0.006763030773319141, 0.012764268527776308, 0.008908509691458035, 0.007352101609935489, 0.00812378490230867, 0.005833673730919707, 0.002901305375210524, 0.0035461859201368637, 0.003092081125020052, 0.004977686040758414, 0.005564370481716353, 0.005350502437895841, 0.00766553164064792, 0.007424977341208474, 0.010466857805893825, 0.009245307662360995, 0.005400136389357818, 0.012425203507079189, 0.005764952357698756, 0.00549524887996642, 0.005104814136336207, 0.004878032461143695, 0.005626918711747225, 0.0039067930310418605, 0.0041389815878089325, 0.006974439672645324, 0.0071903384377510066, 0.008587469085375544, 0.005137943915055414, 0.010585865324758421, 0.007707977101007305, 0.004645009882940829, 0.005079737037746285, 0.008017882561396485, 0.011727972309502472, 0.007817775301023781, 0.009154528572031894, 0.0048116958179360856, 0.006393635051354784, 0.0027547711103785054, 0.012465016717176477, 0.006713455679585642, 0.008408646366186625, 0.008814322329687856, 0.008676871077089497, 0.012639109663502563, 0.011220045162514663, 0.008602111567672526, 0.0031183398377556413, 0.009645477640264521, 0.008119412066601578, 0.011997153700104166, 0.00420229529523058, 0.002190967261287589, 0.008754149440343667, 0.004137222802733497, 0.008726026865487017, 0.015632445581582284, 0.00429570623269652, 0.01105092691392551, 0.006403069654785713, 0.007186313581092848, 0.005145917146278642, 0.005119842172859581, 0.008971878605257406, 0.009519906731929966, 0.0035834691430421525, 0.006835037948895147, 0.003911214283931649, 0.0038149735665862403, 0.004155116791865744, 0.004876607421053595, 0.004959238818022715, 0.0043744338345825485, 0.004331272098016644, 0.005186881825523799, 0.0061451000890800755, 0.001859545036272797, 0.0030477397855390225, 0.0036429054318041615, 0.010188900160241196, 0.0070243974230653795, 0.005860281244324848, 0.004415920192356029, 0.008540552374458598, 0.007477633332564913, 0.012068337249127696, 0.009833931361570153, 0.0037267757978565923, 0.005518770491046455, 0.012610397728849242, 0.012561809277269766, 0.007074737833689993, 0.007430512265798824, 0.004705180498951847, 0.005096805234649497, 0.005854233139990568, 0.006014521453010031, 0.00868383517944195, 0.0055574341362925606, 0.009171518911252174, 0.004458823959554714, 0.004917168112203955, 0.008230470943093258, 0.012924203628981635, 0.007475222578971628, 0.004962916378361172, 0.0037929461677156983, 0.006131042418837206, 0.007030442405978773, 0.004118421134251239, 0.007958272974711307, 0.008923308529131516, 0.010433276772515716, 0.007319496285565323, 0.009743077662418224, 0.005216718909531247, 0.0067062069963715, 0.007816259015590615, 0.007995763422894445, 0.01054487475024987, 0.009263307351317748, 0.0034017004438168514, 0.001230390013266101, 0.005978879201356779, 0.005756236465184122, 0.00926282891679678, 0.008637659071990881, 0.004863339903128622, 0.004642389962509338, 0.008010554364301141, 0.002647720420265042, 0.004609590237669485, 0.004500003198398473, 0.008398302050337921, 0.00736859848865035, 0.003598476220090704, 0.006435623625816428, 0.007721414928558616, 0.0038505712197089625, 0.011805074373122844, 0.005820402177025021, 0.004183839194901115, 0.007503728605116286, 0.010870306222908356, 0.009996268513334355, 0.007544021669528154, 0.0019558266023078346, 0.007570589970772404, 0.009521507935623858, 0.011821827379124981, 0.006526761052493699, 0.002567611216947237, 0.006638475658235936, 0.0045021114484303905, 0.004178569860610572, 0.008929027195116585, 0.010797696624877503, 0.00893456763344844, 0.005618444662009185, 0.013306479717947402, 0.007437058997202076, 0.005157646806475857, 0.005509428885851266, 0.0043258910514072865, 0.00450247135721957, 0.002669815405086264, 0.005841279649925324, 0.01072934178390976, 0.007856052294977439, 0.0071901534560078525, 0.004409712909387348, 0.005064023789100658, 0.013358813831708168, 0.005680288743082873, 0.008155726055008358, 0.007091902948364121, 0.006748042896137569, 0.0050127345775308665, 0.008404087494818756, 0.004411047301203391, 0.009520227055578073, 0.0051783895816745334, 0.0017143433091629094, 0.0060388457759615035, 0.009856751815269387, 0.006462617480701115, 0.008205498865068475, 0.006598649579849453, 0.002743806090925312, 0.008084078828607826, 0.005289831275551066, 0.007614810138357297, 0.009402297220137388, 0.010015805168294213, 0.006565632535591627, 0.004166044344305583, 0.012049113479619311, 0.003595656428593011, 0.003899510805280083, 0.0057539055796578045, 0.004507027500720802, 0.0031033159871218245, 0.0077238958655587095, 0.004959387379888621, 0.009983500382233609, 0.008120093144608424, 0.008733379492952935, 0.005925996838368079, 0.007925885167833567, 0.007456303518813276, 0.004884701124388651, 0.0029252556822385364, 0.007585422802117505, 0.007278311797148954, 0.006742047209682283, 0.012043965084602534, 0.012457397401754566, 0.006164722459565248, 0.006235553583852877, 0.009205573609491657, 0.00717077133359522, 0.009244085189690963, 0.005160103269025108, 0.010576329452939383, 0.008655977072041235, 0.004975856338478076, 0.012824187254104051, 0.00580175869533835, 0.006217447944170058, 0.008322604325201537, 0.0047145490490173025, 0.004339102652224114, 0.00443748802961735, 0.006870349481931362, 0.004370626308900729, 0.007623624320414024, 0.009621648614166877, 0.01185744609143676, 0.006559507341440663, 0.006655544937032375, 0.0077190650618022254, 0.007621166566170031, 0.007721768206161837, 0.003076936923596836, 0.00619554104152887, 0.002318611319930127, 0.003311721996119877, 0.008180285726351853, 0.007852743860837855, 0.0027429255884618008, 0.010329105614796441, 0.013714991632721198, 0.003646973800136127, 0.004501829038002579, 0.00271869898232957, 0.010683022788491078, 0.006212017118056857, 0.006914294535267143, 0.005984217368863088, 0.004760393455541039, 0.004063226162015982, 0.005983151844329805, 0.008872853661889918, 0.006135767426841964, 0.006600511089520335, 0.0064890934578075475, 0.01201317017318059, 0.00579106438207872, 0.006784047530205846, 0.0035951045693265052, 0.005290090695569696, 0.005176132758439445, 0.005713667261176666, 0.001281712184239568, 0.001689203583903069, 0.0069945895232498365, 0.00803256631317643, 0.009800847022737317, 0.007456381641005294, 0.0066826153301133995, 0.004693103741448306, 0.008463811702592604, 0.0035270445739045055, 0.002698551463817759, 0.00784504832630228, 0.005414376835860268, 0.0038680727686506624, 0.0065525223909254394, 0.010797209145596641, 0.009699093878540281, 0.013916638981216258, 0.0041767018353945345, 0.0035870294682973838, 0.005785241363995969, 0.005044586454186663, 0.004788753157407819, 0.011692801826473486, 0.004775357599580884, 0.005766747129141667, 0.0018136881381309704, 0.005913513101409512, 0.004025953706539624, 0.007868620230820423, 0.006691576638768329, 0.007919548133930393, 0.010944840132058523, 0.007102053030956161, 0.00704921398807069, 0.0076863980448505, 0.0056824261324043696, 0.006078577393446739, 0.008117244993459501, 0.0014389929674504228, 0.010466658913785648, 0.0067707294778754975, 0.005257843085697034, 0.013194484059040163, 0.00574785286221367, 0.010666310752641805, 0.0040510890745146895, 0.00576353441031461, 0.011845380673146779, 0.0036848571737246143, 0.01329771114007217, 0.010675260458707666, 0.001513652085750964, 0.004695884023608393, 0.003500687943677859, 0.005461055683867364, 0.004829725719142272, 0.008095570903362756, 0.006773208561178393, 0.00561486536558617, 0.005601962528374733, 0.004750848483770785, 0.010305121913486233, 0.004353926174893267, 0.006074981430459467, 0.010072245227032716, 0.005193579312295038, 0.011733162264313805, 0.005611644075895053, 0.008717488752545792, 0.004329880019759531, 0.007392453577732613, 0.012463087627638189, 0.00526923356096792, 0.008807852542956154, 0.005445892333628671, 0.0032797775610883496, 0.006083069773477549, 0.004791326431852073, 0.007790316135419055, 0.008096771714403487, 0.0062630447094361216, 0.00520477929389015, 0.003620300579228382, 0.005199372695367965, 0.008911738228133922, 0.004388046893487979, 0.00504068886927416, 0.009356894756836764, 0.004092189299022613, 0.005136022893078572, 0.00948792353542477, 0.0030276575702543906, 0.011663112223125625, 0.004157955731365116, 0.004332924541726306, 0.005870991911267779, 0.003287615631797592, 0.011742264198766006, 0.005313994403762951, 0.006068959784484661, 0.003718167963361364, 0.004373639321695721, 0.007917102600609165, 0.0056770858821929395, 0.006788393847991934, 0.008470713077660329, 0.0027134134048529, 0.006317319431870841, 0.007189499966335153, 0.01222338067306485, 0.00706366360378891, 0.0075256949923111875, 0.005854371572003031, 0.008043204813695599, 0.007359808649460384, 0.010590739762638832, 0.007008627526231533, 0.007254027636307631, 0.005089889585028379, 0.007683502902266808, 0.009362567114015768, 0.008283443470817622, 0.009718509416059114, 0.002068853047870474, 0.0036551576059305445, 0.0028563823608753367, 0.009065142183725396, 0.006326951614996452, 0.009789203816795693, 0.004282303277649887, 0.013587379690538678, 0.006076472354131699, 0.00707670760964948, 0.008545712396892141, 0.007454977301155714, 0.009261036576277118, 0.005565483171314499, 0.004552445624441943, 0.011422275999217541, 0.00725256339303192, 0.00861407826388793, 0.0059245182881974955, 0.006643639900704442, 0.006048163822806377, 0.005628493206499095, 0.004344156431763434, 0.008264493318516267, 0.0044422386444974435, 0.011302162147574808, 0.005714901740567975, 0.014638976981927447, 0.005046227181199414, 0.0025549992919954518, 0.0056739391665575085, 0.005720031057849475, 0.007764551476472262, 0.008019633923269338, 0.00391746621979595, 0.007285114804668285, 0.0127995102001941, 0.0038437132848790218, 0.00994665529113308, 0.006628807321522488, 0.004584862894760935, 0.00700923166402709, 0.003971539474338655, 0.009233386237446618, 0.0038969825921279363, 0.01000122190858235, 0.005944546884326527, 0.004167471123319948, 0.0018173036380240738, 0.0060407773528726085, 0.0058726389821842, 0.007883302087347903, 0.0029084991675450123, 0.007386310297729086, 0.006271897136853422, 0.006412770592857444, 0.0071828516376934645, 0.0039478931595040715, 0.007932356153540739, 0.007260301511942344, 0.004505100136057656, 0.005133493396553114, 0.011591864306588056, 0.00501971261290962, 0.011469155991982515, 0.0029482605498294566, 0.005430544157714956, 0.003302218506691819, 0.003409932615826828, 0.006937591221440247, 0.0037328510027564484, 0.0049445036257856605, 0.005904975501370733, 0.004806748437893074, 0.002756411653546812, 0.004520549839145648, 0.00472531764708692, 0.006841361687125359, 0.005745958447766337, 0.005597943622883011, 0.013463880987696346, 0.007372142370440564, 0.0025890103408508563, 0.011537961072116996, 0.0037432440145047626, 0.008957884396541283, 0.0061491798359691735, 0.0047730144549847225, 0.007960820388574954, 0.007705321827957415, 0.004167987733121963, 0.0038373071196690705, 0.006347834188730457, 0.00898429385267481, 0.006604478808797956, 0.008387610891096298, 0.005756199822223631, 0.008331950217608684, 0.007731752972942326, 0.00495327774439785, 0.004341145525986012, 0.003207907934442668, 0.005256670535669334, 0.006664316030964767, 0.008443853435525967, 0.011420027457858965, 0.006102709585661206, 0.00816769139504447, 0.009353287215562712, 0.0054528964939966245, 0.004501373780940894, 0.004732860397051244, 0.004630926984798642, 0.002189212129589094, 0.0028129328722937006, 0.005585903306517359, 0.0009679082243980613, 0.004122892202065813, 0.005024141166543461, 0.00876522633807117, 0.007205941405708037, 0.00697293090318782, 0.009998756743702455, 0.010576609353539834, 0.0045524389126353725, 0.004768874930886467, 0.004217912750310238, 0.0053994952029864695, 0.004616060092367529, 0.00716323902319513, 0.005385031828307028, 0.00730853728491432, 0.007555598495471296, 0.01073413242726911, 0.01033781900658278, 0.010983460205732097, 0.0037653330838615705, 0.007741225672572629, 0.0053212914779288325, 0.0014432128792289433, 0.01087463690458526, 0.0032998803909396663, 0.002931209328053678, 0.005436696514535233, 0.0040667264895600085, 0.006236626709601211, 0.008587811160293961, 0.0042512084135363885, 0.0012288911404109391, 0.005154912321603734, 0.00992535675178735, 0.009582012219474818, 0.0023578718789761238, 0.005499325533402922, 0.009580517348556368, 0.005102687114947479, 0.0026003090840178555, 0.0070988793359668114, 0.004377507478239716, 0.006541982951969842, 0.0025971402681687263, 0.007363344459124753, 0.006240121495801907, 0.002482481965212941, 0.00977641951125921, 0.0047411732094235805, 0.011314830343873272, 0.006495382915868899, 0.0085788428569642, 0.004858665840252961, 0.006379513306702737, 0.005130232072093389, 0.0034821080753999565, 0.00900272277121985, 0.008437374673397413, 0.004679295063819958, 0.0069075931795569276, 0.008299198164526674, 0.0076569041511193306, 0.0036602027348048285, 0.007046328317050258, 0.00216601613899624, 0.008744484904719463, 0.005000046859076893, 0.009411412358380031, 0.003575625058344872, 0.006266333358868985, 0.008941100667317986, 0.012646530660078578, 0.011380797657854921, 0.006478817486889239, 0.009104279140037419, 0.006584763359929018, 0.0064430139897664555, 0.006959439486881987, 0.008833925388912792, 0.00666556890617376, 0.011120177005034124, 0.004988414532161789, 0.010355098529045603, 0.006866640738292204, 0.005911878478415697, 0.006840764373121088, 0.0032647519230774268, 0.005352885508166467, 0.010353462534874432, 0.005984986875560042, 0.008218694786370082, 0.009252906892838635, 0.006040726506950886, 0.004360090513531452, 0.0041220340250290605, 0.007742960823465992, 0.0022338474577849312, 0.006513651700153486, 0.0028834576800352576, 0.011541333871863116, 0.004618946589758487, 0.0031283977152653116, 0.009208061487214928, 0.0016741154500298232, 0.001947685979926226, 0.01144783546897602, 0.007891524352971493, 0.01128198331264926, 0.00462493092527367, 0.006682830179771268, 0.005097007035386214, 0.004865812513887492, 0.007537548180916802, 0.004324174708259928, 0.006170739863164038, 0.004910776579089572, 0.003959773894223951, 0.010728103961790712, 0.008835803300914961, 0.007592867786085561, 0.0038712763931190207, 0.009853066262397587, 0.009912683991957813, 0.011768401091820228, 0.012834344769178054, 0.004720179886031699, 0.0041921524114661, 0.011338803882884498, 0.0026869974062814017, 0.009010707476994218, 0.005929646670778029, 0.011941686324372527, 0.005615891742639372, 0.006864257561173717, 0.004986622307455829, 0.007664089509848777, 0.003207292148168147, 0.009754716036324586, 0.005184389966625022, 0.005427595541100532, 0.005855817042200296, 0.00534742386405279, 0.004691712214029653, 0.006704389908151558, 0.0028701612618453106, 0.006812273840757896, 0.006172602921059637, 0.01005453317628765, 0.0029909251247320114, 0.008417532457732878, 0.00331527848156002, 0.004425162887337805, 0.004315504374873578, 0.0051690886601185315, 0.004307369953999447, 0.005327771144287606, 0.00747851799519847, 0.0037241377361063224, 0.0050617331331395355, 0.001535239268924152, 0.006139132450969871, 0.006758648410819321, 0.006136411639993158, 0.0031762328634795667, 0.01040910973066962, 0.009235084073164073, 0.004993948908104855, 0.0039053245013712825, 0.010327855776999989, 0.00933146305717282, 0.005291043641592495, 0.0072693723317559, 0.003787526145336848, 0.004351549928241868, 0.012793730773829847, 0.008478326805277013, 0.005856131222197127, 0.008260417068449277, 0.007969604002121856, 0.003220133355005517, 0.0037733593367079155, 0.006488068746810385, 0.009246754449654662, 0.004890185767198116, 0.012991802987439231, 0.005070203705829158, 0.005828440579045584, 0.007960913650534751, 0.004365774324452587, 0.002428427173324655, 0.003294496668801608, 0.0059887857448943805, 0.006655338110373288, 0.005046322010136778, 0.009231753325383184, 0.0017424556102447145, 0.0048085364162336885, 0.0027429460971199913, 0.007985533645212685, 0.0056022488718475245, 0.00508710469755868, 0.004766512685137309, 0.007911735218616848, 0.005179716688093573, 0.004109574149086774, 0.007824139612330153, 0.0051705779865319, 0.00722951986476937, 0.007042688790822453, 0.006950343551201263, 0.006161087105812859, 0.00609727357962064, 0.004823365348031999, 0.00791915617774491, 0.013213752256135776, 0.008634050997266773, 0.005834511929120263, 0.010661107884177705, 0.012265302620607956, 0.005540269202182365, 0.006633390661448904, 0.001309617977423209, 0.003583320457840755, 0.003631227016044977, 0.004167561716143372, 0.013148284650809814, 0.007914832169999608, 0.008320256588815671, 0.008069438883727477, 0.0015678349991932366, 0.011741061066211611, 0.006016061395125554, 0.007065327661532635, 0.005629848849941355, 0.003599022336412372, 0.010700228244894642, 0.005862143048923072, 0.004624395968021138, 0.00844436955032361, 0.0057005179718586565, 0.007427587531005381, 0.002458440295698661, 0.006577997287186827, 0.012443178131967084, 0.007780696838280481, 0.008167637789275279, 0.0023888947696500697, 0.0018942154278988996, 0.0053222017115909966, 0.005524114476240209, 0.0011027074212544804, 0.00459739658520918, 0.011809840071096103, 0.004359222997224678, 0.00574142152979618, 0.004043976121703041, 0.0019799929914669683, 0.012950589299678475, 0.0031172209316034233, 0.007739528037489679, 0.0046403568968011785, 0.0035902215703437273, 0.006840873094431832, 0.005731973073330499, 0.0022747314683908546, 0.00725252840302169, 0.00319943541331344, 0.0072437524884677775, 0.010827775663391546, 0.011677592259571028, 0.0051470620029737384, 0.0015779582996649957, 0.01088343599248815, 0.006087365280681658, 0.010824171873051394, 0.0032371571803480924, 0.0064921213043531885, 0.00702657354881063, 0.0050806505733181455, 0.008890452306504905, 0.006530182251578729, 0.011021989093042793, 0.004702748604560927, 0.004377233021271804, 0.002421204686568522, 0.005219909185560098, 0.004548099175112293, 0.004133951389416437, 0.007754997630335832, 0.005970493720170435, 0.008253176554302175, 0.0071409523459773395, 0.009302817076536875, 0.00953037373115812, 0.008514463554015837, 0.006899516019828956, 0.005420094120701796, 0.001800820600776576, 0.005380524276088254, 0.006468579356720784, 0.008834649823366092, 0.004620991898084749, 0.006986362408340505, 0.0057606304656032115, 0.007191318596227649, 0.013704172852115318, 0.012786456860598244, 0.005278775088874963, 0.012474599612985762, 0.011545922475265324, 0.006409510787942366, 0.0021224174560306452, 0.0110904674286019, 0.0048199471184168135, 0.007869042384553592, 0.008852112737291933, 0.004743644853366961, 0.00572292704118111, 0.008158785625641145, 0.004578524778385275, 0.009860111900518173, 0.0015032903836083465, 0.006045371427648652, 0.007234661641708532, 0.007731435002628759, 0.0082151387704013, 0.007409156505536429, 0.004570582232650571, 0.006985076285200063, 0.0065775996422575336, 0.007484647256054577, 0.007276324727851564, 0.009666447140426243, 0.0046869470450315006, 0.0027852952027546955, 0.005648340189819984, 0.008051219441847382, 0.004471722622296441, 0.002532263052489992, 0.009188724182608132, 0.010430358094907046, 0.004075966358621065, 0.007746850004001467, 0.005461840998111484, 0.005392580390799572, 0.0027296611116562324, 0.010707608707801478, 0.012023341946147754, 0.0026558852387419023, 0.0071104391252313805, 0.0057473073477777945, 0.003189191278704487, 0.010842677462679586, 0.005523365880090866, 0.0052961194582036375, 0.004799940053482328, 0.005095693072332085, 0.011845849413707817, 0.011632290734767266, 0.004304425938595804, 0.005125125412026415, 0.005580123124035134, 0.00779443555092184, 0.011537606684601819, 0.006590485243175095, 0.005666213827242987, 0.0061282934376653995, 0.006933261410798475, 0.011971058196504118, 0.006258808805889321, 0.004615019714890687, 0.005002703567960922, 0.008567100066541114, 0.004696464935117111, 0.005949486598967364, 0.002772356634044947, 0.004106987335984094, 0.01248007791202569, 0.010754232176281516, 0.008813422210452051, 0.006124379627561729, 0.0057765272693619295, 0.0023977599012873444, 0.0033624123709921614, 0.005994553789473465, 0.010368998247149767, 0.003783164053339786, 0.009504227508073183, 0.009183063253878371, 0.005972754567044274, 0.007063475478697033, 0.013182764595350869, 0.009733340608028551, 0.004388153254395098, 0.010954953840926814, 0.006764894985728071, 0.006568996664022068, 0.007126580152547186, 0.005639759269064619, 0.0014117947754109716, 0.004197036240241584, 0.007863932994158782, 0.005305994194934381, 0.005610435349858004, 0.012701317290730985, 0.007256927734450863, 0.010410384067711921, 0.006829208056433186, 0.0053973787369761845, 0.007493440793283238, 0.004440442447844874, 0.010146658413490323, 0.010884369352038114, 0.004781135551575275, 0.005277060479710058, 0.010762203074765485, 0.007308202759087586, 0.010915920630060973, 0.01126837517715576, 0.01075705186959773, 0.008068041862700739, 0.004140537667192113, 0.0070136867465704494, 0.012296217045582928, 0.007963901164437208, 0.006602386888924309, 0.009615139065043271, 0.010132718042766917, 0.0057192266475290686, 0.0069600344652779676, 0.007251972091973185, 0.00455994361427803, 0.006929029656667415, 0.009469246216251611, 0.005094900491180438, 0.00821488388949935, 0.01132677332406707, 0.007673597025217915, 0.009866486321094166, 0.006288577254855905, 0.004923597045015794, 0.00570667657375232, 0.0038591424049397556, 0.0051226032106576926, 0.0034309577614440945, 0.007926444819525143, 0.003979890311470545, 0.012453163637782858, 0.007944526907769558, 0.003764701196570773, 0.01043371101772076, 0.006856084955487632, 0.006765820242355395, 0.0024570335457978314, 0.004117892603107024, 0.004223971247814081, 0.006411590420957779, 0.011009843066147874, 0.008313101567320113, 0.005767975300234519, 0.006227596774739968, 0.009260314848596574, 0.003435111352679162, 0.007313502856631391, 0.0062744576366409715, 0.007090960032943405, 0.005818488723697055, 0.007304732783571941, 0.008554478757896994, 0.0095984668928309, 0.008510335420285065, 0.004503151782437927, 0.0073646548473957065, 0.012583762394509587, 0.008767440960293658, 0.007940143325867495, 0.005847302893945484, 0.012634812455419676, 0.004916043204616456, 0.00959822337113712, 0.012175317656544692, 0.006982488837465994, 0.005794590746711155, 0.006552164357485937, 0.008588801551429071, 0.009567005013886161, 0.010433308974956519, 0.011697739579573763, 0.004252512448337062, 0.007176658287195832, 0.007895670982726956, 0.005268772481128898, 0.004615682574804409, 0.005330672717787572, 0.007134608129263739, 0.009733894196659529, 0.005736289789322146, 0.007424572562192632, 0.006367339254768333, 0.0038242079899576966, 0.008985277735340073, 0.004281378064204054, 0.008691844022395406, 0.011030126845059246, 0.005356827473675983, 0.006817591094123327, 0.0045363835122864855, 0.0014106968093119915, 0.0033850094647995188, 0.008248576072312826, 0.004126819058955418, 0.009102047948843452, 0.007172179528613336, 0.0037386336035631295, 0.0037340253409918656, 0.002400153210569945, 0.01094908514644448, 0.006141885644691716, 0.007188681447225032, 0.008605539466439738, 0.004608997959420825, 0.012594835829797731, 0.005821529614641943, 0.0084747496165288, 0.0040542965331796695, 0.005703959283415269, 0.006056764577197977, 0.004539493753867753, 0.011788526914131896, 0.005085208902768019, 0.0030317097377056588, 0.002829175634745735, 0.0034942377738327868, 0.00489424436918269, 0.005413463104180635, 0.004801397089284258, 0.007858141883020125, 0.013409346177588117, 0.005277109272987305, 0.004392003305002373, 0.008025231492965445, 0.004928188224684206, 0.004896421143166288, 0.004648638740929038, 0.004977249582053577, 0.006397264403513207, 0.004711066564915711, 0.00912740749369653, 0.009117083910728258, 0.0028557886073222885, 0.004724562554155063, 0.006940698448021348, 0.0034809980903141337, 0.00796686847804752, 0.004180946699625612, 0.012586383548074015, 0.005190792205085009, 0.005006268969813535, 0.0022678412883160217, 0.006812570069526085, 0.00481404204808188, 0.0008767794975743777, 0.006746561676796239, 0.01153570706132492, 0.006794581446762848, 0.006197746155602869, 0.0061155022662697164, 0.009692957866845311, 0.008853956432246925, 0.0013430988084374676, 0.013590937248725878, 0.007681584236566449, 0.0029777411672254244, 0.012137332612098903, 0.006644760075683424, 0.0049360220210230435, 0.00759642123207125, 0.008827580260175074, 0.008797556172140963, 0.012434151905372164, 0.006175367056204976, 0.00585334855556743, 0.005992609933151837, 0.00863291896574507, 0.007394426803892173, 0.0038675544259691953, 0.004206035215821023, 0.005676612665526079, 0.009701051771818696, 0.004060982830436901, 0.008023952747105195, 0.011937664880312261, 0.003575084736020935, 0.012135824519411876, 0.004733392956927674, 0.0037684152667000316, 0.009347566285781934, 0.0063970466057181475, 0.011360120435052294, 0.006153300912710144, 0.006308274292676259, 0.008428464026429343, 0.011706405186507108, 0.007147238949497347, 0.005399874872445074, 0.00301973974987568, 0.005493802578885465, 0.006554363528778431, 0.006863641023794286, 0.005683664647029011, 0.00901627685101169, 0.011153932798096518, 0.003534069802685138, 0.005114913822301233, 0.01083402499236686, 0.007003519867092708, 0.011537365973033467, 0.008617177349796709, 0.004132171360180308, 0.008769566458876017, 0.00922684339740697, 0.0035618088581538965, 0.004351243462763835, 0.005372597479814912, 0.005533630864474863, 0.007334413730249704, 0.008312428308335233, 0.009953741601859946, 0.005034178363714052, 0.0038596667534008824, 0.0069450610989967645, 0.010634174854425738, 0.004681157138582944, 0.0032539131301812354, 0.006909312708299132, 0.006589885882233791, 0.014538420393776673, 0.004933285134567573, 0.007570842806903212, 0.006766410385695895, 0.008696975747920211, 0.006968434599274843, 0.0026789548935046838, 0.004347070487051177, 0.008748741254837654, 0.010370829172082529, 0.0038960068218432723, 0.0043225117911895195, 0.002060095176973479, 0.007412837096024442, 0.006495413245033231, 0.003737553855712829, 0.0043835217548454306, 0.0056834699867847616, 0.0073971605474717605, 0.006056060310524469, 0.005894521897954207, 0.005237646763302777, 0.008330758265110602, 0.003015243359441844, 0.002677103174277268, 0.007215700385790274, 0.01141952741563234, 0.006943618387772034, 0.005596605907385763, 0.002968954114003803, 0.009647686417689334, 0.011181060591741206, 0.007768074180867043, 0.0071579787820823665, 0.002913184848791553, 0.010352565114606211, 0.004439265519636005, 0.006615268090899413, 0.0092263040766506, 0.0017088955229859464, 0.006806843911366182, 0.0038266025158921408, 0.008512353654065427, 0.00850088541476473, 0.00523065146882505, 0.006230147893311116, 0.00437389610161033, 0.011667516495793874, 0.004566393211341042, 0.008966639575655244, 0.00814389720905893, 0.011502219749106871, 0.007512578142786216, 0.004184578468201234, 0.005963613734711017, 0.00965881070868255, 0.004653335669066557, 0.006437939240586689, 0.009300068490143722, 0.00965197251662741, 0.011515218776953506, 0.0050671666458471255, 0.01381882094121092, 0.008725707264230376, 0.006987157032820243, 0.013170315472054373, 0.012294143558052608, 0.0043400069714860275, 0.004688892279213985, 0.0063846999260949305, 0.008586182474236124, 0.010584210354470156, 0.006489863316336177, 0.008145243638062573, 0.005777324148496472, 0.009467554151821624, 0.009863888846052708, 0.004648000655055329, 0.012875112980489168, 0.00144771460594286, 0.007844040432665421, 0.001039834586335149, 0.009599876220181495, 0.004893251840542208, 0.009350519381140286, 0.006819033173941764, 0.005436117097188157, 0.003714538915091071, 0.00877127595227185, 0.003561424214632545, 0.005168020591708766, 0.012775006335045587, 0.009672945231881936, 0.005526768777948643, 0.006923072139431998, 0.010517855343847665, 0.009343569501070821, 0.009266540459886872, 0.006112582264968377, 0.004881946074198532, 0.00477620680959184, 0.0013434815267528476, 0.004776270546050907, 0.009296792025978934, 0.009382547812725604, 0.007646071176901506, 0.005409466259021301, 0.005017426142030747, 0.007452486132966259, 0.004583494628929182, 0.004204835504080505, 0.004985861226909544, 0.009388046628893101, 0.008596672751227205, 0.004858549511882521, 0.010468016236631676, 0.0058161060709903695, 0.003974267346070275, 0.006895715193862844, 0.007037372103675075, 0.011163587506908046, 0.0064506869965475395, 0.0026465676565910487, 0.006907403916938703, 0.007435966440799146, 0.004016793800979503, 0.009655052123849955, 0.005887531632539649, 0.005335682943774622, 0.009210598311124245, 0.0034426612244237032, 0.004218990539409303, 0.0069163830562287455, 0.004124373981108227, 0.007098894421295684, 0.006636573494738818, 0.00269177644598647, 0.005001328941479992, 0.013487931837852695, 0.005133651743833104, 0.010167806366810948, 0.005251406857830139, 0.010367683434455394, 0.008135259897399386, 0.006513508707343779, 0.007392332333035384, 0.0022821271934154673, 0.0034360768505243013, 0.002758909237603852, 0.007864191355753017, 0.005397056493577176, 0.0038428589450720373, 0.006208413114280277, 0.005841447502434177, 0.004693387803522041, 0.007971320497901958, 0.004626062330873295, 0.005722995276008765, 0.0036377589641945077, 0.005446142305420189, 0.0073664099984312266, 0.004638736299324971, 0.006055188148721108, 0.007336624971800017, 0.0068733406100559905, 0.00793744246416218, 0.004467878092961014, 0.00579792800874371, 0.004187476276718642, 0.010381176725621303, 0.010407813108331523, 0.01030329653794989, 0.006596448173060335, 0.004568329181298662, 0.004444162293343115, 0.00868921649835639, 0.011828793759487588, 0.011509676439139775, 0.00819712513564027, 0.0032714467815245013, 0.008614096297668787, 0.005073819649738142, 0.004675557452604751, 0.004078561156824339, 0.004986749772118657, 0.007043612281143729, 0.006689168330166695, 0.005954492620097318, 0.010413567777617257, 0.012005185369098113, 0.0045039015059247026, 0.007978591372747082, 0.010577572963834887, 0.008600611698939956, 0.005687179505106225, 0.0067730387169349145, 0.01046287988331979, 0.00526273812300546, 0.01257274139951673, 0.00620428070313085, 0.006228630105103122, 0.0056746174072221985, 0.0059306149250484465, 0.007393345755973614, 0.006531246497503716, 0.002671890693460098, 0.00882340008581117, 0.004819447184145483, 0.004962185795875346, 0.010089646072345195, 0.012187191789725525, 0.0048985927606399185, 0.007339902891072557, 0.011028969490336783, 0.007086185789501502, 0.0022345297865437523, 0.011688402526103502, 0.004863106989321211, 0.008151793985355874, 0.011676014749872503, 0.003827593962324986, 0.012983256090454445, 0.006570942427904802, 0.0050660391821189575, 0.01121024555935923, 0.00409709958929527, 0.01076661508305605, 0.0064816658591971285, 0.009411669524718723, 0.006775421514782946, 0.0010205192264724442, 0.004137323147503624, 0.011017036180049719, 0.007264579740316898, 0.009121204671488097, 0.006160447388405842, 0.0056785763979192005, 0.005209377139745777, 0.006907825918952578, 0.010870760472945825, 0.0068276886613999905, 0.010531330896125566, 0.007965707381665526, 0.012999907785437033, 0.01325000017768803, 0.006123823491582589, 0.011317407321509187, 0.004976125850847632, 0.005666099275940578, 0.007958367359717614, 0.007888308511755645, 0.007234073902452894, 0.009523137952337356, 0.009629408966339709, 0.004058451720911661, 0.00544294430233337, 0.004692329243257049, 0.008417280465009776, 0.005388739225375349, 0.011446363782482242, 0.003945841124774353, 0.011475257515131072, 0.008782993929921167, 0.0038239906064446555, 0.003367840204628438, 0.0038260690683878463, 0.002481896914554388, 0.005139012234678135, 0.004038670793005412, 0.0028919804376859154, 0.005147096911150921, 0.004392444033740351, 0.00400568862655327, 0.00519996793728072, 0.008156448574074063, 0.005731093402354075, 0.007559681500290218, 0.010265287250862232, 0.007759799872854415, 0.012351364303758465, 0.002918320462052727, 0.009705000987875197, 0.009828206596120197, 0.006483867917705211, 0.004798423672200851, 0.004043044686719548, 0.00483925303369646, 0.004360172667780258, 0.004835056471268666, 0.008580499671889294, 0.0040299620220652045, 0.005332999015306684, 0.008175817664473246, 0.006096352098125297, 0.007121465686100852, 0.005301547296131728, 0.004139036934051321, 0.005399171263148045, 0.007452289170614352, 0.005866853309906233, 0.0075870327519550005, 0.00713681266269807, 0.004713627106032479, 0.0026671535116024776, 0.006926787270501724, 0.006496477359958237, 0.009622956314563464, 0.0029489222340361096, 0.0067169829623817835, 0.0022378781919670894, 0.0019017750587954857, 0.005296650203081915, 0.0054056611760601135, 0.0053193342590170415, 0.0033397813677003164, 0.006621259562803971, 0.004213921965310873, 0.007193442204578282, 0.004943397826564954, 0.002573372301478278, 0.004882854153991658, 0.003702346768815468, 0.0036908162127214823, 0.008202532041390601, 0.009248470883462513, 0.0043408462013001135, 0.005065485523913112, 0.005406664197859187, 0.008134196540170006, 0.0022945996848582283, 0.010267399887194988, 0.008171909930981871, 0.004584714374482744, 0.006056589928516478, 0.0030353559031625543, 0.010158230124891785, 0.002644318871944065, 0.012144585199368953, 0.012014431328276752, 0.005367571629748074, 0.004622433484471389, 0.005422047143969939, 0.008321461432135496, 0.004715581199652017, 0.004372575929788836, 0.011663710146570442, 0.00864601029859334, 0.008535769033404481, 0.003478536309272779, 0.0050738983905429125, 0.00804890910633255, 0.009872529317486138, 0.006899063848831088, 0.005517489445455315, 0.012820900762490237, 0.009636455522071236, 0.005323379192349229, 0.007615715821630479, 0.012821525619945724, 0.005945822168425865, 0.004368510063919055, 0.005754525280056406, 0.006695886871856036, 0.006777234698440454, 0.0054948787641662614, 0.005899968450666709, 0.0037868505153320305, 0.005615069418358297, 0.004591004859578834, 0.008024039141971495, 0.007542138971893484, 0.005465810526339039, 0.00878528701005642, 0.007420553722153047, 0.003393867120658809, 0.002174681893961375, 0.0072180187282991585, 0.002652064065615877, 0.005410950222929133, 0.006716047162298103, 0.009888459757952696, 0.010696098388197416, 0.0017499419801222803, 0.006980694694012941, 0.00840863096127015, 0.0033425317070703607, 0.008935468274584302, 0.005410754355994706, 0.0054883317003818636, 0.003966015130143274, 0.007944628263911072, 0.004140389920258185, 0.005944378689598342, 0.0038296960971123803, 0.009566876071980417, 0.005485867120581401, 0.005628021106016837, 0.0064004955568240565, 0.008511262201279849, 0.00874981779868044, 0.013058244560975448, 0.006317687565956851, 0.005198114639578274, 0.00863797494171332, 0.005938554383546424, 0.00542438878784893, 0.0019010181688924141, 0.005410166947044003, 0.002898124227803378, 0.0030375495060775796, 0.008000486074437062, 0.003368245721887544, 0.005153912533457111, 0.005685221775304478, 0.007839900619237504, 0.010753087282683982, 0.008097772951670227, 0.006537443916148281, 0.0023069967949120363, 0.007405193189999975, 0.0018702389266142018, 0.010041387305357748, 0.008601963191057181, 0.005590533039930022, 0.008114761472194011, 0.007774770777054204, 0.0031718075385230573, 0.0012513917967761352, 0.006580685070760702, 0.011954768688885252, 0.002539627261167839, 0.009316907523928651, 0.006162839939415757, 0.0023628381619060627, 0.009402517452941125, 0.010253105332822608, 0.011275579119318379, 0.006236468333616862, 0.00814137044991297, 0.0030194249331217593, 0.007830517115473848, 0.01132914075044869, 0.006064602901897864, 0.006009636318679781, 0.011441269786808244, 0.0064944889554727405, 0.00942385907365868, 0.00843333854544574, 0.01178344101456294, 0.003458479611785065, 0.00713121694618463, 0.006380297963414444, 0.007239176422183936, 0.005259936840696775, 0.009527137445032991, 0.005651316979166012, 0.007726714872122505, 0.01213265480595056, 0.012376761632990688, 0.010163990740680699, 0.007166314225095294, 0.009627448650691393, 0.005620192676085601, 0.00595493928436611, 0.004299221869193642, 0.006254487303230101, 0.004909030146405016, 0.0075723246904751546, 0.007101904461680125, 0.0044380284389831095, 0.004965525231270925, 0.004702583016974921, 0.005303286110912082, 0.007749443887907519, 0.011527003825551815, 0.008628113782620208, 0.006676569368710044, 0.007371115352208045, 0.00882908287465935, 0.006746540060370454, 0.00591099414350962, 0.00986572020031677, 0.005760988200367859, 0.009775766129257988, 0.004806305953943595, 0.005545349497149323, 0.010304361090393217, 0.008873687404472395, 0.010661721897436138, 0.005303565261272667, 0.010544371258966945, 0.006880763472865127, 0.0038198874272484915, 0.0037952905673729023, 0.004646236417298482, 0.0031422862881397284, 0.004507320027153264, 0.007208591081107342, 0.007248630247014101, 0.0021865953338981764, 0.00663835184313587, 0.0038602074935690346, 0.009769559484695715, 0.007264242268176067, 0.0031301972426839393, 0.005798108004659534, 0.011755590053128179, 0.006603922371223741, 0.0076164352316192875, 0.005665276692815389, 0.009681702862205273, 0.004809435248418805, 0.013765046156625375, 0.00930855272899143, 0.01468418371347682, 0.007692270684083894, 0.006874418389663567, 0.00642093932084452, 0.008631819685514037, 0.0056542597437095315, 0.004243970599509292, 0.006161019457678335, 0.0029789405826185452, 0.01366408978012765, 0.007956679598524032, 0.0049055148139648215, 0.010233510693068545, 0.007685198413896749, 0.006046144372270762, 0.009858689851297306, 0.004513583801492412, 0.004890517315717009, 0.006769799589464632, 0.0013927087754863066, 0.0070883301839150935, 0.007119527641578269, 0.011301340694809588, 0.005615714941676581, 0.007751981850154935, 0.0018322668404733818, 0.006569463085589098, 0.007259912787703923, 0.003910491307122426, 0.007085506758705214, 0.005469653846805429, 0.005437879276249769, 0.006450658432577622, 0.010235437413360702, 0.005151641523601598, 0.007891556075040513, 0.0067448728816207225, 0.002827225940285891, 0.007445218402158343, 0.005127527394164463, 0.0035128651474677854, 0.004230716378938107, 0.007654207224403693, 0.00690403170412732, 0.003255055049658973, 0.01245745705446712, 0.012279180703793942, 0.006693069680505948, 0.004952826635372408, 0.006471419605347089, 0.003092602123011939, 0.01078899746244217, 0.009850339011923377, 0.00457253697719581, 0.004202711522365028, 0.00701891394837746, 0.013047794943025692, 0.0035067120664403983, 0.00740458007917073, 0.010474877666842457, 0.006576722269477965, 0.010840798386891025, 0.002961782861947553, 0.0038704718681494823, 0.007124773858057342, 0.005645984849202174, 0.005491105428516295, 0.006943585892892321, 0.002217538138210066, 0.004830761995247336, 0.0038537336146161364, 0.008521643953818218, 0.0044051381343353105, 0.0038906680017210564, 0.0063025614091211666, 0.005768782866031058, 0.00815563321081753, 0.01142512777467999, 0.004678847582462361, 0.00996682661696826, 0.009044855306023478, 0.004487180197801777, 0.005474676987737301, 0.003980765054113734, 0.004855133509418813, 0.008958652773232673, 0.010097737625795288, 0.009358329556554478, 0.011299063499692879, 0.013056835650251217, 0.010101663841668537, 0.007442692240746548, 0.004018690102084096, 0.004558358281928507, 0.004339590635904147, 0.0045078201001309765, 0.005812174963961667, 0.006414272440543996, 0.008783778705533853, 0.012117271351485354, 0.008733369670296313, 0.01021159179979917, 0.01004388000120924, 0.0068833744892641685, 0.0065535952675918096, 0.0061060956216453036, 0.00825597619183054, 0.012111281053931156, 0.0036929508705384503, 0.010784095564921936, 0.007266011794924848, 0.006171085384838504, 0.00584069441641602, 0.0075127850593380745, 0.009764365420064997, 0.0035782571704756306, 0.006213598660232268, 0.004252992977002812, 0.005478581619968915, 0.013127875450995806, 0.0065742756460744275, 0.006082820271575477, 0.009697092095996281, 0.004795332404491065, 0.011485775529670634, 0.005792077059820254, 0.010470545037286748, 0.012128204542672633, 0.010503190015923758, 0.006329663131781247, 0.005768403282350286, 0.006446193381483284, 0.0031536387189848663, 0.0030919369451446674, 0.007110801886127868, 0.007544262126367344, 0.007509710781204452, 0.007620391223020774, 0.010672648968332418, 0.008023703741757478, 0.005990411267808291, 0.003918225179164262, 0.005822050346096064, 0.005307688983986122, 0.004670596437412791, 0.006883829914062599, 0.01200620026869418, 0.005472436961893177, 0.004977817379080084, 0.003904681690315077, 0.004280698308000841, 0.008486806616983948, 0.0055324014423601565, 0.0023682581571251122, 0.0056100424983188575, 0.003541486870263514, 0.006844003360988398, 0.007592120072614033, 0.008918885255180501, 0.00522129668115405, 0.00477035948358198, 0.002182340525373301, 0.004408134764579369, 0.00928755435808206, 0.0037021223940666187, 0.006708748912487695, 0.007231060939641522, 0.011163458863333049, 0.0047139162896237515, 0.005275076810539065, 0.013961231879242907, 0.008579139149714152, 0.004348395707507632, 0.005354277786359787, 0.008961103389799446, 0.006011674506235486, 0.0021691160871838357, 0.006462129882020898, 0.007954618071088448, 0.005917460717790599, 0.007488038684655439, 0.006761566913285249, 0.011342539270690196, 0.0047591455320912385, 0.006562017654806988, 0.005957771408978116, 0.007289979472718375, 0.0065725446413438145, 0.005772413919885185, 0.005873335082481381, 0.008629445802604089, 0.005273800835998391, 0.006893452343441988, 0.0049418120156005255, 0.003906791944759381, 0.006141957960683272, 0.003988320677725369, 0.0060810384243139325, 0.006592033461309312, 0.003855240063134061, 0.010764909573123902, 0.004451409329302347, 0.005267944364155817, 0.011499000879588132, 0.004825226799808447, 0.004359236156560389, 0.004948313164670452, 0.004234926971553971, 0.0034952398887445496, 0.010638580022615063, 0.00903991854152802, 0.008029218340023195, 0.0038530328578051986, 0.004821199094378981, 0.002110041425414437, 0.007037559488819857, 0.008017831222426703, 0.011730153742152928, 0.006971191586391791, 0.005891868643406637, 0.003947471969659926, 0.007667145910133446, 0.007694352252100586, 0.002205803537204496, 0.005075810402409437, 0.005808191168651755, 0.006517294405083459, 0.003036414274898112, 0.005156406344770293, 0.007114715861611047, 0.00720514918313373, 0.005147100578671638, 0.002555970559891615, 0.00374437237880257, 0.005303612340083616, 0.005005377533037554, 0.00738899271310114, 0.00551274508331489, 0.004702054836197632, 0.00838676844394644, 0.01289766844526637, 0.00480018944682266, 0.004297984689711638, 0.009942212562972497, 0.0048990980477847, 0.013565963199588969, 0.011632010014644544, 0.005971353636826281, 0.0038306663829269973, 0.011064029698171066, 0.01298490028092293, 0.00572129451392695, 0.0041657044375090066, 0.008816078365117512, 0.011946916668521542, 0.01311330982164486, 0.008169087946338964, 0.009215140910810174, 0.00553658926661115, 0.004372909456911916, 0.003411443740665675, 0.014229267359717272, 0.0030198703040379563, 0.0067536737223268155, 0.005543431950356153, 0.0037975325405288345, 0.0034763583176849393, 0.004619479923620542, 0.005008486881596161, 0.009726607695452298, 0.006088505339994554, 0.00578122575166181, 0.007173288146464068, 0.0018519344512760484, 0.010966211852011565, 0.004749033351944036, 0.005189453031313718, 0.006890338196779569, 0.013463008926458301, 0.012408545645707238, 0.008578160920503236, 0.009129107465948205, 0.009833743522299154, 0.007226842268612428, 0.006045708226343676, 0.010598978710042076, 0.004188305366559689, 0.0058483085271552274, 0.008040069457802487, 0.007414033326843524, 0.003318010816328802, 0.005139932744189031, 0.0060197535002951864, 0.006990471117752138, 0.004480044918744642, 0.006053101753659975, 0.0013935486580762815, 0.008043026958322083, 0.0054447721385518615, 0.0038379475249920355, 0.005544753855161509, 0.007848059925520822, 0.004314385738820693, 0.005488778620527464, 0.0071196546113042256, 0.007617746876206446, 0.004343768300822269, 0.008869670031977486, 0.010547498553199109, 0.005191888182142881, 0.0020882621398300594, 0.009944984874644913, 0.0027451376433817176, 0.002947419621510042, 0.007765347844206372, 0.011957995531320865, 0.006824195539018953, 0.007289077200365117, 0.009620625580253709, 0.010785624223060968, 0.007137549498462458, 0.004496220196211528, 0.00598450591891916, 0.0078081379202943986, 0.00771300955479556, 0.005001940519343545, 0.010681731546430984, 0.0035740254284216118, 0.004504400856848306, 0.005654842445640651, 0.00259562002737318, 0.004667879078443818, 0.011002642707307598, 0.00514037415973373, 0.01383422211049317, 0.0064118043655039605, 0.009760750650676112, 0.005979010566802216, 0.007129592644623983, 0.008972038218558543, 0.005403049504396879, 0.005168886122870638, 0.00537989641204442, 0.0066586351488053894, 0.004438273675189996, 0.004969983910502476, 0.005345337268538664, 0.004945907601866648, 0.0025585119150089604, 0.009716331902479003, 0.005143621854700938, 0.011254910895153097, 0.008519335675860698, 0.0021595664896280693, 0.011010088935047107, 0.006319849412054983, 0.005245606515522095, 0.004345682704367933, 0.0021023228115350694, 0.0022616097160784204, 0.011096793531309358, 0.010871892174930146, 0.0034684701412369895, 0.003980581844143174, 0.002863107261118963, 0.008727101265494818, 0.005134694630917991, 0.004057249541443686, 0.004594187536250736, 0.0035946734622772556, 0.0038710407234568813, 0.005580364503223973, 0.006571623563042065, 0.011438750420081276, 0.0060319037574068785, 0.01199595061910505, 0.0065609045636729315, 0.005935791063813997, 0.0015131141017035014, 0.004213128673424061, 0.004374904020958266, 0.005120396457934405, 0.00632953239468491, 0.007475338745636251, 0.0051728420714531285, 0.0051871978237872755, 0.004387592571289919, 0.008669651016169254, 0.006362365192446811, 0.004345068075871599, 0.005372876465883731, 0.004223411605876186, 0.005494351774661067, 0.006334121298147054, 0.006123788909903862, 0.0050411193126548084, 0.0075636650406514655, 0.011920775075887124, 0.007601714247735608, 0.007820349545085602, 0.005770402124359088, 0.005034352161284781, 0.004559792747174277, 0.005922307787058314, 0.003990643169202777, 0.00545821458475871, 0.004912120449211159, 0.005373125290187419, 0.003964570868599252, 0.009047414496869827, 0.006316382798111994, 0.006063350526840089, 0.006697685636148089, 0.008621392041385331, 0.010206091412661256, 0.005840042056550612, 0.011722656588154745, 0.006010211626817773, 0.010737112061604855, 0.006884027277580509, 0.0053871053504485605, 0.0066869001938085065, 0.006522327876769602, 0.003951912887543176, 0.005753298828664455, 0.00254198288947348, 0.00693140891560737, 0.011684322107984424, 0.010503048873715937, 0.01117579977204703, 0.003530278135922443, 0.00231103370553961, 0.010353431442553246, 0.001069290612249191, 0.0026144613126680856, 0.006022569015009107, 0.006779480083048691, 0.008214688181796631, 0.00694324101883413, 0.003703448637244225, 0.0075467734712634585, 0.004467785336029325, 0.005783727783690302, 0.0053784084120984945, 0.003949842102634675, 0.012102043396605474, 0.005802528475624983, 0.006862521847690904, 0.006727092382891483, 0.004761804382434924, 0.007903820017771946, 0.004571542147486925, 0.0036960434579239886, 0.006583730198693979, 0.013917020609044683, 0.004043369612401338, 0.0056808640782971265, 0.007945117530592852, 0.005066040745312084, 0.010628747066273791, 0.00925775083305821, 0.0036191474203720324, 0.0063341698337921705, 0.00426935866055596, 0.006933949367334038, 0.008476213237522512, 0.007291183212933536, 0.013716088095954586, 0.008511557430466537, 0.007023693326625086, 0.006607155232359243, 0.007414049808034011, 0.01131893780515697, 0.005528149482874939, 0.009346185977382154, 0.0036605909908115396, 0.004722206623884119, 0.008995853507301933, 0.008295923365950753, 0.007587997313345811, 0.00717444250697501, 0.006178408741531181, 0.006045370545714978, 0.00630679878085689, 0.00992173238909802, 0.008527320877023868, 0.007187876069774523, 0.00668422489264864, 0.0013092720844994476, 0.01351413850815418, 0.006186346007551881, 0.0115840722584926, 0.0036577659728836203, 0.0075947279309210095, 0.007005896437059525, 0.0034192600071054477, 0.006081461375616314, 0.012122961297137046, 0.012962412598224317, 0.005519234759296029, 0.005773225284980423, 0.0032330767245081615, 0.009569668982773371, 0.01121432403106621, 0.006699393966660412, 0.013138792408775652, 0.007890255047804011, 0.0051290760422352775, 0.007356511800431254, 0.005427955318950659, 0.009806986347806478, 0.00388679745168907, 0.010560764291934102, 0.006316468510665297, 0.0054248123696080544, 0.006460738527756187, 0.004796558179459619, 0.0023571218301644144, 0.005586650602647321, 0.00585410650143959, 0.009077333995358875, 0.0075793860912049035, 0.003278668005818168, 0.00475624093187092, 0.007845438751679567, 0.008264332781208146, 0.005945008162138214, 0.007120356177739916, 0.006101218244466248, 0.006774506278189939, 0.003036355182437092, 0.00415925914228941, 0.004117826019619016, 0.003278957003131609, 0.011635551489305283, 0.004671180968466905, 0.00856948266169119, 0.010976613809284566, 0.0029425218209463023, 0.003199300303385876, 0.007759552671445097, 0.012101539892471418, 0.004633528332823564, 0.0035569168076955496, 0.004702574343788311, 0.006959353174187357, 0.0026104619024214276, 0.012491849639062858, 0.004696122657748764, 0.0051853932229457365, 0.008646613902316694, 0.01175922516964079, 0.007970913147304257, 0.0031185258464507737, 0.006982857634540621, 0.005722235297520817, 0.009927227053934182, 0.011624176272069124, 0.002666737336379849, 0.006543916161610274, 0.01259550486945243, 0.005422694298243635, 0.008848027826946934, 0.0032443614445834186, 0.006526409479468023, 0.008402928935501897, 0.0056869958885712585, 0.0011096416250253502, 0.00901045679170464, 0.01042858950239906, 0.003878733067358121, 0.012524893787011302, 0.004561576270048566, 0.008418127146423378, 0.00915892611891124, 0.008775922577011827, 0.007934593649596935, 0.0025056974169422944, 0.007928709305946115, 0.007934041722631159, 0.009558200045127592, 0.007707037068629342, 0.009626138525130935, 0.001921178649783837, 0.006579946497649838, 0.004052802114081133, 0.006358760411712554, 0.0052575207769609495, 0.004708977124511087, 0.006181091873468356, 0.005624992653066537, 0.00557577330776647, 0.00722960298688657, 0.012242966077528058, 0.007350908367342403, 0.0046546869371830515, 0.011165443458965583, 0.005263079768928685, 0.011111432200532076, 0.008046128730437162, 0.009636667937996075, 0.0036851670083107063, 0.00544730181224938, 0.006355283058078509, 0.004568517143222178, 0.0060877107643857505, 0.005047660386365542, 0.0011298460490484768, 0.008515008353705077, 0.0047320987429814105, 0.008887832368401833, 0.007125791259951622, 0.0030553939367134325, 0.005459561286309006, 0.001493076528203578, 0.0039471112019771465, 0.009058754078209077, 0.0043349284074372975, 0.006292005578420445, 0.012041191338186548, 0.0013387450362430753, 0.007540137218176531, 0.008344182236495662, 0.008781139051469015, 0.004618305012786315, 0.009463569133248306, 0.007807244455521502, 0.00473835574986093, 0.0031220670593878285, 0.008510604994684893, 0.009268299027693458, 0.004754515789426133, 0.010572003157802906, 0.007578884502567056, 0.009438321015125817, 0.005191531652017222, 0.0021137353112710873, 0.010954768200349303, 0.00837236775654842, 0.008226208297660296, 0.008471454900378086, 0.0051444809229984345, 0.007051577059308248, 0.011218072146212876, 0.007716654523760459, 0.0030106019589644646, 0.003672204794899135, 0.009820850021428493, 0.004796957747298106, 0.0069731184404900025, 0.009341637353406361, 0.006810718072246813, 0.006408558470246628, 0.00609268472577203, 0.006652316666587548, 0.00618911002725646, 0.004254373121607893, 0.007048399907669443, 0.00479320304291306, 0.00836471018286967, 0.007287022934029998, 0.005902806671672826, 0.00511814301063845, 0.006421204487741462, 0.006371670696340228, 0.002513478200909874, 0.00349160518202053, 0.007574876026659514, 0.0047897306043165905, 0.005438621806186109, 0.0014926531772136162, 0.0021039290628771653, 0.006835606409161142, 0.0030921567549584542, 0.009052711428924743, 0.012618370564450962, 0.004998895443130712, 0.0064220776969207485, 0.004612082947738568, 0.009082590943634762, 0.010421834894231258, 0.005673614458936778, 0.006151983023341325, 0.00460154018744359, 0.009146760872982093, 0.01140683364526098, 0.009021170497838502, 0.003910784876473623, 0.00525228587030889, 0.0036510608634434784, 0.010237319546373778, 0.005293465140419623, 0.011806358918240265, 0.007830964804364227, 0.0034471270576099176, 0.007767663248522357, 0.01216445576546855, 0.0012970599343496735, 0.007513499822235583, 0.0026811581706907258, 0.006415574853589366, 0.003402948520434844, 0.005525151517288319, 0.004195395447350261, 0.005265304603126227, 0.007900103567245655, 0.005436372889021092, 0.011239981431863178, 0.010765973250244538, 0.005683046239062918, 0.0073118078353686805, 0.00907729267338148, 0.005574132213517283, 0.012727482720495351, 0.004232413226304512, 0.007966000687127175, 0.00551870016524143, 0.006764893846659754, 0.005990615049691565, 0.006822629461848773, 0.009724949083478842, 0.0047227743909829135, 0.0014312059446892139, 0.011849961475672792, 0.00352892086594699, 0.009882812556090435, 0.008322645602772167, 0.005989739881509342, 0.010428873694995665, 0.008496951348650146, 0.0032290566401595414, 0.00598436683522066, 0.005423438673349253, 0.009836673491029235, 0.006462602286351317, 0.008818626541649477, 0.005479779240543017, 0.006164961713305654, 0.006607942848085226, 0.004130957604418375, 0.0018677687442928402, 0.005350035772324922, 0.004630115098600295, 0.008889792309630284, 0.007058663401378362, 0.005005887735611702, 0.007583709522461326, 0.00985925852197988, 0.008899224460882127, 0.008445967069312853, 0.011398366287830943, 0.007135107588156736, 0.009190664884929074, 0.007154546708373529, 0.004514924413911064, 0.004941369069730939, 0.005967740265651527, 0.006822191802566669, 0.004918895613376769, 0.006053293856788374, 0.007549233802577223, 0.011236653726725396, 0.007484326865815979, 0.008018276279235277, 0.007846924839391237, 0.005840558861980643, 0.012287566424806527, 0.00933119682633234, 0.003479829922596119, 0.007146536736526232, 0.008131974283505393, 0.004401187628880776, 0.005558533597867231, 0.006472718364185058, 0.004673143936360664, 0.006696447210449515, 0.008846316935299307, 0.005182847064157005, 0.007451964478717633, 0.007069335535111686, 0.007286798086009584, 0.004285426025968204, 0.005754026051855614, 0.005087655124676471, 0.008235138446278698, 0.006975559389621042, 0.002963966790217712, 0.0054891149184999695, 0.003280928124740073, 0.00995811309758103, 0.009365078087168644, 0.00647715324323852, 0.010194231219805016, 0.005488769404044094, 0.005167475595087334, 0.004041178952704107, 0.01335744805126224, 0.0038502690384244562, 0.00454662651551702, 0.0075854608481937605, 0.007566617063484761, 0.0022637160807522563, 0.011948242053606752, 0.006601997217416148, 0.009540066653265289, 0.00822122639860986, 0.0057058541849443044, 0.005382218798764235, 0.01218411378594048, 0.0027966417134768365, 0.010553136460305396, 0.010096759839374702, 0.008421337426554178, 0.005235956963068385, 0.011999454023427293, 0.006450073846929235, 0.0028309546286977424, 0.0030796035605436776, 0.006085066360274356, 0.00533560014146594, 0.00712662816333985, 0.0066996105141636335, 0.004588231985963538, 0.0056506376416218, 0.009681208095657345, 0.0016876183244886617, 0.010783813070670778, 0.010740416858862924, 0.005353687164745237, 0.004543451430216285, 0.0037349429873357876, 0.0053687212303539, 0.007710203771840824, 0.005618675907538985, 0.005354124481921951, 0.011869141173313603, 0.011091702248065537, 0.00453670880113774, 0.0009544640577837853, 0.006734876271759621, 0.005172625398310432, 0.006998576331276867, 0.008759262305478964, 0.007488234494899269, 0.005684904666923632, 0.001402643619889765, 0.006183169618283663, 0.006456756156980612, 0.007427705050784036, 0.006649598021396681, 0.006427728142816397, 0.005708600773928435, 0.006763903762993068, 0.006044102629140604, 0.008827074992618294, 0.012055812348156326, 0.004733754072252433, 0.00599622039098535, 0.00428242302478361, 0.010922684309336538, 0.0028049191880275396, 0.006425735156737462, 0.009470328055958096, 0.0090570714435491, 0.006704056914049605, 0.009577035872382197, 0.0032181692993554726, 0.0046657326771438485, 0.00414101034567183, 0.0032728450264005587, 0.003624881428645301, 0.007295596329311074, 0.006946715192701248, 0.013812072769132728, 0.008858406018482774, 0.005267637056300316, 0.003126547672382971, 0.004794306715218673, 0.007809429060116582, 0.005041425938518884, 0.011173197093036519, 0.00812195997539777, 0.010208424030679926, 0.005103929339686486, 0.0038411889681854985, 0.009750665236479699, 0.013243864778187023, 0.008531273323284736, 0.004611079260654151, 0.0072867366614145475, 0.006367428114414887, 0.012270826761263802, 0.006302960980219926, 0.006782120248931786, 0.0031682317774755814, 0.005298301169875001, 0.004538485339431516, 0.009257683617436695, 0.008492484629573253, 0.004096559260703776, 0.009853857723804177, 0.0060538831634270335, 0.007431856050388066, 0.013034980291505679, 0.0047591400729297805, 0.010398372992052731, 0.009925803624243525, 0.009936815821350954, 0.008302951421944139, 0.003627659520028263, 0.0056692447010511585, 0.006038709817363708, 0.0072536681813653355, 0.007595825163808549, 0.002441007191738114, 0.007114302273357758, 0.008484247473839496, 0.007077040238546881, 0.00871677002157686, 0.008487977239576457, 0.005365408925941893, 0.01076861617749316, 0.006509296618405744, 0.009912886091469567, 0.008430059048591107, 0.006546783386432014, 0.009879099648568543, 0.005094916399551477, 0.009570169692787046, 0.005137361181929903, 0.003390641321199213, 0.005305143118001225, 0.011199499169363837, 0.009519548013697563, 0.005612721621074313, 0.005841775265735035, 0.00609622317293792, 0.007731681078402754, 0.01187214923866762, 0.01137733267293215, 0.002577239591768164, 0.008717035184955682, 0.01109886254387707, 0.008397384331804036, 0.009702829853357228, 0.008492632468364373, 0.008884306127761473, 0.004252332938272916, 0.004791187545007406, 0.008122545871797872, 0.011258082631024834, 0.0038673241742278536, 0.0068472534155243365, 0.0039679704181201, 0.009917914175893699, 0.007336835707517088, 0.006912379767556251, 0.0077761240426691275, 0.006545787990911054, 0.0043496042686080524, 0.005087717141622771, 0.004929306994369916, 0.006655658221308814, 0.004905499493318447, 0.005762600189394999, 0.00771228017851306, 0.003770805346578264, 0.006504141952753503, 0.004669536191156981, 0.005428785026613738, 0.00484499315159184, 0.003165605211124277, 0.012329185534716104, 0.007811507561158424, 0.0059816650870001915, 0.006671337723728217, 0.005566867822078424, 0.007450246504161781, 0.004337977479754707, 0.0034643644281416247, 0.005953993040414209, 0.004688781837717062, 0.004532832767179132, 0.007710086338394409, 0.00669469080365182, 0.009415820013691343, 0.011552214917368025, 0.009069186393430406, 0.00396611398795948, 0.0030384815320895816, 0.005213315622796748, 0.00298544509665959, 0.004243087486210313, 0.006465346502937602, 0.005141715992429446, 0.008075638772489395, 0.00642924281189925, 0.0011258395745840876, 0.0069831410354681215, 0.007271418534069291, 0.00969521476864385, 0.006347553152847407, 0.004308199653691737, 0.007200351087641615, 0.005553913026413745, 0.00822354988904451, 0.0033656851637022126, 0.006918781119970069, 0.01066950581872225, 0.006076283080510466, 0.005587748888764248, 0.005712786099116983, 0.004381704805109205, 0.007790435259203079, 0.004485728467000668, 0.0042701620993845025, 0.005642452551845142, 0.006270355998404278, 0.009392660372165906, 0.01356622515289388, 0.006904169930111573, 0.01002136076918394, 0.0015535976891246973, 0.005974956621757733, 0.006219806860543966, 0.009828932640580778, 0.007189349610611956, 0.005018290246182591, 0.008062183467687615, 0.00665599302153143, 0.011984104184736175, 0.01227544755023358, 0.004433758230166496, 0.006332106317270254, 0.012503578728444875, 0.006733776704597445, 0.007699259088869526, 0.008533530881843762, 0.006317081717729801, 0.011344370974237284, 0.010295954610257533, 0.007780256169436877, 0.005140484118712485, 0.00816690434803025, 0.006530019499279368, 0.007103119046168214, 0.0028592569475991893, 0.004412659681112706, 0.005044999047587051, 0.011454591114975978, 0.005885701465840055, 0.006955941305494645, 0.00543965846144527, 0.014708424728786269, 0.005527058218329475, 0.0031612171504079977, 0.008651292687437277, 0.00601767313694874, 0.012158122573200068, 0.007777003987102001, 0.011001037104700236, 0.006560497972504438, 0.005564342191244444, 0.00412979396012316, 0.004475876989936776, 0.006003831924852765, 0.004278747338312021, 0.005353871606255251, 0.005826418321479413, 0.004956736528337002, 0.009700761870497853, 0.009377976993002026, 0.007662285745993518, 0.011675355322569615, 0.003188700606570335, 0.003866939749536148, 0.0038386370226469466, 0.004386762151485522, 0.002946323173792134, 0.0034849556815504078, 0.0063196297775449045, 0.0031165175712335514, 0.0106769439496014, 0.006443561346242168, 0.009829225736425551, 0.010280844353449125, 0.0036263421886835595, 0.0067598095475859205, 0.004992843500220564, 0.006031642660156703, 0.008622525818167168, 0.010409185253473632, 0.008566572180395674, 0.00906933820346295, 0.010260659562477866, 0.004015842941574329, 0.003629516049120589, 0.005718410545934285, 0.004370612216682113, 0.006311391176257203, 0.010289518076184733, 0.007209503736290081, 0.010550401687404355, 0.010958289490315305, 0.004926153782635666, 0.005168153395165485, 0.011979719322094864, 0.007155671871130526, 0.0052582200696688584, 0.009279688973231465, 0.005446893038846803, 0.013300373099792009, 0.007030068049501449, 0.006767377841596611, 0.0045010249786477646, 0.0060069018006658524, 0.008343326694276395, 0.004386052115087144, 0.002806141036323017, 0.006844709796037031, 0.007895380188074702, 0.006408563398594082, 0.0060282805488733725, 0.007373333009073078, 0.001858279069626248, 0.013368332136112033, 0.0037515063665294716, 0.006413879575964645, 0.005783172638946103, 0.004914080865886112, 0.01459386477232098, 0.004499538425967693, 0.006617560527818738, 0.0049096909944749195, 0.010704273891128107, 0.008728248218838082, 0.005036932094264212, 0.00521452616728363, 0.009424903247169769, 0.01018503457467024, 0.009545800983154022, 0.003989818440776622, 0.002962868475857551, 0.006109862867058327, 0.005106150221742253, 0.005756330560685974, 0.007181446670216838, 0.006114441020798632, 0.005218889410168324, 0.005610847097891526, 0.0074088376076935705, 0.005768257357429673, 0.006802306766829652, 0.008694126595793479, 0.001488105879451488, 0.0057246515304964956, 0.009780403583061347, 0.0037379806208708193, 0.007604395702464663, 0.01110949828528518, 0.007016387301787511, 0.004061062359894716, 0.009547066436109888, 0.0033630434988009415, 0.005755559162455806, 0.0063000649357528886, 0.004727004039538853, 0.008298983121550333, 0.0018699470490938501, 0.0035744004949219378, 0.0048944298609827075, 0.006578874290768175, 0.011855111848204467, 0.004983057177200741, 0.005214545747826409, 0.008847984664891693, 0.012521526984794763, 0.00516696428393372, 0.005037384659544442, 0.006225864797677006, 0.00677860960144204, 0.012869408493797477, 0.01172472235548902, 0.005343928077409366, 0.005047895921901902, 0.0036327179213411563, 0.005709219321152841, 0.00719468407212693, 0.008129113494523691, 0.004571881269314448, 0.002298268833573635, 0.005183277767974057, 0.002619331080622226, 0.010769963435411634, 0.008743891089102536, 0.010993686016076455, 0.009703631054910407, 0.004672886612484911, 0.00530907558783993, 0.003716972678380213, 0.005494473388849232, 0.01292173443506981, 0.0051392127392975995, 0.0051035383339030575, 0.014181859028002597, 0.010291329326475725, 0.010374598135986544, 0.006268713629794514, 0.008732811808971, 0.004339697012113409, 0.009216438762343408, 0.007629450364198962, 0.00432602691072016, 0.0041982436322648, 0.006500932950772753, 0.005947451166112423, 0.0061998174154805534, 0.0049062205765728695, 0.007602666636446349, 0.009091070552053205, 0.007328697272419185, 0.0054432433361123415, 0.005183747475129992, 0.006648285073142418, 0.005477794081409145, 0.009940236851224707, 0.007762863951946955, 0.005775623819459393, 0.005552509955415491, 0.005277453363756745, 0.004534502997510271, 0.0028031815070178804, 0.007581739297119196, 0.00739474110459773, 0.014600173126821013, 0.004698441191336193, 0.007255338747730811, 0.00732933518387739, 0.004842079511417753, 0.0027495492714543113, 0.0060624645189327545, 0.005637248997111419, 0.005414109255488598, 0.00683492590162462, 0.011210133185898056, 0.005412322860866924, 0.005327315830615521, 0.006387816694269641, 0.006555801247051836, 0.008115132570777374, 0.009408866936220301, 0.007883478476395832, 0.004163806081640662, 0.005722292849259609, 0.0071471138982207045, 0.0038589760199986647, 0.002698709957645069, 0.003410762090937646, 0.006649464817220138, 0.0049347587926108615, 0.00702934542752252, 0.010298959958859124, 0.010246509256806563, 0.0054699289723312795, 0.005569299817287049, 0.008758606370619433, 0.0031300684873166043, 0.0019454683885614106, 0.00521523048367486, 0.005428761039364538, 0.003291859981911834, 0.005197452365923876, 0.011754967289446853, 0.011052861118670577, 0.008167073124731902, 0.005127308162464423, 0.006931502921589618, 0.004987829436787745, 0.007977194726458785, 0.007261852793896783, 0.009879780000639911, 0.011573244204712695, 0.006945678030876515, 0.0032498468734278897, 0.010744382894870508, 0.005954989113338848, 0.012569696353651575, 0.004735293499668578, 0.005152107230534213, 0.005279528125046071, 0.009723575451316975, 0.00629311907948657, 0.004086288405980888, 0.005699019281397737, 0.008399025902997667, 0.004212930887182451, 0.00815674891327134, 0.0058938146201962995, 0.010547160442422975, 0.007829330376315984, 0.004785432895953045, 0.006737645772307913, 0.001181981659191271, 0.007621770221531263, 0.007880268015116688, 0.009052374238585868, 0.005262124347480106, 0.008113403667988493, 0.009649889619977203, 0.003500778953623113, 0.00586963225443225, 0.0070768232007871, 0.009235235302449822, 0.01276978278143839, 0.005842869785126468, 0.005479410583979421, 0.006525042724279996, 0.005431487454456497, 0.003769295972328831, 0.010484229726580361, 0.005619888760712259, 0.005003854129574564, 0.009432956371633933, 0.008327740789790272, 0.005884315531739933, 0.005987067478206612, 0.0053596370925189755, 0.002619832224734997, 0.011826508539302458, 0.008167583224141975, 0.005393695199983967, 0.006780147323141118, 0.006288338991000654, 0.008853114385503985, 0.009035583234487565, 0.0041531577027683975, 0.007557977181550553, 0.00715240495038094, 0.0069251566561403695, 0.008241722640379413, 0.0028960776718960227, 0.0116746142108115, 0.012201824458475365, 0.00628633103266594, 0.0045893939292149695, 0.006351693595610811, 0.006764331609944869, 0.008065515247083982, 0.003987060609051086, 0.013134674991542283, 0.006083384340442979, 0.011535908082027204, 0.004672868262819607, 0.005113269644368559, 0.009432114874593093, 0.0039231151818504345, 0.004036219758677248, 0.006891096154554531, 0.006558502743320434, 0.005486420388760812, 0.002883267399558422, 0.0038445318758337553, 0.005581067630172818, 0.006035227508420802, 0.006758507977495542, 0.006958052796108222, 0.00614798117724094, 0.006446478361539924, 0.007229403030302397, 0.004000454280954684, 0.0037326351875716667, 0.004229721961575534, 0.008261511737113397, 0.0036100499110106707, 0.008029233922221893, 0.004068777131092495, 0.0042834824029877455, 0.007839283936320536, 0.005024476423371503, 0.009295188111924872, 0.013446745087251407, 0.005677005329479954, 0.010464081411859094, 0.0068137077584811585, 0.002991319305223892, 0.006204372683070957, 0.005538949765054469, 0.005575893191214621, 0.011146464289772718, 0.005397712831980331, 0.0021976680081676253, 0.009776449988766703, 0.005192540735411525, 0.0053026048699120285, 0.004501636408722544, 0.008776838797905973, 0.007602551878348168, 0.00586062876328731, 0.008159744650251924, 0.013192083351735643, 0.007520104496110391, 0.00464598761232236, 0.006496830959596525, 0.007856648714412004, 0.0039414717209926686, 0.006774902479526009, 0.004467954746843573, 0.0030041229894561604, 0.004850009992074328, 0.008438072388125781, 0.008971005094355524, 0.00484978550842482, 0.0035941816568618237, 0.005362475935428449, 0.0009209756169928033, 0.008174630795348994, 0.0065623441676431185, 0.008328305571134818, 0.008554758841219378, 0.013814695817851178, 0.006871615441374474, 0.005906221037660968, 0.006802635760921497, 0.0020114480764846995, 0.00605482033165172, 0.006649570455981305, 0.006807397539661813, 0.011452389131331354, 0.005275141886165105, 0.010454939542977947, 0.0046731874983433055, 0.006363458200629745, 0.0027582575393391463, 0.0058781648837016864, 0.008254951930289136, 0.004440294364972195, 0.009072380877354794, 0.011135428406294282, 0.0059802667732992785, 0.003800198041143688, 0.005156543398512919, 0.006051030135009939, 0.009961398603585555, 0.010478707463944022, 0.005234917985486521, 0.010136343179447893, 0.006004266728847532, 0.01037611387922846, 0.007022220153319664, 0.007553130410632318, 0.008132347687219519, 0.0014614834569868494, 0.006328471170001055, 0.010924194272948336, 0.003848810464466942, 0.005032854039329041, 0.006700353082723086, 0.006099317934584214, 0.006709314176066388, 0.004736750789690054, 0.007135257644648261, 0.004602028466512356, 0.0032987605974732284, 0.008189794226865822, 0.006139052643780901, 0.009272441327741127, 0.009130688905097299, 0.0032709265331025434, 0.0026421355121707415, 0.00493551292001645, 0.009648759346979958, 0.0053631674624162766, 0.00596476617024854, 0.003362001133726384, 0.005029427396296863, 0.006437445383464548, 0.006261110080063089, 0.009871132214831319, 0.005687581462507297, 0.004889498105121298, 0.005818536956146321, 0.0020650034649172815, 0.009646432250569404, 0.009016085100817937, 0.007715142982416856, 0.008514579979319528, 0.005145536529808429, 0.004941977322208543, 0.004700275847642961, 0.007218917714143761, 0.008562183499985974, 0.0047350475748237485, 0.00954042200448966, 0.006038985824041592, 0.004603992931413208, 0.00279093829775675, 0.0027714768566789484, 0.012676445519559817, 0.0066587505794243685, 0.005690402736519782, 0.008570897010682697, 0.004264210304722097, 0.005208563778954799, 0.011931711639856898, 0.0057365483617505385, 0.0025333377821511755, 0.006655196788554457, 0.005584305166684752, 0.004163585780372425, 0.011366255650043162, 0.007952186036106947, 0.013692352698941646, 0.005001735410349723, 0.004466633736003605, 0.008806113537016904, 0.006393724829772402, 0.0073845050512472594, 0.006949309852587338, 0.004153254312552529, 0.0029195566390327167, 0.012436885144870999, 0.00523783486799958, 0.006040467746649306, 0.003127006453315956, 0.008117342327985971, 0.007087863280971246, 0.005056029657205598, 0.008099335869280511, 0.0034770557334980958, 0.0017926725629276254, 0.007713485783325418, 0.008270985272631239, 0.005721255229366638, 0.004286954858004455, 0.005810176464560529, 0.00442067418951214, 0.004501095846511873, 0.0047733825677482335, 0.006098980776204585, 0.0043934480596472085, 0.009567271920219526, 0.005405231664136482, 0.004229273629401129, 0.007021601590238041, 0.008290498866750672, 0.006532019306954415, 0.014204532937968525, 0.006233938977217097, 0.00700784336773644, 0.007713418643294731, 0.005276787954288821, 0.0060755449927560054, 0.007300079671552202, 0.010983014441647634, 0.005239855060784837, 0.0034092848969926016, 0.01007578929222466, 0.007833215574386033, 0.0030182643338407633, 0.00725247463879498, 0.007359977862763989, 0.007789183247173798, 0.00670285200338595, 0.007424286727567255, 0.004656456125670148, 0.008571323165701278, 0.009816639880468126, 0.005579014256947783, 0.00628528959642426, 0.007891883220061877, 0.005114977391521941, 0.005312501601022522, 0.011205779440039313, 0.003926620403425954, 0.004097645822973821, 0.012850542687340032, 0.0073323208152190076, 0.008024790138054811, 0.00765717190112059, 0.004772224796318716, 0.011279166946733341, 0.007892898843107125, 0.008670134459546047, 0.007365684222599166, 0.004245177878746111, 0.005234813142832775, 0.008509162900565598, 0.0015074252926548912, 0.012540323272924862, 0.005514474516421423, 0.002205609700275951, 0.007797009324533961, 0.006223410132673469, 0.0021443727134937223, 0.002996626394282166, 0.004895137177903928, 0.006292340029814499, 0.007361939046367049, 0.005479412334632179, 0.003816630839443824, 0.012281116480589731, 0.011043780604513772, 0.00976589586424231, 0.006021833481058986, 0.004547859711360378, 0.010028615090905213, 0.011103636396772495, 0.004142697205596667, 0.008019840437525733, 0.012481183023639247, 0.006569121790689844, 0.009623873175707844, 0.0038927843738772137, 0.004376161411195609, 0.008600461503445966, 0.0019653360168485207, 0.005673604444795277, 0.008043283343258562, 0.0015917313639353258, 0.007285580923598682, 0.006479985132240551, 0.004845344988431862, 0.004677589964639017, 0.00645271084041613, 0.007822448759061112, 0.0020941195491056335, 0.0035458261133519244, 0.008780314604812038, 0.010774581046755783, 0.00789398988017098, 0.008740387067437702, 0.003568954662730593, 0.0052267740206869435, 0.00713381645582596, 0.003703044166576394, 0.007541268020629887, 0.003889158827994219, 0.0041658768993268445, 0.009725542798994246, 0.004516574761878654, 0.006818650898528996, 0.0016959025511323327, 0.00670469396036515, 0.01464941825500548, 0.006414031364167647, 0.006484819262863746, 0.008078551013999218, 0.00898004288725454, 0.008491119950962005, 0.004916682478459355, 0.004265501682019458, 0.008820826065125301, 0.014362737198357886, 0.006917036098961447, 0.01290377177465814, 0.00611416001791715, 0.006764401285232942, 0.004755292372057853, 0.006058789054399695, 0.005988435724944881, 0.005116461328440489, 0.012254103604649994, 0.005854487760787599, 0.0057751337987885076, 0.0015767706825628135, 0.007307793556649294, 0.011224804795566368, 0.0034562670499263997, 0.012013233252203232, 0.00522030093860284, 0.0032337930802218214, 0.005178921204655758, 0.004667141340386579, 0.007290261215503547, 0.006103319403609001, 0.002592977840305934, 0.006873621311326938, 0.011279656468676028, 0.004806611470073473, 0.005832885970179053, 0.012479632456443977, 0.011221637415238154, 0.004585677336425844, 0.005563900321533933, 0.012265630253686943, 0.012802821604029627, 0.007197050144299791, 0.005414036696737417, 0.0038908397248224196, 0.003975146660998196, 0.006376498204339082, 0.007170847381578444, 0.009866622840418594, 0.0099060665491516, 0.010103145492713433, 0.004847743077204101, 0.006191860362576141, 0.00708883699389742, 0.00752144520370497, 0.003718109104257565, 0.004143899533718357, 0.008327866862019428, 0.005786043544175754, 0.0035384109075392196, 0.008679968969304886, 0.003931851225498511, 0.006877257887149019, 0.012853983864382235, 0.0035009738839334383, 0.004811022971959792, 0.006262090255524394, 0.012888285673568678, 0.004475490846826293, 0.005867369149630033, 0.008609104735416845, 0.011838042110744415, 0.0027189309205501045, 0.008302423675910352, 0.0052008627063788015, 0.006556287820041684, 0.0036205938714309665, 0.007018553778743644, 0.0045529937588064786, 0.005717403521986656, 0.00278115515731072, 0.002186700063690768, 0.005234581521041892, 0.0015617457209530462, 0.004933539863743838, 0.005090759065152971, 0.007268016676899209, 0.006534666098738784, 0.006279117384227136, 0.00870809411898749, 0.0024375297173244046, 0.005175428911218269, 0.0030977167264116152, 0.005260570192433543, 0.00606881665321473, 0.0031330099412845373, 0.008101129899922087, 0.004487363848375324, 0.004358579320255884, 0.004972763332697676, 0.005145470194980736, 0.00639124787074169, 0.004198193680938851, 0.006732387528406774, 0.009866057215281183, 0.008671457774771275, 0.0017314998019299622, 0.005543189918937547, 0.005449003432500022, 0.008362264628911539, 0.007413462585194815, 0.002906569404075436, 0.001698525316474463, 0.011370299482827622, 0.005441090869392181, 0.009317935701915492, 0.006259065310222761, 0.008708650803506805, 0.008707080880294612, 0.004442985577852886, 0.005265749351281708, 0.007856940031260794, 0.0063638196722700605, 0.004773708932539206, 0.008972177888020294, 0.0025237113160647483, 0.004116313018659811, 0.008992438873482908, 0.002599523495576137, 0.009179139130345002, 0.0071597761380741125, 0.007450660215160519, 0.004340249878692332, 0.0047751912676978455, 0.009927113870847477, 0.01261711117318661, 0.00621987336109748, 0.012348725449689964, 0.00626330282673084, 0.008492876405331936, 0.0030811802632969842, 0.0027626082944113015, 0.0059949091340540965, 0.006432757118758962, 0.0041071022426239214, 0.0042692412710747425, 0.006906309425770098, 0.006627535088257308, 0.00573874363256195, 0.006257811805501964, 0.00567300250591923, 0.004968149725495812, 0.00691000179399942, 0.010105909269338298, 0.0024438499604058535, 0.005494633025586644, 0.0021911583149132074, 0.0033077073852630845, 0.004603510772473068, 0.006941641463456928, 0.011312479447508655, 0.008439948427611341, 0.006037048287789544, 0.010307390772621345, 0.007842938255466399, 0.010042882824060281, 0.0018761300087233052, 0.012978334845072576, 0.005986165034825038, 0.005056921036117814, 0.0048696933124387975, 0.0021882560628399455, 0.00583115735560053, 0.004666930572685269, 0.008551380262668058, 0.008420213321880598, 0.006797831841601545, 0.0055452474956749, 0.0055859785819879805, 0.0014281749604500777, 0.0020535765021840674, 0.008358264750036573, 0.006838932683423166, 0.0034186467016156623, 0.007851283854731866, 0.003524804748490708, 0.004745084673110457, 0.012045270064600207, 0.007573367225509617, 0.011437982387787864, 0.004494573444353388, 0.005134303304898082, 0.011241493694948673, 0.003740876172758724, 0.00883542856269719, 0.0053718186238152265, 0.005504631370502604, 0.007752848213148498, 0.006192081707454095, 0.00601984582660677, 0.008781684921382035, 0.004709486301422438, 0.0047150541823574085, 0.0063909786434218855, 0.005402514651151435, 0.01116993987619858, 0.0017367989129047738, 0.005836730722830439, 0.002050556182636411, 0.0070365796932994225, 0.003912439168273147, 0.006262139917750816, 0.008769642250317391, 0.0022616745401081236, 0.006991252921663339, 0.005744569251851395, 0.003278862227506391, 0.009242695863215071, 0.004656167569195334, 0.006612964908499961, 0.00872224064029872, 0.004565546656616898, 0.008029836430363521, 0.007661009631925446, 0.007552934833673708, 0.006302161254812663, 0.006836463521298741, 0.005833723249026269, 0.008228629894221382, 0.005061691456315875, 0.006549551031620714, 0.006899727249651205, 0.002421880850577024, 0.005208295236603662, 0.006604040811515545, 0.004643647432886472, 0.009016355559341648, 0.0070710096834837016, 0.0031256428704328617, 0.0047439462308571205, 0.00828904325763017, 0.008402400019371961, 0.0068150282690604466, 0.0067410161988685395, 0.003138551557111154, 0.009284539351158924, 0.007043791875625458, 0.009517509773137001, 0.00893477528347888, 0.00489150124801804, 0.005487471311592986, 0.006601778789532206, 0.00506432645997103, 0.0033615627688511904, 0.008990491778825972, 0.00844196760681147, 0.011206343957685392, 0.0049778867435747495, 0.006656261801730189, 0.00922677087411082, 0.003294936552960999, 0.006093129417792038, 0.013064272994241254, 0.007112174680070007, 0.00504550775246751, 0.00687307881052693, 0.005335323008797894, 0.007651852244712906, 0.0081135402836235, 0.00905946962848691, 0.006473255760347178, 0.0068966999760663875, 0.010586217022288236, 0.006556270953195021, 0.0057661519581111275, 0.01136921823137685, 0.00502023625340005, 0.007379204685014831, 0.005312951054426631, 0.0052149466738557314, 0.01000437009885949, 0.009193708121200458, 0.0025358307759234806, 0.007223057292846419, 0.005983299257994385, 0.004117898596349354, 0.0035134415572582517, 0.005980724436090131, 0.002772858800659328, 0.00414642755935425, 0.008604349576574764, 0.005847718177715695, 0.012377508905002327, 0.008379650594315642, 0.008356276789288287, 0.009613439835607921, 0.0039839662735788465, 0.00798587466489905, 0.004938092046700809, 0.005103789555343973, 0.006101681427768328, 0.00795156366597874, 0.0035895024215344385, 0.00711525665801504, 0.004843349851845146, 0.0066389327885393624, 0.006539774842335668, 0.005320811509322081, 0.005969493122558926, 0.0066716485254752775, 0.010676486052224978, 0.006584914560462982, 0.005862842040827107, 0.005457820482456384, 0.004814335377833017, 0.011494908472180283, 0.0032325326757545953, 0.008175169483496423, 0.006087001980404707, 0.007299156741089531, 0.0032651185845647326, 0.005615636652601589, 0.006141575832782123, 0.008345281261602947, 0.003767026288910345, 0.0022544771622122362, 0.003279251565735946, 0.004817040661123628, 0.006085011123463255, 0.006746742610086832, 0.007330233677600666, 0.011312327435037543, 0.007191945139336674, 0.007658963763665095, 0.006369620599860068, 0.011180317765158999, 0.010020409782074111, 0.008385523584880991, 0.0065897421432006345, 0.005694161284903014, 0.003977399636641539, 0.0070548435572755416, 0.004123070955245399, 0.009691678894228846, 0.005117234335780919, 0.004457381812054238, 0.00707249412615903, 0.008692418590719272, 0.005624726362930309, 0.008058293032260555, 0.004996365643893846, 0.006112774797661809, 0.006672342869430874, 0.0040998154167732346, 0.005870724340135289, 0.008411498240163275, 0.004271511989259282, 0.00486174361243663, 0.011967685147052615, 0.006948391851982658, 0.0017391373563090443, 0.005859680152001088, 0.005005916244778414, 0.005288412845260885, 0.0057800787943143046, 0.012808733170635933, 0.009080787165238878, 0.006340004332616967, 0.0060033742993477485, 0.0031005612798342716, 0.010968429835511887, 0.00452216979062346, 0.003735512736091882, 0.011902427788093702, 0.006430251479438668, 0.008076259841746583, 0.0062599285239258555, 0.0018049837592913525, 0.005206544658059649, 0.00567189010879994, 0.00875032684193299, 0.006680644945441261, 0.004533109605918384, 0.011011494878559958, 0.004738913124181796, 0.009649519611941559, 0.004880448259677634, 0.00471886541308003, 0.007360273861419457, 0.0077952382132196255, 0.007568756946497476, 0.004724956179308622, 0.005964405015265448, 0.0017108783910337803, 0.005055270999732307, 0.008861047345944048, 0.006609315798719043, 0.00475044128339779, 0.006054939177193235, 0.0038082501799121286, 0.007026729129388761, 0.005613744740704723, 0.011233513199287667, 0.004338251285045416, 0.00600899375709803, 0.0035231692992248377, 0.008090821685756689, 0.011274494860226723, 0.0037422364698924708, 0.007317594575338389, 0.006104006602651835, 0.008120532342111676, 0.005497961635763347, 0.005927581083606264, 0.007224199675429982, 0.005353601062611801, 0.011375809153821146, 0.008081383386306158, 0.00580863664506687, 0.0036516621508538233, 0.008207638198703422, 0.006717334442891241, 0.009159105165802846, 0.004988627644196365, 0.0058478587195813754, 0.004802545568222036, 0.011562480768964817, 0.00781237463840852, 0.005072769830829744, 0.008453819981533548, 0.0031232845910659137, 0.007321997478345775, 0.0026730655833177084, 0.00818705773892886, 0.006104195105749379, 0.0049964210601282, 0.005036347669805726, 0.004107668136604709, 0.01155448894566451, 0.005389565549747532, 0.008164257201097258, 0.006526012352961437, 0.011598418284288056, 0.006558417907449743, 0.0020261216801185046, 0.005706273612155005, 0.0030634734535252097, 0.006873195985034032, 0.0067772752858065765, 0.004760790555451329, 0.010606492696155913, 0.005355393453796562, 0.004701528370748891, 0.00800715875712451, 0.009456295952152322, 0.007624571144822581, 0.008769359373338677, 0.010781988906709792, 0.011421629288365924, 0.004642201845902585, 0.010116582128956681, 0.004171752567909398, 0.006278193389949933, 0.0035359540406882414, 0.008382100911752543, 0.004539824311574405, 0.003631391984923975, 0.0042889686478190725, 0.009068439256918715, 0.006563496749708585, 0.005778437498591363, 0.008089158139450093, 0.004585731800476755, 0.004830788339091465, 0.008118503856357134, 0.007577325175020475, 0.009599313194518344, 0.0045884436082705305, 0.002832634511442151, 0.010697294848348374, 0.011892849709821272, 0.007820196970133286, 0.007511962759803475, 0.0012233850226647971, 0.008766679185976792, 0.004590246768374797, 0.010939465063007229, 0.006929529861497873, 0.010869478254087229, 0.00528638555507683, 0.006575798938097327, 0.003371257265727463, 0.008036270493680971, 0.0065707662218749355, 0.002842398220199436, 0.003796578000314418, 0.010609552834725247, 0.004474483840024677, 0.005452245131687409, 0.007126763156830523, 0.009861136682898057, 0.004197850530583644, 0.005718267748095021, 0.008679557020377943, 0.006479497870519362, 0.009369308348992762, 0.005484073986785952, 0.003067198317287128, 0.011218803838881453, 0.005489015348210779, 0.005035085042124752, 0.005320516560518478, 0.009532697782605263, 0.007410998714504061, 0.007025678972393986, 0.00856017235495832, 0.007936684379809324, 0.007973349315449076, 0.006445939352047482, 0.005808657222727205, 0.012200842566148666, 0.0050093855320397385, 0.002176847500410196, 0.006707242118938108, 0.004553652259892259, 0.004542508749996823, 0.007267211908179707, 0.012525226726636272, 0.005476720713520432, 0.0031437103861600554, 0.0047326208772142855, 0.009358898118027675, 0.0042085381118907115, 0.004404239632401032, 0.005109155598465637, 0.009342626870039233, 0.007091309045137132, 0.008044274913207913, 0.01190753278353662, 0.01038205804645019, 0.006304491822529333, 0.005988850790794295, 0.010028581007674528, 0.005583269887119619, 0.009062403364046045, 0.0036098035255377903, 0.004735973158323097, 0.006797527022774582, 0.0037407354802860516, 0.0032061435439320403, 0.011440186254558823, 0.004027252668762211, 0.003610344383056372, 0.011114893679805248, 0.004077734734988195, 0.009393406329107665, 0.005029899929603755, 0.00837470130342644, 0.006684278874976336, 0.004540613233921128, 0.010583631907879386, 0.005070585053957399, 0.004835960393979984, 0.005848914946102338, 0.006141100558676454, 0.005577283943812571, 0.005006927374804671, 0.004662195320258172, 0.00876097762039046, 0.0054403255231541, 0.010930224338175514, 0.010265646860027214, 0.007373192451882728, 0.013651154824334832, 0.006724492254774625, 0.006631331614380438, 0.005458413989199765, 0.005390241384705983, 0.005896451073718344, 0.005447499276951414, 0.004487400405584481, 0.004954027627492192, 0.003992857550497499, 0.00874581654099599, 0.008974338617962613, 0.007693687318603821, 0.00398665154060228, 0.00632406463357846, 0.004737000875877076, 0.011030667750653339, 0.006707764785928773, 0.0039495069846825735, 0.012900290948295895, 0.004131493467829529, 0.008889707190372976, 0.00424758454398057, 0.003785459470299435, 0.010995352653602243, 0.0067273642121360305, 0.005895117943818163, 0.0034993374302227038, 0.008357024979923964, 0.006527005924074068, 0.005170745121296172, 0.008530500360976991, 0.007452108257276081, 0.006966680587888484, 0.0016203686497029085, 0.0014396102870275853, 0.00781543524749841, 0.010894694746211494, 0.011441678516280107, 0.0021149445329237153, 0.0095836730573102, 0.0056819973650273055, 0.005228618930671131, 0.0039757493601539455, 0.0057443053603552325, 0.006867957541633104, 0.010446622181733874, 0.006308157239081818, 0.007286600867825989, 0.008438310229134313, 0.007299720385614688, 0.005045119982925161, 0.004279273510094589, 0.005036460638635844, 0.0027844776082654476, 0.007019457255195584, 0.006941397779112145, 0.002472557357087007, 0.0016957856245385851, 0.0070362040536374616, 0.0059582491625964264, 0.004233700257245045, 0.004863639917319057, 0.0026209440588890673, 0.006708082019957293, 0.012285850842132243, 0.012920343000944003, 0.004389635017710086, 0.001818696246656102, 0.010809496578171877, 0.007560633336847997, 0.004580812548412059, 0.0075952859421781985, 0.007810475328435247, 0.0052637664843898325, 0.008155389739011297, 0.004157307002005102, 0.0056212910033179315, 0.006234941389929961, 0.007003340853371068, 0.006402605399591576, 0.005134862917976746, 0.005230998723856999, 0.013094257367784719, 0.011717843684587843, 0.009147159605224088, 0.006370523789541779, 0.0058526513270448395, 0.010983070680701836, 0.005730069398663651, 0.005768759776224086, 0.011064057677227568, 0.009721498018381236, 0.002695345914766469, 0.008498577961308594, 0.011188383437390585, 0.0034300892481035792, 0.011091039117860196, 0.005351990326849758, 0.005568931638895016, 0.005433517705563493, 0.006205855434245811, 0.01048200324835628, 0.005685063473551659, 0.0013979464362356832, 0.005597769025059093, 0.0043799041894270205, 0.006064028767008291, 0.0072527744602924535, 0.006248840841332187, 0.007287448009333926, 0.007515357516286551, 0.006726916356666803, 0.004394803044380305, 0.005206385228686386, 0.00622446863486807, 0.004868445263706625, 0.006247244076159243, 0.012848016164039296, 0.006525116672587604, 0.010568309119607468, 0.010457873222707205, 0.004882445641333308, 0.008248089778845849, 0.005105835506617093, 0.007438278101455729, 0.004881535930594299, 0.011574157117043942, 0.011713535115789708, 0.0043807206832155955, 0.00336240188195951, 0.005253921041778679, 0.00563086972340977, 0.010564384127532137, 0.009286860262849781, 0.008435327951430836, 0.005113518645413377, 0.0018282998438541227, 0.003560879336770391, 0.007043801482320495, 0.011012962789244525, 0.0023091593528859833, 0.0069318455629777155, 0.013528142164571912, 0.004845407807090153, 0.005897897564661641, 0.005882635389753961, 0.006310115261992162, 0.0037328981634587766, 0.004600720034963081, 0.0019919547764039943, 0.007821865367559104, 0.005831213275713695, 0.004279766146753332, 0.006786835463289925, 0.005112245748208028, 0.007103141444206378, 0.010406418157597836, 0.0025370922235087873, 0.006927713400986189, 0.0030978433090998077, 0.00849724343793399, 0.003810119518970114, 0.0049007615438816455, 0.0037506694202337288, 0.005604216012453796, 0.006219779584527665, 0.00649019396710334, 0.008136862458984262, 0.0052514043546382505, 0.0034764890803253797, 0.010232960560938097, 0.0048451068220682035, 0.0032014032799548716, 0.007846689283044814, 0.0055403508897551084, 0.010990358771296862, 0.005384661335422923, 0.009513110318026286, 0.006772892774794318, 0.008868979436322482, 0.006393750984929704, 0.00493481679916169, 0.00327428198168618, 0.0030262160677826584, 0.005221507700231847, 0.006551191244770148, 0.009559995861284198, 0.005228540831686881, 0.008166786242321731, 0.010156354028087995, 0.010579656871278584, 0.0038051025547761685, 0.00946817706295459, 0.0029675272444946678, 0.012739600300222495, 0.007624582628728527, 0.006218152186124201, 0.0055944611398965624, 0.005747619608612017, 0.008854180732662427, 0.011050014914314371, 0.007361508793829882, 0.005102903751110197, 0.00561416472887975, 0.011448029790585672, 0.004900118189964595, 0.004444219989517108, 0.011171223302077697, 0.004799924949731246, 0.004451298533250496, 0.008585466665367754, 0.007312631952264684, 0.0054283120407532595, 0.009979070167165677, 0.006625373169382899, 0.009431705055067133, 0.0038831740709660365, 0.010579140163318977, 0.007305929460333352, 0.004599557806394602, 0.005305737206721483, 0.0040591247733550275, 0.003987422791193588, 0.008886431150610729, 0.008686444839970914, 0.009487440909312268, 0.008334859937721126, 0.00407162232790896, 0.004147821921110434, 0.007423946166651712, 0.013321675963377001, 0.003931642651530881, 0.0060921755239226865, 0.004858056597910985, 0.0025982954289528147, 0.006884335535928819, 0.0068198203954350925, 0.0023340828586607817, 0.008357338007389276, 0.004240274561174077, 0.008259189678352305, 0.0048588519269827666, 0.0048660073901292955, 0.006745528385419482, 0.004020615038323285, 0.006595622184259698, 0.006652828341042761, 0.00891173627292978, 0.004482295015291039, 0.0031730277344724184, 0.006221498657325174, 0.004754875722356994, 0.0051922788477463296, 0.011460230789534372, 0.005943131125949705, 0.008066320069829309, 0.0034961646426349352, 0.00708551555905152, 0.005145243186035252, 0.010017898997646275, 0.0037618988028007483, 0.006968807992887774, 0.009360837309271694, 0.0018321576337575736, 0.011476469212069865, 0.006449704476644287, 0.00531980513368399, 0.01277043404630479, 0.004830831080462813, 0.0033218131971754373, 0.005920066609839073, 0.011539913183892336, 0.004887234177360645, 0.0057199193016221625, 0.005029254517817512, 0.008494083837809356, 0.005574046510056495, 0.005436964247259784, 0.006732662959219782, 0.004844406821812862, 0.005738621497822832, 0.0025469234902857204, 0.005361223699294301, 0.009487309555230167, 0.009295238997461121, 0.006615037779214408, 0.005871266026757109, 0.003242972705824694, 0.005995976924054463, 0.0041969725843667045, 0.006002885418198213, 0.006097488487314571, 0.004680032963337174, 0.00897234191666058, 0.0070370226085438225, 0.008013623589494994, 0.00926696572384578, 0.003964626587751464, 0.0026492392410874237, 0.0037521741530241, 0.005603331302588764, 0.00642212915104385, 0.005369279811998464, 0.0075591631366148165, 0.010260255030673572, 0.004454107788836646, 0.0037090182379221695, 0.00957672315673471, 0.007160061735762104, 0.01176946026919938, 0.008371285562574705, 0.004058231790438931, 0.012013420200424741, 0.0120466762797236, 0.009876708423404906, 0.004851363331250353, 0.008947949689653605, 0.010029860976053705, 0.00595239020989414, 0.0035925207105818634, 0.005253815427871733, 0.006463501213006836, 0.0037818787679599506, 0.013089677776499156, 0.009782039576380321, 0.011111933005243142, 0.00671634631683766, 0.005706813083413176, 0.00922139198062357, 0.007292444961614498, 0.012332054903479626, 0.005522908812325112, 0.004180621318036964, 0.003444204688130164, 0.002812107436456439, 0.006754540010235012, 0.006175695035839287, 0.0070614789889536875, 0.003220386432682943, 0.005391904816637336, 0.0031294726005822813, 0.010800197656488245, 0.01010662370002634, 0.005630699801039581, 0.01293457605280817, 0.004178220163018214, 0.00458852151088424, 0.009830953893411105, 0.0038662759147228987, 0.009115670552039963, 0.00974244626154102, 0.0038283288349865077, 0.006264646334110039, 0.005229036671327236, 0.006542287652761606, 0.007411676383574048, 0.00516589748510214, 0.005178946524603655, 0.010363012661639914, 0.011288525567053766, 0.005106529738425443, 0.001935915522676451, 0.007447010210719062, 0.0065285147304879445, 0.007549886938857914, 0.01038168677870697, 0.00975895590823845, 0.0049295491969785585, 0.006086449406046548, 0.003941592510392942, 0.004693624101857664, 0.009319632047988713, 0.00391657172474394, 0.004630775462909207, 0.006816283742416033, 0.004609291930920952, 0.00901619089701047, 0.00793108495994119, 0.006857932518601079, 0.013476108209030228, 0.002075594875257488, 0.011326503797065283, 0.006425181323068853, 0.007717027801109113, 0.009268367717245405, 0.008756571226388996, 0.0063042792317542, 0.005497890460808924, 0.008210543099239125, 0.009564632973351538, 0.010325371154811226, 0.008777422271386792, 0.00951392082082365, 0.009362140365874136, 0.007095949175934301, 0.005214749534738477, 0.0058029736740168565, 0.007468514166018081, 0.004652934691775194, 0.0075029870572526315, 0.004804437777973191, 0.003871196008224739, 0.011784812030772416, 0.002760328054662158, 0.005054900343426405, 0.006169446097868479, 0.0042664680704385125, 0.0049213538258196295, 0.004861287883254512, 0.004971248273274264, 0.010508232949682133, 0.0024029374945607265, 0.004859856658051896, 0.005073422834156178, 0.0061840842540403585, 0.005148941428265795, 0.003839066049741729, 0.01261103484086874, 0.005410736796909301, 0.005654108673965184, 0.009275433530800192, 0.005665813539986842, 0.009318659596386312, 0.0035983734521830447, 0.010576624746266312, 0.009261285235294382, 0.006784485871745032, 0.005120362197927523, 0.006445670269292098, 0.0055398051801533775, 0.004977766371969625, 0.007104445654627508, 0.005777052839170999, 0.004617629564583282, 0.004501342298099581, 0.010320657538126655, 0.005402025599314823, 0.006415193638752553, 0.003227484932646363, 0.00394184527361713, 0.007472241964925002, 0.005274157925216306, 0.005511933945354171, 0.006015925113010706, 0.012811385938910323, 0.005160477878158598, 0.005441182561094519, 0.004693026258485372, 0.007280631982764828, 0.011668393521431716, 0.010036519552286731, 0.005407935202587601, 0.008010639617650457, 0.00598162424137004, 0.011117085085959068, 0.006501635022303573, 0.004866172511320627, 0.008309810494838294, 0.01106991842654537, 0.011697611033551854, 0.009749012188490253, 0.009111530863677157, 0.005096692966867364, 0.0052984973758534865, 0.0052460432951441476, 0.00353842864198718, 0.009960735375001183, 0.009549545491393321, 0.00616194143361449, 0.005398929015866206, 0.0034215522088086826, 0.00999732727608673, 0.0034733824113655745, 0.004127791854065521, 0.004302469533829587, 0.0058931833330797215, 0.007590293482581056, 0.011208404353351832, 0.012081000413682288, 0.00560412296588826, 0.006685332695827708, 0.00647130959153267, 0.0020465699456906723, 0.004170924986305609, 0.003823452929067663, 0.00604422486397954, 0.003521827023485929, 0.007400159525399265, 0.0050342193224469246, 0.005100429262349507, 0.004737525183288702, 0.010260447340629007, 0.009244046518619323, 0.010300584670566966, 0.00845003517787812, 0.003428393262666948, 0.007106061713590798, 0.00512984106882, 0.007891839126295147, 0.005823338515255636, 0.005652474607038885, 0.0015450572156120175, 0.005721884741538091, 0.0019724011661717542, 0.013306688441943326, 0.004858009374720484, 0.003984823104687451, 0.0068306879800488565, 0.007410988692778363, 0.0068952380952178784, 0.008100447308320276, 0.004410758409675822, 0.004380130051305793, 0.008508354338191805, 0.005344791427832712, 0.0057287824298466895, 0.007542717846135872, 0.004859435060035568, 0.010639075071400888, 0.006824062067911602, 0.007233686355066576, 0.005698084617176383, 0.011820248882593304, 0.0046217615464519655, 0.004376225066957462, 0.006263484214372185, 0.007311671962960421, 0.005949584033223055, 0.00663291603811261, 0.004798134300909897, 0.006481758229124037, 0.004643216354482008, 0.005860351614644012, 0.00504805864606627, 0.003967793669681288, 0.008426078230316568, 0.011826097473279392, 0.004946590507673488, 0.005037120869909132, 0.007908522711307374, 0.0016440479387711958, 0.007848954807432194, 0.005923854365460822, 0.008241200866871674, 0.012318456785140017, 0.013486253424145514, 0.005169999418605228, 0.007260192736610462, 0.0077460201290119185, 0.005370312586683504, 0.0070282578843026255, 0.0023051048659233323, 0.004033848711903672, 0.008453168795200354, 0.006357380948449891, 0.0047059840936837195, 0.007364902841403314, 0.007096186221447016, 0.009984684190549101, 0.0038457391704549396, 0.0036086206149849626, 0.007957847225793947, 0.006862531160203289, 0.0030717793865591646, 0.011876739553909745, 0.0014999981666297668, 0.005964354652937438, 0.007846289294394022, 0.00621354961421587, 0.007525894372510762, 0.011797973022802565, 0.011309822600675767, 0.010533583626524793, 0.007733842866142725, 0.004456651944494871, 0.011121388997528105, 0.006238305575284435, 0.007156295383500476, 0.009100607483355356, 0.004304017826730157, 0.009882897116150704, 0.004791940485403538, 0.009535078883413699, 0.006748808309797812, 0.004102638265801921, 0.007902236413177237, 0.007251870207348712, 0.005132771403635653, 0.012072107121267231, 0.009178926278702183, 0.003656398065299255, 0.003709861984814968, 0.006608487108833388, 0.009277234653047034, 0.007981488513900327, 0.009345362331614104, 0.003258914657786186, 0.013071028366586393, 0.007769552053676028, 0.006938288487574832, 0.012351871859422003, 0.0047934654264852545, 0.005105369479691852, 0.006213995128761373, 0.003703787627854364, 0.004799887832128678, 0.004394520395216972, 0.00924719624711356, 0.0037145545474911554, 0.009028314833841627, 0.008701148328522684, 0.004736819802149038, 0.0030173556902801458, 0.005907095625831468, 0.0027580881879433242, 0.008723382377715999, 0.00854307191864684, 0.0065950104595447765, 0.008123795478423365, 0.005252197618800484, 0.0054406434759330284, 0.004993733450115084, 0.008169524436462221, 0.004479800788787199, 0.008460732345694368, 0.010536706349155097, 0.006921518025981326, 0.004947233537043233, 0.0067055194480544, 0.007830296863457521, 0.004875580773807732, 0.010568977180551895, 0.009343333182028825, 0.007864308077282308, 0.00593473559868219, 0.008965001693549846, 0.01181467523108153, 0.007718203932041453, 0.003100798107793184, 0.003325351438612412, 0.00582704191570038, 0.01142131961304991, 0.012614456671119451, 0.004896399229652563, 0.003225810758715025, 0.004536978556060339, 0.00826853442372633, 0.011219679588088565, 0.006512082987455684, 0.01253111295092767, 0.013000712731377186, 0.00583806434545428, 0.003276396602915407, 0.010285796269160949, 0.00583890412847878, 0.008755346764588823, 0.006030825250401273, 0.0079865295546328, 0.0032661098634722404, 0.014239862799063675, 0.005365079904846926, 0.005008610824180639, 0.009109935940662348, 0.003125367490115959, 0.005620222758569842, 0.009414303048053994, 0.005261719846378375, 0.005824107562128458, 0.011154334853548342, 0.004002660402392818, 0.010027210122541845, 0.01025180977219452, 0.007570464135650462, 0.005340608847095914, 0.0030205889459181193, 0.002084696738983761, 0.007598245729361642, 0.011073193614635655, 0.006531433347954564, 0.007917402575691769, 0.007944036701190278, 0.012016852059465396, 0.0041762089784387136, 0.006588863989309287, 0.008651876486556104, 0.011611823527393308, 0.007094181222532598, 0.0045211592571243004, 0.010367553449812838, 0.006074655312766797, 0.0039643812359055255, 0.013774639640458488, 0.004597949046835621, 0.012341231395466768, 0.005886545738549296, 0.007554293622948696, 0.008506878826411155, 0.0053693781042826235, 0.012168140571172782, 0.003732580634463424, 0.006663884751693874, 0.006078742648025486, 0.012651910246362197, 0.006396951981288313, 0.008153798292487689, 0.006095503366145434, 0.0008146237971646333, 0.007156289651248262, 0.003852065393943346, 0.011191867753055064, 0.004076158616869234, 0.01225943671378415, 0.006748443517375628, 0.006644349983362816, 0.010838341447070967, 0.00642942525063738, 0.005803626690008366, 0.004043153955943378, 0.010870386787075062, 0.003200673653909958, 0.005854610670213823, 0.002460733112845761, 0.004907147722643371, 0.005848652311651867, 0.004959407869756374, 0.0034571753355729876, 0.005536699091470514, 0.008893320777588271, 0.01189251635499446, 0.009728493033225417, 0.007443772146160099, 0.0047710264053159555, 0.004304341207922795, 0.002042640753618571, 0.004983501755969811, 0.010198625418473935, 0.005504149716904296, 0.008817673648248753, 0.008422200528841158, 0.005055906461340753, 0.003050334187475321, 0.011928391824572133, 0.005799679869270513, 0.008364918115007893, 0.008702270799607243, 0.0065508007798585465, 0.0021875868331752714, 0.004468181122334528, 0.011941119137320497, 0.004983702804530976, 0.003149534386033373, 0.006794502872676453, 0.00786325230231103, 0.00710087451010337, 0.004289022044317126, 0.006169514358064149, 0.003785198397126705, 0.003096077382364394, 0.009589539041611861, 0.006000954955867484, 0.0029677215042110744, 0.010216874298740911, 0.005527778466782396, 0.0051295273267911706, 0.008613606811186687, 0.005191347456085115, 0.008109582391507598, 0.009287319254014454, 0.009323698619479074, 0.0038273781991866604, 0.008517419352861906, 0.0035993946705176515, 0.007787467555124776, 0.002325648475470921, 0.014928762455824895, 0.0037993564581962785, 0.005932938695600992, 0.008667419489010904, 0.007496320447563638, 0.005733121862542417, 0.009300473029738967, 0.005326936840168427, 0.011664249154141205, 0.008132532627203835, 0.004173428441100252, 0.004146538276648579, 0.004683243780386265, 0.006185482001116231, 0.005050184562775876, 0.005062854301298066, 0.007224864116456748, 0.00853548243923989, 0.013262971860107609, 0.007687172387879336, 0.002190733500715819, 0.007426221405923316, 0.0055768533691346305, 0.0074499568377919875, 0.00623620383242479, 0.0037282316018741107, 0.0015168246796968756, 0.006434435151835084, 0.01229415493505916, 0.009806804278744929, 0.0063027149873682, 0.012971378008564589, 0.009903475872820472, 0.0051857691612434, 0.013687860812930816, 0.003200254306157061, 0.008764090184301758, 0.009176348386696634, 0.006608955460114417, 0.005424893156910774, 0.0061497083696358205, 0.0054868586762979975, 0.004278924509082948, 0.007045293185523256, 0.004362611273213163, 0.008602916623617354, 0.009106653549440399, 0.010123512051364143, 0.0047277640867774045, 0.0047569634880774096, 0.0074696989539047645, 0.002932547116638749, 0.01245303474973202, 0.00596357092334632, 0.00662728156629841, 0.006409365520428909, 0.0055039851153974514, 0.00909607907747276, 0.005924752681289657, 0.0026018733527646363, 0.006387865861223251, 0.007225738116011453, 0.006297611137480242, 0.012468022603201769, 0.0032049030292176464, 0.009538540256496152, 0.007008584591916543, 0.0030929889887370077, 0.003856212999100707, 0.003620985560779087, 0.008569669109521188, 0.008520175109675397, 0.006537010438214433, 0.003419926495091432, 0.0051804606989920305, 0.0037174112286975695, 0.010816577867926537, 0.004417535433760208, 0.007305212548246532, 0.00567546003866044, 0.006855152688733119, 0.00894662441295675, 0.009065162468449389, 0.005226898271840602, 0.012566480365295004, 0.006291805948339425, 0.005742563020795354, 0.004993618642943453, 0.0019171411624729422, 0.0048897107422192655, 0.005226224198442405, 0.004180648202375155, 0.008233427314668517, 0.013401682760846655, 0.005552334438695006, 0.005212415571324035, 0.007017554109168632, 0.010577492461111088, 0.012212378466912477, 0.004800371778111947, 0.012129970794789061, 0.005044339810521095, 0.007273384256288492, 0.007536554248483625, 0.004431012774242498, 0.011880008598829588, 0.009452410869873116, 0.009506495661238911, 0.005048652931305018, 0.0069821728832804835, 0.006742200587438763, 0.008077066270942384, 0.004387098486095434, 0.0034993032283096963, 0.005524413978236258, 0.006827157876763412, 0.007156106034245992, 0.005233649439280964, 0.006256170732190546, 0.003300249797604837, 0.0030523477102346146, 0.007521659660218607, 0.004399402545644253, 0.0041802690755136495, 0.004370622365175624, 0.0043309779749217, 0.00579970652712037, 0.0011862804989053852, 0.006815816418611702, 0.007427114917517092, 0.0058616736593590565, 0.00799773675592777, 0.005691887804829662, 0.005018111286315527, 0.007813211205056046, 0.00804351525224444, 0.006474797170774921, 0.002926273750155067, 0.005401037001452274, 0.01087149715655077, 0.005335684895313573, 0.012893104489994003, 0.004375739618833179, 0.00947656294230033, 0.00824866664092652, 0.0031963924672641997, 0.00642560190395149, 0.012167923892235658, 0.0065662862688528854, 0.012087113392069308, 0.001831355734993548, 0.005289616200987839, 0.007683912860964476, 0.005343356528641283, 0.00631256799526896, 0.007019498925467208, 0.0021758293919732323, 0.005464818874986338, 0.004325649256345695, 0.0018925854272289209, 0.01075178170532997, 0.006504785519644228, 0.011403711659937903, 0.009943384968785083, 0.008217681925077058, 0.00895238546953989, 0.005563463979267959, 0.011315208540505751, 0.008886443495973641, 0.002092179255392887, 0.00885600775669664, 0.012697028137652569, 0.011003552227164102, 0.007487617995279128, 0.004649535073165198, 0.0066641131100742945, 0.006237568639178789, 0.003210187847750864, 0.001506684029072563, 0.00794291424821494, 0.007282104140352946, 0.004724736667461668, 0.005204304884889897, 0.005510288662399086, 0.00437551768087913, 0.003980187498253894, 0.004864811397403048, 0.009512350781458054, 0.0045407311608216105, 0.007951209187470738, 0.005218142880689803, 0.006279328943789542, 0.012244427852875361, 0.004538810328844068, 0.007161864911331089, 0.003073442951535016, 0.010197449308625945, 0.008496262642009015, 0.0031999894958179395, 0.0043323976687589414, 0.0035768592642119084, 0.002687384023170157, 0.004259838185189789, 0.006892010931027527, 0.004024405780977414, 0.005643520239749228, 0.006712637911800949, 0.006688096472697376, 0.011297542535896295, 0.0040542567889175095, 0.005604539152095744, 0.007351047143579114, 0.005263968225086032, 0.005169860004343493, 0.0033227984335630198, 0.012483382624784593, 0.008036293962715609, 0.004083341776795865, 0.007528853963882342, 0.005493715393048534, 0.007472219800331582, 0.005290409545090965, 0.011433455612438873, 0.013576853561599876, 0.006201714929219216, 0.007722508308315933, 0.004123622013827118, 0.0042498188998667166, 0.013470483652373168, 0.008519011323300666, 0.0067569941402283356, 0.007641607634966487, 0.012952542388711897, 0.00361490823492719, 0.006910255290549004, 0.0035846497177528676, 0.0012849944983369446, 0.004279050748933487, 0.005889760695836037, 0.008168219952924334, 0.006721574988126637, 0.0033058622427824588, 0.011117321667919636, 0.01269075225430243, 0.005865447738171976, 0.012072404259419025, 0.008838440901720654, 0.005939462953109868, 0.0069793463829376035, 0.007451038298730738, 0.010895668222318668, 0.009601952659632772, 0.004687563859329069, 0.0024109518722698294, 0.0055070797919256394, 0.008519821819012494, 0.007545323313763029, 0.0037245276075595327, 0.005073963130175731, 0.005402766245225641, 0.0074393674435889534, 0.005727580564252436, 0.006999246199285762, 0.015105160548981032, 0.0034383323191928303, 0.00571666866270518, 0.002701540641047127, 0.00876589405869351, 0.008678853909298831, 0.010554267250704841, 0.010236973906625323, 0.006796939792017872, 0.0071334996320989935, 0.009026380577758493, 0.010014435622858002, 0.007682482451333728, 0.003695011217361318, 0.007556914515317807, 0.005391547580825199, 0.003405080066643546, 0.006343105753801384, 0.0038412433078831385, 0.00657887605912145, 0.0012859777992111736, 0.0053372055322761895, 0.008879432562585006, 0.006120307581269821, 0.004695982213619061, 0.0076445110753359646, 0.009721944083794322, 0.008720890008318945, 0.005602024993747477, 0.004555155786836195, 0.012246820661080494, 0.008637216386484601, 0.0019747659054908445, 0.00330537585257635, 0.012539650954061312, 0.005415183457083116, 0.00761511882852983, 0.0062263467303728896, 0.006213038287768551, 0.007774197754828247, 0.005593108512059379, 0.007557464783912682, 0.008554666342395257, 0.0049084836914468485, 0.00906415513331503, 0.00893923748930369, 0.004758848554034557, 0.00849409145768759, 0.008404605107419921, 0.004960586000663892, 0.001791048329243124, 0.006935071949559248, 0.0037281077214867684, 0.005236568175566083, 0.010340760628017108, 0.004876785277429853, 0.005586087318536215, 0.004268567447770455, 0.010234218744281006, 0.002342436587176688, 0.00855282802878064, 0.004116571398261607, 0.006256735727978274, 0.006826342796223076, 0.007965468177310522, 0.0033018738275010628, 0.006398094496992161, 0.005492839931920171, 0.006921095918181995, 0.006024836475798716, 0.010936127296161464, 0.0062035165074109085, 0.0075669142336905835, 0.0071230634153535985, 0.00409438289441853, 0.004668784116891657, 0.004343034842006079, 0.00440283704204598, 0.011731485783340321, 0.005757782782566348, 0.005081005755547393, 0.007773306560847116, 0.005803088057304217, 0.005361068170457825, 0.0062930965387127, 0.004641858096942717, 0.004660384097358325, 0.00908453066368108, 0.0016751554689882658, 0.011486602660901495, 0.006547922634480148, 0.008143458498826469, 0.006374615717541946, 0.0042382457314175314, 0.00678789579421057, 0.004857717907896755, 0.010473269420647014, 0.007207145369455801, 0.008774388739687847, 0.006886285294340938, 0.00407579744005119, 0.004816048342044039, 0.005989311558381813, 0.007848412746805231, 0.0061737771172712995, 0.0020114211060336235, 0.007087236092632746, 0.005898371147873425, 0.008809169069568263, 0.006322878856398753, 0.008292027487796599, 0.010755208956334, 0.009317996254795255, 0.00335225729773286, 0.0043285787430439975, 0.003614037915520587, 0.005241788786452112, 0.009558542514800015, 0.006361066556415697, 0.007404866401339527, 0.0062264900513205445, 0.010998290324834199, 0.002961670672190866, 0.00472476673444174, 0.007722916038980912, 0.002267178007133063, 0.011933159907568092, 0.012192154822630755, 0.010440193823528985, 0.008251928532137725, 0.004833336707018824, 0.004076505525195468, 0.003500632347764549, 0.0055082851271931795, 0.00668453467898892, 0.0063905266920953364, 0.0051942309076978485, 0.004278480893248446, 0.008319403213555484, 0.006218035519211634, 0.0052931997044355205, 0.00630505128253817, 0.005623790894090877, 0.0048501744087042584, 0.008573897522044814, 0.00611332432349912, 0.005954374813410919, 0.012378631792916718, 0.013275981110420863, 0.005948793827921265, 0.006146969788336039, 0.002654306710417427, 0.006736828975379628, 0.003311571322079594, 0.011736033118885204, 0.004511984812733134, 0.009169147324021475, 0.004536944273593973, 0.002693127725537921, 0.005630333408423326, 0.00667523427496889, 0.005096124374497681, 0.0033214765365346113, 0.007861433912018451, 0.01030355788675063, 0.006288880732050412, 0.005157953808594214, 0.007351788282775653, 0.007466947199932263, 0.006005867595468252, 0.003780485722511659, 0.01248346202058934, 0.008932564505144232, 0.006109961220375765, 0.007644926700001942, 0.010421433289906882, 0.007340165664623772, 0.006398348055444047, 0.00673591407480107, 0.009739072618438873, 0.0057887439116200735, 0.006904598991373751, 0.006903163487961664, 0.004973125192908581, 0.004504762399957843, 0.0033861270962303475, 0.003517635856369636, 0.00678250887965231, 0.005877394463238531, 0.0017611982835204238, 0.008851468904535809, 0.00723863470510239, 0.0063223559762390965, 0.004632121785913212, 0.006481543571349427, 0.006233146128298341, 0.006802045549509149, 0.003833860832655886, 0.002429414514947589, 0.012314971827042614, 0.0036325944747184354, 0.004243863355068232, 0.004551741849940564, 0.006737899462796268, 0.005353431970944302, 0.003386848620879973, 0.0077042558675281154, 0.0053064689412837705, 0.005220587493551207, 0.005215294319320307, 0.001740429399618954, 0.0033488893335351473, 0.009380004546423659, 0.006215386591870719, 0.004048256951930454, 0.007266180548068078, 0.004262971865024814, 0.005094875806485658, 0.005500216371359657, 0.005939451101526982, 0.009399727550127803, 0.0044761511959555056, 0.0092182966945099, 0.00177984603541414, 0.00341795259068567, 0.007318294843793151, 0.008016618136803377, 0.0021375334441974207, 0.008598283035000872, 0.004917106735136819, 0.005337602604374098, 0.005144687551702611, 0.0018755929386722924, 0.0013147897797897291, 0.005417090193078398, 0.010209759343188577, 0.009670591598916811, 0.005128653195214941, 0.006453077992790292, 0.008416459402978948, 0.0072446276416685915, 0.012525298208499768, 0.004819793604704313, 0.011405378265230987, 0.011566979773313855, 0.004624167792413526, 0.004736030101060237, 0.002478836544333716, 0.007889104572824853, 0.011113273611875708, 0.0032477539407660865, 0.00554408279105729, 0.007297882034981044, 0.008735565958027419, 0.005221378746819737, 0.0061764879090722095, 0.007148266149428974, 0.012155420307911384, 0.011423630844999703, 0.0034182162300695697, 0.0038476148711424117, 0.004816662575987334, 0.00694487157869573, 0.009317304241076525, 0.005287204760577984, 0.005636427416991387, 0.005959383927850828, 0.007621783165604001, 0.011263717971547321, 0.007894163833156663, 0.010713499115701764, 0.0050679030625811715, 0.012792145567937946, 0.003260407842206763, 0.011733182845779844, 0.006832462620561802, 0.004880755707763835, 0.010554988472730297, 0.012198363441933648, 0.007061578825509076, 0.003455433812298413, 0.00792193073959557, 0.009292978761384157, 0.00274940692785061, 0.009569232729471109, 0.010334867541462756, 0.0068711667488614864, 0.005335740573502658, 0.004156161011856384, 0.005959195400339207, 0.002860306624003709, 0.003606339037265609, 0.00875095184260857, 0.013624149930053512, 0.004936976886409861, 0.0020217975534921363, 0.005438164143412564, 0.006070101798352769, 0.005208620388373008, 0.01045664698579115, 0.0037644074895387095, 0.006088093257747786, 0.0037726318006955015, 0.0015312294830786756, 0.00978556862407504, 0.00471300793668035, 0.0047862414343814354, 0.007749258707764887, 0.012175073516164587, 0.00533967943108074, 0.004048354186977487, 0.003401406386199471, 0.001974419578369418, 0.007612609803500368, 0.01070070258631317, 0.007126261119354289, 0.0015445069039681483, 0.00541713136018448, 0.005370697058466878, 0.008182114797321354, 0.006623958611028002, 0.008306171883720636, 0.0037102063798649795, 0.006558963382936463, 0.0028503018493441505, 0.008346795322461194, 0.009551207624988019, 0.006389541936884421, 0.012384156301469443, 0.0036095457705308787, 0.005899684776829119, 0.0037552450584243495, 0.010385891222381899, 0.00766867754329798, 0.011212927562087386, 0.004114891205998952, 0.010402723417192125, 0.008544995882196222, 0.0036981329180033736, 0.004988860215266668, 0.0066341501465243015, 0.0036342810314325654, 0.002538977769113957, 0.007085288137851611, 0.0071765935743383896, 0.011012720158309706, 0.002516662978745884, 0.005473999782897235, 0.0071151023719695245, 0.010867134030161815, 0.004996508141312758, 0.006116517507312881, 0.010253115864141606, 0.012287369826456616, 0.004743650435005531, 0.006091121510979812, 0.00570825411605609, 0.005296772797126981, 0.00611785664738922, 0.009499723317401822, 0.006572185648001049, 0.002122085177943355, 0.009185005557219236, 0.002315555934869505, 0.013989541823866624, 0.00923711880788946, 0.004575686120366573, 0.0039865080990617585, 0.004405458823959563, 0.006921771162559577, 0.006803562600374987, 0.0032788787776241, 0.004785867920104691, 0.004883947227006893, 0.0018295098516614217, 0.004210256467545557, 0.0039202884509860324, 0.007900511998969968, 0.013567193459740088, 0.004679623724468689, 0.005562261770597355, 0.0038542937642167025, 0.007507494233355732, 0.0020611557833579075, 0.007895563513002475, 0.005644331387393207, 0.006658046393404211, 0.014085382680005323, 0.007177715457161671, 0.009719133179150553, 0.0052747322776628405, 0.005309691692722004, 0.004294469392811962, 0.011748308120999262, 0.007568965824362611, 0.005300913774206957, 0.006144298351172686, 0.0043504938784872955, 0.00397436037830776, 0.00497063715756279, 0.008538612437036675, 0.011274760817645543, 0.005964023980821542, 0.006750400527483517, 0.01069658498510038, 0.012416382474368624, 0.011718384168817824, 0.00563493327443332, 0.007374127932482329, 0.010790453106437576, 0.0073796431199920475, 0.007048193186247886, 0.003471599888818058, 0.0033200579683588145, 0.002897104289793836, 0.0027373734316723263, 0.0037616162404678355, 0.009687832324070124, 0.0025241714372672168, 0.006517276753716314, 0.0039339532907432945, 0.012746271423301748, 0.008644712551411533, 0.0032784844613416883, 0.0026222201503058617, 0.009521200774312281, 0.012912173405524618, 0.013651911339838915, 0.003977520213395083, 0.009679986516995295, 0.01028808288353687, 0.0064757405819379135, 0.00466333329148512, 0.011195028664487253, 0.013156177872416474, 0.006036462961816024, 0.006300493508185311, 0.0061977805180822, 0.005769009151966872, 0.010874125328251116, 0.01129794303494777, 0.008867841175626643, 0.008461910700839135, 0.010387886867533941, 0.011064391111347459, 0.004155202109589228, 0.011037204566769356, 0.002571166534110347, 0.0031346689399193188, 0.0029851123024919714, 0.013834124099105009, 0.0071678233770726615, 0.002686748977675071, 0.0019744041947515473, 0.004250912711351853, 0.007630075679447392, 0.009770585232653948, 0.007972710453802993, 0.004921674013508371, 0.012838245135155822, 0.006618078189891172, 0.006292762938172895, 0.00719406402547034, 0.007203585091510965, 0.0075568396659839955, 0.008357423643067049, 0.00425145675542082, 0.004049264653655184, 0.006367973847075306, 0.011151412898907188, 0.01174727271132063, 0.0039325549855464045, 0.005136737026890962, 0.01155599488670651, 0.005633466251632153, 0.0043115972321005076, 0.0015461268599686216, 0.004406938746647471, 0.0069328842287104744, 0.007162854048657144, 0.009173026936517805, 0.011899365823275342, 0.004584804056515891, 0.00821620896403998, 0.013777061302271864, 0.01326982904761913, 0.009152222797080114, 0.008442491441095618, 0.012173735870275107, 0.0067964175116918225, 0.006144480996547413, 0.0032773169021188433, 0.004767900184793858, 0.011970745939048717, 0.007917179506270397, 0.0037518326744182748, 0.005746091950605539, 0.007119148720927736, 0.0048454802292494, 0.0026226072231148125, 0.009280228817275252, 0.005722050485642062, 0.005491753631333423, 0.007140341453959783, 0.005479578623728943, 0.004329377702494552, 0.008425415202307513, 0.005676869894959645, 0.005257497041502494, 0.00806453831471767, 0.012024655866549546, 0.002973019089132373, 0.004507865261747757, 0.003761899198105987, 0.007008115131737199, 0.0012173271220569989, 0.0044896498959080275, 0.0070755998869956385, 0.005434971916912837, 0.012941113362395649, 0.004844217014535869, 0.011787220793915244, 0.006568267271382341, 0.010023344618702076, 0.006266330739546921, 0.00540918030499205, 0.007406176205054781, 0.006453254452104277, 0.007392122831174117, 0.0024083027916730077, 0.0056179185215051546, 0.006621632602063821, 0.006098866585603527, 0.0028261099498406964, 0.006306945974029738, 0.0037358141298168314, 0.005941967671696533, 0.007378419539968302, 0.004046384948174642, 0.0027671569502696045, 0.009313939521014464, 0.008244246837099484, 0.00393460707197774, 0.010789638372712223, 0.008774726626529672, 0.008166093065930852, 0.006527150445205927, 0.004227772169304259, 0.010347749335039073, 0.004861389792724058, 0.00426771702060206, 0.011283409537145402, 0.006306058976876271, 0.004052793791595987, 0.013405915406200014, 0.003368589289323086, 0.009290959608145702, 0.0029243460381510656, 0.012705434768552439, 0.0075964069310177785, 0.011764579166320979, 0.006420371031444141, 0.004866433148476859, 0.007007656227641962, 0.00799948510525127, 0.0077698707706732265, 0.004760741693681117, 0.011068152959703455, 0.004169672676561923, 0.013569368423389133, 0.00893924197208187, 0.005718624085604437, 0.00690153979968287, 0.009124133190254617, 0.005182931206853031, 0.007006427574484688, 0.005657722738238945, 0.0057304272775118795, 0.0020749102415198286, 0.00797702629232503, 0.005222572764713196, 0.011615542033956355, 0.009705455488850668, 0.0072178498720751865, 0.00817050197471695, 0.0019287161556696597, 0.0045122858583870745, 0.007070719510650945, 0.004751442912277215, 0.003999349923385234, 0.011684747524741827, 0.006630849010489523, 0.004833753271816163, 0.00663653458273802, 0.011936489443828205, 0.0046517205141799415, 0.004871878757059726, 0.004144332802683156, 0.004335604213687635, 0.0039551481192373564, 0.008674896106950642, 0.007817344058105509, 0.00501410902214533, 0.00516361473417274, 0.0025320084380283207, 0.006357699505454707, 0.005280720783026624, 0.0025720265395334863, 0.006343402104515416, 0.009539171134017196, 0.007393968460416067, 0.012130504040556234, 0.006244678572914757, 0.0015247807942759635, 0.008295495658664255, 0.006220501466240272, 0.010135851852003573, 0.006496491648587418, 0.00395939979471056, 0.005819379497394103, 0.012109952394475803, 0.007522399848595769, 0.008215026905012645, 0.007621138592541474, 0.008241364940765019, 0.011871104005471228, 0.004128224615128973, 0.00560293405040126, 0.006599629506007111, 0.0063045950061925895, 0.0036279571314649156, 0.008990254771714801, 0.01246821106931227, 0.00832282818135399, 0.0066899813509819946, 0.003060804525428609, 0.006773910992233205, 0.005620702288637558, 0.004142837908342521, 0.00704127708564832, 0.011113462197663147, 0.005987954998357439, 0.009413045282244705, 0.005006998862915595, 0.004282396908200132, 0.009506461224188118, 0.004781111387093408, 0.004193308140451917, 0.013849899177127693, 0.00885408324661224, 0.006928404722812222, 0.006823752637689836, 0.005802733552007043, 0.00688039223729299, 0.004175885108005394, 0.005675844585337262, 0.005869661546848427, 0.0075996205763214884, 0.0021540063455141208, 0.005613466532785544, 0.008351843482786003, 0.007243849391492701, 0.004704219747650153, 0.006093679538409515, 0.006283332037551529, 0.00483510775736946, 0.0054296569366262745, 0.005795637358969641, 0.005250698856473926, 0.008546838523042243, 0.005217217748915674, 0.004416095803913418, 0.0009203875336418847, 0.008497013741004613, 0.006982870190743888, 0.009782751624212556, 0.006885160755825688, 0.010436047362165676, 0.00466273372523909, 0.009071698428489849, 0.006834422243987857, 0.0050346585660068655, 0.004805672241970349, 0.006282058774887562, 0.011258078498936806, 0.005187808630171705, 0.004327388771921542, 0.005622162012696049, 0.0034196724483858106, 0.006582718687971134, 0.002918476635825266, 0.007464219973648722, 0.00893111438635636, 0.006314664403337533, 0.0019200248654939875, 0.012536660119978765, 0.011114054547356152, 0.005638509999173255, 0.004906627644027558, 0.009354317717165153, 0.008767206559892236, 0.008466195206025933, 0.0023106855289154477, 0.005433102333688012, 0.012732181945969942, 0.010408859951162048, 0.009324322094866031, 0.0074485971884696335, 0.004849717493907696, 0.006181410138452212, 0.010009624129929243, 0.006237859774072202, 0.005569613771425653, 0.0015413395137453905, 0.008299935783621617, 0.004807317625979343, 0.007129921026012693, 0.005427982225869571, 0.0067861515715845235, 0.010820456754202451, 0.010496072161340419, 0.003944598714304522, 0.002721017026714987, 0.006993009945593281, 0.009455948536226243, 0.0034385271352376876, 0.011043364159197606, 0.00522995110386947, 0.007475604779462994, 0.006335408910668916, 0.009250787012776311, 0.00645819148824589, 0.010575576045637802, 0.004871739018918435, 0.010652494369287654, 0.002457160035398462, 0.006188918592557647, 0.008186214414005414, 0.0038599063426870686, 0.004899677582544501, 0.006323777830018563, 0.009569686264120022, 0.010463524515410992, 0.010118418708091728, 0.004220277056288902, 0.005419441032096703, 0.007884243291310992, 0.00586415694707697, 0.009725827575944243, 0.007896696588041409, 0.003711535558476429, 0.0046130950587446725, 0.01088816901510923, 0.0056754928943315705, 0.0059750732974172376, 0.003402939377745148, 0.0068146187147940865, 0.010842234923723083, 0.005048834247578045, 0.006077458838134657, 0.0070940425187556565, 0.011998636196822008, 0.00646300688262847, 0.006768068488979876, 0.004939464780035698, 0.010491839975712647, 0.005081307731163762, 0.00449115788478832, 0.005861447221270916, 0.006534300797903236, 0.0057983838285517, 0.0039176821315924665, 0.007289330524612558, 0.0031416108654104685, 0.0038802700614433204, 0.006798911936675568, 0.003967063143200124, 0.005066670811117472, 0.009826030364863719, 0.011664959066262755, 0.00541566482497934, 0.007659125749137336, 0.00959446611849302, 0.009871332069901375, 0.01096696005638794, 0.007662000931717508, 0.00828506795098832, 0.0046086649304441256, 0.0021451768719856525, 0.005480904416923761, 0.005064787902030686, 0.0076078445931004384, 0.005195392824388488, 0.001738929769590225, 0.013769666517066497, 0.004896680946366597, 0.008536160910429883, 0.004117770054344606, 0.005626546716706418, 0.001585446231248266, 0.008183040240389374, 0.0077013685348622605, 0.007279905812279446, 0.004823704393075388, 0.006192080650448659, 0.009825095662814988, 0.01184996187598544, 0.00676609440188807, 0.004363115109327678, 0.004587375961022007, 0.0070521037668974445, 0.00526018890748299, 0.0037265950952960532, 0.007156176492773872, 0.005131275268007969, 0.005954557393727514, 0.0029609726283297425, 0.00762068292093589, 0.005565606784881367, 0.004692386840687892, 0.005550413196622958, 0.008099126746372396, 0.009999540043020349, 0.004796751224721256, 0.004096595242389093, 0.012431847219132243, 0.003189366820611111, 0.006539079026519129, 0.006256703570315045, 0.003357287483907061, 0.0043914531199692654, 0.0055748491150608296, 0.005033405878735153, 0.004256125755892193, 0.004625435245747908, 0.008449036716495195, 0.006805900529644528, 0.004207787046548578, 0.010079999968535007, 0.0065969487221378565, 0.004736649566916173, 0.004791914868885944, 0.005696671750931137, 0.0037937494716609142, 0.005993656470455919, 0.008158144472239129, 0.003515438950970327, 0.006843515444072752, 0.003150931927769205, 0.002676114887363905, 0.009591066343249497, 0.0032939484715767318, 0.0047953698439515, 0.004008001682680286, 0.008922816885135548, 0.005661318892513091, 0.007023114841449102, 0.008122076681258805, 0.012394285734032178, 0.004537511077356295, 0.005375063587351682, 0.004780218631867573, 0.0076035292592182635, 0.005640914888337583, 0.005346563827482751, 0.009205802087887818, 0.0031796041324025524, 0.003470476502742378, 0.010623030538420009, 0.012103219456310817, 0.007433141069273006, 0.006177058107951366, 0.003025210028786558, 0.004525472954496134, 0.0111032300059241, 0.00237123896595266, 0.009536158193812988, 0.008526593264940461, 0.0018033193066476108, 0.007204255398223542, 0.004953783180597554, 0.005565610422070718, 0.004778147173446818, 0.012484853585691917, 0.007838231530074374, 0.005658990064567168, 0.008813426336226043, 0.0039118592848123475, 0.00817100225397087, 0.006798145783797416, 0.008757433831887713, 0.0041977066574605095, 0.005755263244769399, 0.0058550383629257866, 0.007318080510814703, 0.006452745759944699, 0.004672005904867958, 0.0073508129088509025, 0.004800454653458742, 0.006949182029792154, 0.00929072916947003, 0.0063909902656164716, 0.004767217701894088, 0.005904284960394942, 0.0020570734947708566, 0.0044524234122390125, 0.006598339958853535, 0.006498259702592681, 0.005146584112254208, 0.006275513273101199, 0.010464279294332409, 0.006601191992662446, 0.002737776020552153, 0.005715942589458509, 0.0011930329908392892, 0.006029118883346543, 0.004601595483898213, 0.004446542555082577, 0.005314886395667015, 0.009086444283562256, 0.006154625582321245, 0.012405756788624756, 0.005984224858970542, 0.005280399022123107, 0.00512753298041088, 0.01210003090230494, 0.006696732252928136, 0.0048148440697758504, 0.0039007984270055577, 0.006953603048089122, 0.005127168168337922, 0.004766055622035683, 0.01233591930954062, 0.0046538698003981, 0.008664911137362608, 0.005918165637998843, 0.003186317857430321, 0.00821780151708811, 0.010941654538531263, 0.0048380958488446766, 0.004865941397142844, 0.004830301310991396, 0.006936287209566499, 0.0070938074206165335, 0.005707872499507507, 0.004560145524586584, 0.004149709575704622, 0.006891336457288011, 0.0033092778934806716, 0.006437139866705272, 0.0037982157107041485, 0.005446997925018021, 0.005913066325770256, 0.009029349300736511, 0.008403149861264553, 0.012962273368406121, 0.004519067445475453, 0.007148290492856252, 0.011487606055364703, 0.005104241498802285, 0.00951116453075786, 0.01138264003320438, 0.0055651487414710085, 0.002797870986104696, 0.012114617035577212, 0.006535488047728612, 0.010045257341181014, 0.00808318322720014, 0.003327267288350352, 0.004824260514768203, 0.009577559773708841, 0.0023297051567963438, 0.010326021336667976, 0.00686311631634198, 0.0053367023598575045, 0.006116633155316675, 0.005074565700500178, 0.00804212211036514, 0.007484712078018003, 0.005885272396157, 0.006497753135075941, 0.003736210658954112, 0.002558561788479197, 0.004734547284301711, 0.005819223480188043, 0.005083806262762348, 0.004623211347616952, 0.005367798579854748, 0.006466107595873411, 0.007280211705976206, 0.011724927089473723, 0.005881904092807036, 0.008733396380206836, 0.009533702935746792, 0.011551141830184037, 0.006355206791300746, 0.005571987951105492, 0.005546908552979719, 0.010012446444543773, 0.012869400434240966, 0.005228409100836126, 0.009417906610638706, 0.005049132693873505, 0.0029469789104499015, 0.00524536594609109, 0.009264605582351346, 0.009934083509158472, 0.005522996419244712, 0.00489822988887278, 0.005140744855707532, 0.005844010218477404, 0.010819680857037172, 0.007645331308021737, 0.005770232760920339, 0.005787430626138683, 0.006646709031728826, 0.011143609217299693, 0.004500423818768804, 0.005523986337403563, 0.006214134170236006, 0.013696796921252186, 0.007572860301172286, 0.005815945827155371, 0.006021321063961783, 0.007572691189521226, 0.003960186152705617, 0.004217659681491982, 0.008371747078306322, 0.004413436825689333, 0.004632503784150464, 0.005015046459757089, 0.002958763632083452, 0.005006419922764628, 0.005566094918221456, 0.00816031768137514, 0.0033512234867685608, 0.007255576185661343, 0.00556568115621317, 0.006675970626957019, 0.0069417559270837075, 0.006100989973498241, 0.008154639051134923, 0.0046824958256677296, 0.004116777670780469, 0.004690338265776714, 0.006416835107214186, 0.006543087960140604, 0.008118753771766407, 0.008436002400076161, 0.007967830058837022, 0.005029039721982694, 0.012383198543846945, 0.006503541289311604, 0.004316131142724974, 0.003922156490205494, 0.008836175838494623, 0.007945326990563842, 0.005015317705770923, 0.008149751967039376, 0.011570191649307433, 0.004972202780402522, 0.0011073710945412494, 0.011405574098271528, 0.012981052390320746, 0.005592984867482037, 0.006028180727188892, 0.010738649768092516, 0.0035406645400545126, 0.012444571712697873, 0.005472329309701418, 0.008939417071378596, 0.006281393345573507, 0.010895857587311084, 0.0022984272808985757, 0.010383572155482742, 0.007935630994535026, 0.008916044317590036, 0.010446760071727842, 0.012668886039452614, 0.0028171144861588813, 0.010014502654060429, 0.012399424665671063, 0.008914143652911488, 0.00400568298248128, 0.011351441601457738, 0.009735243592487206, 0.005303273084223303, 0.008466059680095922, 0.007267587698699827, 0.0062118126568756985, 0.010985023237946433, 0.00644902347680742, 0.010147401542111337, 0.005748421907144932, 0.007586833744287552, 0.006170060986954012, 0.005245619150165006, 0.003800479229188207, 0.00496809926241304, 0.008362966177797932, 0.0072720156464730675, 0.005786498710797695, 0.00893304216327122, 0.0057751620513165226, 0.002479559262684868, 0.006928158985641315, 0.006051097624274188, 0.002234793481945647, 0.012618720034933618, 0.007287792290612065, 0.008390422103040581, 0.005180738236901536, 0.004281952676160436, 0.005838684674539069, 0.007254523875865523, 0.0038324461279511833, 0.008177351307582431, 0.007341319728325285, 0.006962894209111609, 0.012181758821107783, 0.0050261907502089425, 0.0037299606491187475, 0.00594126539828883, 0.011536780809848716, 0.004078011100607312, 0.0016082612226584717, 0.006353344271744656, 0.00605767308086454, 0.0042084283335016865, 0.005016856092182733, 0.005643346690536396, 0.007099368200662953, 0.005292354880014881, 0.008101986908753932, 0.009637476922310265, 0.004650999148684965, 0.007724003397357578, 0.002581605219732319, 0.006800651299889364, 0.003241697793787577, 0.0043447368346591865, 0.004347369431065046, 0.003256612671924397, 0.006392170044412526, 0.0036872207048838992, 0.006695910339630074, 0.009099960217219394, 0.0036881018692675057, 0.007465477958214702, 0.003370023752727497, 0.00573820597549231, 0.005787482307138096, 0.005560043825196649, 0.004723134509853595, 0.004327282237000712, 0.012021190308868484, 0.004193691674759442, 0.0033659433692549766, 0.004469416070898857, 0.0029601100432333264, 0.004510249288230394, 0.008450623964625821, 0.006884356761130662, 0.005761449801236985, 0.006468121820510134, 0.0026520685933127995, 0.0048152906793496805, 0.00532554899739561, 0.0075407428814601675, 0.002494750249678936, 0.010255488475983333, 0.002421635061325316, 0.010374392547916, 0.013565375034379969, 0.005971035560286421, 0.010277776760138637, 0.005724178075520885, 0.005779054727355124, 0.0052978725864598715, 0.006036213971908971, 0.014564920293023937, 0.005569361647244815, 0.004902540902882314, 0.0067898383326711114, 0.007089786419830785, 0.004154253078978216, 0.0021940624398641513, 0.008686982892182228, 0.007765981945573873, 0.009239211472897616, 0.000707662383337202, 0.005535070334323308, 0.012188215210530762, 0.009228017495697651, 0.005651867805366587, 0.00519152173350073, 0.0065551440400960555, 0.004177509368828818, 0.005321320058084831, 0.006836868300082925, 0.005312045116520586, 0.0055083271570244285, 0.005225969747547099, 0.00455539568242294, 0.007952869412457859, 0.003825901608722996, 0.0050980620702303775, 0.005080720247610007, 0.008124351574134651, 0.006468961678567697, 0.012933020904410512, 0.00875599428898273, 0.0023531462451618756, 0.0035167151386917904, 0.007248650586844591, 0.006291436185289668, 0.004269430074000773, 0.005053323839260023, 0.0015573649887331317, 0.004516188178823231, 0.005275040783142455, 0.011228099566282386, 0.008485674440656898, 0.006615218459128395, 0.004056677050859573, 0.00812583488851814, 0.009326665055179192, 0.007667225738526873, 0.006241368918142188, 0.004563050884629567, 0.005285391225084827, 0.006244761010732597, 0.007592887354205009, 0.008986747846240758, 0.0020603196675116208, 0.0036755230964398864, 0.004679727403605485, 0.005609394699720004, 0.009050221045327211, 0.00400303366065372, 0.009630162703053188, 0.004372767731081401, 0.004170894619876818, 0.004641260001401196, 0.00996822440530721, 0.006678483656015749, 0.010493828453786038, 0.007548837624315143, 0.009333091859489079, 0.007681894618266847, 0.004637952269678465, 0.00629969261572426, 0.0020163197882042956, 0.007310772893003591, 0.007462772487439938, 0.0017607350236003999, 0.008778150388588266, 0.007494281845033349, 0.003879454330934671, 0.007551881006793323, 0.006197705152754465, 0.003459460203180346, 0.004537291678181734, 0.007465927027988161, 0.004466399127380665, 0.005260828002951476, 0.004665128872393543, 0.01173042430844579, 0.007766280958179356, 0.007513806848526566, 0.007931052118903971, 0.009640868132069607, 0.0110410686324879, 0.010178002603112083, 0.004076101799721472, 0.010348338096149379, 0.005644246415752753, 0.005423947735931716, 0.008408632125519594, 0.011904711931055592, 0.008748978313683157, 0.013844209095618714, 0.010803847492811788, 0.00594858386423542, 0.007376909111707376, 0.006421085166416892, 0.011501010268004366, 0.0049706408426930925, 0.009625848498194818, 0.010023202958946556, 0.0072192814725420985, 0.002613116616074739, 0.005228464712536564, 0.003819392776615652, 0.007443310178845624, 0.0022497100484785374, 0.006313597523264546, 0.004684573220710218, 0.005799012750923116, 0.00562904617824231, 0.00904710204692674, 0.007901316238036218, 0.012738428982579555, 0.008296454821134367, 0.006271531928292081, 0.012695028348021754, 0.006232850417629589, 0.0074714373495189225, 0.005709518754263369, 0.004760112269437423, 0.00667255154331185, 0.005021841718004983, 0.009809216316653688, 0.005721113974295552, 0.005107425119849622, 0.006558036843651659, 0.0046198483945123605, 0.01210424494856806, 0.006302901483461682, 0.004774732468314648, 0.005260623781833539, 0.007683911141446131, 0.013107083502701974, 0.009891226217354936, 0.008410435713521723, 0.006577363587322429, 0.00930650966170436, 0.008083280644218895, 0.0068332830250312886, 0.0037222681867992253, 0.006497198313303803, 0.011129282604997806, 0.006192204799032902, 0.012656351101096273, 0.009929423371938185, 0.006700913617293819, 0.005410214190458609, 0.0033212105156146714, 0.005184183944165876, 0.012067184782480447, 0.006395537196786126, 0.006099269678961259, 0.009882744835311782, 0.00962188782505339, 0.006027288625592786, 0.007383783732978142, 0.00880896238737168, 0.006976421810643506, 0.006304879590433843, 0.006341318641288388, 0.005235127843020088, 0.0073274919334078295, 0.012187745163271665, 0.006995018275748789, 0.0019220796791739449, 0.0049860415656659916, 0.00771160470157763, 0.005461470198132893, 0.00491830135353429, 0.005319716321298993, 0.006210046887937491, 0.009751096460564, 0.007154687160142297, 0.00426436974676713, 0.009732164956062963, 0.005139882384800416, 0.005034030296847349, 0.004426097019265456, 0.010838260795973921, 0.012942663199265843, 0.00609319930177166, 0.011573273447375501, 0.009588744747808992, 0.011497116681356768, 0.003327680565908911, 0.004172693713067123, 0.005960982120778989, 0.009495037213746584, 0.0065135829446039085, 0.008392730089353033, 0.007132486897072495, 0.01002758441159016, 0.0040507350196715254, 0.0035638502504954195, 0.012133234864027724, 0.0031899456774034524, 0.004170830916755838, 0.006710660535064217, 0.004066806948396822, 0.008210370415127675, 0.005360566288405541, 0.0038881148346871243, 0.0062953698528408295, 0.00858078205130736, 0.008063806629382152, 0.006853457707327248, 0.009359742580586056, 0.005454464296657854, 0.004730382785338419, 0.0038313752911538312, 0.007587028654868434, 0.0065088226121005725, 0.008821994533763554, 0.008352646965435999, 0.0070889005890564455, 0.005643067555678293, 0.004996026813783615, 0.007769183582546414, 0.005893071587790042, 0.002970015323447077, 0.007134824678336806, 0.008762661193123111, 0.006286926471301103, 0.004986892206670832, 0.008326601602721343, 0.007790694314348455, 0.006464189103120581, 0.005077172191943416, 0.006703726882933848, 0.0050119330237041095, 0.004176284353264993, 0.004894250513600823, 0.006717446572357219, 0.007938167937770359, 0.005281563189457324, 0.0039736854413977, 0.007920982150349178, 0.006694009485427135, 0.004134597208918654, 0.007820741405015699, 0.004553851515757951, 0.0070867727570442015, 0.007689934531433003, 0.01124354872820129, 0.005575887333411729, 0.005036847954583987, 0.008764376083275575, 0.006747431514420775, 0.001971031424433414, 0.008653926448201055, 0.008512193959152628, 0.0038962740746549336, 0.006221210297946471, 0.006596512732159149, 0.002551126068571835, 0.008252155036206438, 0.0054471382693544335, 0.002895362599062307, 0.007291277607022944, 0.010963716327952934, 0.013488225794904326, 0.005630437066531087, 0.006990236922173743, 0.007352597900589703, 0.00493357086360716, 0.01306801548309687, 0.009063963302991938, 0.011671651932641407, 0.008402283284213094, 0.010745908840599339, 0.004574400356687592, 0.004785793897170055, 0.006040226147687018, 0.0063740623074828116, 0.005323293869765344, 0.0048945531578355635, 0.010200580627464439, 0.005719359875534225, 0.013034720392414026, 0.00676452163397016, 0.006638791025938581, 0.00884995130486256, 0.006767323197816378, 0.005400670608592978, 0.005704141043594891, 0.004433347916828147, 0.010194385475406523, 0.004945897461764994, 0.006185496916597116, 0.010841388002931298, 0.002424898878498286, 0.006155832384414193, 0.006711372028852421, 0.0056441913576165525, 0.002904383893823454, 0.0057118754014349685, 0.006080370174549916, 0.005766074344111784, 0.010106867286420207, 0.009890186124985715, 0.004087876035020518, 0.013921238794624641, 0.005992513253142167, 0.011183867340790781, 0.0029029312249712206, 0.0024459695635033847, 0.0044157929107611765, 0.0068932979131438475, 0.011457539162811056, 0.005601027679306394, 0.00418051239840397, 0.004778305049037196, 0.007656145537239757, 0.013486929511123184, 0.010466573024353177, 0.003169934838547989, 0.011083797785571468, 0.005689340419884035, 0.008966521871105401, 0.014076614267273831, 0.005635460566519909, 0.005725182679555074, 0.005652384010289991, 0.007729056226097657, 0.0042484535461066114, 0.0036056876767833327, 0.00527488890148003, 0.006959034385738546, 0.005773244688000194, 0.013182795167319893, 0.004706123745154012, 0.00825735774561068, 0.006695044379927585, 0.009380005152293251, 0.007196241073066859, 0.007063865156950341, 0.006525350950493646, 0.006238307221871412, 0.0054583296555675825, 0.010207796746912627, 0.007029061602504088, 0.005048417881167205, 0.005128856024283242, 0.0063162493754192785, 0.005767344595135237, 0.01216299077010555, 0.010078687772445234, 0.004024526628468847, 0.006209694171021499, 0.006173185634996851, 0.005190438677645282, 0.00722369704293746, 0.011809012723378639, 0.006402326894845382, 0.011949310962060016, 0.007570041894438046, 0.011533797321541217, 0.010658922447922412, 0.00791936372768829, 0.004324038858502009, 0.009045971993168969, 0.004632210445665917, 0.007410822763568711, 0.01114573496707362, 0.004725248429095021, 0.0053452540507794265, 0.009998570368542408, 0.011822979101815373, 0.005164207363008541, 0.007020597364478959, 0.005879534463274119, 0.004353076043608254, 0.0014321644378576487, 0.008150991264201105, 0.007236399702220563, 0.005682804599616391, 0.004178349256024425, 0.004993045263347221, 0.009170662358146025, 0.006055149627782999, 0.010297246477625274, 0.005747032733445451, 0.0040660028193052365, 0.006377074800735499, 0.004063289763725655, 0.003647803120082207, 0.002963755670162403, 0.0055952106347241706, 0.010601990223818178, 0.004392036487370123, 0.0068657126212056325, 0.011556447885960415, 0.00668280062256277, 0.010775982811669796, 0.0024606148193104913, 0.006439598654250872, 0.005534783122842195, 0.005079093288014279, 0.010045744408978974, 0.005064827303060017, 0.008993511683826182, 0.00597729423314668, 0.013492848439192302, 0.0046282866910161875, 0.00573484394364331, 0.00946279652124021, 0.0032789966919974617, 0.004675564517745921, 0.00240800734775876, 0.0046103553834067985, 0.00532019726543789, 0.009591101840037636, 0.005421171050499203, 0.008221849643089404, 0.006801535250976112, 0.00795251618863012, 0.011242260244687522, 0.0017551181627313455, 0.0046416111395178195, 0.005266097871177756, 0.011694073944075421, 0.004669361137381597, 0.010962880346138088, 0.010216641342716604, 0.007414139036876226, 0.007206719109179052, 0.0038432865034061176, 0.009835852536761745, 0.006298617552465636, 0.009286795964596556, 0.012200545954646192, 0.005646867859683862, 0.0014759365899987078, 0.006700416319521988, 0.009590379682277751, 0.005810212491706418, 0.012959734896599526, 0.009280363176911948, 0.006653247767969659, 0.005758655270207186, 0.00615433185711051, 0.005653576679611971, 0.009211132891920947, 0.0059337524145187635, 0.005522505545665026, 0.009682483846599532, 0.0031824866304505156, 0.00194337039559494, 0.0037692129225190643, 0.009327255542161288, 0.012992174522681466, 0.006248115427568491, 0.012279579267724891, 0.010426868662988184, 0.005777049425558425, 0.011827134951087774, 0.0070390919249373775, 0.006927378393785778, 0.006251136103665437, 0.005680651085869758, 0.004343329615256338, 0.006061360291029028, 0.005617809969203483, 0.0015377065113237978, 0.007772805118491988, 0.004275730140015754, 0.0058045785932143625, 0.002840274827939503, 0.003193764957983564, 0.011401107038446639, 0.0027179694432122817, 0.013560951971284202, 0.007627948799203832, 0.005687565904730489, 0.004624297753697702, 0.004806592039897146, 0.005890584759697257, 0.004284976325155178, 0.010815293573808754, 0.003320765019850927, 0.0041740556362575894, 0.012967603587443937, 0.007769705416813733, 0.010833575304676879, 0.005894840690678577, 0.006982710609012835, 0.00535476203564283, 0.013589990897438113, 0.0037938658360962448, 0.007261582157235715, 0.006320334994014215, 0.0065335492964366665, 0.013174370787505918, 0.005373466986203077, 0.00838186938347257, 0.008907559823198298, 0.0065215246344215196, 0.007915826489685421, 0.006386913274213456, 0.009245993682187587, 0.006256566882829498, 0.004675718036116529, 0.003836925435751208, 0.0077277699439523995, 0.003337426688926118, 0.005915605542404683, 0.0062177480060946495, 0.004296530970052655, 0.00396497348277104, 0.011952583449606952, 0.007211925221125978, 0.007343005859039317, 0.0057579424828875115, 0.00745969142633765, 0.007384811716169726, 0.001926197006205115, 0.005954514449114198, 0.010097127644925423, 0.005055002380057853, 0.005595721758336814, 0.00579372904477811, 0.011990775852865006, 0.004961868787688924, 0.006778405018173577, 0.009555387976779364, 0.004584240257526375, 0.009798132186171458, 0.004156344156589482, 0.009866281917707158, 0.006998070699250778, 0.00824982217127231, 0.008495180467206521, 0.005206427932267323, 0.012448043569706007, 0.0019739217058168538, 0.006834915527304381, 0.005433851899797894, 0.005976163245475959, 0.005843619839188264, 0.009838362298550292, 0.00907211210757392, 0.010448804919151646, 0.002371788111498331, 0.005506193673317963, 0.004009225090790365, 0.004609203150203661, 0.008356010915535731, 0.008424872855799107, 0.008557785562866202, 0.004959508719686411, 0.009301448542076934, 0.0018783639351654838, 0.0032109689067140166, 0.010925715497815323, 0.01273273871937529, 0.004393873531981861, 0.004003912945397428, 0.008600105862788594, 0.004003519508045223, 0.008343520922829336, 0.005941136235165716, 0.008427972738555715, 0.01386488657874732, 0.005355530612237822, 0.005393541878244002, 0.008643158347705522, 0.010061172633816767, 0.006054889338106037, 0.0069751191599745285, 0.00489715924678844, 0.011349594173527234, 0.00393885031510513, 0.005452715151463174, 0.006653627669442256, 0.005531441009931337, 0.0028351245327834502, 0.006032721649203017, 0.006482124611138831, 0.006186627751487204, 0.003953395098586744, 0.00453991958728756, 0.007721237255700385, 0.01109961925735347, 0.007257289652428762, 0.004659855734464393, 0.005787769755471113, 0.0025704949041238353, 0.010554784948015246, 0.007140169937316194, 0.008579487648295529, 0.010326954704911887, 0.011471419419529321, 0.006038681534287943, 0.005381202384526863, 0.010499033624778218, 0.010354523932695647, 0.005592204946347989, 0.01200435053867848, 0.0049507875830823115, 0.004971604508583827, 0.008249414265820487, 0.005553555372628148, 0.005362561624103528, 0.009552498279099451, 0.003904564290862885, 0.0066443622970687455, 0.006399080405688932, 0.008894716600541806, 0.010423684240478803, 0.011285564207508942, 0.013258629636739839, 0.004407562225787445, 0.01173415833809029, 0.006244686863595224, 0.008857548055062964, 0.005400110252543162, 0.004075237574963926, 0.011091332404721085, 0.007622001495887465, 0.010148104216183694, 0.009412333168529446, 0.0069764006994411515, 0.004561067412397113, 0.009064987206112455, 0.009866525719936087, 0.0043289605590063045, 0.006195071766301246, 0.0049935487304846845, 0.005654836438809293, 0.005037854633718331, 0.007143545796942682, 0.008563631536016563, 0.005394077680234758, 0.013056646247753038, 0.005613427051493454, 0.003943990164560705, 0.006234030875210777, 0.005462890503356759, 0.006458283194690599, 0.004462017111513216, 0.0014275427596754228, 0.00725438430956268, 0.001998987729517296, 0.00964875553154012, 0.005235299498030098, 0.006152248974777604, 0.011361152678972471, 0.009776351678262272, 0.011911607882198985, 0.0028771560849189205, 0.009511208174960678, 0.008640218613207136, 0.004603839015889292, 0.007314678420053733, 0.009677750836515234, 0.012043997959387175, 0.005180246649029312, 0.008142390436485798, 0.004651177013924683, 0.0061344719290377415, 0.007130340668556314, 0.006054066350674959, 0.005741216267260641, 0.010547491961523745, 0.007202350798884347, 0.004474896780348357, 0.004495012432270703, 0.004666511427362324, 0.010375223894364169, 0.0046370622109014594, 0.006881813308143375, 0.0037971675595537963, 0.004859094515983377, 0.009330711242749071, 0.00815513400724317, 0.011532769731482736, 0.005385937412541635, 0.005868162347883002, 0.011637457863918062, 0.003691063791253811, 0.004061150983338894, 0.005752163825943235, 0.005487170542036111, 0.007836478771567033, 0.0028829237084997327, 0.004257779215240033, 0.006498427257390129, 0.010662422298149898, 0.0039119269852412415, 0.007857748559767895, 0.010271268891551989, 0.0059510443125784605, 0.004959478348754311, 0.010221904590136464, 0.003722896781999393, 0.009407256735868487, 0.006288215428806889, 0.009149231675452105, 0.0058017537679662026, 0.0061278723645892905, 0.0055273785574122165, 0.005795190651878362, 0.005472573535571905, 0.004265249102878445, 0.003638210331493557, 0.011490317041444424, 0.004677869731570463, 0.006728428557399158, 0.00846970484767233, 0.012151290809694161, 0.006510668040833142, 0.008260563741457994, 0.004455236402650913, 0.012127005561223828, 0.007727019030026536, 0.00814427134883914, 0.0061091859978525155, 0.006489064029982777, 0.007681248464805187, 0.00751874260819181, 0.005192929729362242, 0.011063739748347543, 0.005723946181164386, 0.0018751928240697022, 0.00480001641549819, 0.0102751047571966, 0.004862316642383272, 0.006665264929932209, 0.009363393160712137, 0.006288734412581968, 0.007312932311202302, 0.008806410012629414, 0.006726534347891323, 0.009697466123929173, 0.010624295355036062, 0.004359665606694206, 0.004818602024770633, 0.0037239888141040356, 0.0067662495715569175, 0.0020860645724683647, 0.01185485906802861, 0.005078179532612803, 0.00594885388136551, 0.010570365043348386, 0.00438020590551574, 0.009189936179005629, 0.0053525964663495695, 0.01100627860184612, 0.0032406640136360097, 0.0032423479558981085, 0.009349354613600664, 0.01038538388986528, 0.007688623572902606, 0.005757275785686762, 0.0068353774596788975, 0.0034902008584859028, 0.005003619946466382, 0.0030024454501418165, 0.0067126027439579124, 0.007457967141288916, 0.008199588578012593, 0.00862146305828739, 0.011074013541454757, 0.00581098194687029, 0.004829072652561262, 0.0032715576248614243, 0.004199602825274072, 0.0082410992348519, 0.0039305028433720395, 0.006362288869992386, 0.006065227680823402, 0.0044863791369659164, 0.0035143673039553635, 0.011075459747560917, 0.0070397711208816365, 0.007556390434148151, 0.00938781465987966, 0.010222728494787819, 0.007473749278458929, 0.009977674052837119, 0.00837498601839109, 0.004798331024473827, 0.004775904884952208, 0.00554799989018312, 0.004175563335586246, 0.005876980744402676, 0.005149030068630525, 0.004778861949016609, 0.0038813326782604378, 0.00637180432742435, 0.010116209162810495, 0.0033897640788821282, 0.004696820869719232, 0.0024345985614532308, 0.0042683910404219365, 0.0050181878998193236, 0.004300523726456087, 0.005657525727870718, 0.0056112835379125425, 0.01031095165028659, 0.006979319461632004, 0.006432798290275796, 0.008252644000436092, 0.00475039507734402, 0.010882282593270846, 0.0039039904348331512, 0.0056842404191912175, 0.007910586353403677, 0.003802630864059699, 0.01116683674155507, 0.014282289079402799, 0.005998936517982809, 0.005244460718569431, 0.0057003143819545285, 0.002673505815221412, 0.004907682727108297, 0.013649814235572644, 0.0069804449259358425, 0.010329484008591659, 0.00789193707331916, 0.012725277342544014, 0.006040422484722221, 0.005793063240249389, 0.006566510809800715, 0.006073673033177329, 0.005748244285913229, 0.012207080429301641, 0.006527992157378966, 0.002307668623484039, 0.008319748902635078, 0.007237949917170677, 0.007442279004753692, 0.0007887354051217555, 0.009452138797278877, 0.010901146451450863, 0.010571653678851019, 0.012303126176915745, 0.008595622696032852, 0.010255099290540928, 0.0028498381375071033, 0.008545256463763352, 0.005393718288389058, 0.0052220402801404, 0.01116004041686508, 0.006947207323171789, 0.012441304697601716, 0.0037094729997287734, 0.0095091051501702, 0.006732270749699616, 0.006355071243048277, 0.005847794348671765, 0.00817790093041679, 0.010704000846239606, 0.0027145096893403573, 0.005702192574462585, 0.004891710298219438, 0.004222334661059161, 0.006362849233547668, 0.005825534977468411, 0.0057337896026307, 0.00396967095347937, 0.005916239868388347, 0.005571287868494746, 0.01156198928165576, 0.010248319961695439, 0.005205231067026362, 0.004493884728411923, 0.007596010506719238, 0.003394898153051693, 0.005835597328901746, 0.007440628023395647, 0.01044219285304115, 0.0076207240894075766, 0.0036422703952314495, 0.009380440995323423, 0.007086264514779836, 0.005589292841813819, 0.004526755222785664, 0.006071612219933945, 0.006646634382597172, 0.009591787437542272, 0.008433475610099874, 0.006786109752591585, 0.004991853028945472, 0.003157423514869217, 0.013828223682259722, 0.009791230222528945, 0.006388175878392689, 0.009645760836826122, 0.006406877729707886, 0.004266704406162923, 0.0060707502587974615, 0.0021377136653646252, 0.007447293137413642, 0.014683667045272863, 0.008929351582728937, 0.004444346433910118, 0.00713959713761262, 0.004770603406863621, 0.009903854117346851, 0.007785733320440506, 0.005367603487950337, 0.004370608350311908, 0.013002636080738032, 0.005112415394840723, 0.010881534870801193, 0.0051706764965076596, 0.007972054357578424, 0.010859544886387924, 0.009699151104338754, 0.0048648373731264, 0.004625659366620074, 0.006602304065667978, 0.006176690971754859, 0.0023302599231433655, 0.0031703513077830994, 0.0020157499702514303, 0.014731835729320762, 0.011227868184053214, 0.00601307698613918, 0.0032947226808908944, 0.009691654620122475, 0.005267482699628438, 0.00606877844022394, 0.0014917930824400116, 0.004908781269772693, 0.00526586582374532, 0.00396094688213041, 0.00876454581075591, 0.00767463844724622, 0.010187485618669851, 0.007040799677479637, 0.002668312308998886, 0.005954242251523473, 0.003740708367889815, 0.008759421061085251, 0.002837755589320889, 0.007369544796003182, 0.0038436012946068696, 0.007248993288673129, 0.010601907604863951, 0.006947410816394772, 0.004389081964079151, 0.009130347773988887, 0.011487832780400994, 0.011612469334862995, 0.012358583425659937, 0.005404639871868666, 0.008494468839849688, 0.007790823076972614, 0.00461431071739607, 0.012119348958741597, 0.006257456366164068, 0.010621692228598933, 0.00647738094000768, 0.004254250046099059, 0.005596868320180873, 0.006352293874429853, 0.002939666563607903, 0.008338612931957944, 0.006816568470594599, 0.0038790936500292814, 0.0027876823907354307, 0.010764913867229593, 0.012986311783608546, 0.0076219756702683005, 0.009862724631830326, 0.004749839664538605, 0.005965551678510794, 0.009710819623042832, 0.005260176396100418, 0.008037246554223103, 0.004648365659586128, 0.008709257385172735, 0.006659147311585874, 0.005071831518131545, 0.0052535354974998835, 0.0068977932950965975, 0.0057618562684223305, 0.005351628534090948, 0.003936067344327999, 0.0035556718244286294, 0.007476061624111146, 0.011517800086918373, 0.00757423266131229, 0.00457550556403948, 0.002796495065582075, 0.010368146742017647, 0.009338754684239265, 0.004509268858852876, 0.00475739943012345, 0.010228738882691685, 0.005755541378423504, 0.0050250811345155565, 0.005371647891914621, 0.012411187614451442, 0.004477453904335201, 0.004852593283514919, 0.0059501388863965835, 0.0072832925463058975, 0.0082767333190249, 0.00831164463006561, 0.0013969733459640895, 0.013658802961729041, 0.005145694343769997, 0.005338674544024949, 0.00824743141430081, 0.005692113823491937, 0.009199429547091971, 0.005469239472915255, 0.002231760435877909, 0.002938715564219007, 0.0011597040000684569, 0.002809644924380096, 0.006899873327683031, 0.00860398295538806, 0.007559788556785963, 0.007600869089876363, 0.011001812968037712, 0.00809085748591136, 0.004394276415959977, 0.007411573002068928, 0.005341776842907177, 0.005401149721718368, 0.005932259310266639, 0.005831080035209217, 0.005615232787210435, 0.004550480203971827, 0.005075872546730753, 0.00550280768040244, 0.0034970437265268014, 0.007481180892309785, 0.0075974044255771485, 0.012786339196872765, 0.005251255820579855, 0.009543979079484483, 0.0055795748560640976, 0.0033254620703406872, 0.007221231771878729, 0.009699352477979827, 0.00879779052443834, 0.006436375976145306, 0.004250272187972999, 0.0017282347642251657, 0.006412146130968599, 0.003205280063260969, 0.00365346427122734, 0.006391262940776715, 0.00693931067977582, 0.009895718488335476, 0.004833324070486655, 0.0072486654750062995, 0.006333982993949051, 0.003541158623954389, 0.004933958756362588, 0.007201283846067498, 0.012076916026601058, 0.005554489759723914, 0.009191484044163327, 0.0094259026000331, 0.005175316383497816, 0.008298129146839047, 0.006623756344930731, 0.003209544252517514, 0.011822739324223792, 0.005540603532169133, 0.00116822834305568, 0.007344226874102073, 0.008495691464293596, 0.00643186059553851, 0.006636833675758084, 0.00531641274185668, 0.007794661029084829, 0.0055835663959501545, 0.007307970215634455, 0.0068594544594078564, 0.008024277055274358, 0.004695030822705696, 0.007530114046362219, 0.0028085989304374214, 0.0027276981112146397, 0.006785206606388506, 0.008089371184468635, 0.0055009967342161525, 0.0040968997830977145, 0.004884489211141699, 0.0038098862443396433, 0.005666777272884631, 0.008620916899670254, 0.0067016570114709, 0.004897266049023874, 0.005872473884907992, 0.009920715532594663, 0.004564880445916339, 0.008078711015210831, 0.007003485194253412, 0.013517930277851292, 0.005587117364552814, 0.004071772300397589, 0.0012366888111833463, 0.006352214614098286, 0.010789616549672254, 0.0063929518330513285, 0.009833747254461726, 0.002937412312730822, 0.004495255174251361, 0.003968142216083974, 0.007119359070519141, 0.01175677312727841, 0.004113037786352287, 0.0037321391543768028, 0.0036534558809047397, 0.0019435066853216944, 0.0026093254196240196, 0.0055425469564445535, 0.005158599608211911, 0.00706933168561626, 0.00573921807515872, 0.008994797865362197, 0.0029808807308300657, 0.0034199746150184607, 0.010058037768091922, 0.01094372614409905, 0.004399411191066984, 0.0050702776714424865, 0.004332951661243361, 0.005433587866403685, 0.0062970256786327155, 0.0069869255267615985, 0.006705644183427375, 0.0038395370554967397, 0.0076113473407505485, 0.004477906052859179, 0.006458471145326515, 0.012663361693095752, 0.005984403702570076, 0.00612931417049364, 0.005260266929274094, 0.011681991110141253, 0.004820832979605592, 0.008089423830443676, 0.00746738313251136, 0.002342437726146042, 0.005147238662749739, 0.006463014862890009, 0.009311465670155467, 0.0018770866950457662, 0.00971870216266971, 0.005075603952422897, 0.00412159064056699, 0.006157164916634095, 0.008034760668053774, 0.0032498699685665727, 0.0034275296079169376, 0.011992004071637408, 0.0027759676315675403, 0.007577254995328287, 0.005263952839204072, 0.0041930523688265674, 0.007839156127369976, 0.006211792047832145, 0.003468260945432549, 0.010507999071613133, 0.005994037221463554, 0.008116465351842702, 0.0030850754024715093, 0.003662770471975357, 0.002347222363757518, 0.006388425303465654, 0.008507509496225307, 0.00877871539650523, 0.003514234503189226, 0.004796475852826207, 0.004609783966525949, 0.006568012464730361, 0.005055677952483893, 0.007564428958571996, 0.011459556686512069, 0.008582752827521904, 0.004273014029680718, 0.005006956272942556, 0.009431623867240842, 0.002963736176453364, 0.0076052568617395126, 0.00585770775689504, 0.007589687598680282, 0.006294648000820191, 0.00907908880092663, 0.00800966933303358, 0.0040352868111984625, 0.005139789926650605, 0.007791451311045874, 0.008542115857238264, 0.006132617803648584, 0.008656177011607778, 0.009335047462605602, 0.005895912121579855, 0.008154528681796405, 0.006380040150958179, 0.0049431231595511715, 0.005432047611131098, 0.0055384596879181494, 0.0039907473494482665, 0.012506581594514461, 0.006246655270737623, 0.008757627448906031, 0.006363497914298084, 0.0072196823979597795, 0.003447061238491516, 0.004251216266434703, 0.005750850271226779, 0.004724180314766185, 0.006684422450628877, 0.006796772960674702, 0.007054352665032332, 0.003586918668167489, 0.006611427141805204, 0.009017064018554972, 0.004450450554671675, 0.004177824534965263, 0.01060906276873358, 0.00676734283213181, 0.005838101338034307, 0.008150245659329388, 0.0074673615775424865, 0.006478674738076175, 0.0025346212022420446, 0.004958112037292175, 0.006036405834608124, 0.0064486641719216494, 0.00636019154806299, 0.001995368342715652, 0.005640399126308109, 0.007195260996390279, 0.0035710662498960317, 0.009767698300219209, 0.0033338357733479203, 0.0031178682700642914, 0.011203676415925675, 0.008245010847668266, 0.006362339324579566, 0.008059525632940316, 0.0037456209705456394, 0.005575953829394999, 0.004728495275265799, 0.0057058720778708286, 0.005396979110808459, 0.01124479123557717, 0.004461514546723669, 0.005715721100363731, 0.004515149130798106, 0.00275645436036635, 0.0021573001319009776, 0.008435656884766017, 0.005108118455970751, 0.0068826823335379275, 0.0017334249364990143, 0.005447476109008762, 0.006431004577461227, 0.005400475134613506, 0.004992584963523991, 0.005705388613492372, 0.004323476836103586, 0.009325542553623967, 0.003560455473287367, 0.008280925863027373, 0.01028354417342658, 0.009675371007119599, 0.013647011827665695, 0.0037089322716940634, 0.007981116963716502, 0.009756408748722026, 0.007785390836153806, 0.01083486959200674, 0.011444353994478323, 0.005341883908172457, 0.0039228181146703815, 0.005043062287605156, 0.005962909937308988, 0.012101059157566055, 0.004644990007674746, 0.010672417337678774, 0.01253909708632352, 0.00799092617231044, 0.0049386058147674414, 0.004497424684001161, 0.010392047738412683, 0.002618410991725279, 0.00744757357855956, 0.006292832940804371, 0.005916347137501986, 0.007721814535656436, 0.007904742519970746, 0.005951287904865004, 0.005710222418469113, 0.00445897232509887, 0.005171708175430223, 0.0034463831331216564, 0.008501580551447558, 0.010297862879475175, 0.0051224457966480424, 0.00442460504929901, 0.012123116640084818, 0.008153571228147553, 0.0013308316657776656, 0.008372549905553719, 0.00827234876263079, 0.006295996359886611, 0.002735541573737737, 0.01047086303501762, 0.006447405800116095, 0.011403069841599153, 0.012412142217925188, 0.006198068114783747, 0.0075102932322458574, 0.004703069306527532, 0.0023095161294060295, 0.007776426604360686, 0.008334666286927455, 0.0060073721260703004, 0.004955428113511523, 0.003684371516655914, 0.006607382867118868, 0.006820053060273321, 0.007409070513879028, 0.005813897621427932, 0.01230051657889078, 0.01215486495835784, 0.005213771607152767, 0.011184965146793954, 0.010462210924943555, 0.003095237103496963, 0.007650325714514012, 0.007363516294526681, 0.00901097973750913, 0.007885217006834054, 0.007769483191057839, 0.0024021928484724924, 0.005473621767902365, 0.009704082523753915, 0.005369344220366609, 0.00865053106742614, 0.0031619560885946135, 0.007652219824961714, 0.004039229135258412, 0.0055075011248756165, 0.003472164502393872, 0.0059623128735756935, 0.006902941441860327, 0.006940773878258861, 0.008848563486869744, 0.007555123955100411, 0.00420218548440089, 0.0037832374403778345, 0.00424947449633983, 0.0063792163306420815, 0.005047321110257965, 0.004541380957962152, 0.007340993819832075, 0.005254865311169695, 0.0044892885527589065, 0.0033695925833869, 0.00671889355180059, 0.0024089526478604075, 0.006401828502243388, 0.004253029344974204, 0.005769397781826223, 0.007090428589325415, 0.00883608371496631, 0.006151262269441278, 0.011378889337378517, 0.006343643486832006, 0.003961583220607382, 0.0058410276876663374, 0.0024655523145726394, 0.008212028926992024, 0.005416286536373474, 0.0060237923282310795, 0.0064681732700271576, 0.007186726151052765, 0.007596769454483931, 0.00550665221807245, 0.004115213019463364, 0.006323025351968981, 0.005427620402795973, 0.008115575465322777, 0.007571767687962498, 0.007323829240731978, 0.005542334384342539, 0.007885813696973202, 0.00479803876140705, 0.007514284999798174, 0.008045941690632868, 0.0068547558592790036, 0.00437753448179845, 0.006945469451289776, 0.0034455718535664685, 0.004508962649939459, 0.008786547843147812, 0.005871353112733437, 0.003505305943243427, 0.0029105807204079445, 0.0034020830480945654, 0.010567569229471193, 0.004045485052153965, 0.008482364691268422, 0.004656856338544641, 0.004156288647830308, 0.0016568853722459596, 0.0066434411127911114, 0.00679786445896715, 0.009005610969219324, 0.01086354584097051, 0.0052243329377996296, 0.008693480076986834, 0.006138051321628356, 0.010297964181092752, 0.0024263819047294433, 0.00997956080621203, 0.004584802252601879, 0.005057166671882724, 0.004879217540326442, 0.0053009382573546045, 0.005572270484842611, 0.0077828032808566075, 0.004930054576398434, 0.011348656700594758, 0.004234096384117692, 0.01051233784946164, 0.005084925830223497, 0.002012901257084572, 0.005929303811510396, 0.005671364172695284, 0.005527890260014965, 0.006890037952286492, 0.009901123843699962, 0.00904687861987573, 0.007392641466991632, 0.0014121403260877901, 0.006458608292050954, 0.003816105032996067, 0.007713800066215706, 0.00517620915602043, 0.003935198407447555, 0.0041277349972235165, 0.0056008768103148095, 0.008694274251926317, 0.005296348388448044, 0.006689869175116145, 0.00856910152939371, 0.0059378113870750026, 0.0114038199556693, 0.0024626907445296845, 0.0028923852550949646, 0.006312890616474462, 0.004513942870709671, 0.009468451689001707, 0.007024865940096802, 0.0031667779835033846, 0.009287147768588497, 0.00589342703281856, 0.004649490301028323, 0.010591834178634766, 0.01293024387297646, 0.00708990114250686, 0.0111670355578855, 0.005216464197692853, 0.0047932894503095605, 0.004421926427903497, 0.0016025708924861841, 0.00545268672064286, 0.006590422072505335, 0.00513762107773723, 0.006097674816148424, 0.00406180673530844, 0.007229049486960235, 0.005273761174151922, 0.0047351136722832135, 0.00874845751109184, 0.005657818637708945, 0.0042297095696081765, 0.007153570537181965, 0.006753828433813398, 0.0023956670294095215, 0.003286711607623908, 0.004238177877312028, 0.006708106240429823, 0.006133250811414932, 0.009394039900499316, 0.003606827272937683, 0.005876749701460881, 0.009520549752528761, 0.004189998134189941, 0.008740927311903405, 0.0044997216185773455, 0.005087290183104176, 0.009561475085019484, 0.00704437617054654, 0.006687009820983985, 0.0031540628474561105, 0.006876902834977729, 0.0037291345555527334, 0.004145278201937818, 0.004190412376574413, 0.005308431591656681, 0.012003468141006026, 0.013371745742405359, 0.003945594212431674, 0.006694781261963451, 0.0036224973868789535, 0.005195645754953079, 0.006465299600699186, 0.00272126944247176, 0.005711818570303581, 0.009542287886476208, 0.004593147408685711, 0.005278968199880293, 0.010286157220450258, 0.005563125119993103, 0.00632413807729979, 0.007900553390704525, 0.011072949141851958, 0.011182005830205247]\n",
      "[0.07279319729227787, 0.08171411336767131, 0.06513266363779821, 0.08253614779851577, 0.07547511362544125, 0.08083543711458833, 0.08294387006544349, 0.06585447628352299, 0.07936054093938462, 0.07733171785319952, 0.06524349366522011, 0.07796032748010982, 0.07811822772446213, 0.07953577292430872, 0.08074682275224188, 0.057648485118927284, 0.07857260585981231, 0.08599302374218479, 0.06231341012614872, 0.0622164732141524, 0.07977632803793966, 0.07800364301430741, 0.07976037671709663, 0.07642413951452559, 0.08056427901869853, 0.06336404083137501, 0.0734242805365676, 0.07706572612660002, 0.061808027344616746, 0.0765631243589508, 0.06545697664615314, 0.07887549310120703, 0.05953295968617012, 0.07912799239849642, 0.07723435523310557, 0.07788669476183509, 0.05877524437508247, 0.06945316806986555, 0.07568946422956087, 0.08569104211315595, 0.07487437365906231, 0.0803131410485499, 0.060458252102874754, 0.06664202802952657, 0.06434743976862417, 0.06757039727072245, 0.07321869976595986, 0.06546524468738898, 0.07606232627131977, 0.08079554910150978, 0.06637115362702606, 0.06852419851142215, 0.07399642822354856, 0.07554642011216729, 0.08061272191439849, 0.06894459482832323, 0.07012127357615931, 0.06196425461206933, 0.07294109493870109, 0.07787774094921061, 0.07089096532941042, 0.08496742179807289, 0.07940649028649649, 0.0682678702067899, 0.08209076566907324, 0.07511651551327628, 0.07974055443036904, 0.06892793471145237, 0.07311740284086439, 0.07963035778103084, 0.06576750587294565, 0.067361461386091, 0.07964125910309722, 0.06730593604489449, 0.082205333767173, 0.07903895766454204, 0.06505039194644821, 0.0796324827095884, 0.07466140133469769, 0.06423378841881355, 0.06549127657474466, 0.07322403634107187, 0.07066573514162093, 0.06952152100178385, 0.07798895658161147, 0.06667552923059801, 0.08141554955026109, 0.06350958095489707, 0.07028127458695435, 0.05745846940411178, 0.06462046352372879, 0.06414162068146856, 0.06955366321185999, 0.06369187083188771, 0.08403379287552379, 0.07688769585059275, 0.06451850339496083, 0.08058760029285066, 0.08008222243459458, 0.07958548292770944, 0.07801984358578543, 0.08026290727549383, 0.08144389854827043, 0.0666715865804799, 0.08396656156163153, 0.072980300374427, 0.06564920814808191, 0.0818361584163591, 0.08049813701414521, 0.07887127663184096, 0.07861210720043628, 0.07634971529307198, 0.0726037242050414, 0.07897891384188946, 0.07620022611765234, 0.08139776652885572, 0.06771034184984134, 0.07576875113320426, 0.06294905782969787, 0.0799994160293532, 0.06758076283260055, 0.0817715934972041, 0.06338264333356987, 0.06740852106890781, 0.06308221011564706, 0.08029770866053054, 0.08139088852737801, 0.06928199172961046, 0.07301096616788498, 0.06092705518589999, 0.06739765316450241, 0.07018742100612878, 0.08404698710493724, 0.08332693214851458, 0.07383966844184256, 0.06311359742352844, 0.08013228604022571, 0.08180805027358268, 0.08469261675829212, 0.06655405322979548, 0.05834017617434337, 0.0707857938873751, 0.0708122816436146, 0.07502201994876512, 0.06656480169816317, 0.06380166368475612, 0.07304991521467981, 0.06644439260254999, 0.08169062226656205, 0.06331371826518713, 0.06670170767996128, 0.08516726491646087, 0.06990459116787046, 0.08004106421466389, 0.06290657971303293, 0.0831282629222943, 0.06843364039633199, 0.06707603601858865, 0.06608090611331204, 0.08021314817076018, 0.06904606054200595, 0.06785399263532449, 0.0822261697818926, 0.06241054876651732, 0.06760233839628124, 0.07516394160808287, 0.08282266792789279, 0.07796162303217465, 0.07828922734278375, 0.07712543797860567, 0.06841275894371954, 0.06595392053738647, 0.06783170701151102, 0.07993325791475432, 0.07933973206227003, 0.08350355164543681, 0.07593839250587442, 0.06570619872669532, 0.07901040562179365, 0.08329103061550898, 0.07934317516169974, 0.061759087766733146, 0.08050400713504646, 0.07990600258882145, 0.07915739096903483, 0.06233064595033666, 0.07863945096160413, 0.06259867396013799, 0.056306968957465765, 0.0682045032978193, 0.07344778606810742, 0.07297919517364324, 0.08255689038769298, 0.07709561573273671, 0.08096807252263928, 0.07985736989760901, 0.08124597586968854, 0.07306864220820272, 0.08073704386751096, 0.05923751814427626, 0.07669093317994007, 0.0790522867669414, 0.08006030645721794, 0.07937842398780155, 0.08170208155762748, 0.06627077220235306, 0.06959711169616943, 0.0685874726717834, 0.07143028067356895, 0.07963375912561588, 0.06249928177776096, 0.07843443156765431, 0.056072761926712116, 0.05781023246615098, 0.07922015818583016, 0.08336213331104479, 0.07492845071386453, 0.06992138898460211, 0.07911393706325592, 0.060640451724298716, 0.083218689681363, 0.08029650556585459, 0.07262794982874132, 0.0809942394016438, 0.07486068313302377, 0.06044348111588711, 0.06127498511872561, 0.06928133338935774, 0.06384280124312987, 0.07886287902250844, 0.07592047003385852, 0.07185939515991967, 0.07945526915628254, 0.07843455984202657, 0.0597595753054598, 0.06649168096406456, 0.07897832172494881, 0.0837986792162845, 0.07703183676071368, 0.07915644586913036, 0.07521295274204408, 0.08071675936565487, 0.05475462780254469, 0.06758920439156633, 0.07528151808702596, 0.06445928563574053, 0.07367387834729598, 0.05854255454876191, 0.0638525806030183, 0.07603697460100217, 0.058512802009438036, 0.05884186893300006, 0.07335986998045727, 0.06675430021465731, 0.07063679229899691, 0.06811678636943194, 0.06524143160881661, 0.05986134281042783, 0.0812387156900091, 0.06417430128236046, 0.08018055005131687, 0.06620029826181821, 0.07056827397224288, 0.07653032975636646, 0.070557211847142, 0.0682009471359509, 0.08376829472165256, 0.08391513036595434, 0.07380823841861932, 0.07940984941425047, 0.07891686143915669, 0.06621624715272997, 0.06254121078402133, 0.06339364134887776, 0.07947599028483572, 0.08031318307295002, 0.07896807227195661, 0.0781309441303929, 0.06956585068504328, 0.07521471848082252, 0.07991297679275833, 0.08051581438257667, 0.07799607425039135, 0.061828209896085146, 0.07958274560668621, 0.07781191658186914, 0.06906657517269019, 0.079302378068315, 0.0623037110655357, 0.07871325392949535, 0.0691551567001553, 0.08022961715869824, 0.07002206775901036, 0.08121807551718647, 0.0799761327847531, 0.06685006156842745, 0.06466021656322275, 0.06505682563412632, 0.06934371623820805, 0.06515249913640271, 0.06849539492356871, 0.06239292219319328, 0.06723363413869386, 0.07116382573476997, 0.07782342848159035, 0.07180039422871673, 0.07693603377424539, 0.08126995175655857, 0.06861208043770817, 0.08039271813843823, 0.07117930490416827, 0.07239972952787234, 0.07974127324380002, 0.06419563314818294, 0.07957597959493293, 0.0815830374278056, 0.06516709057698306, 0.06961442269637323, 0.0637520531383418, 0.07049402480803407, 0.07942163459012648, 0.060806746522146564, 0.07706811461754991, 0.07957852259585929, 0.07078474912310392, 0.06610758318276569, 0.07846940590892743, 0.0731138904505779, 0.06998348124551436, 0.06900350560378815, 0.07939387022027523, 0.07455082038539569, 0.05780659495835848, 0.0789160803784065, 0.06925635629548821, 0.08126807119948817, 0.07943806657254357, 0.06658028144329438, 0.061771377967014304, 0.07779845038573056, 0.07742726663771202, 0.07978412335175361, 0.0697531538936763, 0.06134173333107763, 0.06148378785066096, 0.0800721177101074, 0.07849185753056893, 0.06341986052763474, 0.06431710913452018, 0.07132471976167203, 0.07022711421339624, 0.07665810225824236, 0.07968634004273874, 0.08007175987229978, 0.0783171518049394, 0.07133210839557137, 0.06400513792399369, 0.06914333408554567, 0.07882780395760318, 0.053863932301901965, 0.0822818850177628, 0.07009175269187214, 0.07808508341076542, 0.07135070534381373, 0.07971632298191712, 0.08187398976980727, 0.0592454227300523, 0.08049023126668946, 0.07983126627919764, 0.07264645338499358, 0.07325898168438674, 0.07535316863371012, 0.06929944089456047, 0.07011291405735823, 0.06035333942923, 0.08351243077033435, 0.07863712945225461, 0.07931002060821457, 0.0758535961067167, 0.08124052704803193, 0.07907035594508859, 0.07459029661022099, 0.060022956938626935, 0.08133391447059755, 0.07597081751637039, 0.07063177279224422, 0.080677433380827, 0.08109782643780167, 0.06337184045498316, 0.07643060257910476, 0.07937891424118457, 0.08153042254494604, 0.0784607277795512, 0.07869850112910085, 0.0781104581645124, 0.07376962634003213, 0.07037038300683146, 0.0666725608049933, 0.06981565392733423, 0.07878883480380881, 0.07936395916970926, 0.08011764979645722, 0.06982471238030723, 0.07906559425330259, 0.07893878943273902, 0.07888237766726175, 0.07750114477414595, 0.07893428127635647, 0.06414434740334142, 0.05932320396286766, 0.0745375343890236, 0.06628066356976582, 0.07807169131384085, 0.08251325405868082, 0.07568548112566907, 0.06604637531798861, 0.0784242662925388, 0.08024036027652054, 0.06790111095797711, 0.07856612663677863, 0.06530591355198603, 0.07918647870052757, 0.07178129993465814, 0.07779266194735157, 0.07896232889471286, 0.073627264895279, 0.08278879589099987, 0.05789522891290201, 0.06361719272903849, 0.06502102545893207, 0.07728514051390122, 0.06212609595308634, 0.07145543273996749, 0.07479974001675914, 0.08111379341590204, 0.08187082481803926, 0.07118541830189858, 0.0786672519725729, 0.07903912446089169, 0.08096185154685948, 0.07948335254834081, 0.06392209384430385, 0.07963380362060021, 0.0639419969495345, 0.08001087206135132, 0.06687713590171693, 0.07707743877055123, 0.06258840438911924, 0.06928752756594164, 0.0704976834518386, 0.06432537017015526, 0.07559641461036658, 0.07716269515078397, 0.0814467694904179, 0.06978344762696469, 0.06469266919412225, 0.06193326930344899, 0.07828333889762717, 0.06340344943508208, 0.06668598140407779, 0.08077965400020709, 0.0649636556827398, 0.07862475491788513, 0.07658805073950287, 0.08185660140855563, 0.07339676718218137, 0.06689086474119167, 0.06268173772695874, 0.08233222175203758, 0.0829920663472024, 0.06717030740762535, 0.08170972864941961, 0.0819301596897702, 0.074729512145774, 0.06737925545963626, 0.08063618005183176, 0.0706726544233125, 0.0604696753620968, 0.07833019182216314, 0.06781138397373034, 0.0812645336308186, 0.08296993090416865, 0.060171486763422356, 0.06087636995882069, 0.06503151293967482, 0.07743472814968956, 0.07643812330072748, 0.06860864106955919, 0.07469311305332589, 0.062063348474280036, 0.08456877578777497, 0.05895536018264815, 0.06859045285039689, 0.06433548257955896, 0.0850575028482908, 0.06636218803422084, 0.0631897880319366, 0.07431562176515223, 0.07924147507426132, 0.06012601904927985, 0.07653681452203835, 0.06271756680802486, 0.07948850714965243, 0.07671875985105596, 0.07559117710089425, 0.06454023384353133, 0.08082006972252698, 0.06167336066213602, 0.06036866089580305, 0.06956091541107844, 0.06494651469235943, 0.07523259580086517, 0.06227749761189431, 0.06969333022623735, 0.07821635955812295, 0.08078877816007501, 0.0772419545776373, 0.06751491319046106, 0.07196306927012834, 0.054445525626080564, 0.07854499289566338, 0.07649883800980047, 0.06765625167188145, 0.08077175366402317, 0.05717960136708627, 0.06596938896113591, 0.06063575712491674, 0.07156875914495196, 0.07924234670245449, 0.08217638014531446, 0.07857729412060468, 0.06204599443506164, 0.07963703592808172, 0.07918784987796919, 0.07566764341739114, 0.0801289322632243, 0.05741546654382192, 0.06554436504865453, 0.06726117098797059, 0.06654716589004618, 0.06635861845968825, 0.07332877876093873, 0.0636650032579572, 0.06747727814140722, 0.06268823291130336, 0.08318401361304804, 0.0805109999632787, 0.06785416080965703, 0.08121708939052615, 0.08304488919029338, 0.0636771766671057, 0.08040342539444671, 0.06514080540726512, 0.0652420946495512, 0.06977216586542354, 0.06382559557466815, 0.06465319298252302, 0.08354925036353136, 0.07973938590468502, 0.07103731816438577, 0.05178072676025785, 0.06665504420272814, 0.07799802377475062, 0.06770084408354629, 0.07933972809071635, 0.07986785056121466, 0.0834840231807717, 0.06724932249816883, 0.07975614018751088, 0.0780677509129846, 0.08134781838293763, 0.06635749378292294, 0.07795003614684753, 0.06947777973134293, 0.07983142671617381, 0.05962596275329374, 0.07504444930816175, 0.08060688172469054, 0.08244027156549757, 0.0810039328735168, 0.08074718652530682, 0.07361310988512142, 0.07503350210288728, 0.0805690970789778, 0.07838940504026413, 0.07754099469734098, 0.07894018415102683, 0.06483451927723045, 0.07827639708867438, 0.0790101340148185, 0.06928466633165797, 0.06310156686045301, 0.07631818925121976, 0.070417460330165, 0.0675446574491286, 0.07864806730101588, 0.0678915724331554, 0.061593910220005724, 0.0801015396147668, 0.07246549463502958, 0.08318079509973518, 0.07610095242611165, 0.06940328624232008, 0.07963142657101888, 0.07890652171100561, 0.07791498682345942, 0.07679151048389662, 0.07497763058490449, 0.08207048189133667, 0.0696687965516187, 0.07967599108565225, 0.07927827941831389, 0.07931245479635272, 0.06093101304575536, 0.07998997410199334, 0.06306519440545008, 0.07435328948618473, 0.06358142192375886, 0.06158611659021351, 0.05892619803383935, 0.06257083021795938, 0.06804078928837838, 0.06822545221083053, 0.08422369533246371, 0.07149469896831138, 0.06960228489836842, 0.06172576023904071, 0.0792241215755923, 0.07878071456836686, 0.07799957061902411, 0.07984048764504921, 0.077872389434291, 0.06915308504239649, 0.0739534035555892, 0.08050926816144059, 0.07062383829656918, 0.06597044287672933, 0.05877352258522312, 0.06622600921199034, 0.07943051319316338, 0.08054157331937344, 0.06596044724351324, 0.06379101509397359, 0.07790412208188958, 0.06955532276753565, 0.07796082859921535, 0.07971585109599075, 0.07761390480467871, 0.0791305126163879, 0.05329692930027022, 0.07824393511831006, 0.07951874301764354, 0.08011038933652283, 0.06717776836758761, 0.06353587192530631, 0.06957578755009301, 0.07939237434552297, 0.08413047904507878, 0.06869696195973415, 0.07488681204576514, 0.07128440565221295, 0.0758860788165318, 0.07339902819414518, 0.0769099575820329, 0.06570600308876062, 0.06724652554186956, 0.07290137368582189, 0.0798627157808748, 0.08030367046192154, 0.07345868130539517, 0.0613249908029625, 0.06971116571004568, 0.07883889706900195, 0.06680028626278399, 0.07925269086457182, 0.07750509608348351, 0.06363887399273645, 0.06868345464136884, 0.07346885010853609, 0.07953739037860616, 0.07768928823618654, 0.06082973557069179, 0.07418392573341263, 0.0746079924260634, 0.07874636866652664, 0.07921418349917393, 0.07504511133325362, 0.07176821173503177, 0.06606246591818077, 0.07895619998416789, 0.0637173603484531, 0.06429484749352864, 0.08222412626107077, 0.0820124962129696, 0.07642131956070468, 0.07473113781917562, 0.06714355431761015, 0.07544182395572667, 0.0578994423967459, 0.08184964882538129, 0.07918485813610689, 0.07546577030781682, 0.07924778059250702, 0.07385255772988501, 0.07113963496889784, 0.07804961202721529, 0.08059723970536893, 0.07048274817986862, 0.06669775017483899, 0.08157246133831514, 0.0795896394955371, 0.0639759082464555, 0.0664131560422903, 0.07930929033020082, 0.05959203345219851, 0.07364198099481983, 0.0812511167143376, 0.06610645593218989, 0.07783014065920753, 0.06500539334497221, 0.07650774877323722, 0.0662942036912374, 0.07778737842003546, 0.06023889733739035, 0.05877252800245218, 0.0815013870192661, 0.06620637583696636, 0.06328169962507474, 0.06997798646209481, 0.07095218934481243, 0.06616970611630096, 0.06429613217126902, 0.06476146468391204, 0.0682893775745404, 0.07855838576555615, 0.06858027606649082, 0.06740445764324737, 0.07906165684231653, 0.08206385325937285, 0.0780587119584254, 0.08150090656636301, 0.07064825068727013, 0.07352614865180444, 0.08325779307760803, 0.06678222568132235, 0.07667722403306107, 0.086354480942438, 0.06871387364345119, 0.08020875326759269, 0.08002704740593065, 0.07892821045559746, 0.06432204254649683, 0.06395387820693103, 0.0816356263925997, 0.08018125438915075, 0.0774310722425489, 0.04983064569804056, 0.07254615195829923, 0.06144173273412427, 0.07087570798964007, 0.06618244906489731, 0.08152644799329413, 0.07852294171857699, 0.07023867638273461, 0.07955446108242613, 0.07635397231760119, 0.06160729989151416, 0.08027200459531691, 0.07922155206394861, 0.0655633676244748, 0.08093801498734793, 0.08079882800503399, 0.06954138531008369, 0.0790842671113131, 0.08214053459402915, 0.06988188517661732, 0.07603118180953522, 0.08085022092490785, 0.07729139485679784, 0.07914419535813963, 0.07556849707174051, 0.06685058553341322, 0.06816366623109622, 0.08303252605794789, 0.07695084146309314, 0.07148408983949574, 0.06677719791486003, 0.06462749190611265, 0.06092714314223983, 0.07664947051592241, 0.06099693651795616, 0.06738454641514514, 0.07819329991543893, 0.06416152885362325, 0.08090796016699972, 0.07588819853040142, 0.06581835452723116, 0.060542304241691, 0.07781285885503601, 0.07944884741049173, 0.08210488291533631, 0.07891431293669807, 0.06256602098163158, 0.08429115266628909, 0.06514832463572268, 0.06960656982384548, 0.07566830165995304, 0.07765428087161225, 0.07695861857340473, 0.0766599132844778, 0.07120585944798453, 0.07014166238532256, 0.06710625016056415, 0.07999765450888151, 0.06871975075028025, 0.06992065150116034, 0.07301513644411019, 0.05582259494457112, 0.062436474306371066, 0.07926938865727241, 0.06720825086583748, 0.07267500674670029, 0.07757202703347423, 0.06725138899482923, 0.06811765658944878, 0.0835337766330754, 0.06971143450843904, 0.06553939190333943, 0.06716220882215597, 0.0647437027507603, 0.0809588418175079, 0.06978569779074612, 0.05896877780169453, 0.06747428684246283, 0.07920147092011302, 0.08148404744941684, 0.07714801086330897, 0.07966001157277733, 0.07817846850256004, 0.07103663703456974, 0.07827018749880088, 0.07798789517295242, 0.0712243234297675, 0.06265796317922631, 0.07380422951973437, 0.06358235437247664, 0.07069367831103912, 0.07271021636046723, 0.07943580011502341, 0.08229064883030723, 0.05533382600015973, 0.06451562790644032, 0.064795121841016, 0.0682027395829362, 0.0627504413800259, 0.07423497701529, 0.06263739507358121, 0.07246827595095104, 0.057161812307063124, 0.06797787609143183, 0.07867694351244266, 0.06183383377827932, 0.07061685852740321, 0.06167140072460203, 0.07994322547226244, 0.07659518202282962, 0.08056007795362316, 0.07887620593337491, 0.0689420443588117, 0.07282498519352427, 0.060344433322518126, 0.07024224040400891, 0.07054932066102873, 0.05673092008027761, 0.07234898407257052, 0.08169042028814048, 0.07910996768658972, 0.08603040061056368, 0.07331438638339201, 0.0644540812141532, 0.08014980573008745, 0.07221100204806492, 0.08019551004922022, 0.06564930158008976, 0.06713973050281108, 0.07876902894417818, 0.06348422209068252, 0.07928265084110608, 0.06891904833715595, 0.06442054385684055, 0.08119436786144148, 0.06505677845676658, 0.07996900759811322, 0.060354451692195527, 0.06791378199858034, 0.06707509342216642, 0.06337481470950339, 0.06081546196132628, 0.08017944943071534, 0.0573592524547546, 0.074578010555426, 0.07902831527357379, 0.07979893437304021, 0.06531388190108182, 0.06838143675491608, 0.06556943934063202, 0.077148280857405, 0.08061222159865297, 0.06761802316661242, 0.05846505509216091, 0.07799751623933149, 0.07243678558861547, 0.07910863052744532, 0.07970430997541789, 0.07730900113225021, 0.07892860126053496, 0.06808410053383479, 0.07299005847110582, 0.07552227358307256, 0.07562970481218667, 0.08545919795274164, 0.07846522694296858, 0.0736015962271881, 0.08326333819857143, 0.08429099385722598, 0.07946789004435487, 0.06616183014588839, 0.08155300463926558, 0.080240503438245, 0.0683079013597406, 0.08001767144913625, 0.06704743584457272, 0.08035934746084132, 0.06624501707319905, 0.06102413626684967, 0.06671327687125943, 0.08460867824989425, 0.06593592543415994, 0.06898698802503785, 0.06494935720283453, 0.0780208351740269, 0.06800637780035824, 0.06058831742533877, 0.08250062550947061, 0.07034326903335983, 0.058623833229801324, 0.08404489582747005, 0.07959745513614484, 0.06720403018317443, 0.06126801221996443, 0.07225470443078302, 0.06872817617998882, 0.07708284592216028, 0.07633749706568183, 0.05974378583312863, 0.07782734715664903, 0.0748185348886475, 0.06217736112339469, 0.0798481658949842, 0.07303900386101245, 0.06134467985827353, 0.07726457465184819, 0.07640781892006528, 0.07832450425938203, 0.08015838557584246, 0.07135250231035783, 0.0653557986465389, 0.06749517002502602, 0.06601583790582108, 0.07334730332789315, 0.07809782197181668, 0.07630263629316617, 0.06682287931090547, 0.08054153162608217, 0.06020857339206735, 0.07119919032287456, 0.06902174966730243, 0.08009385633816138, 0.06503660246297344, 0.06602184747056135, 0.07816575545630197, 0.06751256314459742, 0.07980143555079379, 0.06689348516969805, 0.06833232003732112, 0.07658218035387887, 0.06504850427397382, 0.06728004493942974, 0.08206434006045923, 0.06223285528160928, 0.07964512175273854, 0.07858297466431745, 0.07412737245385978, 0.06663536964442934, 0.0694882139732077, 0.0657309720578208, 0.07170364877678095, 0.0805662682725947, 0.061382682115952776, 0.07810744760724282, 0.06884862652898716, 0.06472791816460965, 0.0713702332556936, 0.0677608945704761, 0.06657530846114282, 0.0795452439639091, 0.06846002240169674, 0.07894783275950129, 0.07064227690478042, 0.0723452908944285, 0.07992030058548101, 0.06976986865429775, 0.07814960495967886, 0.06585012448201723, 0.08355465861148616, 0.07006509455152844, 0.07661421267256609, 0.06487986910882604, 0.05706611380343441, 0.05535818819638182, 0.07884979033358562, 0.06019173507202065, 0.08054730767958623, 0.06369212643592684, 0.061777234384543, 0.0704352985208364, 0.06041552713154432, 0.07527029340917303, 0.07889018990440685, 0.057777864593486994, 0.0801416340700372, 0.07968250902624002, 0.06695132201764267, 0.06836433292370338, 0.06423671704124931, 0.07011767267725724, 0.07428087541908629, 0.07957429139322374, 0.07962864696359706, 0.07945159340803111, 0.051895753371263544, 0.08088302689986698, 0.07575876796706672, 0.07977614581187538, 0.0669449578285906, 0.08447981643281598, 0.06800269578407282, 0.06305367745866577, 0.06623319305605713, 0.0789321780061316, 0.06467928207389431, 0.06682586605443945, 0.06129533498600421, 0.06776161777808064, 0.06680428229330472, 0.060305912626768196, 0.06484578057522097, 0.07746796040833052, 0.060677946736430746, 0.07945629628958534, 0.07277675802108799, 0.06423109844351609, 0.07526668173660143, 0.07868446549394481, 0.06915591073467381, 0.08191364672989185, 0.07744778925900295, 0.0720955152638077, 0.060634730264988924, 0.07514728211320623, 0.06216492777711422, 0.05714800513311745, 0.0801267568484733, 0.07817121607524996, 0.07795464418950507, 0.0693164846471326, 0.07114162914976334, 0.06496861880570638, 0.07066554858895543, 0.06366263138758582, 0.0819553739511147, 0.06358614191840611, 0.07875735070222631, 0.06422356160571391, 0.07774314629193067, 0.07864287625643936, 0.0796615693055831, 0.05916463440417974, 0.08129147620209942, 0.07865181294628318, 0.06365364964787337, 0.08430972887052327, 0.06576562330516099, 0.07093503692941448, 0.0643775713207727, 0.06603765481742996, 0.07796723330479792, 0.06702478607816925, 0.07335786107059813, 0.08453502426751507, 0.06759439405002726, 0.06756378325480074, 0.07762906709396436, 0.06607936105279504, 0.060173926162795745, 0.06883971553110055, 0.07914356176428959, 0.07789397877328942, 0.06803518717693383, 0.07709149368069784, 0.0786629290032857, 0.06736612191014023, 0.053287562376090024, 0.08145456757649164, 0.05674539778862957, 0.07799906968201294, 0.07912671714118599, 0.06054570544087878, 0.08220018639593217, 0.07774603466036246, 0.07926734872333971, 0.07225382167529058, 0.06967374170851173, 0.06256448662564809, 0.06436083590016013, 0.07846203744941761, 0.07941299925664505, 0.05742410941301276, 0.07878930103836068, 0.08065169594232942, 0.08085042947156329, 0.0792969900866131, 0.05916890346161723, 0.06438672129571303, 0.07843039658700958, 0.06908931283121515, 0.06965427725947144, 0.08110500083221203, 0.06767978725825656, 0.08075935104816598, 0.06743388168653605, 0.07548677576681606, 0.07930602968617396, 0.06599763960714769, 0.06693119783413194, 0.07170860126124133, 0.07242082441936985, 0.06697014397601454, 0.07787201785895373, 0.08043280208119068, 0.07797981963147406, 0.08038801690980327, 0.0630239781176341, 0.07080252466568601, 0.08385016728020916, 0.0642725546533615, 0.07064733497454631, 0.07170930915298444, 0.08371763448436637, 0.053955145225434806, 0.07183294144853697, 0.07900739672996578, 0.07349615060924873, 0.06682985501406363, 0.06763393721914987, 0.08088439401244825, 0.05863611814012521, 0.07879218372954125, 0.07944941692203995, 0.08004320395838618, 0.06304041501550404, 0.07414789431654298, 0.06573040210072614, 0.0687363396129301, 0.0745329816441474, 0.07829894000686355, 0.056105299433632815, 0.07908930802020803, 0.07997511014578183, 0.06381537315948113, 0.06498441712061397, 0.08027157960074666, 0.06655878493086392, 0.07844594055656802, 0.06606709210621373, 0.07745747557593156, 0.06443659289820176, 0.07990344403102928, 0.07182206421982817, 0.07945910537773093, 0.061755236886149686, 0.06877785964798423, 0.0643988406196759, 0.08397205699487087, 0.07316775554940702, 0.06080541593245518, 0.07158211307458434, 0.06672687598645886, 0.07652985385166845, 0.06307548856436407, 0.08116002495680034, 0.08183927004559621, 0.07512902694006515, 0.07023859385245015, 0.06822821672717375, 0.08028103756221946, 0.07038429647269803, 0.07356914120319734, 0.06094355270000834, 0.07740814893974879, 0.07751438990214465, 0.06544512053472758, 0.08045433615062068, 0.0650336960103572, 0.07173670375491213, 0.06300809302867072, 0.07168080391284459, 0.07707794107767216, 0.06952671523896958, 0.06343620432696302, 0.07561385659925311, 0.08077030221835406, 0.06483048425808055, 0.06518297724627871, 0.08319980292409916, 0.079238894282362, 0.06831502709344651, 0.07002413096714571, 0.06014833907217599, 0.06426535703516123, 0.06384209571008889, 0.07580095424997911, 0.06873031616055612, 0.07997494490387733, 0.06368863986765237, 0.06877792353382489, 0.07969847322971245, 0.07453214635047971, 0.06298762008370781, 0.0803865221191727, 0.07911011157374974, 0.08153549846538721, 0.06085027231577777, 0.06223536213791237, 0.07940361154850119, 0.06754530700945524, 0.07449666468443213, 0.07480150933805332, 0.07846324144689301, 0.0783235801719057, 0.06581440716165037, 0.06904894871973372, 0.06369636773379365, 0.07267821765487112, 0.07258869578577867, 0.0803072303820404, 0.062317013727155375, 0.08006385135238671, 0.06531919584632594, 0.07687808622936353, 0.0700633797976705, 0.07656845274601239, 0.07642988320164341, 0.06815904748303754, 0.07216902298770521, 0.06350663656104977, 0.07422584943937707, 0.06387658458971827, 0.08007165461510383, 0.08265950697785791, 0.06018970854404, 0.06520960878678991, 0.08024505168295491, 0.07772924886538043, 0.060749536420687596, 0.0713220005802915, 0.06956284116016745, 0.06629436984056192, 0.0794803086070997, 0.0740229037525421, 0.0576808765763726, 0.0637975251438683, 0.064587269027067, 0.06676072635992775, 0.07710976703818591, 0.07649751473887281, 0.07850775781860382, 0.0793714920569676, 0.06657917648692407, 0.06665585833453337, 0.08237079676991599, 0.062167286561537, 0.07914821924230249, 0.06665486085783744, 0.07995437028498897, 0.06305282122221284, 0.06695831740323338, 0.07007696353292367, 0.06576443018939052, 0.07886597741350647, 0.06573544797297465, 0.06317946259247396, 0.07687255854933746, 0.06418316055226365, 0.08083059171815794, 0.07047355400598675, 0.08094239249046105, 0.0686528154641533, 0.07902345090942957, 0.07076597997173416, 0.06369846661815465, 0.06807471697112952, 0.07863114837418383, 0.06618025244542634, 0.06697047565081626, 0.06973501989520996, 0.07617152904457, 0.08511939393761965, 0.08141470093617581, 0.06456066921552947, 0.07954576337652874, 0.074787900886659, 0.07953131172313624, 0.08260287029728224, 0.06807782624400484, 0.07688285180781718, 0.07897200858232648, 0.06911058760140064, 0.07118214221093921, 0.0566220062857988, 0.08129606268354647, 0.061215283910186706, 0.07614156967435329, 0.06462417733516676, 0.08021992145498355, 0.08057775616084842, 0.057721430290862595, 0.07837199883689765, 0.08116926071982933, 0.07378909834572533, 0.05469436488541324, 0.0787808049520611, 0.06628999009265224, 0.05889934805226534, 0.061717288482364734, 0.06214280607058483, 0.058564114747120435, 0.06678230108628117, 0.08043090054167575, 0.059641260862138286, 0.07811901685277738, 0.06609200745480545, 0.08022959223341569, 0.07085739544613337, 0.07962556116479191, 0.06263574026459517, 0.08081744621902888, 0.07886089262804502, 0.08406381368583797, 0.07955463180000585, 0.07865143980392193, 0.07266430104616417, 0.07865951486261123, 0.06110161959818654, 0.06517211384178936, 0.07947992244157363, 0.06184359978978333, 0.0822511453426636, 0.06606521752276362, 0.08241176198788203, 0.07904126548754106, 0.07973249186336578, 0.062793735340131, 0.07310215524613001, 0.08042457814972183, 0.07932262394632877, 0.07956579000480672, 0.06809930857491914, 0.08018644730930187, 0.08048648752901713, 0.08015354947294309, 0.07996884673540296, 0.06089353557211014, 0.06390473872461046, 0.07908012131995884, 0.07972588139674838, 0.06519922980087184, 0.07665546803111215, 0.06721910738426776, 0.08106160613056157, 0.08424544054661615, 0.07932675421552225, 0.08192647423074965, 0.07212266739332787, 0.07993805808536363, 0.06518060040410435, 0.05966252258607556, 0.08198357448133343, 0.08223445457204344, 0.0803465307625851, 0.06060527413990378, 0.07404512542016936, 0.078558954696779, 0.06294503488886806, 0.06433523980504158, 0.07236234886296548, 0.06211260433090658, 0.0796947107536269, 0.08010615086727983, 0.06299791563308463, 0.05800749913418757, 0.06459858674870571, 0.07830483166314768, 0.06192007901502098, 0.0647282789833344, 0.07679434322090813, 0.08271732295024133, 0.05838861207153298, 0.07925705613935863, 0.06453212989432924, 0.07942818503792341, 0.07871550020764702, 0.07915801275136759, 0.058245744923079115, 0.07987801729247948, 0.06087457008014804, 0.06906016272731598, 0.058624436693260305, 0.06231513787110306, 0.08020637084241691, 0.0785486966138751, 0.08202725588258834, 0.08499847260312444, 0.08386654543715108, 0.08189083112530185, 0.08492248496164465, 0.06181335139645211, 0.07811483745047176, 0.07739819762269574, 0.07647980798488294, 0.06237142530506351, 0.07725409271303874, 0.07284424065273169, 0.06106018431112551, 0.07911190879044526, 0.07806431531100211, 0.08042957998710852, 0.06353444750360754, 0.0792261514809395, 0.06473416823896204, 0.07282760747759977, 0.07843801562082561, 0.06358294725055433, 0.0779024165040847, 0.05684666145504282, 0.0757677065555981, 0.06992469957569532, 0.07924288737214599, 0.0722030438447134, 0.07781770689105527, 0.07867653529287545, 0.0684649129739735, 0.065172564725736, 0.07516256797076254, 0.0797560419214319, 0.0828521312828655, 0.07994894902659658, 0.07804526583886671, 0.07101204350114595, 0.07829725260544725, 0.07716551880133819, 0.0794363144380249, 0.06832610624063332, 0.07999725994787334, 0.06524974977625092, 0.0842455361779687, 0.06793490626329217, 0.06668123514620249, 0.07675397379152149, 0.07982143477464489, 0.06606875751284759, 0.07411042525090518, 0.0682710435004707, 0.0772442574733896, 0.07947713464573707, 0.07952852487518867, 0.06565754420117398, 0.08659071555915418, 0.06860829736003202, 0.0797079754895326, 0.059224862529380334, 0.06968977671318873, 0.07376843780597048, 0.06403472566700566, 0.07607270514543804, 0.061650929339635424, 0.07899264177969756, 0.08095762032764796, 0.06238761921183202, 0.07982601123047459, 0.0804292452334527, 0.07896800122277083, 0.06008488699084995, 0.06926582962003291, 0.0796575442186303, 0.08030570291323468, 0.0661288525477258, 0.06298231344556719, 0.06688344227489801, 0.07616550769875274, 0.06936781567281157, 0.08532088791783485, 0.08472207018830734, 0.08014959818161556, 0.07970643762347979, 0.08050815462815783, 0.060807652996971946, 0.08031838002181026, 0.06733460616364327, 0.08017998085904775, 0.08407623302470896, 0.07426889230745672, 0.0692954843969663, 0.06260561567565248, 0.0659593688043861, 0.06872760115304681, 0.0780980592506842, 0.07876399591733627, 0.0720533351094814, 0.07076880401629042, 0.0660561507585657, 0.0583365594594031, 0.0798384069101237, 0.07982860530099883, 0.06184204335855967, 0.06592532775120058, 0.07469526212618087, 0.0774055908645158, 0.07397974074021485, 0.06835371650952549, 0.0626083618634888, 0.07912489929345295, 0.08001944062451775, 0.08212923542250963, 0.08258830383836381, 0.08080811699985012, 0.0678733677727517, 0.06359920693187963, 0.07298801244704106, 0.08055236632266873, 0.07975140722376219, 0.07801580983605244, 0.05223654575449735, 0.06953056313868952, 0.06302025717222454, 0.08195747900057809, 0.06577539387551729, 0.07010478042073694, 0.0699093823883713, 0.06704001185997399, 0.06441100788716818, 0.07948776356968039, 0.06356010841718959, 0.06257649285794561, 0.0654555441261049, 0.08024047794642729, 0.07462990937671948, 0.07413474229868863, 0.0807139269504815, 0.08122328472798784, 0.05750914856596866, 0.07008194154592623, 0.08037840974554833, 0.08021653741391907, 0.07915585619074333, 0.07715882303767704, 0.08093113127392815, 0.07885416482846133, 0.059433304065654516, 0.059667442681181605, 0.064039115074359, 0.07863212317650312, 0.0574388803990816, 0.06878177992044637, 0.06675065625993751, 0.06557415195423595, 0.07347064183632718, 0.08167350249547599, 0.06772669595837046, 0.0726307204236239, 0.06610462633400128, 0.06078305681382745, 0.08218920297974251, 0.07226641574825417, 0.06668864089506127, 0.06793021750937182, 0.06678219668479284, 0.07414807624710633, 0.06420533356246248, 0.07674587989331433, 0.06815605997265792, 0.08184033760659347, 0.062446854519662864, 0.0757662021463825, 0.07589190343100867, 0.08092121399293402, 0.07790678978250598, 0.06648180323144508, 0.07868745148935162, 0.05637108701645, 0.0785671396849201, 0.0662791616503511, 0.07911239655921266, 0.06962581507201267, 0.06830910642773091, 0.07689744114310579, 0.06409598741577266, 0.07894387093499937, 0.07995903429175306, 0.06785489042859388, 0.06438574050093754, 0.06758083313818618, 0.07893527081290566, 0.06165944776627932, 0.07906489010668882, 0.07431839673924467, 0.07656773721389372, 0.079466690061284, 0.07795466096920413, 0.07955225410953759, 0.07137144354394993, 0.06917625536160962, 0.06736542052978771, 0.07845840719910872, 0.06745900818160266, 0.060577849419592385, 0.07898068100395095, 0.07285210870600642, 0.0785535730137291, 0.08287242191684932, 0.06392396161264509, 0.08078072769296221, 0.068659508965643, 0.08479928269017006, 0.074318854580462, 0.07997635479803476, 0.06050998220992671, 0.08010035773309461, 0.0816299591794929, 0.06468294151950948, 0.0786058872845466, 0.06154273604438808, 0.07969423163722103, 0.06753338885367202, 0.07125143381744618, 0.058698836918442326, 0.0712026585696148, 0.06147864971224384, 0.08193597990637416, 0.07935163321986474, 0.07141038193200079, 0.08083237254889755, 0.06945854895780305, 0.06370655208610375, 0.0635489913426099, 0.07788953173786896, 0.0709341100267778, 0.08062609568400517, 0.07420982235610295, 0.07915098058610315, 0.08102371274701968, 0.07867657967671038, 0.06729577019595082, 0.06498978236764846, 0.08090227831200011, 0.07465404002430846, 0.07681272848322472, 0.06891051784355345, 0.0786356180968775, 0.07534913461412816, 0.08144657384317656, 0.07815705280891597, 0.07581076814211866, 0.07910796220398598, 0.06433890493827135, 0.0641673164758103, 0.06914616279625002, 0.06254403710350245, 0.07892975618113103, 0.07750748965944856, 0.07755397274488866, 0.05991013736654593, 0.06245695651231593, 0.08023118946234309, 0.0854950022885563, 0.05927081094575297, 0.07790422644750002, 0.08036890313147883, 0.07933344396770106, 0.08337857772117405, 0.08012842311308899, 0.06735536741089894, 0.0767975754517825, 0.07687101512885608, 0.06524403540776862, 0.06792260027810101, 0.07859012815679414, 0.0779539263048349, 0.06530884949619284, 0.08092561764172776, 0.08132283816911683, 0.06706646955779517, 0.07633857806638907, 0.07699226526137282, 0.07154432338993416, 0.060445575669112336, 0.08068039233573879, 0.07967279039167237, 0.08209652581078918, 0.0787121015829194, 0.07347741019700525, 0.06989683411301602, 0.08000512377119086, 0.07475164128596389, 0.07942347806732825, 0.08474000597586054, 0.06175504730986921, 0.06806588467617398, 0.08088773482780452, 0.06744440266288243, 0.07787596174970794, 0.06891193165276918, 0.08013711853242461, 0.0662607859040843, 0.06479074468093746, 0.08138207981623193, 0.07909826091365443, 0.07712558740487153, 0.08014568835912701, 0.06509770371312135, 0.07524345287820501, 0.06616242576843187, 0.07983550727358951, 0.07010190365653118, 0.0829039114167277, 0.06853045656653549, 0.0783647411978869, 0.06628013208325484, 0.07946827565312585, 0.082452631717748, 0.08110997547615338, 0.07843986478461668, 0.06777325892259436, 0.07813890216712481, 0.07958412082437868, 0.0632508408838849, 0.08230595555044026, 0.0671026801426035, 0.06323847480891433, 0.0616345932741097, 0.08017358229241146, 0.06985387801570597, 0.05804010894729525, 0.07437913717141992, 0.07914165835672825, 0.07849222699920233, 0.07040645458280281, 0.08207437993024896, 0.07184303968203297, 0.0784901318743882, 0.06927301984662923, 0.07728621369831475, 0.07821542284919773, 0.08028882370837856, 0.06597759741003027, 0.07271098416167779, 0.08583523539986437, 0.08315123641190535, 0.06912893517935496, 0.0773948994884777, 0.06893551902736339, 0.07626839370038345, 0.0810979605552496, 0.07793884933994008, 0.08419020037051468, 0.07912765927844558, 0.0796163054238385, 0.0713989829444732, 0.06149323346906382, 0.0796375232061613, 0.055570425464238224, 0.08228487663943544, 0.07812726395352845, 0.07443255772220932, 0.0853034429083233, 0.06417341173107523, 0.07410042357354449, 0.07234759714269517, 0.05600428658707741, 0.06030246565473288, 0.08266558076353005, 0.07506686313132133, 0.0734440547318732, 0.06713042504909308, 0.06637971802744663, 0.06916451055679858, 0.07160206569728791, 0.06310003261759836, 0.06535441598258684, 0.08131525107518443, 0.06514921124388352, 0.08026184815883121, 0.08074740576620303, 0.07278429826755806, 0.0783281784464601, 0.07145157989006728, 0.08003157906409882, 0.06492848121458353, 0.07900116108168909, 0.07988039661554187, 0.06417439319327521, 0.07817861107946841, 0.08334036492200052, 0.07094247641596188, 0.0782370881443472, 0.06143168393270761, 0.07514849052399684, 0.07007608140659159, 0.07431875277293228, 0.06648075407590584, 0.08033963115353202, 0.07790052410803011, 0.08041941443289118, 0.06188936259102558, 0.07792490098190531, 0.07914572724205707, 0.066368606815954, 0.062187313313431636, 0.07958467330305263, 0.06259042678922402, 0.08144767342386876, 0.07805376628398057, 0.08444052872982435, 0.0693832756080348, 0.06768145386340703, 0.07832878224844025, 0.07701253682619215, 0.05969678557334298, 0.06632659225594609, 0.07559092918658919, 0.07793310609628215, 0.08159402833792358, 0.0769657555299061, 0.06253311129256597, 0.08009771473385847, 0.06209372931359002, 0.07801574086528364, 0.06589968807913955, 0.07396346651377902, 0.08129953012138945, 0.06824305297335602, 0.06248172716039895, 0.06610889260433124, 0.061110090456029685, 0.06340325554420782, 0.06280196680457976, 0.0669699128441476, 0.07100416538320875, 0.0661132098718365, 0.06795012635165895, 0.07004044121222688, 0.0727250615492916, 0.08033070419902674, 0.059994631973706594, 0.06703372903853339, 0.0691765530446208, 0.06930238873518715, 0.07750662386109455, 0.06601999040024766, 0.07473658400834726, 0.07935237679801033, 0.072251177278086, 0.06008406898140656, 0.07866751509431016, 0.07754543140075065, 0.06866756616985267, 0.0682364609790256, 0.0769704758690649, 0.079116761343227, 0.06364691913596196, 0.07788985318970316, 0.0659580061983716, 0.06960472929165809, 0.06511269626161896, 0.0760552186338583, 0.06403623491120781, 0.07563244008752736, 0.06019523208049143, 0.07552822278069649, 0.07962179569615609, 0.06578253948771343, 0.06621949562420065, 0.06362260820845515, 0.06900023780090238, 0.07823924649147058, 0.08423268680836413, 0.06315112587290542, 0.08331935071887199, 0.0617085155816821, 0.07964693748672201, 0.08124127595736327, 0.06431216924428626, 0.0788188988010301, 0.06666881248191273, 0.06817884771806598, 0.07618733973529876, 0.06867290642582977, 0.07471359288365728, 0.0651529502986719, 0.07823197516796017, 0.08084599942551345, 0.06308271080937687, 0.0695072547493836, 0.0724329731610713, 0.06877047564465524, 0.07879802368475218, 0.07330366373415254, 0.07354341771232958, 0.06887160772466384, 0.07791127545434659, 0.07401957730450066, 0.08137454101108123, 0.07408278670374316, 0.0807069367061513, 0.07946279300889474, 0.06440276972768487, 0.08023581657453313, 0.061693002132957926, 0.07876300505205228, 0.07863110068132474, 0.05735761925280753, 0.07827538997276755, 0.06992828001831022, 0.08023982743490554, 0.08021814583615106, 0.06220534226619026, 0.06497411804136961, 0.06159924847444957, 0.056605788693895265, 0.07830568428125964, 0.06784567006310212, 0.07640186267650109, 0.07972134666951003, 0.07923839021469588, 0.06573008058686293, 0.07006106817575922, 0.07941312873969546, 0.06623341655821914, 0.0626706107781699, 0.06454653855982374, 0.06281748087497938, 0.06948024540054962, 0.06968475222841711, 0.07925973329958913, 0.06871829982011986, 0.06358520963290128, 0.08028460537885938, 0.07934104286849031, 0.08021581162797276, 0.07864373729638977, 0.0835067592739263, 0.07889933408622113, 0.06572943262975117, 0.08285767641469965, 0.0688966806457871, 0.0544950300970768, 0.07992085262329755, 0.07541168489589653, 0.07786936245844195, 0.062358322696886334, 0.06568147824914264, 0.07216861351218659, 0.0628078174343146, 0.06828780102313617, 0.079403480067395, 0.06552438940638894, 0.06590928205748672, 0.07547158175171376, 0.07472919211021332, 0.06706007789363047, 0.0796535970767256, 0.0629005119575132, 0.0804073356753451, 0.05427696181838916, 0.08484870869300738, 0.07431344483602177, 0.06822728522164404, 0.06204636616000797, 0.08249687497256979, 0.08030798057815527, 0.06585818002173095, 0.06704453454062897, 0.07333813730492074, 0.06500756932156507, 0.0792249697474814, 0.06640661799507075, 0.07953768004569138, 0.07280810911045994, 0.07028876794740037, 0.06517839456648467, 0.07662698938441675, 0.06542017316657682, 0.06696500394285605, 0.08038559709309623, 0.07883129140160754, 0.0811384665138972, 0.06147763167549142, 0.07008958591346316, 0.07903942826660042, 0.07778294059274951, 0.06296873310902482, 0.06745621466611132, 0.0748668464346263, 0.0862412233228745, 0.07923692682708408, 0.07736480044250452, 0.0611178895121295, 0.08391563599538844, 0.0710387594080623, 0.06923258585547018, 0.07861425605586475, 0.07793307745077739, 0.07789901019773694, 0.07807413874085868, 0.08120471198996855, 0.07926498338752422, 0.08325343812484344, 0.07848640147243223, 0.08619908540930157, 0.06592723058936784, 0.07787312578567772, 0.07139551967882542, 0.0649955616279171, 0.08080155206238583, 0.08027917663723488, 0.08135345036432742, 0.07895882666432544, 0.07988418921605797, 0.07770700856837562, 0.0796893716378032, 0.07966028016094283, 0.06684931685029456, 0.07708807600591437, 0.077163501549265, 0.0808173648084997, 0.07966435902801161, 0.07089940127723691, 0.06717199242914065, 0.06384203552349675, 0.057305748803466006, 0.06781037428527596, 0.08052747805136162, 0.08032509580236856, 0.08056003255716934, 0.0714403109673629, 0.061449103795550304, 0.07906231774407649, 0.07902377563179033, 0.08057881087955826, 0.07069138686712616, 0.07846329884632439, 0.06227281292156906, 0.0691713459382039, 0.06940663832457727, 0.06865208358353693, 0.07125212338416109, 0.06428379215545078, 0.08035387558232578, 0.0796528429060963, 0.04971836909560971, 0.07814491909826109, 0.08071325823837289, 0.07288148254473105, 0.07977714382607815, 0.0743083582351298, 0.06541393942902256, 0.0668635603760156, 0.05866842695106405, 0.08164181957601767, 0.06301539339986358, 0.07911065813862535, 0.06561039256143633, 0.07322437019941241, 0.07897177841637006, 0.06509579772039162, 0.07848382499081187, 0.05730099652535984, 0.07254973379940799, 0.07287220189263906, 0.07709073865427878, 0.0725084989514521, 0.06919404147147264, 0.07656111464649792, 0.07090758988168445, 0.06598936022013493, 0.06307116185269546, 0.07495521317511974, 0.07890787170036603, 0.07608572416432907, 0.07256440175580238, 0.06829443229795383, 0.06903428820857332, 0.06749303686317877, 0.08020929581245438, 0.0799916602772496, 0.08768373087981142, 0.06535375859145053, 0.0701621211327001, 0.07997588641951259, 0.06569654908537978, 0.059120075287744524, 0.06661916083857075, 0.058899047584669, 0.06838433818171182, 0.07923076314758841, 0.08193433194764711, 0.06455441001865399, 0.05764085003642439, 0.07767266741081963, 0.07126951967010675, 0.07351991086933578, 0.07874287048211653, 0.0750971916706948, 0.06767835512116947, 0.08158199067453092, 0.06416045923697729, 0.07412337939568898, 0.07888329537559786, 0.07249582722641855, 0.07277677193428443, 0.05743529634897143, 0.08087224855239884, 0.07891748965622306, 0.08110719294438525, 0.07832410320209691, 0.06479060557537263, 0.08178114861089948, 0.0785969518378751, 0.05650944769869005, 0.06473428452477556, 0.07877564202745499, 0.0576138415802511, 0.0771425426633096, 0.07361571953321151, 0.08073488118358894, 0.07892577383469027, 0.07664903143291482, 0.0626753490123068, 0.0784138724946829, 0.07991695669419786, 0.07042854626608358, 0.06259007724182096, 0.0674582432379071, 0.06519413784734918, 0.07958381107385297, 0.0756395352367044, 0.07869005343101874, 0.07084090166469346, 0.07660430493934234, 0.07827599975660293, 0.07867491806977968, 0.07117634459117281, 0.0783034289588848, 0.06635659545970099, 0.07032733271452751, 0.06340410363816584, 0.07880241248460226, 0.06276912867957345, 0.0779198116182313, 0.08298413349277917, 0.06412164492872521, 0.0793447157086928, 0.08045907039950746, 0.0746781277296218, 0.08354235499935309, 0.06636435872006369, 0.07836258671705715, 0.061875751751725924, 0.07712183097266428, 0.06527057315308134, 0.08226939617951125, 0.05880324018850697, 0.07627575209631693, 0.06125949228571107, 0.05907050401424199, 0.05514785748429779, 0.07934873135731511, 0.08015721172673342, 0.06754034814743101, 0.06564783961363434, 0.07967413168875917, 0.07297066316043009, 0.07637803420316257, 0.08367195652790198, 0.07933944953721371, 0.06751741501531894, 0.06415349316104131, 0.07882675960910321, 0.06601212992932928, 0.06411932774339882, 0.06970128314353709, 0.06987488815871123, 0.07969631611092098, 0.07792964267555673, 0.0647732621419869, 0.06769240408304873, 0.07717232495305455, 0.08120300157904184, 0.06812268523772198, 0.08328928883530352, 0.062359082805168664, 0.07618952052164685, 0.0821862339032537, 0.07951629150328908, 0.07216939721639046, 0.08107029446512859, 0.08027513525032867, 0.08140971732268594, 0.07243181200754578, 0.07641160475991408, 0.06998324592351964, 0.07625495565177938, 0.07786088503342153, 0.06887891922960682, 0.06862074376418167, 0.06321036980015278, 0.0806366063930835, 0.06558923611398854, 0.0658067917767841, 0.07140459761422903, 0.06542001517305696, 0.06361269728192771, 0.06618345158791479, 0.08375858601179881, 0.06957850057172182, 0.06530477282415369, 0.06821896721474721, 0.08133520933502006, 0.08009354650457946, 0.07488475586053031, 0.06303147980007143, 0.06745577796597385, 0.07760639331740783, 0.06848704480488572, 0.0756722377825677, 0.07868748241246656, 0.07977199745192712, 0.06587228031172904, 0.06280308874416372, 0.06033311805555811, 0.062035761089710706, 0.0785541990515399, 0.06871020366043662, 0.07518409877204286, 0.06478198607005578, 0.08254386683905422, 0.07010478920732123, 0.0767174511236676, 0.08127478329983684, 0.061339350769123745, 0.08131539731318552, 0.06828338055443653, 0.06254538422698175, 0.07861277405151386, 0.08004562985095023, 0.06761346759631864, 0.06514392735607233, 0.08176917345042169, 0.0642828318545098, 0.08176204628832111, 0.0779507498420111, 0.06605958921011229, 0.06651287963733848, 0.07709690018285578, 0.07770898527163841, 0.0792884308744428, 0.07813431848434002, 0.07753899402971508, 0.055854447477830756, 0.07967151092542331, 0.07444637624362924, 0.08014574772712477, 0.07855138996394294, 0.0819008205509271, 0.07777339339392775, 0.06498015154233179, 0.07878398406566937, 0.061388469723509795, 0.06372392844894795, 0.07775195294861904, 0.07957648571652316, 0.06044939904851631, 0.06463630003890652, 0.06758656400850087, 0.05831121251702236, 0.07358943536291564, 0.07158118296713854, 0.07790384716595629, 0.0675891080966086, 0.07790495802629199, 0.07917594608469532, 0.07772744441422609, 0.07627827289159206, 0.06551621990015848, 0.07726004149058323, 0.06284815192425416, 0.06892716588644904, 0.06012995135447925, 0.08369020892223493, 0.07933961820361955, 0.08157418987879457, 0.07848260307441293, 0.06487014996095272, 0.06631132160057922, 0.06305016400647814, 0.07794337197144874, 0.07046367492276194, 0.0808975627637639, 0.07507969035568617, 0.07987938064307888, 0.07819958670164597, 0.0737692239793255, 0.08026495495834339, 0.06601414164812094, 0.07885071992486176, 0.08018041462843667, 0.07693076168339759, 0.06482027497282919, 0.06847074331278859, 0.0638201901996801, 0.06688086499003773, 0.0769728061367233, 0.06920354655478407, 0.08008437870379995, 0.06324515797103847, 0.07550434079800723, 0.06472454423348492, 0.0794925592673979, 0.06653790903965125, 0.07996025483830049, 0.07908391219484874, 0.07843177650288813, 0.08395494535081248, 0.07944613083219343, 0.080087232178496, 0.07906040265130848, 0.07123381349834439, 0.07220204224621513, 0.08032725001947252, 0.06967560391145035, 0.06908531109550714, 0.05692891577630191, 0.07944841005628404, 0.07710940788667695, 0.07223560563653264, 0.07895720186290542, 0.06678102085742356, 0.07919911637660194, 0.06323533609491519, 0.08039987467824726, 0.0799099696195671, 0.06949919074046941, 0.07447112707163013, 0.07794301942618898, 0.0804568579079011, 0.08149989700270642, 0.07794299513662639, 0.06522801495413545, 0.08016030892870019, 0.06880808511578315, 0.07466461385112502, 0.06265623752063468, 0.07950960149313434, 0.07857450545640779, 0.08078436464398259, 0.0783822305138066, 0.0758236632540983, 0.06653910072056457, 0.07121181941785112, 0.08059942586314328, 0.07831864350753254, 0.0774211341278484, 0.0784192823242733, 0.062246634262730874, 0.07831467267965038, 0.07986694271910104, 0.07903978771010095, 0.07021033521398307, 0.06676567479437545, 0.07964288367586117, 0.06312915352205349, 0.06723577630520404, 0.0622081770283649, 0.064562684957263, 0.06590453474741277, 0.08107314264918539, 0.06835292874804666, 0.07966038369649366, 0.05282664692941315, 0.07703897173562566, 0.06038671920901132, 0.06754493005747277, 0.08246679354902949, 0.07848538069804323, 0.08392393353475926, 0.07242887772332796, 0.06825172341543725, 0.07753117879992778, 0.07797571036760258, 0.0613181734996527, 0.06000330146045875, 0.06756574423350868, 0.07662025793024192, 0.0756518554906283, 0.07136981967278548, 0.08420640651310125, 0.08009186052152517, 0.07367671323814652, 0.07880059830785394, 0.06183193912219015, 0.0617395046967861, 0.06492504384279561, 0.07967423815010538, 0.07872552018013733, 0.07841927964010245, 0.05980362432389056, 0.06530594741584672, 0.06286691511451935, 0.06045211525906307, 0.07964934580749884, 0.08006165381682666, 0.07941379513534196, 0.06686505245079648, 0.07946478225586699, 0.07811657457175922, 0.06957488128972368, 0.07871194762354292, 0.07808446930988056, 0.08153365561597319, 0.07865361498460294, 0.06059852499895734, 0.06573633543144672, 0.06447058821657795, 0.07742995529310213, 0.06756949480018279, 0.08068726747264328, 0.06571181960686977, 0.07480282862813321, 0.0696713281177517, 0.06880791048507305, 0.06276942109005036, 0.07958361779844338, 0.08007454496617734, 0.06744217038522994, 0.08513101510621776, 0.08085689371890183, 0.0651099819901661, 0.08287554933529293, 0.07630603227735107, 0.0701998115036415, 0.07502530184414963, 0.08084364960774329, 0.06884904722162122, 0.07660238983200474, 0.05705206463456612, 0.07935984933619458, 0.07582858637481166, 0.08388623697704442, 0.05812476605058241, 0.06638237365548263, 0.081289286208202, 0.062257051086930054, 0.06760743033386626, 0.07811643021698297, 0.07196517201655601, 0.0689181229309982, 0.06401576504226096, 0.08106229335638904, 0.08245142448818835, 0.07898450341440803, 0.07739827687393197, 0.06796311469147977, 0.07859123604826657, 0.06686360981979057, 0.0756486743208757, 0.06602798713251813, 0.07914137647959774, 0.07500522086622154, 0.0725248848890058, 0.06925023483341154, 0.06863719592569192, 0.08078348261896239, 0.08042530285320736, 0.06044833457022363, 0.06965780335397818, 0.08023899157639842, 0.08050673208731643, 0.07680992638251179, 0.0637612423904735, 0.07990490000383, 0.06707634928390518, 0.07378208046947692, 0.06587037423932042, 0.0789407315120294, 0.07880394192598804, 0.06646796597991722, 0.0746857142644504, 0.07837060723395767, 0.0793743921982222, 0.07804188192420344, 0.0646030779786241, 0.06723831134794969, 0.07473044498307227, 0.06251628253740182, 0.07501594742967194, 0.06781579825049686, 0.07850961370356595, 0.08164616648217056, 0.08028507166216832, 0.07588599507086628, 0.0685091543227947, 0.07494316738355437, 0.06372860869640307, 0.08364135667162721, 0.06783617177665477, 0.07982720330457267, 0.05973905930626804, 0.06751464993631254, 0.0787674712163446, 0.07676972634038948, 0.08109019218044325, 0.06841224472655663, 0.06692378784152786, 0.07941167314738627, 0.07093799187860719, 0.05887392202748765, 0.05606008957625624, 0.08275935720389728, 0.07093130753942056, 0.07461797593790426, 0.0661805086339734, 0.0762744421371945, 0.07963441180235639, 0.06925432963292016, 0.08027042039008918, 0.060549015406789884, 0.07642701950203833, 0.0836719835593813, 0.06723630882325486, 0.08317576103067395, 0.06337383557308736, 0.08121959059441873, 0.07817745824999894, 0.06088301093708645, 0.07900069057130225, 0.07777847102290462, 0.07857665936937494, 0.06287180794139133, 0.0694211351854554, 0.07927196349349969, 0.06814412025108546, 0.06959386301200773, 0.06291194708568625, 0.07718255236037523, 0.08195748531666128, 0.0789330770941861, 0.07037165050834471, 0.0584180744880529, 0.07969994773480389, 0.0819567668140764, 0.07232186491850433, 0.07982475523324174, 0.06226723156211127, 0.06367185597974803, 0.08240420881930959, 0.07357682767250634, 0.06654270002225977, 0.06144239119721985, 0.06592144238280989, 0.07265337356630874, 0.06634871115056418, 0.07475507984996121, 0.07408237471118809, 0.06262484068106924, 0.07419930074989073, 0.07797106526112153, 0.07971560251267817, 0.06176239756874804, 0.05835533162968216, 0.07196897801964841, 0.06355468207730292, 0.06514855693471829, 0.08104121096930392, 0.06579272260007724, 0.06402103976948134, 0.0756469829724328, 0.08276982303336916, 0.06196115731888546, 0.06545676887063576, 0.07639481666139947, 0.06433837693947077, 0.06740074427239504, 0.0775391743367784, 0.07651484821839091, 0.07502842464976328, 0.06083449293032925, 0.061144272376295834, 0.06900145845626812, 0.05928375853094579, 0.055455852123771, 0.06413829576666799, 0.07963888846151165, 0.08229272971531747, 0.0794498964827889, 0.05714104543419868, 0.06771092653533949, 0.07186050153368759, 0.07023639427979864, 0.07670513341810675, 0.07135643134212073, 0.07922165257947922, 0.0793408835315062, 0.06862596788757355, 0.07919975935648249, 0.06412167871398211, 0.06697573920972776, 0.06949935357123666, 0.0665495748277335, 0.0762149730689178, 0.08109929043802745, 0.06220150797742404, 0.06726156240559693, 0.0767152039684242, 0.0640682939644028, 0.07430509772197888, 0.07209076181360081, 0.0797009180677662, 0.06089293695702305, 0.07822870319081916, 0.06820465889831216, 0.06426641552651911, 0.06393252437379976, 0.07845417285689414, 0.06495401366882049, 0.07829963946851176, 0.08126235303849423, 0.07976822467706451, 0.06485175009336092, 0.0681629477795269, 0.06337463411433306, 0.06468153628762877, 0.0639863780056435, 0.06349442702545126, 0.08014872413320404, 0.06642124218428236, 0.07971311271984552, 0.07948986392127838, 0.06670935698826426, 0.06644450092406395, 0.0706455878082917, 0.0572033783802255, 0.07544217072595263, 0.06735954636439064, 0.08157392868365784, 0.062367028805161984, 0.07425016602503914, 0.07984912644866017, 0.06655419851887169, 0.0800763262084916, 0.0770999309730906, 0.08428609189206736, 0.07617852480069139, 0.07055369567358816, 0.08002381569366869, 0.0708959641162498, 0.06927535278738756, 0.06697403392983597, 0.07961335731895233, 0.06892173305252387, 0.07939411523283862, 0.06341081408266117, 0.06901858814596892, 0.06348431810568057, 0.07993856124740355, 0.07909618072631712, 0.08469891323448231, 0.06777393539650688, 0.0725087964000442, 0.061048489089999484, 0.06447739640906781, 0.07202428895757582, 0.07912545643946713, 0.07997224027762886, 0.07933959728480935, 0.08028199093018024, 0.08192311411707026, 0.07858883048297857, 0.0779395434936377, 0.06414028457170917, 0.06064849088642351, 0.07648658128871053, 0.07281049664672858, 0.07570395288135198, 0.07684746006623626, 0.0781282265975702, 0.06924079978735333, 0.06887310613662706, 0.06663674807309401, 0.06907406505667964, 0.06328111608942903, 0.07880653613549277, 0.0638577060559014, 0.06493989033225311, 0.07019669394334434, 0.07692691827796308, 0.07710005663180484, 0.06848505463119642, 0.06395244617657503, 0.080802329194429, 0.07180008996122292, 0.06714901381953117, 0.0796494133501625, 0.07578822146760783, 0.08143764449037504, 0.06746495637750913, 0.08087201740001485, 0.057323687471129585, 0.07998596275702112, 0.07068349771231949, 0.06584108553136683, 0.06160560812393712, 0.07825679603022147, 0.08238907361990815, 0.05645922620401425, 0.07754331954564082, 0.08033469598670441, 0.06612282690953493, 0.07564380594160842, 0.08099079652350483, 0.07770003738305087, 0.07237152171661214, 0.07000146569929078, 0.06586071019987014, 0.07136546133728082, 0.06381091859995006, 0.07598390726914862, 0.08063214938426957, 0.07934822905743079, 0.06562742803686843, 0.06484652114442918, 0.08070409017127701, 0.06638039195415928, 0.05832365470740384, 0.06217520381645984, 0.05561084601911025, 0.07747909739866432, 0.08106659434341999, 0.07499601232549477, 0.06822521712519114, 0.08017052572788835, 0.07839731248371667, 0.0760610424831193, 0.07899594423810728, 0.061683912507764734, 0.06304883412442266, 0.06507889619788307, 0.0797177559475029, 0.08196268556832234, 0.06358762947253586, 0.08118535168836948, 0.06892745674787033, 0.07922628250476588, 0.06720154541257212, 0.07877324402208276, 0.06724863149511262, 0.07732695196641047, 0.07986147129405226, 0.08063686688782111, 0.06760175433204421, 0.06898754024115436, 0.06587139833038286, 0.06535937476943422, 0.07276909271401029, 0.0834844671983811, 0.08069132102526848, 0.07417943374359022, 0.0699663317864639, 0.08189583630628215, 0.07282319604487478, 0.07975112478621817, 0.0777107410826512, 0.0788651299698171, 0.06247735654976861, 0.06748867729543957, 0.07808230883187656, 0.07865180985460844, 0.08079455655292893, 0.08032779423955741, 0.07452164981275226, 0.07930975479847653, 0.08180451057625457, 0.06712657322963471, 0.07223189391378548, 0.06468685175486076, 0.06276429245289024, 0.08171717586359517, 0.06539113241509141, 0.06767636149357066, 0.07995613335570094, 0.077709511268479, 0.08319974727315173, 0.07152993191371092, 0.07403090076711302, 0.07908827457711134, 0.07996667617515253, 0.06908008370671674, 0.06101916223789818, 0.06468688876175831, 0.07849779224654656, 0.08002793033390912, 0.08032105326905764, 0.07224095673863834, 0.07749490363638825, 0.07937326500894713, 0.07358861320607946, 0.06504703637891246, 0.0696426594777547, 0.06793003701180864, 0.08056356217013931, 0.0693267760064847, 0.07772549022059035, 0.06289437831435911, 0.059406556968925335, 0.06565754661975144, 0.07722100514509704, 0.08167492686279902, 0.05890053992063572, 0.0526579405936798, 0.08304993087838458, 0.08078632504387967, 0.08028409115986382, 0.060829904477969265, 0.06949664108028633, 0.06757895871201271, 0.0740161337008215, 0.06720154184492524, 0.0638473227850292, 0.07098701578827049, 0.07499331073866637, 0.07083680090071097, 0.0779352977591262, 0.06173130844520819, 0.08026372664644979, 0.07110685019911898, 0.06700566088048755, 0.08318656628128136, 0.06086798537901259, 0.06965750990379631, 0.06133086112674462, 0.056482161049626514, 0.07410333211817122, 0.07949033270521522, 0.05783263903551395, 0.07711166780068482, 0.08088647964709084, 0.07072644640268262, 0.08197864158564387, 0.05769967961683859, 0.06859976506390053, 0.06697094696297488, 0.07769427585148977, 0.07921150428932788, 0.08041846892096355, 0.06895075196793746, 0.0693291381058949, 0.06722516243252315, 0.07484524673226968, 0.07140358988053105, 0.05456314568147461, 0.08076974561826236, 0.07693742728515097, 0.08006192671460213, 0.0688376951547474, 0.06512521560653826, 0.08203976254146453, 0.06384070641699113, 0.06068390878489387, 0.07222296570150395, 0.07867782399512473, 0.07966552566015325, 0.07597378158186475, 0.0784946730930711, 0.07924835471074225, 0.07923770356245514, 0.06867513939636141, 0.07561658763491445, 0.07188020594771961, 0.08037034226623095, 0.08318926530046498, 0.07851555867808291, 0.0771185336624089, 0.057889036114300386, 0.06283143631026024, 0.0731938515795858, 0.07537571992885936, 0.07892700140583037, 0.08034475984756503, 0.08025078503486814, 0.06895678687128334, 0.07916593076720158, 0.07936837200874108, 0.0747873576222848, 0.07112627941065122, 0.06768884251674265, 0.08001434609603378, 0.07385464696472012, 0.06643289144158225, 0.06651390626958718, 0.06793008802723866, 0.06885466114727908, 0.06945286575599123, 0.057593663765371894, 0.06539406678852377, 0.08108439224080242, 0.07885929835121466, 0.07107252322581088, 0.08034859075076448, 0.07143565912088104, 0.08032664638476406, 0.07666322184021478, 0.0677471233337441, 0.07657478834650124, 0.06706747033482169, 0.07780380621978457, 0.0771206343500585, 0.06898589883728244, 0.06360396054668575, 0.06703778289626604, 0.06315189796894903, 0.07943504567532421, 0.0744327805808521, 0.06721283088515376, 0.06316839866488819, 0.08025181080454764, 0.07936119981431423, 0.07072852130925429, 0.05483354334757136, 0.06678008847814897, 0.062176252393797524, 0.05443126096846487, 0.08013906334483654, 0.08474185259826357, 0.07828034185248162, 0.07076151174705782, 0.07938675231979904, 0.08551078229905204, 0.0541998654272864, 0.07809492208283285, 0.05767230913439821, 0.07000787153220542, 0.06981553858250762, 0.06755753400679859, 0.07713585467551505, 0.07170814277285424, 0.0633891558163239, 0.08034627736809262, 0.06463586065985326, 0.08096714396680899, 0.07936476724843192, 0.06471379462158292, 0.07096543632750331, 0.06049199774091778, 0.06392694623745958, 0.06636799597498987, 0.07361122127666918, 0.0670322725036633, 0.08008944557499119, 0.07201124600771751, 0.0798496687765986, 0.0781150944173112, 0.07934805878358113, 0.05572663424270683, 0.06349475404483867, 0.0805313015190955, 0.07720967655304242, 0.05785381938856257, 0.06797426587073324, 0.06272517085519629, 0.07098627130450488, 0.08078779592353053, 0.06860662904860103, 0.07199364383164976, 0.08057274106416963, 0.07772555774135102, 0.06815458609017123, 0.06486757531290585, 0.07809600819333395, 0.07826098437057259, 0.0813961505857398, 0.06656626281807417, 0.06731791411347353, 0.05474389305646812, 0.06324238677626234, 0.06607404985944088, 0.07942462620364024, 0.07211186829151386, 0.0809006737516174, 0.08296959574239808, 0.07945471480126769, 0.07814706123022508, 0.08224430933344906, 0.06337371405341985, 0.061536158127708025, 0.08280340359731092, 0.08051770728847744, 0.06693264094070621, 0.06722586243816846, 0.0687269405193978, 0.07774125956486445, 0.07980437777219647, 0.08009057788917852, 0.07446013406772885, 0.06806308937750026, 0.06771169900494756, 0.08356085178940824, 0.06873475469349113, 0.07980763202573396, 0.0783077462903137, 0.06990596953197366, 0.06509937655994691, 0.0628111756544187, 0.07901839538447544, 0.06236322137803798, 0.07357515335945312, 0.0817970514194262, 0.06478081942850064, 0.08412443382079188, 0.06589794989577659, 0.08204597734488785, 0.07629852654170784, 0.07218795847066248, 0.0810740113750098, 0.07942644464959991, 0.08098389254811, 0.06806217357698219, 0.077791824541427, 0.06611412017921359, 0.05592573912702409, 0.06045310977696536, 0.069000583686998, 0.07964707962796574, 0.07941013716367955, 0.07856793257183052, 0.08027834255628719, 0.06871568946133483, 0.07473002153582743, 0.07056306486397561, 0.0778120455156381, 0.07979983313300253, 0.08019586064711656, 0.06896356889318922, 0.0655102286311201, 0.07317493767353427, 0.07256459751795744, 0.07899607536782004, 0.07842414630222827, 0.06498846909302242, 0.07738071618958858, 0.08315143652514903, 0.08013926930724123, 0.07914817250216225, 0.07829207992358382, 0.07811061097961812, 0.0792852507460838, 0.061978212427128775, 0.06753978617335768, 0.060767318851689886, 0.06222030875466411, 0.060001085861256465, 0.08083015628883125, 0.07441289863510422, 0.06205460404231507, 0.08025111292164114, 0.0581872605333797, 0.0784879782264347, 0.06735497771605371, 0.07294589011729148, 0.06759318323873534, 0.06451436710012541, 0.0643429145727777, 0.07875755871173631, 0.07655118958772146, 0.07751302534342626, 0.06687184958659449, 0.0775699915362864, 0.07903637928058953, 0.06359582308883, 0.06494212575053677, 0.07107988832110672, 0.06274046431164242, 0.0769997281982588, 0.07454504411628365, 0.06320129092706452, 0.08013422943662223, 0.0733620185531544, 0.08015808276068388, 0.06137622028685098, 0.08043109094393087, 0.07843834973913584, 0.07845843926805564, 0.06462607620127307, 0.07960354883721267, 0.07835473986205524, 0.06556793677263441, 0.06805819237930968, 0.06909700821650991, 0.07377761780411705, 0.06262649797314873, 0.0685991372893801, 0.06459043792442903, 0.0657173937826736, 0.06345491892135707, 0.07840266580176551, 0.08239727177735436, 0.07130434569149213, 0.07474751374832952, 0.07114523996150462, 0.06988122453726155, 0.07334301298959967, 0.07996482323201347, 0.05674422927179917, 0.07496973953783359, 0.08180734239671364, 0.07935095950211281, 0.07107813444800472, 0.08573191310198038, 0.07730263941998561, 0.07806376667949019, 0.0801383393689869, 0.07532187050332048, 0.07310225611996872, 0.06465074434933123, 0.0815801119248913, 0.07719024706983463, 0.07858022313373843, 0.06320905992163871, 0.07902713766822902, 0.07221621306638147, 0.06348314174017909, 0.07847019530126785, 0.07784071860107655, 0.06795410076041974, 0.07746897215206984, 0.0789009456484102, 0.0772178233456836, 0.06442359097737727, 0.07031941488172941, 0.06164723479568574, 0.060060695584805174, 0.07054650998413842, 0.0649277001458602, 0.07495293680183843, 0.07326238060617471, 0.06237994035695365, 0.08014177221170131, 0.07054945883228982, 0.06269572437689187, 0.07594022221177846, 0.07994469707270294, 0.08297741081451927, 0.07589015719995204, 0.07083361968249272, 0.0790305733333086, 0.060462915736987435, 0.06886667186997704, 0.07974044380214936, 0.07419630970092417, 0.07390601779892332, 0.06152101569461576, 0.060936053177248324, 0.08299222419566202, 0.08050297499160378, 0.07868440762247934, 0.07586497084941235, 0.06410558122419957, 0.08499487694923413, 0.06315383587434306, 0.061479971177097914, 0.06824323251073797, 0.07601910376257653, 0.06401173270336799, 0.06448810506639835, 0.08149513428851049, 0.05986093396261545, 0.08126359399908434, 0.07723536007528814, 0.06993337477666085, 0.06811698279113387, 0.07105167344003423, 0.05881689531017782, 0.07780692083474076, 0.06003328286257318, 0.07956271047965073, 0.0731736250410677, 0.079386607888716, 0.07697999754265092, 0.0703333467828303, 0.07250990960848198, 0.07813286171445602, 0.07698288137550398, 0.07932318083303552, 0.07864130837732178, 0.07131203422437536, 0.07704951816635867, 0.07206222580640724, 0.06758491703770153, 0.07383169961114054, 0.07816575280167587, 0.06421725622348576, 0.07503476760890847, 0.07845396408732319, 0.07008359254404392, 0.06726433593724604, 0.06623410736605757, 0.07631436423090711, 0.06501297742945202, 0.07998183598843173, 0.07497017649606126, 0.060652106348749096, 0.06302818991114885, 0.07731066896462108, 0.08071550214720227, 0.07462717890890651, 0.08004206189624508, 0.08183194257436957, 0.0694744939046458, 0.07996924123100997, 0.06308796995394013, 0.07193863148684447, 0.06789471533338831, 0.07821757355948332, 0.08077261906661387, 0.06587893135218592, 0.07933013364573074, 0.06670026996956314, 0.07754304066701885, 0.0782319040982425, 0.07838038149278712, 0.07417024186132828, 0.08007919782086073, 0.08066721549047294, 0.07443694543705386, 0.06074433054451662, 0.06891167585432577, 0.07580207667276778, 0.07794190918461721, 0.06207332133782298, 0.0647177107366045, 0.08550104675044638, 0.06755455915111953, 0.07928569873342031, 0.06308312267401808, 0.08319725225851551, 0.0762278056365393, 0.08134114381019016, 0.07823006104584075, 0.06486241465171241, 0.07711925223797854, 0.05960175704649916, 0.07248498177725873, 0.07997223996275746, 0.07894083359637034, 0.07134308677675018, 0.06407297246865065, 0.06667930401674653, 0.07786022597573217, 0.08201666023240176, 0.07950160947827715, 0.06149758243963545, 0.07287231114120156, 0.07964893316994043, 0.07696654350834263, 0.07947020593206913, 0.08043194928990653, 0.06289321151439622, 0.06314256863375071, 0.06214081041099875, 0.0789815243350327, 0.07850839657243676, 0.06679420944306108, 0.06222506342207817, 0.08151549823721026, 0.06800020483241596, 0.07600631976097384, 0.08001344738717438, 0.08033749325734864, 0.0846933461734336, 0.07916874935502415, 0.06610574405257831, 0.06856446967807214, 0.07162423548165779, 0.06800984360210038, 0.07818764017581742, 0.0651378796310667, 0.06434662267874397, 0.06940963250422294, 0.07959270411395329, 0.05627689918039372, 0.07596127136913917, 0.059672148065200305, 0.059562422573603196, 0.060746955850731414, 0.08271935596692966, 0.06573252498190466, 0.07668530313376294, 0.08418168633096403, 0.06848186959979274, 0.06932690630345109, 0.08467369358043293, 0.059433837964064706, 0.08180072969160257, 0.07884297726682007, 0.06612673624232376, 0.06662759336409528, 0.07840555880491669, 0.08135044340995072, 0.07160013109325407, 0.08299860791613246, 0.06858736108213591, 0.06371405008132945, 0.06892470881735578, 0.07253228915484704, 0.08088189230717471, 0.08182395447775745, 0.07955039008026789, 0.05561720265932652, 0.0656472614619377, 0.07971259576751748, 0.07565688251893073, 0.06606440840199827, 0.08088807401781736, 0.08004878958705135, 0.05969072068239989, 0.06257759783242932, 0.08411846948760347, 0.0685753550514754, 0.07417551269149364, 0.06713546409574087, 0.06500233507095932, 0.06238287310397402, 0.054831112718778434, 0.08000480776041984, 0.05887801524435755, 0.06858182838741235, 0.07387499729578172, 0.07890250314000119, 0.07527030676169667, 0.07399539893684988, 0.08238182975736162, 0.06852201663546363, 0.08191570545912596, 0.06694629232888326, 0.0581491472640449, 0.07254095579615086, 0.08370185117710789, 0.057280882828594476, 0.07450999798781047, 0.060017646606099324, 0.08344670210959512, 0.06400448527949264, 0.07577814660957917, 0.0801103582341395, 0.0658913004734924, 0.05727434619119296, 0.0638862189163963, 0.06321701716662269, 0.07905563971377022, 0.07085139875112706, 0.07978792204512879, 0.06981298464190917, 0.07829252238769502, 0.07972691824604733, 0.07943291358461312, 0.07740693760243497, 0.07959060955187897, 0.062334969282786826, 0.07816472712077749, 0.06944512050238058, 0.06397199809160574, 0.07785182873550808, 0.07267312795059071, 0.07605642769173127, 0.06701979726933041, 0.0718776738916108, 0.08076471526448453, 0.07337397613262292, 0.08121771128376377, 0.07995240586309564, 0.08031819882776549, 0.06486850773558668, 0.07018752922352793, 0.07847825083721552, 0.06427879692623466, 0.07503201751450499, 0.07371789394613847, 0.07834409636410697, 0.08094141714153542, 0.06617967147163598, 0.06232607758111782, 0.071867251742295, 0.07927279681093465, 0.06399254402331882, 0.0695795389689521, 0.077760042678818, 0.07487571587114178, 0.06480921970254447, 0.07895161034583269, 0.07702461085056074, 0.0783399966103836, 0.08270646487296462, 0.0788472830449172, 0.06493416629281096, 0.06747553069540947, 0.06561024432395439, 0.07451240171311373, 0.05840211475403716, 0.06842707490598936, 0.06653888868176765, 0.07721359159821019, 0.08125770414120587, 0.08173632021889823, 0.0795026817939237, 0.07901123670112509, 0.0660861046760123, 0.0797571259089121, 0.08142763103933394, 0.06535238225021517, 0.06573176748949332, 0.06955348651469376, 0.0777928163700046, 0.07876302829824869, 0.0609038159059846, 0.06880003542399253, 0.06288075825113167, 0.0678943931927251, 0.07070840413591424, 0.08002663680915842, 0.08255015906131773, 0.06728406735014891, 0.06529363641912102, 0.0725609355347574, 0.08312172613892053, 0.0734387099728003, 0.07775314628476712, 0.062009120241825984, 0.08198170620098282, 0.061874497799067195, 0.07545542074457741, 0.06474778652420987, 0.0823880915081885, 0.06678878467950061, 0.0848154556654208, 0.07807665530550853, 0.07997903962754481, 0.07344272767210641, 0.06200014486994998, 0.07878293802061093, 0.08012641554172145, 0.07785079050828433, 0.06642007934676866, 0.06807695331730407, 0.07913399302460422, 0.07893426480472956, 0.0718290336137438, 0.07936801412304585, 0.06746008796787605, 0.07791445892964478, 0.07926739278435598, 0.07482173943320233, 0.06330393040892175, 0.07063550719303809, 0.07589620854302893, 0.07863144447397183, 0.07045479480314831, 0.08081274340597137, 0.07061755822089572, 0.06191964174670328, 0.06357580583413436, 0.07421715152326235, 0.07036202852999997, 0.0656645615078005, 0.05620632769474105, 0.052876289178011876, 0.0683471590677472, 0.06339905648989483, 0.07953150777585921, 0.07539379609650358, 0.07891563389843691, 0.07772380279983336, 0.06916114125321958, 0.07070672554691437, 0.08320318663720332, 0.08198799514898546, 0.07716794490001855, 0.0808424587841445, 0.07431266284805793, 0.0700253629206076, 0.08411494614742555, 0.08033636932275165, 0.07638325548420334, 0.0733256221219751, 0.06343237763172431, 0.0704110342233061, 0.0642685292532723, 0.07853479726499082, 0.07155608427116822, 0.07845533290087706, 0.07836841393441996, 0.06273680230621195, 0.06183254192782189, 0.07813139423084209, 0.0817059488487829, 0.07794507588695279, 0.05882554700814247, 0.06245139942360906, 0.062265495850591816, 0.06424022675754837, 0.07348598815532444, 0.07803033242768347, 0.07976098925982522, 0.07653716258575385, 0.06846115944478766, 0.07880750477904137, 0.06648293579923736, 0.07119265743257562, 0.06427686573645483, 0.0786531313744219, 0.08102855726199633, 0.0754007173205118, 0.060926501261743066, 0.0694380396828591, 0.06871289687063319, 0.06857855591287167, 0.0785155472428621, 0.07909694112876803, 0.07673654802601808, 0.06094643561787837, 0.06827754407427386, 0.057887774375382055, 0.06465461258442817, 0.0773527986929073, 0.08020693414116761, 0.06669797497254473, 0.073910166041678, 0.06853901726477306, 0.0783786441914994, 0.053708661505694526, 0.08007760452685152, 0.06557096543511269, 0.07010989400904033, 0.06907930555564487, 0.07700290338982682, 0.07719854376446748, 0.06701409971504915, 0.06007395406141473, 0.07519041545963669, 0.07577282750270567, 0.08185202759002154, 0.07087953784051, 0.07999686266193481, 0.06612958777965897, 0.07845700524473982, 0.05715307365945098, 0.08070572406381753, 0.07713470212577432, 0.07828381823404522, 0.06432712183844234, 0.08101296837493961, 0.06626162239948295, 0.0653876498265052, 0.06768360467688918, 0.06941083257745481, 0.05744690593642526, 0.06756822937298058, 0.07952864284478679, 0.08050015883692192, 0.07858036380444164, 0.08348755973783596, 0.06332242558570571, 0.0696158450959271, 0.08035627097514761, 0.06722152818071699, 0.06923828225060785, 0.08025836111354581, 0.06561412501507914, 0.07951019828236977, 0.0793147381391, 0.05943965923947717, 0.08126954495182938, 0.06518283317124607, 0.05207067837223187, 0.0683224792295246, 0.07792739888985996, 0.06768657312888055, 0.07154932111996921, 0.0678643212302866, 0.0794189371514492, 0.08189128419700246, 0.0728749409104333, 0.06903126899303927, 0.07423084564771855, 0.0783655061472262, 0.06704910255354504, 0.07039861861979457, 0.0809015350530772, 0.07806923432214938, 0.06612156283644981, 0.07365049184586356, 0.06254058729973427, 0.06933393413396795, 0.0776993944618752, 0.06583818049995276, 0.07866589837262358, 0.0837635556490957, 0.08106479456112087, 0.06869741015986787, 0.08002880642050617, 0.08160348874213233, 0.06558314465717244, 0.08216941484205302, 0.07201894168348937, 0.07845001269991275, 0.0636427767063607, 0.07927511306648721, 0.08279195728476532, 0.06752879983616794, 0.0692863862494145, 0.08441615297779229, 0.07990230586372978, 0.08004900172363509, 0.06844364453888739, 0.07876944149009597, 0.07583750127278353, 0.06728384422230137, 0.07852035092315829, 0.06477234349491796, 0.06966553302274923, 0.0789302456602216, 0.06862285117394835, 0.06778015672629757, 0.06954240961995065, 0.06080126390088666, 0.070511076812933, 0.07264830692200448, 0.07794346825193668, 0.07943223547358333, 0.07435234831450029, 0.06627944840432033, 0.06626139861241417, 0.07834296607296734, 0.06285553980789406, 0.06405678111205877, 0.07830908430339965, 0.07227329516279431, 0.07209402706796314, 0.07270386765372384, 0.07888301111816873, 0.06621424957944423, 0.08239572534126245, 0.07693376614200302, 0.07180561013415816, 0.06319791824272736, 0.06496978945740517, 0.08361075784137569, 0.06763459815311886, 0.07489032509731491, 0.06739426695654359, 0.07317524707010832, 0.08283514768101459, 0.06548604725610056, 0.08035185036219296, 0.06535403872476268, 0.06100535801390069, 0.06343360054936442, 0.08026489061850327, 0.06576905932082637, 0.06501796244552306, 0.07160162177229268, 0.06727787244834328, 0.07884751478721896, 0.06559188155856362, 0.05539230984559486, 0.05321427046837317, 0.06856782843148086, 0.07783106769692577, 0.07968915522133804, 0.0659576970362391, 0.06930722799749613, 0.058918957203660895, 0.08002685852474527, 0.06607977500269424, 0.07940321225658332, 0.06837523294706005, 0.07167253598380573, 0.06520919049368136, 0.07787145121209, 0.07952828559468492, 0.0723713190882385, 0.07884625031044541, 0.06615352567269202, 0.06898873368747928, 0.06889133250098436, 0.08013295019998495, 0.07993905033160584, 0.07936797068548376, 0.08025108824389258, 0.06558126990603534, 0.0731543608002581, 0.07265050350988685, 0.07130400423251923, 0.07701797437562057, 0.07844744398987219, 0.08044780925374606, 0.07959963757298823, 0.06649366550336577, 0.062420497935936126, 0.06505566897162604, 0.07898443773289532, 0.06672045489402795, 0.08318487847198151, 0.06510264540333699, 0.07806805997104739, 0.06830138553180361, 0.06921841357653377, 0.07854999966670774, 0.07766105697976723, 0.07982700488585784, 0.07044624825737267, 0.06553109219333589, 0.0803030468943512, 0.08239465312717927, 0.08126246864333603, 0.08054725536694186, 0.06698149423422094, 0.06561122501692146, 0.054378298490164845, 0.07908241814157663, 0.059045502076245225, 0.08181197072126949, 0.07814769407904888, 0.08333222121615542, 0.06585714947011077, 0.0779413412248375, 0.08071280391659984, 0.05951345834805998, 0.06666502408614344, 0.07867797695386007, 0.07679456949152487, 0.07660947895350576, 0.07960748910316452, 0.07890088560133798, 0.06314978402832921, 0.08361597714831781, 0.07736426996086966, 0.0583297986149856, 0.07183546986747998, 0.06818117781478114, 0.07700236013659094, 0.06544766436982768, 0.07944207399087802, 0.08055711873350291, 0.083332993896643, 0.07036202344294316, 0.06204693924366857, 0.058908038935339614, 0.07145519040230269, 0.07678423028021002, 0.07091882614751034, 0.07045106504973382, 0.07910439329629292, 0.06217447922285556, 0.079513130158892, 0.08072613367497418, 0.06288956601070068, 0.08048866553173367, 0.061100651922859704, 0.07697371919826157, 0.07390825400824451, 0.06410679474465404, 0.07995677539646949, 0.07947049943475556, 0.07133777470360264, 0.08076848684772168, 0.0754818354388511, 0.06404479633305057, 0.069424302671857, 0.061238845927898605, 0.08359867889677755, 0.05927681340880998, 0.07258633064585733, 0.07956713579108195, 0.08027450544312305, 0.07949140390786093, 0.0779259616341824, 0.0678933097943932, 0.07950419435569389, 0.07908224528513517, 0.07541466768299447, 0.06901794662312474, 0.07997138007131378, 0.06569931049027207, 0.08152822171152016, 0.07616113614862223, 0.0675987371348814, 0.0787696351475573, 0.0625542655794587, 0.07266114743532635, 0.08041785836607875, 0.07903280266584585, 0.06659547737866164, 0.07811143990901835, 0.05902862532819782, 0.07856512689903222, 0.07699829539334602, 0.0830685920670678, 0.06861486251630318, 0.07119683813026187, 0.08042385163563312, 0.07921260723376122, 0.08197662328573604, 0.08001106478744216, 0.07000869538194907, 0.0663452825117225, 0.0670803495763762, 0.06651221112543605, 0.08150266251454066, 0.06641241163714803, 0.05753180998423828, 0.08200400688476411, 0.06114564582163363, 0.07876803978110264, 0.06118512165942317, 0.07908229224977245, 0.06572565542776024, 0.061081877762256986, 0.06645178268694465, 0.0833286560432625, 0.08035734581575098, 0.07553141919853416, 0.06156340733673914, 0.07993286561007208, 0.08013407795925065, 0.06813857160058394, 0.0818013708039929, 0.06304707474861083, 0.08025813172771604, 0.06736397347397904, 0.060450035861544425, 0.08598541549992118, 0.06192705803972405, 0.07916653919972674, 0.06345822432234158, 0.07839077427011754, 0.06368955288258694, 0.062109700444267564, 0.08136478328479331, 0.07779180716870439, 0.07779387170589251, 0.07950389323572077, 0.06640369427347059, 0.06511184838624383, 0.08139634955300852, 0.06327435426834811, 0.07060272764637147, 0.06513283113122896, 0.07595107401774186, 0.05950590637792309, 0.0752011293076335, 0.06398235621098336, 0.0788513927390304, 0.08113923737277608, 0.07677014629752298, 0.07636280793184291, 0.06869915468985524, 0.06693826108395536, 0.06752252551974164, 0.06655706846046845, 0.07117676633966195, 0.06916824106872461, 0.07121426213480159, 0.06367449944919554, 0.0695937856208094, 0.07263827409388579, 0.06599446475472066, 0.06896052626529785, 0.07844448039372755, 0.0699266202387754, 0.06727755431076805, 0.07982144157306506, 0.06650552930983396, 0.07764438574308022, 0.07797280182630065, 0.064528355156099, 0.08294676624591098, 0.06588528280832946, 0.06027562120557112, 0.06315408762977788, 0.061249703020150946, 0.07958376612192401, 0.08017428204335474, 0.07629546417770666, 0.07831082224158685, 0.06687126681852461, 0.07031250734731462, 0.07002122291428477, 0.07864985534974614, 0.0747778530220726, 0.06410064366950655, 0.06678878989965675, 0.08150895328825174, 0.07848351157794012, 0.07336729125393227, 0.07416299550602345, 0.08156973802249176, 0.07384874297958488, 0.06168148887574118, 0.063679978986392, 0.08407039489760953, 0.05922441587299995, 0.07851482192248552, 0.06427926082657649, 0.06094445406418213, 0.06909960898166954, 0.07085438866167887, 0.07736315420678999, 0.07735730822428497, 0.08017353903034263, 0.07239314095143033, 0.07965632738451375, 0.06660599258513888, 0.06924404557577447, 0.08262088317117874, 0.07167831811309126, 0.06525377073272888, 0.06933467668209403, 0.061980445221648486, 0.08005048042499076, 0.0628764707409714, 0.0786170576007133, 0.07934003600524014, 0.07770475731984246, 0.05548922629394532, 0.07651867888176514, 0.06688902734425699, 0.06706931541476482, 0.06738405143263775, 0.05900450805046655, 0.055138403043197594, 0.07124697651080049, 0.07660401559466636, 0.07729012525092366, 0.07916731630994245, 0.06452446386265578, 0.06419611437477647, 0.06748251410466673, 0.07123357915356697, 0.08091750741471379, 0.05756865045135567, 0.0640024378619139, 0.07563551349750956, 0.0707954597050895, 0.07818269730142512, 0.08153723236057588, 0.06540587488968877, 0.059608391073100016, 0.07653638720400113, 0.06749124235379406, 0.06440667763951576, 0.05961990143562473, 0.08054892477629029, 0.06075065648092121, 0.0777402114128546, 0.06505659927678444, 0.07830966998664256, 0.06410918281357829, 0.0683537144725738, 0.06342295391752399, 0.06240266782013032, 0.07270193142875442, 0.07780917697647788, 0.07130677421618718, 0.06124322185566592, 0.08570376271058486, 0.07765924286172106, 0.06988920067045203, 0.06148981504855345, 0.07501981757378791, 0.07771184251342367, 0.059381891314471906, 0.07687289873029741, 0.061370201310803306, 0.06628859164406578, 0.07805887507819072, 0.07958701494316699, 0.08088183835184769, 0.06593209946017325, 0.07998917106791371, 0.055574573274651366, 0.07511412409333919, 0.07707139408977841, 0.08017397027752707, 0.08489998515053557, 0.08012310263806557, 0.07191762944276864, 0.07578279453255381, 0.07011439585603656, 0.07202022129559263, 0.06644776227857621, 0.07783177825149136, 0.06219627643273764, 0.07458996428800681, 0.06722871783144473, 0.08019363043056242, 0.08091151012037907, 0.06126214022604493, 0.06352673496776831, 0.08165834367671936, 0.08039306580906896, 0.06262701958978086, 0.08031815726446233, 0.06722033426176648, 0.07886606364874785, 0.08325082934278241, 0.07773523731253947, 0.07004781212727926, 0.07351069280058856, 0.05692457643079084, 0.07773215096679205, 0.08000613540345751, 0.07971360927170851, 0.06005956933520723, 0.07399570372207466, 0.07168213888750867, 0.06328718046762279, 0.08569358648293984, 0.06920171999976153, 0.07015593501051566, 0.06635748721757181, 0.06357883753557193, 0.08005273261021752, 0.08045812786727978, 0.07386301817690942, 0.06369345453805224, 0.07830142624948414, 0.0753298169886245, 0.07843938250834438, 0.08239858800594002, 0.057824996186557905, 0.056662286911344936, 0.07349607258878385, 0.061047889813153226, 0.07916983220659357, 0.07993741154759647, 0.07856023671977282, 0.06741586577590009, 0.06886439323004678, 0.06699882159871115, 0.07060625001445239, 0.05829473641463995, 0.07865206332521366, 0.0680586191314475, 0.06659796510297213, 0.06661730096487135, 0.07406307668217942, 0.060230343485, 0.07205419796259073, 0.05431766515938605, 0.07688529540529454, 0.07978420793207751, 0.07712143622086333, 0.06011322007353856, 0.08317517464325479, 0.08273286106735112, 0.06661533329224739, 0.05960300356172709, 0.06475217847578245, 0.06338409591608204, 0.07019705298707095, 0.06684334901585293, 0.07144239898549828, 0.05925184688263954, 0.05810027384706671, 0.07879499194542554, 0.07202260379579144, 0.07747851414254733, 0.07962541199703657, 0.08082072961975503, 0.07885334282434353, 0.06430363015248648, 0.06303617925613357, 0.07902437088886445, 0.0815703345636221, 0.06227143831466144, 0.062486730319934486, 0.06198131350759117, 0.06241544377644797, 0.07914464466078187, 0.0717168333610029, 0.066863594664576, 0.08185797812657451, 0.08102327535527742, 0.060864239712806856, 0.06479153762170993, 0.06592855456620683, 0.07817691999176735, 0.057571347901063066, 0.07890912452981161, 0.07564666669472771, 0.06549973077752656, 0.07344185037260377, 0.07820039613282043, 0.07360538089565279, 0.07726270437217676, 0.06976854758468728, 0.08033186069865945, 0.06623227241924524, 0.06511480603368933, 0.06822627189258049, 0.08028769745122359, 0.059911856025545905, 0.08103243508139432, 0.06261383068128061, 0.06909023103353744, 0.0615410772028689, 0.08022621425319475, 0.07638848434656105, 0.06541310700014927, 0.07565328019846476, 0.0786151144405573, 0.06531775606078019, 0.05451525076626343, 0.06776896309250463, 0.07270141712638975, 0.0676661814642049, 0.06554631024979561, 0.07512469216337768, 0.07961190705470017, 0.07802375067095343, 0.06721623804532517, 0.0798787838481399, 0.07851049848999339, 0.07720233012454006, 0.0643411211220731, 0.0693785452580803, 0.06826936019100154, 0.06379776543379273, 0.06430604503596185, 0.07886908086658037, 0.07911858233540418, 0.08062930247985818, 0.07725314537090872, 0.07201733345293027, 0.08010875377205388, 0.06397395331676839, 0.07007510352084284, 0.0572559675269868, 0.056764982787402746, 0.07820038773157703, 0.07901232055037083, 0.06079861266965672, 0.08142000999062722, 0.08236948210076579, 0.06200605282032913, 0.06389488871954041, 0.06702858951250913, 0.07694971949171484, 0.07995320426562691, 0.0760360593900081, 0.07039067202602707, 0.06602777060255467, 0.06631954515907992, 0.06416391135706029, 0.0533273609751366, 0.06177096253590132, 0.07833420916918599, 0.06559102858052002, 0.0699273762131046, 0.06520198274472526, 0.058623571903757304, 0.08388778918050961, 0.0677252538676146, 0.080120455728297, 0.06465323666239078, 0.0764718858951875, 0.07083758035849298, 0.06865112783133648, 0.07088258300018195, 0.07873558287216775, 0.07024239003938375, 0.08025906635282103, 0.07957899834146707, 0.07737733161059852, 0.05970702131745389, 0.058445488211794815, 0.08161225457776038, 0.06374884309324559, 0.08175723657630243, 0.06902544541257467, 0.06625657921344108, 0.07897048664014078, 0.08029244101134027, 0.07379506847894118, 0.08076429793864304, 0.07969604599164448, 0.0664603486795838, 0.06017143115012497, 0.06278308250878685, 0.08000692354113416, 0.07540569548204375, 0.06882188434862967, 0.0701321796330123, 0.0673178036010231, 0.07538747796293067, 0.06729111941306766, 0.07797078518425335, 0.07897962607618247, 0.08393206871744598, 0.06589458752790323, 0.07093126307062139, 0.05947135586823774, 0.07264833757584395, 0.07843580749384357, 0.07972034248861073, 0.06301676382961205, 0.08432835039113697, 0.06493903883682414, 0.06546502924954804, 0.07953120232312408, 0.07809381794005765, 0.0735903264843239, 0.07737996207087633, 0.07696877886605383, 0.06764841194034502, 0.06258440842601871, 0.0807768372401581, 0.06109595710184477, 0.07893577549249478, 0.08190461237259626, 0.05753244399864213, 0.08367695123816733, 0.07684488629680315, 0.07822266566170012, 0.07980180855981987, 0.06800789747256046, 0.06925260876928932, 0.07854324343433042, 0.06927042251899238, 0.08091505255309865, 0.08092431892393279, 0.06337834038886175, 0.07832294842942275, 0.06422548193242128, 0.07874643608275395, 0.07565172329435359, 0.07615197177272807, 0.08154740644209099, 0.07511527664957944, 0.06744382374390215, 0.07606791923597606, 0.07905020625598723, 0.0730551586566365, 0.07975070744991451, 0.07888203645216936, 0.06797926492729221, 0.07894340686621566, 0.06260035870980504, 0.06690313464403015, 0.06481540459949893, 0.0852258805661968, 0.07984615781487342, 0.06202462047752535, 0.07365528998508525, 0.07977055735032763, 0.06573226088111375, 0.07973800036975824, 0.06477212678680841, 0.07309349624165509, 0.08134952703406519, 0.06722494804097486, 0.07968049805019628, 0.07925347796340022, 0.0645529656914917, 0.06698017757730161, 0.07363103274243843, 0.07217596268063585, 0.07685723314119407, 0.06785748979816808, 0.06017595437381315, 0.060793430367665255, 0.06409512986970768, 0.08137068666264653, 0.07042372408558022, 0.07311890139612127, 0.06364366830082305, 0.07923496065810026, 0.05878471566627249, 0.06786186613579591, 0.07750179412241626, 0.07985685409953186, 0.08004513819002966, 0.07760479373133213, 0.07252193211294829, 0.06678083155705214, 0.078575840289676, 0.06569880625729976, 0.058212184330781916, 0.0817309187525246, 0.06955624866936469, 0.06441492988688743, 0.06713184720213014, 0.07365198225917571, 0.06326738366604782, 0.0736688799854999, 0.08193101951305558, 0.07724925265483372, 0.07483149438403036, 0.08107982574873278, 0.0712950920636235, 0.06449367369040114, 0.07995976580118214, 0.06369502091858993, 0.06245819197031104, 0.07849933795654859, 0.08065136012744467, 0.06788563064004421, 0.07330583524179897, 0.08093363331652179, 0.06555972726056955, 0.0829170730448849, 0.06981214785649838, 0.06874986116092527, 0.07932579427433778, 0.07373288403996636, 0.07957364057839454, 0.08045243478353291, 0.07584428927959007, 0.06820145142930846, 0.07947608375458146, 0.08058379280630747, 0.07658573044828713, 0.08308639731761938, 0.07941642884992471, 0.08107561970919194, 0.06350453643743723, 0.06337026073463425, 0.08185521578044593, 0.07657899185570112, 0.06473918606055147, 0.07927801574921413, 0.08106474808694253, 0.06616466598607139, 0.06604599009076166, 0.07039506319882888, 0.0828580264787894, 0.06331237674258039, 0.07559098971838532, 0.06123045155728945, 0.08065042644211905, 0.08245487429700406, 0.07905205427819192, 0.07698943088177392, 0.07041551421587663, 0.07215691569548922, 0.0657445287490122, 0.06007529643292772, 0.06731124774585401, 0.07874188551363392, 0.06575433311306875, 0.07993107176264962, 0.08044989784442659, 0.06677796319827922, 0.060634805829646546, 0.0779945491030499, 0.0681732057497521, 0.06752489960339968, 0.0817834437106449, 0.06475590038570253, 0.05944016992541227, 0.0755932244401045, 0.07829432272313269, 0.0704431365230284, 0.07402332535857442, 0.0802674259535073, 0.07630974874787987, 0.07925326320563134, 0.07972120995417814, 0.08203625191758922, 0.0663349214684351, 0.07104807575750798, 0.07856910455342808, 0.08073741776072597, 0.07994743219016491, 0.0754341717055434, 0.054509047671510866, 0.06605610426066752, 0.08142504539175655, 0.08308858850025316, 0.07776885842897867, 0.07046601432230594, 0.0776598646853548, 0.06310206190223229, 0.07953022057777209, 0.08135395786113163, 0.07432550699837677, 0.06243720459305034, 0.07689462343013372, 0.08550015535448158, 0.0794041999843775, 0.07870847929177346, 0.07605321766739667, 0.06575516205684372, 0.08210723499584914, 0.06720479119219784, 0.06515169892387682, 0.058666501610096164, 0.06814226000944729, 0.07394533168352371, 0.08082507164632259, 0.06351405593046956, 0.0673173711478127, 0.0798462775215264, 0.07149825205947948, 0.0776578359566657, 0.06635780437036282, 0.08095012035323414, 0.07246854463524095, 0.0795243307652869, 0.08096185349224319, 0.061167370006932856, 0.06065338871093771, 0.06740538348953545, 0.08050246766470628, 0.06692264719220645, 0.07800536586722524, 0.07843225075639099, 0.06295223673828117, 0.057512906009741654, 0.07370174733181932, 0.07984815948695684, 0.0680888488078605, 0.08030261837322274, 0.07377199444628779, 0.06189382526374831, 0.07926277489292767, 0.06678920228274414, 0.07748915629273834, 0.0750732068550404, 0.08299602676514271, 0.06408777139941242, 0.05519159316980311, 0.07835090368232432, 0.07172716260515678, 0.07317958761153584, 0.0543888269511925, 0.061170292949104754, 0.060611965946849894, 0.06943747098274411, 0.06819742842765679, 0.07268688895235154, 0.07957425203769163, 0.06925455018773112, 0.06433356941314257, 0.07872696000199988, 0.05767623033671455, 0.06569353949438234, 0.0616966446019536, 0.06997803688414635, 0.0792531235186961, 0.05663382468047309, 0.07961560249369475, 0.0664070880258976, 0.05769322555899584, 0.07723107765817681, 0.06407034123253483, 0.06479568978731394, 0.07664645785008127, 0.06220640486745068, 0.08080903930189919, 0.067578674135044, 0.0671838436294245, 0.05790741572203022, 0.06414979713464856, 0.05963848336331318, 0.07134625605912287, 0.07507332353630128, 0.08213129073458192, 0.06733809218763138, 0.07254108663141308, 0.07098018577520086, 0.07533092085266929, 0.079764473359368, 0.06962982946116648, 0.07673570326095981, 0.07724283650145648, 0.0716537343827703, 0.07963239442021847, 0.0672871275639651, 0.0712178464160521, 0.07939548050440497, 0.07821567378348318, 0.07909380012089257, 0.0786391335461433, 0.08046864961188613, 0.08149417524185161, 0.07920225965326967, 0.0795477550322514, 0.06765889130997656, 0.06406579489097201, 0.06490646286175955, 0.06979314351521822, 0.07863692657930198, 0.06457443276589295, 0.0814687829431045, 0.07792045268383445, 0.060688089018512095, 0.07868793244658558, 0.0689341146697098, 0.05941171630723505, 0.07765534164656628, 0.06782587242618991, 0.0766917870655489, 0.06383269434778169, 0.07946788241454085, 0.06745674059371887, 0.07932311939697946, 0.0679404899392478, 0.06499163721989681, 0.053370470055604274, 0.06537384403266203, 0.0801621696920016, 0.062254933922229375, 0.06667514878780298, 0.07977749403828718, 0.08148477940510661, 0.06855202842169338, 0.0764459863263995, 0.07911860957198147, 0.06891085557447647, 0.07640950562621157, 0.07870962166808984, 0.06306949766667104, 0.08125000032806123, 0.07651739661527474, 0.06136125099093276, 0.07074767821157157, 0.07605193194985217, 0.06501132815251315, 0.06323547492449068, 0.08200674941164986, 0.0803727754560536, 0.06334604929912985, 0.0642454768622811, 0.06480951591480283, 0.08024626428571549, 0.06775943148857008, 0.06993196024462582, 0.07953532517879137, 0.0791175330444337, 0.08141583873640422, 0.06326080496623912, 0.07303901663350097, 0.07982905394918631, 0.07136502735989969, 0.0826782933666168, 0.06666727388375562, 0.06483860784264697, 0.07933687167218935, 0.08066163294545622, 0.05424027575307648, 0.06373480315980197, 0.07588964229819793, 0.06733044540288256, 0.06795730047470207, 0.06658304244583, 0.06272836052336986, 0.0661558448505682, 0.0850336070400357, 0.06532916780045678, 0.07388840706353515, 0.08357515220718552, 0.063832012751168, 0.07009090686739243, 0.07391401896413628, 0.07838806863201746, 0.07870767286234207, 0.06392807524761762, 0.0699693300702232, 0.06683966061644948, 0.07909943440639447, 0.0800692912214043, 0.06517031081775992, 0.06800539209089428, 0.05798346329543327, 0.07895176752830413, 0.0698654192531417, 0.06344574482314706, 0.07942094557263019, 0.07478308600506495, 0.0762397419590781, 0.06168096574701375, 0.07249218024679907, 0.08038542483019631, 0.06250398308267621, 0.0680646539245426, 0.07862059253662619, 0.07952447287611698, 0.07676447008910865, 0.07987296013605007, 0.06456068211204247, 0.07947976507835572, 0.06123276892059485, 0.06338858233353183, 0.06734492540423703, 0.07832338647525752, 0.06568023058883088, 0.06784618786162043, 0.0804143443864436, 0.07983840966759419, 0.08040071504321013, 0.06687490258863787, 0.08249222435738461, 0.07107385086969313, 0.06621972648207464, 0.0779870135493811, 0.08623287656074972, 0.06085311324330508, 0.06433025349395262, 0.07084775845010358, 0.07903863680270617, 0.08094708059783778, 0.08332206820451554, 0.07780390710147561, 0.0798723146924617, 0.07794067663633196, 0.07572246704058334, 0.06585435692733949, 0.0802451061090058, 0.05511341766639921, 0.06831955459973212, 0.06277774340972857, 0.08061285305889815, 0.06762880156622783, 0.08165144287490489, 0.06758542713218008, 0.06429089457959455, 0.06500443573910035, 0.06738900913029774, 0.07833108917772823, 0.06863585669779461, 0.08130176892110264, 0.07676343885592618, 0.06553765351692331, 0.06089750921061106, 0.0781693567509635, 0.0776428343483181, 0.06825576362439449, 0.07741370004795511, 0.06367918362127041, 0.07864504897504271, 0.05974474670533553, 0.05576059996271478, 0.0798697098261631, 0.07615555972626326, 0.07231267838035801, 0.07202514538932943, 0.06660382287307022, 0.07775221150008006, 0.08181827707303646, 0.05734591911946838, 0.06618041195025394, 0.06667197084580766, 0.06517355425698815, 0.06618153723808774, 0.07770946212341732, 0.07084532433106841, 0.0811410390136591, 0.0762070256997728, 0.06517720431666921, 0.07879162771511324, 0.06715343656721656, 0.06486503175789393, 0.06318144425435822, 0.0713136259113544, 0.07186396120329565, 0.0800223053922635, 0.08393449600207163, 0.06929723123172436, 0.0724051450554494, 0.0625372593698725, 0.05816381337879876, 0.06791162478128099, 0.06369742014097018, 0.07940070274846121, 0.06502312486683005, 0.07665284605179988, 0.0695262574282225, 0.08355594662638767, 0.07060301202966562, 0.08047616537406643, 0.06616587231890918, 0.07788298497245723, 0.07978980648331123, 0.0798526233268711, 0.08199368199862703, 0.057837924972658966, 0.0656560365954882, 0.06540587062880403, 0.07776209732414052, 0.07870569520408838, 0.06007922594902048, 0.0791241454562747, 0.06580199377489761, 0.08510804236641974, 0.06504080343571111, 0.060901691661967405, 0.07291627686440201, 0.058897345803201134, 0.06533090796194319, 0.07404516714160161, 0.06077237753169772, 0.07959298472754685, 0.07965211732941929, 0.0659089706884738, 0.06680229704110116, 0.0640119220184199, 0.06471395167000056, 0.06457090700211353, 0.08148407744644431, 0.07988679307946348, 0.06868058902323919, 0.08192635637615518, 0.07100378593692876, 0.07903558834967818, 0.06700994837271526, 0.08272610160775717, 0.07822332031655671, 0.08013431169429423, 0.06354293415141953, 0.07987377604082509, 0.06690574287556915, 0.07886348112909368, 0.056496829047062234, 0.06993364908664167, 0.07651223453110093, 0.06747131097047065, 0.06332165259555882, 0.07542280253904206, 0.08265530360239073, 0.0825799769119163, 0.06399530005273571, 0.08012969879252894, 0.07891342294779023, 0.07767822319119073, 0.07962099428189393, 0.07197303018525429, 0.0690468709393016, 0.08017620299880014, 0.06953668232131616, 0.06869206196613364, 0.06456960620654525, 0.06712625263174278, 0.0781694118370316, 0.08326994977095863, 0.08141270673887574, 0.07804311216196347, 0.07836568385810977, 0.0671392841771009, 0.08101352099613199, 0.08055418247393675, 0.06591863499431506, 0.07478366666816709, 0.07962071634727497, 0.08099440810450659, 0.062430689532346775, 0.07332168181344911, 0.08172759546649215, 0.0792765546513354, 0.08246952224174027, 0.06835875565454567, 0.07838069039577829, 0.06591774213342014, 0.06532646916119027, 0.07916215897218265, 0.07726750537848377, 0.08094891562544876, 0.06083801474755559, 0.08031400084141954, 0.07862917539547493, 0.06077748946519524, 0.07637177684020384, 0.07850576281088285, 0.0705399557991405, 0.07880441674085088, 0.06732508966738807, 0.08142330911091236, 0.06831480135883966, 0.07828859633883768, 0.08100401824087372, 0.0776700139628326, 0.07837116280435119, 0.06580233363391748, 0.07955857239581518, 0.07780740579791516, 0.07305649537102868, 0.08417697675901403, 0.07717453346290583, 0.0799974315530857, 0.08156891857057008, 0.0829645477783736, 0.07983542388811908, 0.08093897534851503, 0.07748926084419354, 0.06079996227600406, 0.07847443237228315, 0.08205574438826795, 0.08222853781658387, 0.081010925810799, 0.07861882234098089, 0.05563890323357938, 0.07998718884394326, 0.08147453456123739, 0.0685686878854887, 0.06414359355845736, 0.06292883612138868, 0.05847479642070883, 0.061081192913876946, 0.05414778150623899, 0.06507846431654082, 0.07998123865102784, 0.07486910031153893, 0.059863008377531016, 0.06280728237833072, 0.07753351108292902, 0.06944567658964874, 0.07969349718125056, 0.07828776154003557, 0.0797499197926642, 0.07820635730848564, 0.06521511172248962, 0.07752406946124124, 0.07600593331907808, 0.07969060672857704, 0.06246730080171033, 0.08192835376009751, 0.07619863543495721, 0.07076399720186681, 0.0623570386662633, 0.06689154779647338, 0.06887352858884362, 0.06247675530080569, 0.07784545164403175, 0.06902290054805042, 0.08075055521653118, 0.07516234713835743, 0.07003259807328668, 0.056802585076150075, 0.08059403985400765, 0.06747961189869002, 0.08494854493619576, 0.06877032724720247, 0.05917983918591954, 0.06535668121702103, 0.079389223602379, 0.0673989261743938, 0.0800011293465774, 0.06125835295973856, 0.07842175261921049, 0.062398559522720984, 0.07022692912167743, 0.06335716418316707, 0.07452382234329707, 0.06358157320582364, 0.059386729765383374, 0.08652585395289067, 0.06484919383698602, 0.06826409845580905, 0.06288395623547868, 0.07649154607719623, 0.05904859130205759, 0.06273522712258707, 0.0627685902545774, 0.07894670054360127, 0.08150331794661002, 0.06558197504369434, 0.06468722023087545, 0.06215733821836342, 0.07508939541197919, 0.05245065811590543, 0.08162186366138305, 0.08005428342518031, 0.05677976919438262, 0.07317743652469397, 0.0832665264917972, 0.07202768003878753, 0.06276639651461133, 0.07487024462805593, 0.07944604644660966, 0.06921274276658042, 0.07756909531606844, 0.06941938976465928, 0.08126141895267752, 0.06664174718891298, 0.07561784084902406, 0.07634254684425783, 0.08343666307646237, 0.07663709557362888, 0.06263672642681621, 0.06369749242017315, 0.07453970898151334, 0.08083600591777666, 0.07635274686362069, 0.06226346914114768, 0.0795661820182894, 0.08121098440182518, 0.06575190799776776, 0.08496724328002815, 0.07961509840884975, 0.06653600132994554, 0.06506085220697115, 0.07478740234244349, 0.07581470517098188, 0.07155506842719886, 0.06598957772979787, 0.07744406395270295, 0.05973825172980385, 0.06831859014035432, 0.0793612764076064, 0.07861001789111972, 0.07525708682846792, 0.06838010073047908, 0.0804137709800031, 0.07696076229907799, 0.05559401034373326, 0.05860846085484678, 0.08154536448356559, 0.058319643935700806, 0.0748767877694996, 0.0743934211142871, 0.0723167401331431, 0.08066098736253391, 0.06081874456614065, 0.07495902587030671, 0.07948904693894844, 0.06478743738373947, 0.08194388947696918, 0.0625034883646934, 0.0701773399313623, 0.0621146613207861, 0.07577644697458844, 0.07967461958413069, 0.07918562677791406, 0.05908143004378558, 0.0817814147473922, 0.06965797510367826, 0.060873436297909, 0.0634718285334313, 0.07936750922158663, 0.07230230592062128, 0.07988747645508937, 0.07980266392983155, 0.06627853646182007, 0.08009879198927107, 0.0772502059165361, 0.06127260533746566, 0.05516909493797129, 0.07778310481980372, 0.06287068805496208, 0.0668626170941861, 0.07888631200371367, 0.07669274464275502, 0.06332415852580332, 0.06869644599274656, 0.08046853566097346, 0.0754544245289213, 0.07845163589439004, 0.07200739543150209, 0.06946763950235976, 0.06581442106067331, 0.061233794741454003, 0.0790225538427228, 0.0742270935257192, 0.06701740751016773, 0.07568828174994388, 0.08115718074386766, 0.08069462974204604, 0.06345875004190088, 0.06743153079530867, 0.07961409194578006, 0.07145664784907337, 0.07817140628359102, 0.06419523819376033, 0.07325839750919105, 0.07673206885061362, 0.07725685757466795, 0.07878972641971606, 0.06874768027512383, 0.06527121149007373, 0.054206648161133276, 0.07931132693004528, 0.07911601190214665, 0.08005312518224093, 0.06722771015783482, 0.07836490211308388, 0.06836360974270404, 0.07895327623359978, 0.07840757188489261, 0.08515456156110912, 0.06920184412336365, 0.08472695005829158, 0.06798793224410497, 0.07909016104856446, 0.059354825441304944, 0.07872337652678829, 0.07081414117665502, 0.06732870110428155, 0.07997098887008022, 0.0805769345766454, 0.07613177658174954, 0.06949676491585541, 0.07835903847881195, 0.06390086614792956, 0.0748709323175186, 0.06922163573769083, 0.06580598522896075, 0.07937413557251084, 0.06756488141271062, 0.06930762320229572, 0.06922128507104562, 0.07451380111715179, 0.06798783926828368, 0.057809759226463364, 0.06942489958153275, 0.08062708099657206, 0.07872099415851537, 0.07839216657478974, 0.0766458629125932, 0.07628931642752927, 0.07228464521650176, 0.06831935870671099, 0.08345239651245578, 0.06713429712226614, 0.07329182487240583, 0.07935997058303805, 0.06702505823669834, 0.07349111199395165, 0.0760467530726053, 0.0791239419856619, 0.06990232939764938, 0.07967978766330854, 0.07587379882904527, 0.0600158982535464, 0.07751034586256374, 0.08042725069406241, 0.07423968069661292, 0.07892542957572414, 0.07641078067238956, 0.0728076180748664, 0.07455106631028856, 0.06393051567326168, 0.07449625132307898, 0.08022994310419755, 0.06719020671827793, 0.06924016008436466, 0.08053216149508287, 0.07826926552438208, 0.06278412721096627, 0.07941933301461651, 0.06721840979530708, 0.08093740635615258, 0.06092736803755543, 0.07971770764786641, 0.08165798218069496, 0.08048704724331768, 0.07610896684102612, 0.07883722114775396, 0.06650020260140327, 0.08181794893907292, 0.06942324578471613, 0.07077242803979851, 0.06526319849717767, 0.05478437527263523, 0.07876217844793552, 0.06717101813983936, 0.06968504267765271, 0.08469238148949157, 0.07866440716278529, 0.06745788011705812, 0.08084556491726219, 0.07937542705197377, 0.07031546257359411, 0.08292695553979063, 0.07110474183796807, 0.0850422311916628, 0.06033202097084811, 0.07757730479651138, 0.07952276317262326, 0.06489108699857783, 0.08068139254347693, 0.06920463546655096, 0.07935732642234779, 0.07394785502368999, 0.08247226936915354, 0.06259778327214992, 0.069830547579439, 0.07440499311787609, 0.08164056404168626, 0.07454232202251027, 0.07273656854851351, 0.07991874599838468, 0.061248316640893065, 0.08062012836590851, 0.06523581820670041, 0.06320674716924898, 0.06877750807541391, 0.07905660837563297, 0.06155427063599901, 0.05934433951503497, 0.07591411674406277, 0.07999721318142251, 0.07031607710729114, 0.075044905379979, 0.07498183469890865, 0.07146805968898469, 0.07593172347523174, 0.07977429458672543, 0.080413945144353, 0.08072282098090919, 0.07465598403602565, 0.08402651947819294, 0.06935600719771055, 0.06162175795446191, 0.08218835827724691, 0.06769079686676131, 0.0752469490256433, 0.07712565669789882, 0.08001736092452125, 0.07789633241501032, 0.07575257171723145, 0.07479205866640523, 0.06712346865848576, 0.07763410568657729, 0.07976142610501238, 0.06964270226631288, 0.07773829510167671, 0.06471944389761948, 0.06872669920212489, 0.06970808732703133, 0.0707283917028619, 0.07838075036363215, 0.07841800641521476, 0.06304593456492849, 0.07775287558796133, 0.08232615378373515, 0.06686528091243356, 0.08419774097654462, 0.0687504559538902, 0.0716645775155193, 0.07973079705898073, 0.08005080213597532, 0.08022260887065513, 0.07836131314801169, 0.08123713308335671, 0.0761768879267908, 0.07772487226656404, 0.06944218186633196, 0.0576459204024632, 0.06308953786318501, 0.06407464498119142, 0.07007100641364314, 0.07914904538271618, 0.07738663808978304, 0.07901727399176935, 0.07966068823965011, 0.0806638687771837, 0.08099800161840844, 0.062367676511614366, 0.06300958381623992, 0.07507926569025562, 0.07103258649153994, 0.07864787956746509, 0.06873653491416527, 0.07539378760253788, 0.07774427581960948, 0.07975327729735446, 0.07369847723459005, 0.07807088473175519, 0.07107762487828519, 0.06503256206765529, 0.08228622838024695, 0.06085141319350466, 0.05914634127494631, 0.0777184082869309, 0.08041800017743422, 0.07132250121752781, 0.08086298480041751, 0.07423324317455136, 0.07944816071222446, 0.07615332308427522, 0.082405837173592, 0.07741368405020543, 0.07773822428424162, 0.07864923414715944, 0.08010204876586542, 0.06671795963427109, 0.05920366680594114, 0.0628193583000567, 0.07639788340468566, 0.08084103675601469, 0.07938617155139806, 0.07903368783062518, 0.08013027753655456, 0.07762602047637203, 0.07223926765742923, 0.07922025159444862, 0.07304564798384212, 0.07347812099216196, 0.07250888985047223, 0.08084329731476357, 0.08408930560952607, 0.06895525969521377, 0.06380932787455983, 0.0778988808632393, 0.06940663760580933, 0.0788230956366075, 0.08091806807757444, 0.08075420891975654, 0.06916690406079001, 0.07859295824884772, 0.0666678576206581, 0.07683996847599801, 0.07854438486874143, 0.06642085769316787, 0.07198902541128156, 0.06590536038087723, 0.06449265408745496, 0.0711951783052587, 0.06668284949121868, 0.07761756694982275, 0.06572473678370447, 0.07785624531353692, 0.07806147959264101, 0.06253580193205957, 0.0795094226779637, 0.07333471107317022, 0.06510237977777109, 0.07284011874312188, 0.07969840794204829, 0.06233205634566095, 0.07506523890629554, 0.06194732186177025, 0.07980559945794262, 0.08179223252896523, 0.0768423690666373, 0.0702446673575529, 0.07997218002700285, 0.061864407326155925, 0.07964751501605893, 0.06294724860585818, 0.07221778440422515, 0.06752537973354635, 0.06988438323111375, 0.07655485413510826, 0.07793902432986545, 0.06819082453037285, 0.0693269635217059, 0.0787438724187698, 0.079175200307652, 0.07635880635451207, 0.06431048036391619, 0.07821912469177263, 0.06317741149549133, 0.05529701654740281, 0.07860577398420694, 0.07686159100750921, 0.06398472685954859, 0.07836777078430636, 0.07501032107914143, 0.07433278942119054, 0.06541059811762855, 0.0629638618672495, 0.05537033413253769, 0.07688783302388923, 0.07641970753881602, 0.07951182656103073, 0.0763663333082804, 0.05612434820877485, 0.06405973445188595, 0.06631765217600558, 0.06736731305820283, 0.08041898077243481, 0.07600599372696987, 0.06621347972603132, 0.0652559140749432, 0.06848305856771214, 0.0808173709393888, 0.06479368392444798, 0.06838879666585133, 0.07962682048190492, 0.06202716432663621, 0.07632989289175679, 0.0671940461424969, 0.0669049003006547, 0.07851234297464905, 0.0812627244061065, 0.07217111236823538, 0.06830372613468214, 0.0774941036996179, 0.06359698702354526, 0.0641235278531914, 0.06367023653596074, 0.06300984056267799, 0.07274527866699017, 0.07951731223992967, 0.07408357233083526, 0.058172732560699734, 0.08077313938383482, 0.06815785028481783, 0.08268843409235352, 0.07836159109075348, 0.060385353582304235, 0.06735469202096156, 0.08014387505368842, 0.08035754752847551, 0.06038836599746049, 0.06396779117730078, 0.07658243860212753, 0.07777569170137881, 0.08068052685913052, 0.06516520607217363, 0.07952160703166554, 0.08061296178967152, 0.06230094950628429, 0.06296890749405602, 0.0780173070123158, 0.059530501260623085, 0.07966675597131441, 0.06283710468439099, 0.08182767320184807, 0.08394310135601739, 0.07171111302313035, 0.07629398669443102, 0.0780186973702181, 0.06670101262452985, 0.06629539141532331, 0.07973147631058627, 0.07020561348524451, 0.08284086116722551, 0.076412621324287, 0.06646246350284235, 0.07376185356014787, 0.07748883222963013, 0.07944772529352581, 0.08000164044251114, 0.07802749824250386, 0.0798164123219684, 0.08089358785763517, 0.06814696544031995, 0.08032865852870866, 0.0529605228021049, 0.07634422755952473, 0.08329594056273758, 0.07031887528032674, 0.06421129213566107, 0.0669411481991489, 0.07891047773434431, 0.06742686285070927, 0.07782965703231652, 0.06842612567290993, 0.05665640713823538, 0.06996378938347977, 0.06786060072477094, 0.06911925044138138, 0.06509934153056218, 0.06720024377281437, 0.06584858371221002, 0.0653499983481662, 0.06413028038661378, 0.07568256900172948, 0.06036591422553558, 0.07162826913629124, 0.08029609431739798, 0.07589988358076241, 0.07921882568710704, 0.07879527227265844, 0.06528303273036754, 0.05943139466370058, 0.07981632997850888, 0.08130092603503927, 0.08193223026127322, 0.08320988558296491, 0.07650244289524198, 0.08202872340335328, 0.08129586196056175, 0.07591894438850544, 0.07115947120222951, 0.06727406062080736, 0.07413038957536072, 0.06575427743575053, 0.07693618550679919, 0.05983629692068183, 0.0620373261652115, 0.06550944634810948, 0.06485712559350854, 0.06627526726748299, 0.07872373529893183, 0.06253373252853674, 0.07983380014569863, 0.07237618565715064, 0.0796446946590836, 0.07776897617151826, 0.07884117203274073, 0.08106667042469376, 0.07971501700218238, 0.07963698103369787, 0.06856524005376277, 0.06708934781528016, 0.06954354707718828, 0.08259282743164613, 0.06287625011161024, 0.08116107735298951, 0.06414373058247969, 0.07761872248286014, 0.06559114476316144, 0.07713832301348503, 0.07897862355496116, 0.0626362496433412, 0.07825732146292737, 0.08053709763563134, 0.06809532591957784, 0.06435162262737265, 0.06393147180805929, 0.07447155642252, 0.07880226559470481, 0.07847753004057846, 0.05886693667390456, 0.07659074128586661, 0.061214412498935396, 0.07905364755973295, 0.0667204954952592, 0.0568441207474917, 0.06026482864762344, 0.06604978897517592, 0.06553604310538046, 0.0658736507088385, 0.06563648189568821, 0.08057347572722139, 0.06910344814104306, 0.07866249336060799, 0.06717341874311242, 0.07805976941500037, 0.0664759954605327, 0.07163560865878191, 0.07568596419137126, 0.06538151611880685, 0.0677051799147289, 0.07955278635866785, 0.06290708063758577, 0.06554592939455926, 0.06663588008212602, 0.078687936757668, 0.07901501206934126, 0.06423930401663457, 0.07933861047250104, 0.06519835290326419, 0.06934887952620686, 0.06862969955449966, 0.07923178231094295, 0.07104350380720181, 0.07612639853904238, 0.08181544277463662, 0.07632577025977315, 0.06423742760311786, 0.07031094435376334, 0.06943086686895403, 0.08042541346773277, 0.06899346150040529, 0.0628024330298628, 0.06816933937092368, 0.06436021805677948, 0.07531209161552911, 0.060086905877891277, 0.0815384042787598, 0.06780700463705454, 0.06740511739123325, 0.07790370905647204, 0.07859932158490153, 0.0796847254079159, 0.05874093846486131, 0.07839472251350411, 0.0798836750348898, 0.08055708198426889, 0.06838263744970198, 0.06487426617619697, 0.0692498700986382, 0.0611537698200523, 0.0636496967733662, 0.06376736710433963, 0.07082330554770724, 0.08015115537273303, 0.07830090536984226, 0.0789665755940724, 0.07913684033068322, 0.06415318938077051, 0.0594399142527083, 0.07926223285072061, 0.06385215808527465, 0.07961309892290422, 0.08116208799346623, 0.08066921087231041, 0.08198503996129561, 0.08300579215743807, 0.08075083577282016, 0.07847832430574815, 0.08132635719586258, 0.07947836334062415, 0.07056707341547341, 0.07163242746668429, 0.07794264535154098, 0.07001183323029304, 0.07946631637384402, 0.07226107037758732, 0.06367151833831498, 0.08049859917889612, 0.07855391038210063, 0.07866414357299288, 0.08011364469023766, 0.07756051741135658, 0.059901446287945956, 0.07249798617311935, 0.06666859566896804, 0.06880206941759284, 0.0790459116660606, 0.07882093322123383, 0.058511110317714894, 0.07181124993681931, 0.08075608726048165, 0.0645690080431303, 0.07838926496653752, 0.07342833751503086, 0.08060008647558418, 0.07908035251739215, 0.06925293858213426, 0.07038922708640535, 0.06439536182274982, 0.08137859019423062, 0.07054827305323824, 0.07236504707238134, 0.06639289458756682, 0.08280977296387296, 0.08006352598382348, 0.07564302120284515, 0.0813772340863096, 0.0794529598928763, 0.06663851056986902, 0.06313648388280116, 0.07660136202256268, 0.07793515858168122, 0.07722701620458584, 0.06483422958958267, 0.0677199183981747, 0.0737884978747434, 0.08051011346240274, 0.06648781957996762, 0.08226532372997991, 0.07944431407671268, 0.06295843912316451, 0.08267220456267738, 0.07181944683338241, 0.07869196386374959, 0.0785527288453336, 0.07997419431562378, 0.07548745568343507, 0.07959926058118075, 0.07551659080952515, 0.07944814473794996, 0.07741014774968302, 0.08471246131485669, 0.08047190613496838, 0.0728828173243424, 0.06548351961264112, 0.08071205230591302, 0.07622666007521965, 0.07752772679213477, 0.06213761509482238, 0.08250362002642346, 0.07694151034761115, 0.07679611064860764, 0.07826223378077804, 0.0675059000644555, 0.05329483689791998, 0.07893046762195227, 0.06975065243995686, 0.08072506538010521, 0.06879436078768958, 0.06601833993822094, 0.06820390215092983, 0.0809927377729456, 0.07388966205126034, 0.06442917118961856, 0.06324278459691672, 0.07843103114127277, 0.07800866262853912, 0.07741938850279893, 0.07215955813695704, 0.05697305959012887, 0.06785870896165083, 0.07884581770570186, 0.06175383150785354, 0.07535323460612763, 0.07923994620427585, 0.05878689180483477, 0.07886057469371303, 0.07542534617907286, 0.07779451572806904, 0.06683229193579707, 0.08183160569461793, 0.0674722296129237, 0.0673941584971225, 0.07994101853678735, 0.07980609914342492, 0.0621560890634415, 0.07908110953454334, 0.07906647371867584, 0.08101132305594287, 0.06871252664982064, 0.06100852653910775, 0.0812571314821739, 0.06570426887735163, 0.08138271993900918, 0.07971444919033416, 0.0765690371846928, 0.06422199227645074, 0.07953583563737372, 0.06307033513911348, 0.07521783592492234, 0.06421617986720382, 0.06843928276750066, 0.07652980602000069, 0.07533805458620568, 0.0629471658779136, 0.07661750577419986, 0.08006580003033645, 0.07915291561523304, 0.0770250363702427, 0.06998324660083448, 0.08233992066802898, 0.08071546734142966, 0.07738506075858503, 0.07607190310465303, 0.06055377672498792, 0.0795604496941574, 0.07724104151164636, 0.07020042744722314, 0.07850307743751535, 0.07987307780831189, 0.07042970191333317, 0.07033890817555652, 0.06473438949979912, 0.06397039772635714, 0.06826528014851183, 0.05797805251105211, 0.0657546647793723, 0.07026236792819046, 0.08034340943788695, 0.0665898339672183, 0.07696003259099848, 0.06416767537877535, 0.06261424459303673, 0.0813774484274153, 0.07978786355338915, 0.08170612139019191, 0.08096382651783753, 0.0789018686876874, 0.0689561089523211, 0.0682058861550248, 0.08455102805866886, 0.07441163531328655, 0.08318489828600915, 0.07283592202701349, 0.06824542247980261, 0.07113209441889252, 0.07147388660046433, 0.08084313765077383, 0.06689896463410722, 0.06839585275951132, 0.06294821995762775, 0.05920211015684902, 0.06030442648796393, 0.08084811136484626, 0.06890917866316014, 0.08006419822847222, 0.07537533553232416, 0.05459806705045148, 0.07886982099631197, 0.0759234834858399, 0.0807726625979955, 0.06864045167575614, 0.0797104057463944, 0.08237430863170864, 0.06685753818102602, 0.06326572461130513, 0.0799862924106455, 0.08085981029611856, 0.07639919784873467, 0.07698190628712812, 0.07952771624678347, 0.07868939560819999, 0.07087211476449962, 0.06317771209836717, 0.07893426330628911, 0.08030053573160295, 0.07999394763268898, 0.07858919415650313, 0.07284391287047699, 0.07403907527698912, 0.0807678067089287, 0.07796982440953003, 0.07577168420445493, 0.054765824517009655, 0.07591756178139333, 0.055855945805818694, 0.06496586825323698, 0.08010881605345271, 0.07969075634683051, 0.06341585759328984, 0.0659548485297393, 0.07966216701123262, 0.07989844405266752, 0.07884063451523245, 0.06611462371608347, 0.07953013682241206, 0.07624106053564082, 0.07353866997230427, 0.07550034488432886, 0.06411151472410402, 0.06498631856213277, 0.06865228670359047, 0.059388087267281967, 0.07961318253687973, 0.07566161366077583, 0.05689371130056833, 0.06316243799647156, 0.05385016484305114, 0.08133371151356998, 0.07113181033862469, 0.06106546289258009, 0.08141575341399415, 0.08012802359024902, 0.07043917523132721, 0.06975554885440736, 0.07974051021530278, 0.07385340768036242, 0.07263873508795751, 0.08589327803222037, 0.06865248717958995, 0.0632117865635115, 0.07985850145451377, 0.07867413521923536, 0.07731605883320274, 0.07481278174674501, 0.06601789207912931, 0.06490923969082331, 0.08167079132045008, 0.06682199282742259, 0.08070006399795729, 0.07327672858970903, 0.07503462645858704, 0.08046302578532984, 0.08026131358745293, 0.060287618326231814, 0.06946833635970118, 0.06399189846900666, 0.06852751426124122, 0.05973050722919646, 0.06993318735962983, 0.05806189389605232, 0.06614868814878609, 0.062161832952307976, 0.06629680974803988, 0.0789610873917358, 0.07785047286536316, 0.06851403442451089, 0.08157361070184839, 0.06678365514902179, 0.06391179180265935, 0.07970162563233066, 0.06958815149667749, 0.08031022244437011, 0.0779093148626263, 0.06208072033986067, 0.06712928910453576, 0.0760551226896801, 0.08059703393896767, 0.06284015729973569, 0.057276443058242886, 0.0780200268540231, 0.07207894916081017, 0.08033637789608451, 0.07165618231524844, 0.06682908854568227, 0.08237538817635215, 0.0792431674393845, 0.07205993811455405, 0.08061822229596086, 0.07872203648625226, 0.08124803089833492, 0.08068002482942303, 0.07956612645482625, 0.0637264272490072, 0.0663401647563661, 0.06718108504879518, 0.06036072399058666, 0.0659535270614902, 0.079620600998413, 0.06603388442429405, 0.06907946893480509, 0.08015702930099282, 0.0641307831179223, 0.06619865529511472, 0.07507616596983681, 0.06786425492539806, 0.06747448770469114, 0.07933414981893411, 0.07077695806330384, 0.07830345247835344, 0.06577071438152858, 0.0751289943074345, 0.07213117490464045, 0.07350142663032952, 0.06391820265118707, 0.07085900879860714, 0.07919453727026782, 0.06494611354973949, 0.07881606439980683, 0.0794118264045874, 0.07703738203290554, 0.08399212307485622, 0.06905076803251502, 0.07889745127765381, 0.0796743814248749, 0.06633088076600681, 0.08246046290726713, 0.08286371173775571, 0.060843067956789204, 0.06736284759124954, 0.06597593975090496, 0.056800653666141517, 0.08075778682102921, 0.07796583454074948, 0.06677073858497212, 0.07952005730331438, 0.07235683272810853, 0.06300445382778455, 0.06278584096537126, 0.06552044271836956, 0.06510684358435548, 0.078775047296838, 0.07607221953279797, 0.08201446704471278, 0.08246166593322621, 0.060832166285906236, 0.07786165655283768, 0.0748995004288069, 0.06820048972227866, 0.06765885571263147, 0.0679908831912953, 0.0795068524683373, 0.06049415297680986, 0.08040578844304383, 0.06593305893935936, 0.059275120943451165, 0.078758479083509, 0.07739864642911005, 0.07193990408252171, 0.07962823348310993, 0.06638268665304249, 0.07022328320578777, 0.08296956559716082, 0.08277695009584647, 0.08043759635126803, 0.07731801020916867, 0.07921625050642969, 0.07985236362975634, 0.07898922427492541, 0.06865890000135638, 0.0666508617663141, 0.08251831114588741, 0.06659048192580887, 0.0707796291320272, 0.08075640192159071, 0.07741253290517962, 0.08016186804064737, 0.08054707132344593, 0.08000089829723615, 0.0625252269086814, 0.07881594241956119, 0.07109388361265027, 0.06169199895886687, 0.07958959134113947, 0.07712751912843775, 0.064478074047651, 0.06516624508895075, 0.07907090044199871, 0.0642101260934959, 0.08138364110849163, 0.07120043991172842, 0.07967160779873984, 0.0796129757158548, 0.07866904218100912, 0.06085707321711273, 0.06170467395222291, 0.08339117766372373, 0.07646591308745292, 0.0782466984928199, 0.07518039220377513, 0.08011971581666147, 0.06508427764008717, 0.0694020693356385, 0.07057950691499049, 0.07246740917883611, 0.06787610700542485, 0.06478236249117496, 0.07703840853348702, 0.063404222594202, 0.06487743428678386, 0.06859373545700673, 0.07321653356284061, 0.07650529978924642, 0.060459601668378445, 0.06317487173441581, 0.07611582965547714, 0.0790999817521857, 0.076388506791692, 0.07574049344140374, 0.0773205553910525, 0.08066975816252983, 0.06353072425267413, 0.08163967692853716, 0.07000953857345411, 0.06127084320509315, 0.06080821592824345, 0.057702661417707565, 0.06433512045495345, 0.064977358784308, 0.06556032699597024, 0.08033883758486084, 0.08041119048291072, 0.0652018978371443, 0.07062026036277988, 0.06204453109593885, 0.07541265785238858, 0.06808578584517062, 0.07718100487789423, 0.07606321800218026, 0.07810647292444715, 0.06187544877902249, 0.0657950411874857, 0.08125828768072813, 0.07969396230995007, 0.07793515025525147, 0.06674454968864221, 0.06715052998969166, 0.06781103525994864, 0.07527878746220919, 0.07867485708277014, 0.07791207668044427, 0.05968735241976739, 0.06589918696309513, 0.06425125905889836, 0.07866632926814546, 0.0834725468130842, 0.08001397755645191, 0.07957974678235287, 0.0786756488773015, 0.0631547912735528, 0.07776383405907682, 0.058078999007647146, 0.0802456985189602, 0.0639013396958249, 0.07935168419936393, 0.07943622829435028, 0.05857603976365375, 0.06708796009392155, 0.07240654721851622, 0.08033728381227197, 0.08056019856688265, 0.07126420951549821, 0.07453557755868877, 0.07818473749002615, 0.07848565009531586, 0.08213782372430802, 0.07965700764053123, 0.06631721095122707, 0.07684995157792528, 0.06531161088365055, 0.07642929469271408, 0.08475939175239414, 0.06622588973675822, 0.08182479161036563, 0.05555530821252571, 0.08127882120175395, 0.060632722730968806, 0.06359505436729931, 0.06380039547395214, 0.07934968650951445, 0.07813232560606519, 0.06222293307019654, 0.06909003192819893, 0.0725908936615102, 0.07514733885822045, 0.07786989796007625, 0.07881011867040627, 0.04929053512006323, 0.07868183871792474, 0.07819818905657605, 0.07989626157369116, 0.07906272075289335, 0.0666606228781182, 0.07837065357637168, 0.069562102856991, 0.06035590334206145, 0.0811853946236618, 0.0786473252499465, 0.06400468899557928, 0.0736472951584637, 0.06523577317955116, 0.08316365162087924, 0.07398693861274114, 0.0671259447116891, 0.07758401984377504, 0.08059661218489456, 0.06620630828865497, 0.06522096250782894, 0.06476843099123115, 0.0776235063551395, 0.061491880991388595, 0.06790935221123454, 0.08172759783993963, 0.059526067443831564, 0.07489869653849922, 0.060286695889070756, 0.06550462191252855, 0.06914004268458913, 0.06718876042268368, 0.07501068838609891, 0.08300989819981802, 0.07002605078026425, 0.07603859323246734, 0.06514841483185413, 0.06608204316741303, 0.06633202652883201, 0.07928326536579314, 0.0789875873029734, 0.06501668545685484, 0.0657034354559691, 0.06819637881035798, 0.08137513646848601, 0.07674183252870222, 0.07959493261556602, 0.0804344251816576, 0.0807757209964813, 0.08133304102486853, 0.07165584792680973, 0.06082459947961195, 0.07146562584350685, 0.07048347358237075, 0.07078064727076785, 0.07470623038063226, 0.07914496765861027, 0.06643125493564224, 0.06376809192465072, 0.07962049273529435, 0.07420865741006272, 0.06359993987846886, 0.0588607774226175, 0.08314617473307388, 0.08024757404012674, 0.07766314718276841, 0.06028529582423078, 0.07492801681423693, 0.0780787519212974, 0.06319573533140017, 0.06906163442858808, 0.06641240789740534, 0.05535038794447084, 0.07723972043671518, 0.062139541869540356, 0.07763816055532588, 0.06811322870816713, 0.08093616509847427, 0.08038302049005477, 0.07832516491011249, 0.06449998712256458, 0.06456604665983302, 0.07693461247154741, 0.06222127153130669, 0.06451542425679381, 0.07948074856364923, 0.07058062937662586, 0.06233485933531564, 0.07219368710204772, 0.06643133020957152, 0.0810846181326423, 0.08033978027452786, 0.0702813104025501, 0.07786492094673288, 0.07684717977616151, 0.06724734700554988, 0.06551551474808288, 0.08390657252601842, 0.06776861076623053, 0.078818936693731, 0.06719815725990165, 0.07561478866149356, 0.06941810213061064, 0.0797250144633515, 0.06486410893203592, 0.06202572684569256, 0.056326638557969835, 0.06375998812410999, 0.07157570389164074, 0.07747587972952254, 0.06878653791777192, 0.06478036517985027, 0.07849030709098499, 0.08142628612463079, 0.07483291107441654, 0.08030581650531371, 0.08384468893990635, 0.07836556847169077, 0.07664364505712486, 0.07835785665146773, 0.08001298391247769, 0.07699744163599086, 0.07400317844394667, 0.06468959235819445, 0.07167957985835259, 0.06322676177498467, 0.057040359930104256, 0.06504824401620875, 0.07039480881275499, 0.06364865630682429, 0.07778920157760104, 0.07680088138664197, 0.06606469418771835, 0.07411858496922571, 0.04995314299635106, 0.062148040104089766, 0.08116635521392028, 0.07434233110832406, 0.07609931701213614, 0.06384187706504516, 0.07043243859742201, 0.06047445311726338, 0.0736054812777351, 0.06885418405076543, 0.07837727459609546, 0.07814306662364465, 0.062253123761118384, 0.0738019576386258, 0.07073433622914627, 0.0794920381685635, 0.07670526698920864, 0.07508233887729594, 0.05689945055835833, 0.08151347002842957, 0.07966511845984493, 0.06148870094680593, 0.06758469199328332, 0.0630605223267196, 0.06807952337188437, 0.0712675431410333, 0.07896598124877818, 0.06202793172412111, 0.08190544421835316, 0.07838090137849615, 0.05870425240971818, 0.06522033488096761, 0.0795702728865718, 0.07399204779832487, 0.0813594128772945, 0.07663228552557734, 0.08060906072236437, 0.07787719051207459, 0.06761361189998166, 0.08024411288427034, 0.07031958805011361, 0.07943236349372296, 0.07851800204950526, 0.0672296614537545, 0.07013010614330718, 0.08237745903934639, 0.07486867968112514, 0.06934829818545185, 0.0742840154910235, 0.07601851652394732, 0.060005404957801683, 0.07876076164456106, 0.06273216498394489, 0.06403523863064464, 0.06949963734878345, 0.06917261414804138, 0.08123621487082015, 0.07101602094074229, 0.0815678912753586, 0.0658507030030153, 0.08148186732362685, 0.06760379813810864, 0.06089629532680366, 0.0633542559996813, 0.07557725976065502, 0.07987432074884028, 0.0716590978505268, 0.06558568120878303, 0.07829263626336201, 0.0675941519568254, 0.0732946285971546, 0.06570624537269036, 0.07992038019808771, 0.06930594526662692, 0.08234500750125007, 0.08119071265357734, 0.06996301966947789, 0.07967523852020826, 0.06912061381392089, 0.07834733865176388, 0.07042492006770089, 0.06901187000658615, 0.07337390740957794, 0.0667871821616257, 0.07978561132651281, 0.07815951175098951, 0.0715994746257978, 0.0755153953310375, 0.07634661510103595, 0.07491933382606317, 0.07897182445798571, 0.07766860333905765, 0.0766941678040837, 0.0772949631416546, 0.07739751897665, 0.0791308570346215, 0.06157344491352047, 0.06262942012590031, 0.07618100436166347, 0.05901762965570568, 0.06751787648301598, 0.07792779403238535, 0.07951429316635529, 0.06665202921453366, 0.08297923136429483, 0.07297591262400203, 0.07002229615067943, 0.07765103607920783, 0.08059550456243114, 0.07764665930810583, 0.0643675587713106, 0.06338217678538233, 0.06625513898365547, 0.06230019200449457, 0.08133566773103991, 0.0570974453931667, 0.06429272371609179, 0.064193423831406, 0.060483719486823045, 0.07951610272842385, 0.07943230484698843, 0.08079032221620797, 0.07936928268042054, 0.0622526940243687, 0.0713113447295552, 0.06405998180114922, 0.07832872201716777, 0.08050430774643537, 0.07894086557714802, 0.07560953477061187, 0.07555548911898752, 0.0783984383768737, 0.07924710871666583, 0.07738104867379009, 0.0727029244569629, 0.061226176704647244, 0.08088169979875777, 0.061711492539966675, 0.06456014847645897, 0.058945687108346065, 0.06159933262028539, 0.07333686323424755, 0.06377594395262921, 0.06694403529428285, 0.07701965166603861, 0.08030634211596338, 0.08023073915926175, 0.07971349455764279, 0.0642521366943888, 0.06733178225474375, 0.06439503533646783, 0.08315107318847673, 0.07733613567635834, 0.07792042494476994, 0.06375990704662256, 0.06675638643622536, 0.06586938767430028, 0.07346250819516476, 0.066566439917211, 0.07087506923211018, 0.07859979561226216, 0.07011742836032973, 0.06410119145952996, 0.07235771874762909, 0.0627709807277666, 0.08381492804754395, 0.06554526415039856, 0.07800790655383229, 0.07048509546164461, 0.07579508307892341, 0.07758474074305738, 0.059397475029533145, 0.07046029633407853, 0.08279729886914565, 0.07264740921909787, 0.08212092614813364, 0.07891905921269525, 0.0728505528556391, 0.07648227677512977, 0.06032757774165499, 0.07822198338191912, 0.058733395486970895, 0.07319863906626882, 0.06469767555445045, 0.08178243038360467, 0.06569385372956493, 0.0754829759786767, 0.07990948733470422, 0.08085654739307124, 0.06635148202948028, 0.08455353117659577, 0.07887646440631559, 0.08091757033109943, 0.06815790889362423, 0.07664265580028465, 0.08074438065506875, 0.06232313277286974, 0.08162417093355523, 0.07953531094244021, 0.08197481179835171, 0.0806074431851658, 0.0723601840909053, 0.07782312557667055, 0.06088152430328233, 0.07931856552995128, 0.05613589181051358, 0.07930656245426056, 0.07585708423888311, 0.06876428072114635, 0.061346061821072585, 0.076234291107832, 0.08033408287784072, 0.07889326062404352, 0.07431179836459141, 0.06822785611655667, 0.066946364815688, 0.0789092317716085, 0.06820528100917951, 0.0655331557852288, 0.07535858925985812, 0.08021844630040388, 0.06247186613980272, 0.07859051880838368, 0.06813781679216671, 0.08063541344840093, 0.0659908261016547, 0.06962356942888895, 0.07975149114315581, 0.06880491928651775, 0.08052549912309892, 0.08317459091447195, 0.07588032083770298, 0.07320352213490242, 0.06494882121662741, 0.07204327143083294, 0.08072248405921018, 0.07151165708418213, 0.06390808599493943, 0.07629592084904391, 0.07977589084387467, 0.06251266698651377, 0.08115715027825739, 0.0692189037744164, 0.0694613229779076, 0.08116273587588461, 0.08062869695129012, 0.062065624504646935, 0.05811029119465073, 0.06451507657951061, 0.07847359152118338, 0.06969498953436519, 0.07329262956058187, 0.06502345012788904, 0.0757945207403572, 0.08003711535626597, 0.07920201521245811, 0.07901169190760186, 0.06532545034170406, 0.08244930650616536, 0.07907908249825617, 0.08168862405752068, 0.06177776425195597, 0.07628054870626373, 0.0650195909520638, 0.06863087714340614, 0.0653935189719282, 0.060896883046598176, 0.07331381764154157, 0.0854013688479521, 0.06664596658542687, 0.06394296443502959, 0.06602909158231968, 0.06981320847830232, 0.07482341874285811, 0.06247881935343238, 0.07827760576465814, 0.06662038182239965, 0.0834838407417785, 0.08015888149849064, 0.07461350012527186, 0.0806005299671888, 0.08058979865291717, 0.062472651284474, 0.06735835951990128, 0.06643135578706848, 0.06563564624362632, 0.06293511088150272, 0.05688258248079457, 0.07733428483137472, 0.0622972709902908, 0.06458323425825255, 0.062146570215444966, 0.07760152804691037, 0.06732705755411175, 0.06515239386893507, 0.06527686002053783, 0.05692717563970266, 0.06582270319987733, 0.0765636150678956, 0.06379810076243299, 0.0650505771762274, 0.06175543244145052, 0.06750653878375097, 0.07162702357633308, 0.07934149826285383, 0.07218648038808871, 0.08020336360393106, 0.05956960025041035, 0.07839585867213424, 0.0805224612096863, 0.07183982233490804, 0.07974325536706202, 0.06551510318258925, 0.06695220008237147, 0.08022208682981907, 0.08048538693055825, 0.06439404734552931, 0.07821256709008824, 0.06748264148724875, 0.06357370970538294, 0.06829114549532306, 0.06675730964722185, 0.07402309504519262, 0.061558387878926826, 0.06826376577507375, 0.07921420907414037, 0.07019979497952182, 0.07320636087538236, 0.07967510166294656, 0.07546783594235712, 0.06898554920650732, 0.06389548401481375, 0.07881499427247653, 0.057687440925162155, 0.06120137771149834, 0.0804175410112447, 0.0792222334431684, 0.07770594058171909, 0.07066057252760359, 0.05840867623794627, 0.05044406064978121, 0.06823721684502337, 0.06653956845327594, 0.08257089045394235, 0.07857572497968839, 0.08135442138916098, 0.07657407698516631, 0.07496825202157678, 0.0685321958064784, 0.0714800408542115, 0.06781238202840972, 0.08271566127176035, 0.08080190522509287, 0.08206625832757515, 0.0798560861452671, 0.07834775592443706, 0.05969857377285834, 0.07329085868815098, 0.0641597028776048, 0.06578757004363404, 0.07840854811753202, 0.07578503653118038, 0.07599847805621159, 0.0773656316124811, 0.06918902661371176, 0.07873001798034632, 0.07256772333925529, 0.08019989224403458, 0.08014839772369715, 0.08059345931440277, 0.06212933303137879, 0.07655944836438283, 0.06598571543192029, 0.07967098840882361, 0.06712649823163527, 0.07692254928025624, 0.08412695516605484, 0.06866444250233027, 0.07649507897689631, 0.0790837459979067, 0.05757762696234272, 0.06978251610840136, 0.06563607905542715, 0.0661413393832231, 0.07125298455263634, 0.06199856636491135, 0.08029620420332163, 0.06499956251973493, 0.08105387660182231, 0.07465370865223593, 0.08003250903068528, 0.07947915187207523, 0.07619830178993123, 0.0710964006836795, 0.06642135897511783, 0.060355679513295055, 0.07967851031146014, 0.06450198919046163, 0.06334663721202581, 0.07820068963062211, 0.06815711597022905, 0.07019186720655517, 0.08313168712859068, 0.0784637497303169, 0.07220446964839412, 0.0714695649119773, 0.06692427557303862, 0.057382760099820435, 0.07904245265605672, 0.07848831033697397, 0.07015635777617818, 0.06960995544009245, 0.08035840791050348, 0.06795043840329514, 0.06472130006363193, 0.07955474050794277, 0.08030952216545678, 0.060761630599804266, 0.06822137152961305, 0.07519138824404714, 0.080976516891333, 0.07819363072695218, 0.0635198587175733, 0.0799029088434042, 0.08052096565221666, 0.07495077675337286, 0.07792759862338891, 0.061302603121932434, 0.06743191087718911, 0.08092606761354809, 0.06775366594062286, 0.07025141911165657, 0.06456027861150491, 0.06231300775595603, 0.062397476604834405, 0.07878181301298619, 0.0659349286278781, 0.08118464687070605, 0.06828122350609878, 0.06562631486366759, 0.06841613569681015, 0.08033224828824005, 0.07924229256242524, 0.07910059333941137, 0.07204018333755788, 0.0799889406917793, 0.07770022991855405, 0.06464910188202412, 0.06362990614865513, 0.081297730703625, 0.0747764221685327, 0.0753151604661609, 0.06982514791626743, 0.06994666221230257, 0.06487279031424024, 0.05348777094300787, 0.0801050178362934, 0.08095600257180616, 0.06370208087029544, 0.07902467658230264, 0.06833967698859288, 0.07932803586592073, 0.07883472751568224, 0.08158254120768091, 0.06599654461345845, 0.08140442427508252, 0.07873537166130704, 0.06898525198349732, 0.06347228028484218, 0.07530940167792309, 0.07942715773520179, 0.08414682007050293, 0.07987263454618504, 0.07137601635190687, 0.06732383626770388, 0.07888101645541461, 0.06374716913565191, 0.06999799175062464, 0.07739049677385779, 0.07918392726386113, 0.06764735909499446, 0.056999359770718384, 0.07859955526979681, 0.07970116065322914, 0.07594230976575939, 0.06740133201200293, 0.07846536720007108, 0.06773931612843051, 0.0728735542067708, 0.06908345830252563, 0.06685292535734721, 0.07908023025085882, 0.08111260235172697, 0.0684932172867092, 0.06903871015906009, 0.06723228111423922, 0.07854584524576433, 0.06127046307643367, 0.07833798226582278, 0.07203013640168815, 0.06426539614059823, 0.07982614599101777, 0.06269657577756382, 0.07281938885995877, 0.07824937519759163, 0.0667060308305816, 0.07875805368506002, 0.0655425328872793, 0.06703457739167064, 0.08094242494795882, 0.07273476173011686, 0.07534812149568529, 0.07995041278180766, 0.07278634530791894, 0.08033814917502846, 0.07110062908678756, 0.07090326654471095, 0.07630644472357746, 0.06708376714523781, 0.06011617657694611, 0.06764555012614912, 0.06300810033915415, 0.07526956489819377, 0.06117485154149664, 0.06626499826137361, 0.052938375674980685, 0.0789745012795867, 0.07088901939489867, 0.07821941494182587, 0.0732985055806947, 0.05958141890680096, 0.08037085592049188, 0.07956628943374457, 0.07693368448109905, 0.07658798235282079, 0.08003252834062072, 0.07830421876652364, 0.07868001247482012, 0.06782863358090137, 0.05853342215415088, 0.0722544369872024, 0.057230444405964975, 0.07505890568592692, 0.07803786211795334, 0.07150197953105077, 0.07701436707847847, 0.06963738204442267, 0.06320831531877358, 0.06656806249399129, 0.07271866548165905, 0.08014207599558179, 0.07561570890328675, 0.07951647734281521, 0.08318257911370143, 0.08066130961158972, 0.07995533215105537, 0.08272104312328273, 0.06113706394688197, 0.06718908232699142, 0.0685440859443693, 0.059222539587202756, 0.0827832385869058, 0.07365882770477221, 0.06328592668553953, 0.07962024505003085, 0.05950355679665049, 0.060995393029123456, 0.06783786395431415, 0.08595008482361562, 0.07903382926164548, 0.06380583398364569, 0.08046797830787686, 0.06468993290638189, 0.0730347257229894, 0.07189599738863427, 0.07573184906278019, 0.06572999059511261, 0.07924870150480377, 0.08157952395685432, 0.07842242154294554, 0.08066145293284885, 0.07062956820268057, 0.060206807404534664, 0.07267607827156809, 0.08026014942258874, 0.0749143197909607, 0.06234731942247329, 0.07493960425346619, 0.06761708328095713, 0.06594361581358485, 0.0612506721414602, 0.0710334892417542, 0.07418814605815524, 0.05827140978095506, 0.07912223251810643, 0.07872371721567846, 0.07449808843217771, 0.06504867314629725, 0.06407542115989706, 0.08053946054181721, 0.06834889574240816, 0.07876142076790556, 0.06834084221315401, 0.0790446909242086, 0.06500717111025008, 0.06893483373288302, 0.08111936175242915, 0.07980176721689894, 0.06904165038446461, 0.08692594750821249, 0.08004046529075413, 0.08102689481552415, 0.06718428157750504, 0.07939673542837097, 0.06738487797824068, 0.060966011969174075, 0.06436880996599398, 0.06917540057681255, 0.07761445884260189, 0.07824049510049504, 0.07807013481775735, 0.07969426827960445, 0.08163711208262427, 0.0784004085419648, 0.06758737605793068, 0.0676904267874659, 0.07585177078589146, 0.07809830274323895, 0.0683695948028014, 0.055617352148590045, 0.07257095090560958, 0.06008046603251653, 0.0655870508308813, 0.07658259232895713, 0.05440893595634162, 0.061486012587349106, 0.06533225722931739, 0.08048936721944812, 0.06420045763955261, 0.06764273634004335, 0.07424501215232299, 0.07954336313076213, 0.0737021903126573, 0.06451102603172393, 0.059812580111330206, 0.0808625576705528, 0.07923858269043317, 0.06647988651589436, 0.06980578122003923, 0.07955540328884946, 0.06443691143247086, 0.07811477860506183, 0.060547548525046554, 0.0762341338130241, 0.0632729431892313, 0.06888293341916611, 0.08095319910101471, 0.07887959857050697, 0.07332392844502014, 0.07627905116991103, 0.06309408909341073, 0.06683713102863316, 0.05669977997196279, 0.08164712875359374, 0.07302449085212345, 0.06263059507146418, 0.07647357919297648, 0.06697352906720216, 0.06779704107723704, 0.0649830222212459, 0.08158038917315882, 0.06386699803400901, 0.06507217496126286, 0.06473095355112606, 0.08073247742711633, 0.08011540905737438, 0.07291668800075858, 0.07415474238188524, 0.06942822741752758, 0.08136817841642913, 0.08077700356523812, 0.05961324519352505, 0.05309681178235134, 0.0760531181170267, 0.07224965498254943, 0.08428642783833945, 0.07031324789066914, 0.07952801941451414, 0.07940535589280899, 0.06295412061109604, 0.06376767962901395, 0.07124373432111127, 0.07860880652925803, 0.06554705681179257, 0.0644040465755903, 0.0772595301899222, 0.06903742744310172, 0.08242302688981103, 0.07927852055115164, 0.07948564875512519, 0.058526498038753476, 0.06922551987190712, 0.06062159918348856, 0.06019853210065136, 0.06537177703212604, 0.07710508256612902, 0.0702958161122135, 0.08076005240650673, 0.06586397830680515, 0.07615131575123382, 0.06783073639682932, 0.0579611037563128, 0.06431462359253841, 0.07930963240380041, 0.06915098730123016, 0.06678764153236108, 0.0671315597662648, 0.06672791593390397, 0.06522483434518699, 0.07639945841810086, 0.06722529079745615, 0.05365002763866894, 0.06511225259174516, 0.07933889802795575, 0.07298339264021887, 0.07804826446952216, 0.06479775984502564, 0.06277198873643143, 0.06109839653493427, 0.07234184027360152, 0.07824413751914179, 0.07718676448678664, 0.06952309319165939, 0.07916522606303011, 0.0820608807199898, 0.0817818149234487, 0.05955051793807887, 0.08137284799678636, 0.06458364661717916, 0.05892942676022231, 0.061292650813391525, 0.07308257542804636, 0.0640786480544568, 0.0702240895012785, 0.08258331815232497, 0.06555640146018482, 0.07687893849056571, 0.07179263738180947, 0.08122646370635074, 0.07050695450571089, 0.06440492194284442, 0.07682121677732494, 0.0778227197826136, 0.07182537483377417, 0.07922928838695495, 0.07308773671473413, 0.07061945488732829, 0.07841201702408902, 0.08389921629917997, 0.0762258815194812, 0.06410617841283507, 0.07492242646388068, 0.07972996843037505, 0.08463849967722106, 0.07996356162446988, 0.07438305234244397, 0.06797571171885207, 0.08039870596108192, 0.07797516881769113, 0.06213125706532142, 0.08031199309645716, 0.06111296734597191, 0.06643363761212996, 0.07867938979483258, 0.08056223353450878, 0.07734659905380721, 0.0701772275823181, 0.06708696172821496, 0.059953050807133736, 0.08058922943143805, 0.06914531338410314, 0.06574179813868172, 0.07547253731193251, 0.07099473955182589, 0.06229512014020098, 0.0646374337394341, 0.05995425274369291, 0.08165625191896782, 0.059947112778870555, 0.0806814810195219, 0.07571256540919898, 0.06667982353368092, 0.07865146527766348, 0.0658411920148953, 0.06710579255221373, 0.0755090969090919, 0.07463475925179491, 0.06717309760539941, 0.07942334824997477, 0.06298753591799938, 0.06641807639170351, 0.062258134026485154, 0.07139626446719105, 0.0693952051322712, 0.06635887118730438, 0.06230050091636932, 0.07974160168043987, 0.08104227067025442, 0.07686410511692095, 0.06423219336716549, 0.07791143802561891, 0.07880994123826913, 0.06875186053633227, 0.08297442420081297, 0.06281134172636717, 0.06988111647838333, 0.06564807970020037, 0.06534697989205962, 0.06831203867094073, 0.08022419717000753, 0.07228694506240826, 0.06866713917008099, 0.06608485906390223, 0.0639633924965303, 0.08006985157333599, 0.06915010667233801, 0.08069686407695026, 0.06958337376891326, 0.07694499529307103, 0.08016822189051873, 0.0805739439246646, 0.06614451178771381, 0.07836944068491213, 0.06877773285945105, 0.06598442245981376, 0.0800035273910773, 0.07429554256140776, 0.07842298136622262, 0.07932747508060091, 0.07972152764234802, 0.07456129548754707, 0.08011087578188192, 0.07945630706092334, 0.06383340864436587, 0.07579835010906828, 0.07779553023053916, 0.061186709988403164, 0.08231178605256738, 0.08109493024892188, 0.06759620340329577, 0.07819805017044743, 0.07870355145056016, 0.06597541390775673, 0.08471721490983262, 0.07963248286467374, 0.061321355812574946, 0.0688815747226329, 0.07566182424720785, 0.05700254132703629, 0.060829502759659176, 0.0787816946630441, 0.06489232448599651, 0.07765707320035928, 0.08084281953402576, 0.07698298484223692, 0.08329216484508437, 0.0591879059112144, 0.07878910678349198, 0.06207636842794048, 0.07231989746002758, 0.06821027052504237, 0.08038507546038193, 0.06728393083450505, 0.07461904701513773, 0.07669820924680551, 0.06902002322025498, 0.07229748052904399, 0.06826492200910422, 0.08414098644016649, 0.06284194251053563, 0.08334609662109974, 0.06943371014894768, 0.06682155188712588, 0.06241521766411353, 0.06642259660906064, 0.07919696786864437, 0.07827725268492922, 0.07961514165232432, 0.07739135831602457, 0.06674863894931819, 0.06232465729288393, 0.06623558202307707, 0.08040286591948298, 0.07425429701397471, 0.06502869115196222, 0.07677725304251669, 0.0642946545912632, 0.07829938223536381, 0.06826850963298085, 0.07082250010241296, 0.0804997467126685, 0.08152374263813422, 0.07321819641498442, 0.08062045289116439, 0.07183356983310549, 0.08032998018164574, 0.07924247330211559, 0.08282911453550904, 0.06076247905919464, 0.06519104708267777, 0.08146580294367858, 0.0761209180288326, 0.05728740944427169, 0.07886912527401396, 0.07937170205807591, 0.05627033460345179, 0.06602873218747056, 0.06553240016024468, 0.07858420640214105, 0.08191900991781431, 0.06704415228493119, 0.07868053959292126, 0.06392762027474848, 0.06705630459652051, 0.07842398885669558, 0.06848670911934665, 0.05908592637369009, 0.06760004579355089, 0.07935553398652523, 0.0657541433324088, 0.0739792279797467, 0.07974093028940178, 0.08240032471452655, 0.07799918565067139, 0.06550599622206546, 0.0800471781675026, 0.08028738141251329, 0.0646660827558791, 0.07349673411260228, 0.06993342215554861, 0.07946326142140271, 0.07803991434159467, 0.06287287183336805, 0.07775978853349418, 0.0771987042224178, 0.07482478822338029, 0.06370586929505997, 0.08213894330939932, 0.06923951622532609, 0.07663946446493322, 0.081098396979309, 0.06809544387721296, 0.05653787558955533, 0.07734350536214134, 0.0737951951041066, 0.07700968127996419, 0.06732104735043574, 0.06066919692912454, 0.07397443594505523, 0.06718018568814212, 0.06923720148274684, 0.0643458560995872, 0.06845118872051241, 0.07233883371942038, 0.0603292575365104, 0.08043416815130744, 0.07995898823376403, 0.06768704907381709, 0.06997549878840796, 0.0677016852267422, 0.07711942237088253, 0.08266428189509704, 0.08278427034349334, 0.06791159226067475, 0.07382968510338163, 0.0743714065919211, 0.07498836534122547, 0.07943101384898908, 0.07499434722146256, 0.06855239293545712, 0.06351827814880932, 0.08374346661668652, 0.06744454819923178, 0.0708643439405757, 0.06724028667233442, 0.0690671943317081, 0.07823609005756701, 0.06603903797328879, 0.08042549529423167, 0.05502411385244804, 0.07703911777653095, 0.07640376062632334, 0.08091435533596784, 0.070666696351068, 0.06478596262188088, 0.07952593267726557, 0.07267363957349617, 0.07052256968395812, 0.06717872904593851, 0.07332267416492405, 0.06214602861754418, 0.06903319574211972, 0.06457658164270999, 0.06569273946024166, 0.06380897174392348, 0.0677314202868403, 0.06717410480384291, 0.06030901387870357, 0.07953328671503268, 0.06447132665546536, 0.0802345735948772, 0.0798374628931334, 0.08002100945746696, 0.06524970442777411, 0.07025388659152676, 0.07230949798365553, 0.07246322422595831, 0.0802182725879716, 0.07311202873665702, 0.06085311870111416, 0.07900386532606499, 0.06095631031014621, 0.07016732633211613, 0.06562590836717626, 0.07772318167023548, 0.06507391998205625, 0.07964779220850815, 0.08008806359626303, 0.07983041091785527, 0.06647683157026557, 0.07952565790116431, 0.0759600409720715, 0.08426934443711057, 0.07311593507091556, 0.06933983580618637, 0.0774614218335778, 0.06348814145162603, 0.06354869729036174, 0.07913517106119626, 0.06988093387372715, 0.06615344619267625, 0.06802457351647115, 0.06636254448353238, 0.07021530412743265, 0.0770045742655762, 0.0777218282787422, 0.08019314933951731, 0.06872460418997667, 0.06184713521234308, 0.0762536548892624, 0.07930664135906393, 0.06963668818941186, 0.08064133180971342, 0.06731255745903808, 0.08506489570547328, 0.06584474354485252, 0.07896688095686888, 0.0644167921152775, 0.07696043920926274, 0.05871400437091882, 0.07920309914900582, 0.059815679139793826, 0.08149691335122776, 0.06538186840461468, 0.07096885720817685, 0.06691411367724409, 0.07894831418261065, 0.06138414437040647, 0.07593367619331237, 0.06934574827578557, 0.07874582297084247, 0.06892862723845064, 0.07842516486145189, 0.08005903113896981, 0.06608018933241953, 0.07979350668223871, 0.0657450011253563, 0.05677984910876782, 0.07869348287641367, 0.06153459366078553, 0.06108344620388957, 0.06868806090643433, 0.0821091111517253, 0.07005955945522285, 0.07188138293364404, 0.08296759292542129, 0.08088246413963665, 0.06726150300105117, 0.07954382104243606, 0.06597028327190382, 0.08006368314600655, 0.06900556593047277, 0.07359008128780924, 0.07926989460282022, 0.062954555064162, 0.055518863264137554, 0.07630551758154697, 0.07972143824828648, 0.05758910863365325, 0.07558583500118772, 0.06118009513871747, 0.07975082600282772, 0.0797049117367148, 0.0617447147694227, 0.06652524978926752, 0.07827549388268903, 0.07840333136720339, 0.07938967725149298, 0.0791087904925721, 0.0835695882345471, 0.06987787461580475, 0.07867013245472039, 0.07780725133250369, 0.07155086322948301, 0.07071767455480785, 0.07864424077615506, 0.06474389573345114, 0.07715560325002875, 0.06311293417230929, 0.07083136789838372, 0.07780269218477578, 0.07460547523366473, 0.08016672124191626, 0.08019516840534796, 0.0762635655819107, 0.07783188199793215, 0.07919130591984216, 0.07404806855656637, 0.06816270454703682, 0.06362198186167192, 0.07846360232580012, 0.061618691297898875, 0.06275091477800816, 0.08109670210417642, 0.0659945105196033, 0.07626115568085504, 0.05929624915703646, 0.06548568135520315, 0.08013321479736098, 0.06626889845430553, 0.0703903673291354, 0.0791897775871001, 0.07590994602659155, 0.08222193348844682, 0.08057776002960386, 0.07732426651444485, 0.07200452820108859, 0.06749849257793603, 0.07024344779493688, 0.06659423341207657, 0.05767513239450118, 0.05953500377508896, 0.0642333870158515, 0.06570889915951986, 0.07235547882180351, 0.07850492313496328, 0.05727777216175053, 0.07316415960265976, 0.06456891562512165, 0.07944097252356758, 0.07095256649514335, 0.07081877717646937, 0.07613073797101302, 0.06571177276691396, 0.0794612523918134, 0.07697376037721525, 0.05188456541748103, 0.08088599523706314, 0.07761488593999116, 0.06672287343250245, 0.0628461430160118, 0.07333376108813464, 0.07984965530762964, 0.06168985015593432, 0.07007820171909387, 0.08138173019133764, 0.06455096012362575, 0.07437628840953794, 0.05781137970011462, 0.07725628954140006, 0.0792204036786438, 0.07876550583908293, 0.06053640979198161, 0.0765449423021354, 0.06791450705240891, 0.07069984576290873, 0.06995041018479546, 0.05909622179115426, 0.07088903339375006, 0.07850478896453178, 0.07239650540315394, 0.06698044197633185, 0.07417727783727586, 0.06954421351664515, 0.06274011067268795, 0.06259441452766369, 0.0556914195431333, 0.07684560767672151, 0.0644782782734145, 0.06960055145616767, 0.07472748214706372, 0.07053436542879446, 0.07875772953816616, 0.07476435132622272, 0.06975053973555118, 0.06654362142402738, 0.06745897531076865, 0.081913857380178, 0.08022653667181937, 0.07921579269470579, 0.06177213288748845, 0.0582913451349559, 0.07978550151358084, 0.06885934590786219, 0.0628385607327556, 0.07960338386023319, 0.08333954215326253, 0.07976841070904601, 0.07719128537218717, 0.06945152129490187, 0.08196422381016495, 0.07770585393204177, 0.06628697071388663, 0.07926127154852068, 0.06499737148972769, 0.0663030476658412, 0.07924328371238783, 0.07881103856377362, 0.0788228668649217, 0.07263163563917556, 0.07842160022584552, 0.07941936428528162, 0.06367227506168582, 0.06333938480146148, 0.083640352599635, 0.08412337045066014, 0.07754031845992843, 0.0655212835443059, 0.08068868503622965, 0.058919995129412775, 0.07864848764110184, 0.0630481517394543, 0.06311746049704248, 0.06339144103067777, 0.06752571014523921, 0.07639762556445573, 0.0649645104161892, 0.0692994766636529, 0.07715913357651187, 0.07589407639511977, 0.06965857784505262, 0.066293284830992, 0.06885009366208406, 0.0745843467142144, 0.07295297645027637, 0.0785524209969759, 0.06147839099997097, 0.07055386911207463, 0.08063119569264039, 0.08042844411849749, 0.07022402404953479, 0.07953264973259386, 0.06772764189538567, 0.0789954560847043, 0.08076877398563492, 0.06313572734464834, 0.08046261367715037, 0.07030099431390305, 0.07900596271803081, 0.071670633551805, 0.08277979105020068, 0.08047655116263906, 0.0598759325517118, 0.08142261348421817, 0.0716637319262346, 0.06713242160719829, 0.08251991490151302, 0.08069699776621746, 0.07957199592288408, 0.06171691826923022, 0.07926112731334718, 0.07602495879576449, 0.07126096232503823, 0.07957960122565802, 0.06520819856788707, 0.06616020540650405, 0.08214068180761572, 0.06695344082661234, 0.06883795558218173, 0.06997487739749744, 0.06778509255462133, 0.05595558705942826, 0.06590509591714448, 0.059756043387104996, 0.07814459343525264, 0.08014152142081828, 0.062277544313180555, 0.08171043259191045, 0.07981503537716762, 0.07689288493141369, 0.07276018169838522, 0.07600082735792926, 0.07669401564848029, 0.08058329086712636, 0.06760930445721504, 0.06802314459348313, 0.07728136935926459, 0.06735446370376832, 0.06343994219970626, 0.06922716412406843, 0.07476861662664488, 0.06729704803437042, 0.08184982264177396, 0.08015821788456876, 0.08070092898829863, 0.0653465446949821, 0.06367495503945837, 0.07890902973275984, 0.06469502617036033, 0.08058649116259659, 0.0680983161024499, 0.07902981407846614, 0.06738237348335717, 0.0780487110602578, 0.0716769655705586, 0.06996497664332452, 0.07443940036414581, 0.07732583928325905, 0.05853631609677069, 0.06652660526296099, 0.08319157243719813, 0.07110299934176698, 0.07300478615117646, 0.08005719278447215, 0.07896734380248531, 0.08262390377901936, 0.07740236782338787, 0.08024743816414885, 0.08013017574414807, 0.06516170296312195, 0.0638976693886993, 0.057839135341309314, 0.07809809574975826, 0.07918495506151171, 0.07869779202107338, 0.06582725480362932, 0.06307983446396177, 0.06649708746734088, 0.08293870079348568, 0.07911921753663857, 0.06294170612714516, 0.07819187069922486, 0.07719760077984401, 0.06993114844858675, 0.06779770182042721, 0.06706969215970902, 0.0687302108711399, 0.07820284050275235, 0.06538333938578711, 0.07994499952403886, 0.062493204697653834, 0.08146143072435655, 0.08237808780877509, 0.06193508773063732, 0.07512225584004559, 0.06012766631394894, 0.07536052759894431, 0.07942851851865243, 0.07729060775092357, 0.08076921790744643, 0.0762582341842442, 0.06758637727809932, 0.08100253826393775, 0.08064395604876434, 0.07946424132605487, 0.07249490061017921, 0.08067890012713001, 0.06639826584522561, 0.06261947921928179, 0.06507874525173624, 0.06688793398531381, 0.07840930561027698, 0.07875670943941945, 0.058301982122614913, 0.08092800763647615, 0.0771682474111227, 0.06382295533094541, 0.06567319929997086, 0.07934720344478804, 0.0707186858852096, 0.06313317832663297, 0.08256421561514661, 0.07602298952136397, 0.06856339271379502, 0.06885587965395928, 0.07711453922724973, 0.06944902374889914, 0.07645647167515827, 0.08295644448712661, 0.07866483380378954, 0.07056744781167872, 0.07456488517041747, 0.07003139259524818, 0.07970780544782674, 0.06537920138018949, 0.08088826066788854, 0.07936507931670468, 0.0729435373961354, 0.07913478107074974, 0.0657085553233258, 0.07112292321560877, 0.08059924985348293, 0.07747889830072303, 0.07291936370103642, 0.06834038023109695, 0.07745294519308908, 0.07424755944075712, 0.0703959287737654, 0.06480532876551638, 0.0795070941406254, 0.07659988674009087, 0.06285671029250266, 0.06695772244514751, 0.0555918328578717, 0.06411391279363828, 0.07682785249767039, 0.0670440638610154, 0.08106130002559046, 0.07156296689304069, 0.06769058264533662, 0.06285903054582823, 0.05973121215914026, 0.06356258619097765, 0.06694287256389564, 0.07522081839484406, 0.06759482231921506, 0.060485533852824694, 0.08169614885393554, 0.08032946432140046, 0.07651509886163703, 0.07873558848535951, 0.0745811597653909, 0.08223725762153315, 0.07752087662379212, 0.06566525268879683, 0.07062197602443746, 0.06392234055261677, 0.06908588231295247, 0.0809112100139721, 0.06032457415740134, 0.07014482361133698, 0.07484019258073843, 0.07828780372784469, 0.08096887727707959, 0.06526911288419063, 0.07153734248099929, 0.08070578151411348, 0.07576959075290021, 0.07856090894580973, 0.07191590554096838, 0.07904344716143868, 0.07822683511241804, 0.06646035870504269, 0.07421236217970326, 0.060849599583719556, 0.06780312612038482, 0.06337691680973667, 0.07890152386069679, 0.07554964291507246, 0.078774137975104, 0.07573598999955515, 0.06296846413650468, 0.08034631909699433, 0.07810414842046205, 0.07717067511972278, 0.06810810976710165, 0.06872115149964496, 0.07951068400307189, 0.08105488459395903, 0.08171909746506639, 0.07432057670966825, 0.06568810175622647, 0.0816677079852225, 0.06852751535307913, 0.06145473323371291, 0.08018219960862576, 0.07918548181504187, 0.06253313725070514, 0.08057409669514436, 0.07279098649904837, 0.08453030060480606, 0.08091170933495405, 0.056087011442048515, 0.06809665928621447, 0.08096273260685617, 0.06349536098222526, 0.06662394618708967, 0.061880256859926, 0.08085163709328483, 0.0666867094972237, 0.06959483489147211, 0.062429831327374265, 0.07830141070797403, 0.07922770430913975, 0.06489985088467427, 0.05773109463037214, 0.07489638838334697, 0.06434541842292403, 0.07899369531204263, 0.07818725489762796, 0.08165018726294801, 0.06425728489952232, 0.06554565813758742, 0.058907223064493, 0.060472147016676386, 0.07514154982860213, 0.0540887670290191, 0.07301259307679037, 0.06650270435462857, 0.05551741903017035, 0.06692604299698886, 0.08073578317457132, 0.06445766092095123, 0.08142524739089432, 0.05789999839568528, 0.08025627177350424, 0.08061570877312474, 0.08145063753438404, 0.07492492761026398, 0.08065021660702588, 0.08068338338235476, 0.07035406805125372, 0.07761435689476576, 0.08103611581803875, 0.07861198046265701, 0.06985443479721645, 0.08088812676330762, 0.07927884110136825, 0.06933101405425537, 0.06697324949697674, 0.08562539084027018, 0.06323717609763789, 0.07071832005910629, 0.08026775544859814, 0.058174844284471505, 0.06825960126745564, 0.07885025954713806, 0.06998238965947234, 0.0701674330629874, 0.06894002830330831, 0.06489001802408527, 0.07173381913863774, 0.07771761547565177, 0.07327823109714886, 0.07902716841880028, 0.07833859693260886, 0.061313682355766334, 0.07731158721381794, 0.0773189355450168, 0.07222026023416353, 0.05429519699107084, 0.0789361415617321, 0.06626532452551284, 0.07532555919540061, 0.08029761259867654, 0.06746350476615903, 0.0841339902805473, 0.07390279834002135, 0.07855791908151716, 0.0791866789190083, 0.08103081196103817, 0.061051164269943003, 0.07939715639886633, 0.08065010036702874, 0.0671196542344355, 0.07747942088415709, 0.08126357923587087, 0.06476407891487114, 0.05798862621089192, 0.08138747264441362, 0.06765800883531285, 0.0811157960019314, 0.07361959827815812, 0.06548470502318122, 0.07258991482037946, 0.06299216778841431, 0.08012222160032689, 0.06587214815160958, 0.0803371592470348, 0.06779044699275336, 0.06741367417291899, 0.07307092336344621, 0.08138254410212328, 0.08006400957568517, 0.07871257236374224, 0.0712459957041677, 0.0785412406964325, 0.08090634677500097, 0.07845675493525009, 0.06183002641835338, 0.0824569165241076, 0.08422345914077459, 0.07934517934011823, 0.07867538284468414, 0.0764719613034373, 0.07914542175169315, 0.05860652951167561, 0.06066755433824998, 0.07057624825952874, 0.061592593212821053, 0.07266564825939989, 0.07889724088830989, 0.0668231392025073, 0.0672342088685899, 0.05226809954321632, 0.07833137003238712, 0.06125593174806384, 0.05967538008864382, 0.05763016831656034, 0.07634059980784061, 0.07647744395405566, 0.08219368148411726, 0.07915321865605351, 0.06938698018536417, 0.0677200254968935, 0.08126978615202576, 0.05924378128103071, 0.06862272395382137, 0.05849816724889628, 0.07805195691309702, 0.061703075935174316, 0.08024013202723926, 0.059478143112462425, 0.07319199449445163, 0.05998106890973607, 0.06991422572285916, 0.06806192428337805, 0.07904048239372502, 0.08351131620731628, 0.05358887850540895, 0.07947116404637082, 0.07696167934650337, 0.08006698850611745, 0.07949080304445694, 0.0630075187981866, 0.049408096849307, 0.06625831834936345, 0.05926250365355029, 0.07789896279727097, 0.0692124269446876, 0.0664345482980352, 0.06735636382838278, 0.07669084114253163, 0.06177627065864567, 0.06761639951284486, 0.06293401702242586, 0.0551624140566033, 0.07834683821681597, 0.07283625476451668, 0.07373074314632823, 0.07624132669778072, 0.07423080932995199, 0.08024517507017215, 0.07331038339406236, 0.06446537547276521, 0.08562981805809422, 0.08146243153010782, 0.06480179854663089, 0.05767060652756905, 0.06230736355514668, 0.07923787510467767, 0.0685297742427127, 0.08080386813489945, 0.06664206254564652, 0.064742109023536, 0.0632637566987614, 0.0819816300926178, 0.06838439738989528, 0.06293494954490893, 0.07914363608518389, 0.08001115503761931, 0.06633381083610718, 0.0644365459026472, 0.07721521864304758, 0.057756083910016465, 0.07740902763010003, 0.07594641330682642, 0.07246670544952628, 0.07932638860171777, 0.07994865211570558, 0.06845200414894086, 0.06317132243479437, 0.0797549229365382, 0.06719505376188653, 0.07550448722626905, 0.05856893215815961, 0.06832049517452624, 0.06969434362597725, 0.06415591264420993, 0.07104434914155809, 0.07308648584903402, 0.07267471735189408, 0.07809184632935952, 0.06299965664205666, 0.06040317628695232, 0.06582394654880222, 0.06659647316512178, 0.05943643871418237, 0.07929391586683475, 0.06334423401234897, 0.07767180361947108, 0.08253956351576613, 0.06258478808620176, 0.07832153678675505, 0.079546239641669, 0.0789186304256358, 0.07800030617438154, 0.06749397930944231, 0.07655602036352752, 0.07951240943739066, 0.06814499599422671, 0.06711386506226406, 0.07645658742686728, 0.06676051941851209, 0.08118297425026305, 0.06481816300301214, 0.0802497568897614, 0.0680390242372942, 0.07020778723447123, 0.07170407358780652, 0.07802539796763489, 0.06488899207681724, 0.08181046363410817, 0.07502460876082244, 0.05182197198868707, 0.06935893737843372, 0.06360365087788472, 0.08146040154943279, 0.07337088727878112, 0.07818027334587233, 0.07712718498566506, 0.07954726651572464, 0.08046104486736537, 0.07697082616695404, 0.07879858924487337, 0.06396113123217197, 0.06474903875171881, 0.0677467270109037, 0.08090471238208127, 0.056702449904566556, 0.06458547308533542, 0.06840181985874863, 0.07267041861927431, 0.08251004803127203, 0.07584705026791762, 0.06965718665673755, 0.05999799703001891, 0.06514629114597309, 0.0710215146731056, 0.08264570792255527, 0.07175378072555152, 0.05959564394547683, 0.07966015448436795, 0.0688915688910629, 0.06257623453306295, 0.07117675694684968, 0.07976218802096763, 0.0635916279785713, 0.07886314187425993, 0.07806292898425002, 0.0796913871219489, 0.06217103033530819, 0.06115432409583827, 0.07033482675292597, 0.07938218859580952, 0.08122013972463332, 0.08064445870246907, 0.08099992658481164, 0.07750136013265797, 0.06646670559297665, 0.07783623527493562, 0.07748611178057518, 0.07607984351781531, 0.07116410538765842, 0.07268700993766646, 0.0786682486064583, 0.07878610741680174, 0.08156780455288169, 0.06811281263538399, 0.06083274817555845, 0.07914500952632982, 0.08086745363449684, 0.07885064917751855, 0.07757102501882009, 0.08051939004231588, 0.0640001924343682, 0.07376303034432893, 0.06926708614135932, 0.07602780392093601, 0.07283735589026957, 0.06297817904949615, 0.06666671482769343, 0.05747332065518061, 0.0802756195239865, 0.0707937922343706, 0.06112800641247894, 0.07916778740636003, 0.07143273047543618, 0.0720152124893788, 0.0840758670622243, 0.07526503462323005, 0.07261047951231465, 0.079847265237407, 0.06348835592489013, 0.07722360447502657, 0.0775177250822563, 0.06518150379395171, 0.061950994935315785, 0.07446059644766008, 0.059105710107460824, 0.06451463903604664, 0.07967640819691724, 0.06604554150423743, 0.0820886700401002, 0.06850738278190194, 0.07886884572932618, 0.06631025377233161, 0.08108036619474332, 0.08014820176631235, 0.08011422279289394, 0.0704800061874892, 0.07228573429474969, 0.07803754857095403, 0.06974306964768325, 0.05907118333176764, 0.07782038954672749, 0.06258922145498373, 0.08306022248513613, 0.08179564667995559, 0.06758131703199367, 0.07849864216776338, 0.06858788690746913, 0.07790239294563975, 0.06219939316899505, 0.06449681955800468, 0.06615736635431017, 0.08075111070913028, 0.07031176192230117, 0.0814507108400593, 0.06870713990802575, 0.07034723787910684, 0.08259718498099468, 0.06580845429284281, 0.0790660824717377, 0.07795682838107869, 0.07936988669492394, 0.0754019067239243, 0.06775395830602335, 0.07836070827247003, 0.06665028274961829, 0.06608499880294234, 0.07540235413107624, 0.08293929623430103, 0.07391939010434527, 0.07953147359315521, 0.06453297569765755, 0.07375217666004538, 0.07030946576804839, 0.05899114237917565, 0.07985879972911429, 0.06841016339123297, 0.07936288392688193, 0.07938199727950809, 0.08037941619962231, 0.0730709421799397, 0.0633684089186897, 0.05142488576688075, 0.0796282276058771, 0.06370572232567538, 0.07868871169519134, 0.06641751860119675, 0.07189243772609993, 0.08100774096517126, 0.08244186731527268, 0.08226239292689447, 0.07542028001354462, 0.06309555596304488, 0.07842695357976864, 0.07494861987708591, 0.06542267921531003, 0.07117050208865079, 0.07071741967572158, 0.08123676744050982, 0.07053358726182109, 0.06083655942196391, 0.06490527007112225, 0.06995284478967669, 0.06461050525340496, 0.06512008176958388, 0.07783664801660634, 0.06314938110692417, 0.061864667618073584, 0.07842859008261689, 0.0626104795788057, 0.06121580098904769, 0.08174694370860895, 0.07907667977944699, 0.07042776240204425, 0.06469940669424912, 0.059281668408006895, 0.07928211288399703, 0.07942786863138772, 0.0722266922941517, 0.06286761103521225, 0.08185360257336612, 0.06166760382821636, 0.06538078013765979, 0.07108668426833663, 0.07895074400340918, 0.07661197696853597, 0.07230727093174408, 0.08007200541888618, 0.07082067948564119, 0.07271784311788632, 0.08029864714597895, 0.07654430689458201, 0.07364763326465945, 0.08088410205838999, 0.07992726719042553, 0.0636628622310542, 0.07762745136228504, 0.06684875549867904, 0.06875620248080028, 0.06715105847949304, 0.0664571253237959, 0.0798326606258525, 0.07829231304461583, 0.07582782172739637, 0.07224497006049205, 0.06287207521065395, 0.06768261210664005, 0.07057222316958113, 0.07862628906242607, 0.07999799290069451, 0.05952213641348749, 0.06562367737306243, 0.07910239167583452, 0.08087258672502748, 0.0627374159574704, 0.07962480346018891, 0.08128225038722826, 0.0662427116092389, 0.07948097274930695, 0.054337182910284755, 0.0826045448716077, 0.07864317114962528, 0.08425139917217016, 0.06401043859691569, 0.0801884081784186, 0.06209405260047629, 0.05886225072439809, 0.07789261721714617, 0.0615512492486114, 0.07859995659129468, 0.07260097808618343, 0.07848088759314677, 0.06344130460454121, 0.06733492494304096, 0.08059300288013699, 0.07324303743761819, 0.08279890582896765, 0.07055715396806603, 0.07036030414049811, 0.07947810322625484, 0.06402804624702053, 0.08460095723590609, 0.08231657109101399, 0.071371659708899, 0.07143666467474746, 0.08026474730364319, 0.07449089740879687, 0.07922181353849872, 0.06011218275401297, 0.08215738050199413, 0.07670134820794483, 0.06416339926045043, 0.06510830809189175, 0.059723957831396834, 0.07718999946370789, 0.07741708741938379, 0.0743821004150767, 0.07924087600844325, 0.06346521914329542, 0.061275018449706245, 0.07402444943422298, 0.06200196209184531, 0.06642596060993543, 0.07223239393339057, 0.07176256411355693, 0.07601011949394229, 0.07959234623843585, 0.06417482796357885, 0.07722015428183719, 0.08724467099468532, 0.06913930922402774, 0.0675261916415522, 0.06398587339307918, 0.06769075887937354, 0.07466154505441878, 0.06865097571252844, 0.07975766360934675, 0.07892327061517944, 0.06617446081952705, 0.07640121661902538, 0.06976277597811162, 0.08161091855043047, 0.08042549690077433, 0.07140283421607643, 0.07804952583820476, 0.07171285865546143, 0.078959049033169, 0.08371785655578226, 0.07785452961404483, 0.0810219223559158, 0.08091197938167233, 0.07913302266612181, 0.06718328706719728, 0.0801766502809863, 0.07287253367837587, 0.07827727710470156, 0.06335049333069331, 0.06753631369053491, 0.0667214100826122, 0.08480926606186505, 0.06422847335400639, 0.06541539120708567, 0.07894291831102918, 0.074532765939413, 0.07065880940016164, 0.07866893534137948, 0.05929586806832324, 0.06568563293147102, 0.07493379457866402, 0.062182384794473064, 0.07102511310173742, 0.06756870669936517, 0.06860263996435992, 0.0856014499106943, 0.07472130818726148, 0.06780632457918097, 0.080029944116418, 0.07716982551484028, 0.06330419495639979, 0.08244426391298901, 0.079321111263563, 0.07068089365060329, 0.05888247554802962, 0.07983135609277815, 0.07260220977405417, 0.07566285195995733, 0.06660610583712956, 0.0822843345885976, 0.08204737771442368, 0.07773730029351508, 0.06460403550416569, 0.07798904172873009, 0.07587601133337414, 0.08015068097632051, 0.06161122477853195, 0.06754013364468332, 0.07864884076477095, 0.05965115625169715, 0.07972400121902476, 0.08642296054960637, 0.06095438369881036, 0.07255514446066513, 0.0712503739146736, 0.06252947864291417, 0.07829900823518257, 0.08153003605459333, 0.07923720676210722, 0.07956296402887264, 0.06842794184722505, 0.08029676311711495, 0.06631664269198982, 0.07678876745403963, 0.07682011314813786, 0.07608257582417396, 0.07420879819762673, 0.07884507661818052, 0.07880794667348277, 0.0650697586676804, 0.05630264508722663, 0.08027962452135091, 0.06889592405807085, 0.057900978931067285, 0.07576544405610239, 0.0804222122464992, 0.0691645635439983, 0.06701147017719374, 0.06274324309256887, 0.06496953513112372, 0.0629230759141828, 0.06432411294474262, 0.07995147269513005, 0.08264952333018027, 0.06540448819725209, 0.07865830719888411, 0.07465059918435181, 0.07354818893730307, 0.07910558824653062, 0.06815860378551002, 0.06919942161514425, 0.06014057488647054, 0.07960848663941429, 0.0832309273904202, 0.07887809347532453, 0.06276981844594302, 0.06541638760696683, 0.07935607362320177, 0.06602939338956608, 0.07297420201670342, 0.05713539893119071, 0.07253108691045854, 0.06450895653543842, 0.06840304692705414, 0.07973511806374575, 0.0521392347255144, 0.06294125378994139, 0.06818480105476188, 0.0616285448375976, 0.06331871323746557, 0.06180698796276289, 0.07920712548030075, 0.07135464629600503, 0.05963978236631881, 0.08330205253467765, 0.06326665367298598, 0.0651483543380256, 0.06463554504533253, 0.07940499264991052, 0.0808210943919026, 0.0653963131020892, 0.06676426840419736, 0.06633602797884079, 0.06579784166687001, 0.0809687946627561, 0.07907186666640656, 0.07132393858481713, 0.07492027382553147, 0.07612368621607508, 0.07460714119735051, 0.06812056641644437, 0.06127182228968931, 0.0708920212254912, 0.06939107274426938, 0.07504256000868616, 0.07765538471478307, 0.06309772476827069, 0.05323491709672728, 0.07868121986223563, 0.0782405297491116, 0.06919320413636128, 0.0783718476723001, 0.0662007385822211, 0.0661085889162036, 0.06986919790084284, 0.08074133108032874, 0.07949882538560536, 0.07516846503099377, 0.06680211764544257, 0.07760218182137713, 0.07236434421752189, 0.07738719057917275, 0.07917025636162185, 0.06066704111892578, 0.06312449902560928, 0.06615781198556102, 0.07554095840804369, 0.06930059622707813, 0.08041282978691677, 0.0817158338396915, 0.07574933574594953, 0.06498840675461595, 0.07614377854684551, 0.07950340733145429, 0.07090317585462957, 0.07925591247218344, 0.07949629413453449, 0.07316205521118843, 0.08073714638791264, 0.07926106615757793, 0.06754413384152709, 0.0786418913159298, 0.06723441228326409, 0.07811074598590356, 0.06641382401627216, 0.055509433219620714, 0.06673367584010399, 0.06430894546540465, 0.07679122787504632, 0.06104860144024001, 0.06679891293433446, 0.07979017314397528, 0.07179265005450115, 0.06450198678984176, 0.07529182471819526, 0.07950158265082079, 0.07872510358034743, 0.07581328667640463, 0.08048545104477216, 0.08053660425432807, 0.07883272747654316, 0.0735895038642799, 0.0639893661532807, 0.07932937312414562, 0.08016963491808006, 0.07606338545550388, 0.06932613087954816, 0.07065362659256429, 0.07930595081651981, 0.081140109586769, 0.07727463040878776, 0.07902648680808719, 0.06728518060734584, 0.06789324922429504, 0.07861122605885233, 0.08253595653197955, 0.07831576979609974, 0.0656996998639158, 0.07390815403949891, 0.05934998831362157, 0.0800448720455245, 0.08091884424350537, 0.071826834796438, 0.07837494285014758, 0.070121955391967, 0.07928855369503023, 0.08280272628654585, 0.0786109178044199, 0.06976468756727583, 0.061002578373136, 0.06359229789476532, 0.08211692837894723, 0.07145037565085195, 0.07953587259323028, 0.05829430051870175, 0.07246385885956076, 0.058975154782919925, 0.0654492829954679, 0.078766341328759, 0.07854056843386831, 0.06951081343152389, 0.08054802756654779, 0.06643177242974749, 0.06252487581301402, 0.07352929327352391, 0.059656903071814184, 0.08143885986243109, 0.08001128148264292, 0.07899028422631367, 0.0646238315373135, 0.06874649676991426, 0.0638839696429617, 0.06394697952542709, 0.06089265302275159, 0.0695724359383451, 0.07873891762889387, 0.08472227045125724, 0.06725609717940158, 0.08001939793829371, 0.06697990016348923, 0.080988767273513, 0.07984295377629723, 0.07889248537206223, 0.08518799720847595, 0.06069000661461169, 0.07676056499229933, 0.08153920835949362, 0.08036379438631715, 0.0811878944476597, 0.07853096060615723, 0.0707741831099167, 0.08014991105979219, 0.06559525939054572, 0.07111660771403924, 0.06689214983737818, 0.06489286162643072, 0.07262143546266499, 0.0796835581411943, 0.06655830046518059, 0.06916480741232967, 0.08025638314555582, 0.07053003985501492, 0.07981917071780868, 0.059274939898753966, 0.05976073222542845, 0.07146762341454917, 0.07646425716042601, 0.06472704214098476, 0.06319875187842172, 0.08037769945303629, 0.07817467584113375, 0.07841653826021854, 0.07646362122352082, 0.07688169159430437, 0.07123992189313573, 0.07869174935744676, 0.07736256166159249, 0.07763768956527047, 0.06859204247311071, 0.06765916417031942, 0.0811776820101722, 0.06277877571656777, 0.06857862851087805, 0.07194780943196014, 0.07852346735915934, 0.06201476202232706, 0.05683000367997555, 0.07747977455902132, 0.07331812812837829, 0.06965503275897396, 0.06508593686109099, 0.08001587616581503, 0.0636600570845566, 0.08086947809755354, 0.06703957433880336, 0.07057975402131912, 0.07286442646899585, 0.07912162473026603, 0.08098412886867311, 0.06475044075252961, 0.05787316065204363, 0.06392529071310014, 0.07631350950307074, 0.07807677478231322, 0.06096422160884108, 0.079181242298578, 0.07320509362439301, 0.054750536127369215, 0.07061970645838664, 0.06715181254904212, 0.06865819907628366, 0.06099065190675978, 0.07419218242159552, 0.07828254422053604, 0.07205438963568468, 0.07944260617110603, 0.08092831137103103, 0.07668934400723548, 0.061301499415109095, 0.06676751604128343, 0.07884252672229043, 0.07354404555231109, 0.06783667144080673, 0.07429396406909704, 0.07857855326934225, 0.06398033386965991, 0.07994220557194807, 0.07941854994137461, 0.07984022338771447, 0.085353772776578, 0.07412475787746245, 0.06622078209959609, 0.06920846589503243, 0.06338974634481362, 0.06670775947040376, 0.06470721902486072, 0.06259755070575401, 0.07073581563771211, 0.06866306347192914, 0.07982307382303173, 0.06798384791883243, 0.07545356234184374, 0.06432065684784538, 0.06702948921485188, 0.07417943969131303, 0.06494205433307199, 0.0700905583746913, 0.08309688246122592, 0.07970687547195633, 0.07458270766494712, 0.06956036809675324, 0.059218327637010515, 0.07727969422446515, 0.0677030501235847, 0.061246325114203935, 0.07990048789263733, 0.07126892130805175, 0.0646839454704763, 0.06307008715931775, 0.08196805893432935, 0.06282549903796954, 0.07647218928502736, 0.06821422942371508, 0.07919330506481871, 0.07679007681448255, 0.05890280948653923, 0.07205920882607286, 0.08197659636280356, 0.06763495975369338, 0.08032851595541077, 0.057195838443041803, 0.0778210999747894, 0.07865582213828588, 0.06316795859137636, 0.06628041016425236, 0.07365451475581566, 0.06762170365913658, 0.07624145087193511, 0.0671025102289131, 0.07167942110556945, 0.05792407686825278, 0.06660355201535154, 0.06321658938918144, 0.06592136844433649, 0.08025769122733602, 0.07984694708589857, 0.06542094163309874, 0.07277253934529457, 0.07546992180386573, 0.07689664991370468, 0.0843737276926427, 0.06339818435887325, 0.08409205391775355, 0.08023711099094584, 0.07978191169239016, 0.07727123523287975, 0.05800767201991674, 0.06538386554773103, 0.08182298923059803, 0.07005388963696514, 0.06762063615908061, 0.06373951904751218, 0.08278355357375086, 0.06568516956378037, 0.07431279823162593, 0.06289084890597747, 0.07757936514237218, 0.07965108809304788, 0.05809253284620484, 0.07583325028594191, 0.06338217737860076, 0.08198842251990072, 0.08058387356749563, 0.06249225193209798, 0.07753551446680347, 0.06444173050830382, 0.07818380642936118, 0.08105045254322142, 0.08166425783581593, 0.07607150611877238, 0.066122238327306, 0.08413214000048416, 0.07838754509772344, 0.08071257406751259, 0.06771537611660942, 0.06147567749108006, 0.0803293263871322, 0.08038389393117785, 0.08016420627475042, 0.058774095856665064, 0.08156571838476132, 0.08287779084452401, 0.0818420412298902, 0.07714904815497124, 0.08115981290256125, 0.06845563870240426, 0.06405219103873677, 0.07253215999692433, 0.0848109296151088, 0.06578188781747725, 0.06319233896407883, 0.08096882745071927, 0.07639720982890542, 0.06915589005491696, 0.07131326937685646, 0.06677374961236159, 0.06250262760184505, 0.07961847748900537, 0.08014082074829584, 0.060838301055737336, 0.06754870460527548, 0.07814879941905725, 0.0681476594937365, 0.0730062035268407, 0.05762990853851071, 0.06601387955834148, 0.0674767426240218, 0.0799460917778636, 0.08431896006700158, 0.055981728473880124, 0.06606200833639979, 0.08099164921842321, 0.0793573601948098, 0.08031635305656964, 0.08018445799514731, 0.07730749704355941, 0.07471946815912292, 0.0679866578590883, 0.07649223367499852, 0.08014131487498596, 0.06784317864495078, 0.059141557760751425, 0.06074777020761734, 0.0760529534150541, 0.0812617986719149, 0.06492444766364372, 0.07113595327683488, 0.07647757980197806, 0.06601538967116943, 0.06772486838275658, 0.06556684850651252, 0.07705638094383778, 0.06756655849524988, 0.07683378144578257, 0.06399120492379859, 0.07741724244922552, 0.0738650383179114, 0.07045789809551527, 0.06498352024573513, 0.06449332505461684, 0.06530604292235004, 0.06093950540410712, 0.06664717771697343, 0.07303856814330689, 0.07822286058927311, 0.05399662355860182, 0.08190704755794638, 0.0777443612908086, 0.07871248413827914, 0.08663653505840992, 0.07878490855672583, 0.0773512775648665, 0.0787214295083405, 0.08225632508636758, 0.06762700382328159, 0.07673376173280717, 0.06287620216541602, 0.07642789540348295, 0.07947763927941828, 0.06467869945252316, 0.06945853415168501, 0.0800918708625254, 0.08021300896366365, 0.07878802896908862, 0.0840533490010343, 0.0699738444122439, 0.05848730289366498, 0.06279333149392412, 0.07601928280903693, 0.06461580962490439, 0.06405935833955295, 0.07241669445379405, 0.06183263981605435, 0.06491879627997336, 0.0678159738965114, 0.05909310748766918, 0.06254032123774213, 0.08133608927062023, 0.08014142515803857, 0.06694395003256962, 0.06455974661008322, 0.07681873150638002, 0.06007492781409467, 0.08595002518788056, 0.06412918476178399, 0.06602539260203026, 0.07899957859832751, 0.08486584776947713, 0.08275825048842549, 0.07359931098541402, 0.06507351698907082, 0.06732272177805416, 0.07848159856848788, 0.07914256360727348, 0.06994357550899973, 0.08041023482499349, 0.0742215458232935, 0.0594292069427964, 0.05771033279084091, 0.0791390759264168, 0.07803614689538273, 0.07237074169719328, 0.06578452814820937, 0.07418582075190815, 0.0795389783373084, 0.08097343160429496, 0.06545383321163678, 0.06563375881957896, 0.07847563354615024, 0.06692793483843512, 0.0630563516430232, 0.061052808887179115, 0.059753678838423106, 0.07779021889337963, 0.06337954402126895, 0.08276048475228093, 0.07817260801573768, 0.07962919288789064, 0.08096150326784188, 0.06207086600534652, 0.07984433201825894, 0.08573882935085489, 0.08721959313784007, 0.07754232349497094, 0.0779311716481315, 0.07913915644018729, 0.08172939492474524, 0.06565235608310574, 0.08081706819528114, 0.08037567213248452, 0.07886423066046933, 0.07980415299543402, 0.08070166464957734, 0.08177731479395302, 0.07200423254263534, 0.07540503715437533, 0.06965221180349979, 0.0651689554277336, 0.07875249499596908, 0.07934838931253005, 0.07873133506562831, 0.07781002435938082, 0.07976951957254644, 0.08017214899484149, 0.06202752974355914, 0.07906238867345677, 0.07632474047775645, 0.06331418578338291, 0.060197438978614654, 0.08144293830391601, 0.07815452807390484, 0.06719290069842655, 0.05705355516193894, 0.06362560336947097, 0.08009238315696814, 0.07886802629923989, 0.07429870530861916, 0.06207193701486997, 0.07748923092202442, 0.07765473666933816, 0.07085434961933659, 0.08040784529839914, 0.07847337466514309, 0.06771886713289058, 0.0701925025861115, 0.060291805363218876, 0.06684654181768701, 0.07817449504373213, 0.07955041541825922, 0.08069882663880856, 0.07688862570970578, 0.06593062402913664, 0.07912908992447171, 0.06704722555090249, 0.06707662935498916, 0.061466012465185585, 0.06799938729300173, 0.07872552354817107, 0.06716707924872867, 0.08157214209340426, 0.07992877404362599, 0.07133752500974423, 0.08068389100049404, 0.0814519039741756, 0.0775580542497077, 0.07414524548811137, 0.07995161444792757, 0.0810291835809336, 0.0709291777814373, 0.08085900405568609, 0.07581708706980983, 0.06856256963238783, 0.07821364979476429, 0.07388474170147485, 0.06563837238263057, 0.07100097275602002, 0.073257081422904, 0.06724585915857084, 0.06830000093602084, 0.08405345931587441, 0.06704313985467793, 0.07998604006444611, 0.06633015785650989, 0.0628008348675914, 0.06595336669275174, 0.06806986553376031, 0.07105033001189694, 0.0649200911729386, 0.08429837311558269, 0.07853203532716631, 0.06944275272788408, 0.06190014478287931, 0.06767166660433727, 0.06509902050679568, 0.06632344582909826, 0.059907737237194524, 0.068078619833487, 0.07886665834419164, 0.0790115046078607, 0.06464344518169989, 0.07983453056886534, 0.07018847786751833, 0.08044232272344295, 0.07322127654153042, 0.08067367847114032, 0.07508679055021428, 0.06936144232411696, 0.06709322662107257, 0.05889216923179493, 0.06375101859641141, 0.07882718063446711, 0.06849321643521664, 0.0599661469953601, 0.08127432874456264, 0.06163547839971232, 0.08502384155876662, 0.06501455643799783, 0.06120036236439413, 0.05627348145264556, 0.06976335650955316, 0.08217845332896342, 0.07800943946461464, 0.08315985143555714, 0.07935046520453495, 0.07912616549472591, 0.07984552041183059, 0.061863390680404605, 0.07712255089417279, 0.06353480592188197, 0.07879240376004067, 0.08051892134009483, 0.0735918742029771, 0.06870503206635585, 0.08053742284759782, 0.06125874511598566, 0.0817384276275658, 0.05235374885434011, 0.07873527439044951, 0.07920649986344348, 0.07924412434792438, 0.08302683885342114, 0.06367046539975078, 0.06651398701675523, 0.07307630459772878, 0.07824639768914864, 0.06747961896515174, 0.07627025118132139, 0.05686611082699151, 0.08078080872751436, 0.07874448929508297, 0.07116680545666951, 0.08283179121217057, 0.08020441258371491, 0.07972025910623493, 0.06547390280798253, 0.06576212836150924, 0.08514830936602749, 0.07017875688643942, 0.08020811661039763, 0.0792148305683577, 0.0775149880379071, 0.08032122179073997, 0.07804273995357021, 0.06374222355189701, 0.07333185743517495, 0.06639197931912169, 0.06217612434469787, 0.07732271464818863, 0.06915617756706181, 0.07971902942961734, 0.08247900182491225, 0.06848512726592107, 0.07217706727021309, 0.07731586383645948, 0.054418533540926815, 0.06869343107232405, 0.06029328569864944, 0.08067362311856908, 0.06920883721319222, 0.07981754755975286, 0.06913526034471465, 0.06573777814085713, 0.0654451918168028, 0.0772837622046369, 0.07289889958508008, 0.06259476006300255, 0.06714891048659882, 0.06663286344706496, 0.07909898446612149, 0.0748015670326584, 0.07666431340965564, 0.06575695665446703, 0.06648824649627874, 0.07395810722462852, 0.06496915743769299, 0.07981137683312357, 0.0713928595958497, 0.06344103262001928, 0.068847091856876, 0.0825513685424793, 0.08067185587053288, 0.08009510320394642, 0.08108421372595513, 0.07753905368216989, 0.0798624938476378, 0.06061419843858947, 0.07966461392616937, 0.06865414224289455, 0.06714388388282036, 0.08132090272021615, 0.07174516198689124, 0.07996502392269703, 0.07829347875049522, 0.06896271099884244, 0.0782629773760389, 0.06684194168549813, 0.0747542232158174, 0.06366403271606919, 0.07917728525499486, 0.07815124638865695, 0.07994179730345419, 0.07731692459909739, 0.05967667080597765, 0.08110906675044001, 0.07944423786131163, 0.06354217704371325, 0.07069246753535925, 0.08022907825823787, 0.06729376378953657, 0.07925710810667395, 0.07400135388770204, 0.06416671069457093, 0.07201257722286489, 0.05900183793525503, 0.0651038459667523, 0.0798369617035762, 0.0803954616406706, 0.07110314386129883, 0.06832899473542473, 0.0680731296617884, 0.06883124805080143, 0.08224453303640829, 0.06968223134636932, 0.07593712339757774, 0.06661435862569356, 0.06362310013705516, 0.06318376003806578, 0.08105136693241911, 0.0751944774750414, 0.06621085237686329, 0.06318171528405245, 0.06738829951552293, 0.08089483187112417, 0.062022999568876566, 0.07987763817018223, 0.08272823466024906, 0.07828240483620551, 0.05835044328140274, 0.07306235215846757, 0.08047770121932307, 0.06250070984337353, 0.06670668542307924, 0.08220119581753377, 0.07955169750297657, 0.06893525675169919, 0.05721339201144385, 0.06678374714463053, 0.07170251115105385, 0.06230375630874926, 0.06617431061866783, 0.07201216779283834, 0.08074973048050553, 0.06529971355346875, 0.059037770888320185, 0.08067718620777443, 0.07856785049612011, 0.08009808932222615, 0.0635526763282874, 0.07799827905204901, 0.07970155122571292, 0.08164582229047945, 0.07909082701280819, 0.06539370347358328, 0.07944700370615344, 0.0781167858805253, 0.07991808708411266, 0.06685659612737178, 0.0629985765532995, 0.08204727939366607, 0.08073418606695845, 0.06214402107322165, 0.06775596874489967, 0.061230766422732584, 0.07911654327510187, 0.0635105661128033, 0.0652277811619123, 0.06530452983945846, 0.06983931293533843, 0.07580939523533672, 0.07340094520948724, 0.07802859942949247, 0.07463208845523048, 0.07659603010053291, 0.07329302071701634, 0.07508506036674624, 0.07853675622699709, 0.06438283062756545, 0.07477759144197817, 0.08094429490601775, 0.07969840740749143, 0.07127961544425825, 0.08336487034341442, 0.06077311056238803, 0.07866999615437427, 0.08092069532679888, 0.0677842021280481, 0.0666075924159705, 0.05737595459450448, 0.05936158882635283, 0.07175242737075206, 0.0775696045457551, 0.07948079294024832, 0.07728613241280745, 0.061261193825669906, 0.0741477823239238, 0.06716584955270906, 0.07749761158139712, 0.07264633854002377, 0.08128189033449144, 0.06785193466542676, 0.07059187925698246, 0.07996038667303934, 0.06403126447831772, 0.07943518628902373, 0.07070565029521277, 0.079883576428317, 0.077644895483207, 0.06974446466180395, 0.06697237490777534, 0.06615846835578598, 0.08306489108661387, 0.06466092072312378, 0.06332692677430857, 0.05540287338790864, 0.07484573776989999, 0.07895091841688545, 0.060644151673991155, 0.07932392370739362, 0.06253524737310683, 0.06893497197463024, 0.0554958555163754, 0.07903800045401721, 0.06699036831954873, 0.06019374328384915, 0.07842722101801435, 0.06101354677310263, 0.05819598986660358, 0.07655752810830564, 0.0790895188070192, 0.07453623073093794, 0.06917233328359201, 0.08091853381984383, 0.07765024684880079, 0.07630973652334304, 0.06974844046917703, 0.08139371464974886, 0.07620311138484617, 0.058359366447137996, 0.07468368215888219, 0.06257615794690777, 0.08118139132143906, 0.07170356550457958, 0.0680085962183962, 0.08510802635863736, 0.06339535099078997, 0.07928575707878836, 0.07528431575777399, 0.08491934515501373, 0.07153555415811313, 0.0796228113769232, 0.06968753575122143, 0.06435159183365119, 0.0793413699376196, 0.081276732940289, 0.07935398430144583, 0.0795716069882821, 0.06840474617899577, 0.07412793510911324, 0.0649701375111969, 0.08130538011271465, 0.06782677305174427, 0.07641087947861386, 0.08289789225307848, 0.06861971100426378, 0.07902216185875914, 0.08164483966756535, 0.07520869112963217, 0.06403075693948365, 0.06817607983300278, 0.06498591124815478, 0.08213076799951446, 0.08132711198639511, 0.0646153202582286, 0.06302450013474468, 0.08107224191468904, 0.07784561789211027, 0.08112820652542804, 0.06310979964542296, 0.05448298413306595, 0.07310821121931187, 0.06943560283590748, 0.07934994051735746, 0.058690159552146584, 0.07926701339208864, 0.08000861538696473, 0.07697142069703777, 0.05586317922891836, 0.07250280272007287, 0.06830293666191857, 0.05383472516288235, 0.06709694159261075, 0.07100979574720655, 0.0800804768657091, 0.08359604151032132, 0.08041702676984903, 0.060002273026084574, 0.0658048456344848, 0.06078442744288681, 0.06597877056079328, 0.07158451381377873, 0.06073676134901227, 0.056810851518244734, 0.058199019477140804, 0.0799107255540932, 0.06785256823802105, 0.08118803012077197, 0.0670332332691176, 0.07851256733578009, 0.056540688854854575, 0.06378693088107573, 0.06830176256706941, 0.06816235572074977, 0.06351292202906537, 0.07876317456990505, 0.07813638724936564, 0.07403302035468635, 0.07703150417956525, 0.08023147645493466, 0.07852649086485977, 0.08273217950189606, 0.06576911538105118, 0.05727010873808452, 0.06815195725770216, 0.07976639779505243, 0.06610048816129234, 0.07987888245032135, 0.07790521549417156, 0.07786261674684311, 0.08263963449114631, 0.06371460051272855, 0.06635987672593263, 0.06635753241031249, 0.08077568010486683, 0.07912534328373608, 0.06476793346739909, 0.0846873186143714, 0.06855191926551574, 0.08199464334709394, 0.07578669347468174, 0.08039052030302268, 0.06580422740001446, 0.0641820493595983, 0.08128662320335062, 0.0686978087474924, 0.06571602601835341, 0.06821523426850698, 0.07421945965382466, 0.060270572834577, 0.07597481276817171, 0.0696524131318691, 0.08033784200613549, 0.08190992210711379, 0.06896594670161782, 0.07166577226971511, 0.06827022163984847, 0.07694351597527621, 0.0727200742613823, 0.07471343739841477, 0.06588556372929037, 0.07961271860879461, 0.07899850635018621, 0.07341752731022859, 0.07575445466707621, 0.06126224145140764, 0.06320776057106477, 0.07016542730482651, 0.06148286899402814, 0.06127663075510049, 0.08032080346902117, 0.07963543544076986, 0.07931389613003316, 0.06967439469084936, 0.06586322810522839, 0.06891420036672281, 0.0791563512364, 0.074741960971012, 0.06982275268772918, 0.06278376167840147, 0.0763683481608867, 0.07089163898295421, 0.07691024774949767, 0.07928601059155749, 0.06387759139329466, 0.07829643391009439, 0.07766134624357836, 0.07059757172169112, 0.07818546037166976, 0.08058758379629216, 0.061248847727898154, 0.08142597826929558, 0.081432210869808, 0.06870286769346855, 0.059971136117531736, 0.0730027351921717, 0.07741141006071685, 0.0640639002711046, 0.06489604253346264, 0.07072622246819008, 0.06651945964072181, 0.0646347893448887, 0.06559187756230957, 0.07107110377682828, 0.0795211178805006, 0.08018616467446242, 0.08045232057372856, 0.07309283760622674, 0.0703473429114675, 0.07818922990403698, 0.07299879473437529, 0.07926404088770403, 0.07671870618655645, 0.06971867339704706, 0.07347147768011314, 0.08039958517803424, 0.06952504885428971, 0.08171071158601932, 0.07603320690374393, 0.05562658390877702, 0.060410085427090796, 0.08141663276208357, 0.07172675445253156, 0.08022748427813643, 0.07042505238116005, 0.0683650431106212, 0.06623079959530699, 0.06529456531598322, 0.08221448043846487, 0.07889935628600553, 0.06224487740639623, 0.06735994455858973, 0.06934260687160453, 0.07803736397044686, 0.07145829215723606, 0.06734122871408328, 0.06153242529419377, 0.06611898564927644, 0.08047250428742798, 0.07861298790174588, 0.0646487026665914, 0.07818804001204323, 0.07294694926361432, 0.08054844428909168, 0.07320914996637352, 0.08026958074065493, 0.08055673344467584, 0.06347390566966597, 0.07686083163612324, 0.07811600039148917, 0.0780878280537944, 0.06336441049416205, 0.06791877197311577, 0.06753927519495803, 0.05464097500093098, 0.0661988005314867, 0.08140199292749077, 0.08217664072536057, 0.0732113677520693, 0.0625487230443819, 0.07700243213289876, 0.07034337013320806, 0.0804372153866447, 0.06477278453058101, 0.07938591271534885, 0.06854740848688193, 0.08170086129399061, 0.07843997535737958, 0.05584298918904677, 0.06943835048732273, 0.0689151407636888, 0.07952262852478975, 0.07638482976353012, 0.06598814750369007, 0.07896605434053539, 0.06644485675815257, 0.07705991209765994, 0.06903201609830038, 0.06878537313758668, 0.05619858682754262, 0.06848524009600583, 0.07512804647875863, 0.06498999067361218, 0.06065411014991486, 0.0809392072390223, 0.08320545269820513, 0.05942230599988846, 0.06658330007311782, 0.07873216508340573, 0.07095105362398711, 0.07365689033344344, 0.07766903216888182, 0.08019120241855142, 0.06246228507877609, 0.07491444636018163, 0.06502742754718625, 0.06507109505708326, 0.06707193374549711, 0.08017617290279731, 0.08107615307195443, 0.06779128703322058, 0.061759414984586564, 0.08186735998130121, 0.08044170185888518, 0.07124851985483907, 0.07187645744118841, 0.0771427449599158, 0.07286913372428921, 0.06925506480990144, 0.07859021052322059, 0.08320652368629985, 0.08335702506017285, 0.0642343730832517, 0.0826327115869008, 0.07982221996996425, 0.06409799059053496, 0.07885942675952004, 0.08119905877311415, 0.07793878747039638, 0.07841115757906694, 0.0659336040085642, 0.07805295311071163, 0.07434367607875064, 0.08208641587903409, 0.05804524724534667, 0.07894984960342473, 0.06575036945028587, 0.07937939640316345, 0.07629296586664608, 0.07937472034790716, 0.08119672826005478, 0.0800294017378556, 0.08063969371914609, 0.08011376270298548, 0.07532659126336001, 0.07840696278380925, 0.08051177241886123, 0.0664081886766171, 0.08077372696179547, 0.0805685758584821, 0.07926646941356363, 0.08196894541884625, 0.06814165562258412, 0.0800951931579554, 0.06695975697147769, 0.06917517941509711, 0.07956325954369803, 0.06272079194782314, 0.0669553271779064, 0.07800367365996147, 0.08091324522159882, 0.06705692260505298, 0.06720511357832122, 0.08129307631206034, 0.0763646482652087, 0.07223014467746795, 0.07830706285132169, 0.06760060844901464, 0.058141890795243324, 0.0777245814853688, 0.06252622968680448, 0.08337443970878002, 0.08043477439740351, 0.062220911011283894, 0.06817182449720292, 0.0788427255881818, 0.07559033907170801, 0.07962274051453529, 0.07308752049887225, 0.08206937025251465, 0.07888122358814517, 0.07343544756323812, 0.0624084930424563, 0.08202749897086174, 0.08099690245102666, 0.05902572362980713, 0.05991493740493928, 0.07839186276917447, 0.08344213734169359, 0.0694073833651724, 0.08140313066485128, 0.06617180072182939, 0.08000459333350259, 0.07099137873209697, 0.07695571482718125, 0.07725059979374695, 0.06387543234712396, 0.07082954047242578, 0.0814599670097298, 0.061149927515457864, 0.05752292093316872, 0.05613501341741235, 0.06199080864952708, 0.06771018255087424, 0.0704584976893467, 0.061904020981106124, 0.0684193821767624, 0.07282295105766988, 0.06901235716898534, 0.07690366373396813, 0.05589016830750914, 0.06752525623796585, 0.0634349934790034, 0.06780003766513952, 0.06326820244736606, 0.06708529337071875, 0.08047984270894701, 0.07131057020815727, 0.06470541476727731, 0.06996292201980202, 0.06618146638239276, 0.06458304795116508, 0.07901532537684856, 0.06333217742343089, 0.07238154695257835, 0.07907942944488972, 0.060510930168403726, 0.07435897430751895, 0.0775791653878589, 0.07885096494404276, 0.07860717963188506, 0.08018932106989198, 0.07442614374876481, 0.07963153792296422, 0.07869171923821536, 0.08113050330400119, 0.0791823580906065, 0.066092100511274, 0.0637975713906716, 0.057346329712831656, 0.0807872333720838, 0.07752312843416373, 0.06442126796998048, 0.06521709937543131, 0.06228288964827994, 0.06962833495062551, 0.057779554082319905, 0.057518431230392214, 0.07771944710338925, 0.07961460419667443, 0.07700840463297583, 0.06871217892924776, 0.07060749568496043, 0.07881417364427085, 0.06711516844946112, 0.08000952932488271, 0.07212888835771944, 0.06933533818030105, 0.07284406117590411, 0.07930896023706403, 0.0768627730817175, 0.06663847821200093, 0.06331681737164062, 0.07680037418683952, 0.07427177598459238, 0.08346476908865168, 0.07994476825870454, 0.06392385972558642, 0.06299754480505967, 0.07776292789696466, 0.06529169286074124, 0.08187472802849168, 0.07878095666689988, 0.0634944897919936, 0.05765282746266586, 0.0724954533742455, 0.06946713066518165, 0.0707905740833303, 0.061199615076205735, 0.06911571384416129, 0.06708985381935445, 0.06353088582676525, 0.07701818248206078, 0.07725136038885028, 0.06964627969032473, 0.07984397316668092, 0.08025896315243913, 0.07789829550683895, 0.06211561780633459, 0.07279062798222918, 0.0603269752745224, 0.06355327103609419, 0.07428246187760093, 0.06676272947323299, 0.08321506687246412, 0.07137050844608933, 0.06361982146796412, 0.07582991554950015, 0.07448507051428835, 0.07867284395367007, 0.06565369200984496, 0.07725039365409929, 0.06836672440799776, 0.06124947932689899, 0.07986614778292428, 0.0761967179770388, 0.07062970023250982, 0.0799799740352141, 0.0773972454800037, 0.08166758693141457, 0.06463982477902441, 0.06701351943411003, 0.067507032515882, 0.06264020495877409, 0.06618104440822123, 0.0783938880236144, 0.06897428894886509, 0.08006242952379197, 0.0809915944298455, 0.07745552871748063, 0.06426768100629181, 0.08121754469074653, 0.058767791448368724, 0.06580951044156536, 0.07966490379858981, 0.06132613839088975, 0.0643424284271935, 0.06565852536187855, 0.07854791526735168, 0.08391926449081583, 0.06821298504935606, 0.07848556649000926, 0.0828371004634375, 0.07754734796806034, 0.08116994203397832, 0.06745453121891154, 0.07697906095770687, 0.05997493110097602, 0.06896435731657975, 0.07692767927171011, 0.08029664825219245, 0.07877556102127405, 0.08013807909607279, 0.07998907620407919, 0.0634297186839275, 0.06961231034503068, 0.07515656039607164, 0.0802344028233763, 0.07908207254159445, 0.07588277915462104, 0.0804100975361215, 0.06583504125044291, 0.08041341067926173, 0.06821132923217373, 0.07961207676922691, 0.06500526189305453, 0.07319074526520128, 0.07891263906224906, 0.06504221844505303, 0.06069763440929855, 0.08035454752496458, 0.08008147134210912, 0.08030039561427432, 0.07893435267849372, 0.07177247779444983, 0.06850302982585732, 0.08394481995579203, 0.06786413897134838, 0.08070235041193988, 0.07346553604052485, 0.08182091917073393, 0.08018766580575619, 0.05982502635838063, 0.07765851099384409, 0.06505729394141471, 0.05855820715674346, 0.08227573401063831, 0.058649111165399136, 0.08028227504235352, 0.06703214689094579, 0.06983258290653681, 0.06701028837086812, 0.08011568231690769, 0.0790389228241108, 0.07704380265352431, 0.08288006997249495, 0.06754729423337144, 0.0809201826009012, 0.07742617353407419, 0.07010450501647272, 0.06214350859190852, 0.0687526473438359, 0.07984187652062945, 0.06587133911488902, 0.08074717243350119, 0.07857249666108292, 0.0721806375851625, 0.07345244357358752, 0.06225850784031948, 0.06462439165243328, 0.07980915662033466, 0.07947111206720864, 0.07852890200257856, 0.08341048099320167, 0.0757893337871057, 0.06568592813520038, 0.06489657131726699, 0.0767154058477569, 0.06467409778876287, 0.08087668828189974, 0.07875381055321048, 0.06235885081017836, 0.07677699953856139, 0.07905226354083941, 0.07385202934697004, 0.07578391434935056, 0.058669296858028595, 0.06544529453579535, 0.0713327422430309, 0.06258886931687384, 0.08056039184164093, 0.07747400173885316, 0.08030456889611487, 0.06593189449235842, 0.05960457025087615, 0.07796030415509737, 0.06536988736208316, 0.07957369766911093, 0.06239267635124915, 0.08080196054528155, 0.08018913341748776, 0.06592419057811844, 0.08072962454306115, 0.07908706070319808, 0.07895340930749731, 0.06809242814957348, 0.0812140010536922, 0.07113530665414061, 0.08084639918930343, 0.06832194833453346, 0.0801760372489938, 0.06698826786137885, 0.07981886818590544, 0.07923500225329991, 0.08158294861452631, 0.07801780588002821, 0.08052016072781856, 0.0631802633085177, 0.06829977920417767, 0.06005354965680201, 0.06684386306223737, 0.06537278133526943, 0.06403548529314902, 0.06579679498521225, 0.0765561438150504, 0.0650019216893278, 0.06503937595106803, 0.07044311626443675, 0.07132204709590362, 0.06423681449695452, 0.06757204805392948, 0.08042855160585217, 0.06726494087795266, 0.08097733628886811, 0.07523486058058412, 0.08435600806390278, 0.06508046732067926, 0.059960717014262116, 0.06993851755266504, 0.08303536088199182, 0.062177692373548116, 0.06381136060777415, 0.07714519101343513, 0.06976815042679681, 0.06258459716196088, 0.06954255388916278, 0.06646380781109452, 0.0794999360981218, 0.07379055441941862, 0.06131049195008863, 0.06502303450291422, 0.06569984346742444, 0.07332363651154085, 0.0695490542392209, 0.08120422534231071, 0.05565831625520974, 0.06971669167211299, 0.07798410058242493, 0.07871638845851892, 0.07221393799005439, 0.07896312965927041, 0.06002235855749351, 0.07897270238021097, 0.06847444359646858, 0.08110341143909533, 0.07578094232035756, 0.06158987045982595, 0.07707268100482041, 0.07997279422299501, 0.06443239082675496, 0.07967724658795398, 0.06769101387143739, 0.06145935759655455, 0.07168803857284088, 0.06804295700716112, 0.059681389928137776, 0.07679339981196857, 0.06581933220202744, 0.06219388153334499, 0.06695035794132746, 0.07721765713129379, 0.08026684411198916, 0.08463514124819674, 0.08028903629266007, 0.08370504356180207, 0.0697110478791561, 0.08000717447393006, 0.07880238823129039, 0.07985558235823365, 0.07975588372226065, 0.07781382125014699, 0.06719031018061244, 0.07951807972484756, 0.07145201299233304, 0.06598481397411163, 0.058664880214167034, 0.06946300065996955, 0.07914034206473916, 0.07970606059318924, 0.07987184214505064, 0.0660417489041292, 0.0646280333312812, 0.07839030056365795, 0.06503281024596233, 0.07131707591121798, 0.07839559534500018, 0.07634372330853281, 0.07875662300842555, 0.0760480584528168, 0.07978321193506134, 0.07740837538317931, 0.073184974117038, 0.06321546731293372, 0.06761914921660564, 0.06781093642967691, 0.07705302349405006, 0.06516141230447041, 0.07719567302247798, 0.06138703506040942, 0.07813148779394116, 0.07626984991230167, 0.06364227852405399, 0.07888307546186551, 0.0665593373915567, 0.07989586483416838, 0.07230894060358235, 0.06489589343206963, 0.059988186180899405, 0.07953495608941694, 0.07958998867481464, 0.07209181570275588, 0.07174511149657431, 0.05620360637516421, 0.07873488825855418, 0.0810776834618035, 0.07076584999074775, 0.06031607927007259, 0.07926621410563872, 0.06875109961267771, 0.07917844373666297, 0.07916299839188305, 0.08360351295915376, 0.07315330356334553, 0.06460661092938687, 0.07977887123602162, 0.06386897828186161, 0.05527984634204537, 0.06891079211937204, 0.06568411740241308, 0.06792779101578754, 0.0789429576033725, 0.06778813871496409, 0.06362126339818003, 0.07883334858878506, 0.0725875555573174, 0.08255501744191647, 0.0770693905528268, 0.07088206691525309, 0.07958622050818082, 0.06852978038058032, 0.08112117314357142, 0.06519116958305923, 0.0631189686506346, 0.07172855110892408, 0.06548744056688507, 0.0672984132925524, 0.08036599135792875, 0.07470697688111437, 0.06514200779934648, 0.07428871322786261, 0.08075833124065943, 0.06388824801118569, 0.08119645230268738, 0.078259770585748, 0.08068601250769993, 0.0779022050792436, 0.07863983668178057, 0.07936349017580467, 0.07245710190690023, 0.08009674143478343, 0.07056988088762724, 0.07192622436670963, 0.06257785418431107, 0.0808632822198156, 0.07906734644946818, 0.07348871809155487, 0.07053417603250332, 0.06525327453461457, 0.07877221856586569, 0.06535171036048373, 0.07844215176188063, 0.0686022776041432, 0.06184683016670123, 0.057763597023946386, 0.06380300408621732, 0.07130741952678038, 0.07053332944448906, 0.06142047062646462, 0.07485373990494316, 0.07967788545112912, 0.06871594877757001, 0.08070407381601151, 0.07870084860931029, 0.06711262682147774, 0.08267544974464243, 0.07078303360937098, 0.0630530241460183, 0.08043696699655951, 0.06682483638238458, 0.07852027868354416, 0.06373590096153298, 0.06896335311279728, 0.080002893768342, 0.06617505634671048, 0.07814581009024948, 0.061715002163252417, 0.07669325558376841, 0.06647941968350403, 0.06830640383139389, 0.08055310640405063, 0.0664467074587871, 0.07709938228982885, 0.0791158200051158, 0.07975562179189953, 0.06946914199886829, 0.06550650846982185, 0.07629837066388115, 0.05632205261616491, 0.06762242963139299, 0.07837997808115303, 0.0688100322037075, 0.062378197642942224, 0.07965397126788842, 0.06848620149797849, 0.08012749395319596, 0.07912596728835464, 0.08056944258700696, 0.07664221152967998, 0.05935477704729924, 0.06127841987300737, 0.08313095203285072, 0.07952683565697831, 0.06165756509788296, 0.07711469641014165, 0.0792820781127855, 0.07452942645256114, 0.06431598935616567, 0.07025468774663364, 0.07896041291699948, 0.062080293674615816, 0.07787748136433856, 0.07755685785438092, 0.06282810982665704, 0.07290484562614505, 0.06664323841789528, 0.07953469148647516, 0.06398202515250664, 0.07859355129959061, 0.08137775752571788, 0.07493636802702432, 0.06999257922070966, 0.06848357032162102, 0.07923885051975563, 0.07790763503357526, 0.06706467352853046, 0.07902922641504447, 0.07976629291452406, 0.06736713087645882, 0.08106911023617701, 0.07800348649588959, 0.07831799772170948, 0.08457294201031847, 0.08450947409478447, 0.07935348670658451, 0.06858769720764359, 0.06534990333243196, 0.07871245689649488, 0.07914737138211694, 0.06937175887065167, 0.08097418185029787, 0.07044808518998566, 0.07278603103040387, 0.08203287251170925, 0.08137297643694526, 0.06087401449465452, 0.07543385128985479, 0.06750720497821838, 0.07862821008598682, 0.06077852294091084, 0.061333651330898846, 0.07883276910356658, 0.0793434308786341, 0.07934119304285488, 0.06966545077548443, 0.07401837734058639, 0.06353162578663873, 0.07250510722484098, 0.07303525269680271, 0.0640894140090785, 0.0792610678129449, 0.07598750814349556, 0.07739368540194695, 0.079139748073781, 0.07188277944826446, 0.08065731341086894, 0.07066950607085874, 0.07172607725796162, 0.06463317323617122, 0.07824490550554768, 0.0567859505872917, 0.07879548044748157, 0.06409745219203707, 0.07910671726869482, 0.07947081458422653, 0.06668137560863471, 0.07981117916530091, 0.08044450493668627, 0.08646786078597511, 0.07728000389487161, 0.06378579961882679, 0.0804690510779199, 0.07896094565378066, 0.06708339271935422, 0.06688346092739683, 0.06479696194981217, 0.06488465901435726, 0.0696235894043795, 0.07421497133459876, 0.06983243597439673, 0.05292677475076585, 0.08360762164201946, 0.07839443924284323, 0.08170137531134682, 0.0699750442649729, 0.08011180222190369, 0.06466876824888923, 0.08286071660582794, 0.07489547682309126, 0.08048580566243123, 0.060881791164439404, 0.06601691083935113, 0.07022802864068814, 0.08165396861672138, 0.07009343811890248, 0.0647330037994169, 0.07930057960992185, 0.05873617308175642, 0.0791395849926912, 0.06304240553059424, 0.0790237557640598, 0.07989129388313898, 0.0807835923189579, 0.0812630759544824, 0.06743946022705995, 0.07984428992346909, 0.06347086912652589, 0.08000529653623441, 0.06794642509283315, 0.07044132395844101, 0.07786875978439436, 0.07759901000510643, 0.07265329272862839, 0.07902367017955417, 0.07071052708317185, 0.08292040227624928, 0.07704444377411794, 0.057674479929089195, 0.0798862675131173, 0.08086281214719228, 0.07558919671550803, 0.07247952662258304, 0.07638911077494519, 0.07563975286909715, 0.05905598830271149, 0.08022075293479389, 0.0767698672299003, 0.06571279418765878, 0.06323405797091829, 0.08199876456086659, 0.08117629727423244, 0.07917296515810691, 0.06519059328782487, 0.06303065966967886, 0.08006185313810274, 0.07232153958189103, 0.06636498012306316, 0.0644858572940833, 0.07901278730868189, 0.06649893871694065, 0.0738599962820462, 0.06262895576784139, 0.0783061031060338, 0.061446238865557654, 0.06400168066664723, 0.06981969377044774, 0.07730156509663959, 0.08018787088059301, 0.0685059697203647, 0.08201857930852373, 0.07992398673120091, 0.06075433661186002, 0.06680977695470425, 0.08012839878954084, 0.07833392398857664, 0.08325099232536803, 0.06308248622442733, 0.0703753898466888, 0.06478880307164246, 0.08013665523490313, 0.07429820879745429, 0.07761918181774445, 0.07791234980507272, 0.07963684193020595, 0.06848928456728136, 0.06430123661716215, 0.0714132377136331, 0.07783287654030979, 0.06798203693099718, 0.07909853267616039, 0.08042056459799286, 0.07156059913910261, 0.07788851697587845, 0.06371738466167996, 0.0787609470450754, 0.06589614210072105, 0.06792921576441152, 0.07030177464932257, 0.06900558776362413, 0.08184300317758324, 0.07957121669351103, 0.07945503809285848, 0.07777354156051292, 0.057254938661693795, 0.08003068554747253, 0.06352956868724009, 0.07675143531400182, 0.07267262429215161, 0.06875189987848818, 0.07933119392366363, 0.06944645187192952, 0.07970363003341614, 0.08346719745027924, 0.06772390518602843, 0.06696145901415225, 0.08011409838963292, 0.06778263980152892, 0.07965771636120025, 0.06567096368666298, 0.0653600183309381, 0.0637305259292025, 0.06934848455644456, 0.06937567982713609, 0.07540944414112769, 0.06577691415619549, 0.07965125488346232, 0.06876122871663849, 0.06913309103159136, 0.07842946171532576, 0.06871277187296944, 0.06710891456616118, 0.07334701829068205, 0.07357724864072021, 0.08071339024880429, 0.060337692475891526, 0.07907391807357678, 0.06934622755954879, 0.05968086195331694, 0.07864840881531916, 0.08126033338017893, 0.07816241445248283, 0.07866799117360176, 0.07639943869877293, 0.08489533388859045, 0.06344393524739086, 0.06844276671610507, 0.07964884412854883, 0.08185035055435695, 0.06486125664130124, 0.08279962737811979, 0.06985746043245747, 0.07460524456347108, 0.08097274708224834, 0.06863380793179265, 0.06582820957542469, 0.07879523409877266, 0.08237943155022506, 0.060660545161140215, 0.07944316187984152, 0.06933492995314965, 0.08000782447289465, 0.05977664647132375, 0.07150560986395799, 0.08341309714363483, 0.06862005198423858, 0.07838460792000086, 0.07746753103938742, 0.08136288533210934, 0.06588971131602026, 0.06674555922855058, 0.0737584878951348, 0.057546385637753154, 0.06869042981685777, 0.08005547932086149, 0.07450902336133475, 0.0806464951624058, 0.0666840906599728, 0.06404234480305815, 0.06144397553183835, 0.07566840239033196, 0.055872600291125764, 0.07976454706371301, 0.08000953399082804, 0.06527646677644687, 0.07001857139958756, 0.07841452101462759, 0.07877624682406154, 0.07825916536744243, 0.06675177082949825, 0.07953228589508528, 0.06878735656717155, 0.0685443305712723, 0.07732143285662844, 0.0743032533570302, 0.0742718798299849, 0.07664226997241905, 0.059792137333502006, 0.08115960701789111, 0.07554398652804165, 0.06294897973594146, 0.07831276732955933, 0.07872309702511869, 0.06502776153596641, 0.06990383380505634, 0.05985291164359854, 0.08230275747949636, 0.08279023238285066, 0.07989228494578107, 0.08253345463741794, 0.07396208888397611, 0.06508795848179347, 0.07079071080083303, 0.07248971411768719, 0.07981351478985037, 0.08413031830044253, 0.08015513170726654, 0.06665703518118919, 0.07983827973884121, 0.06474532797416141, 0.06592243230594944, 0.06694302690180012, 0.06677910155455428, 0.06750834236865666, 0.0732821057934491, 0.06556779175753621, 0.07903727869253599, 0.07944718692695402, 0.058569264758922865, 0.08110726735082156, 0.05723400302842267, 0.07380989669453361, 0.07360032914076557, 0.07784263102770844, 0.06332729816293042, 0.0683550861431076, 0.08069196357044348, 0.06764497733179105, 0.08102346637012879, 0.06888418855268524, 0.07895110814962751, 0.0608402687345492, 0.07163849361355933, 0.08154688754411508, 0.0787907694398883, 0.08077783546173288, 0.07440094186114228, 0.08029846294367043, 0.05581814943425383, 0.05989372416839388, 0.07767110502125628, 0.07912990608601687, 0.07000240813616077, 0.08064674760281844, 0.07929925201308281, 0.0794566714199116, 0.07863779212774938, 0.07996725534841316, 0.07325588675088324, 0.07021140157402987, 0.08103936158531351, 0.06110935575302909, 0.0764090828388407, 0.07553483823524672, 0.07865116620065253, 0.06265294634965163, 0.07889998866117373, 0.06464529636515524, 0.07813746675946792, 0.06853066246028663, 0.07853255046562625, 0.06568560432370396, 0.07975555673527356, 0.07792826260509059, 0.064052018118983, 0.06712706465446401, 0.0636327231650723, 0.07353770872701512, 0.07904861312698407, 0.06291069905687156, 0.06570287135071354, 0.055592832799643485, 0.06665564766355098, 0.07770925332217847, 0.062262992883739536, 0.05868819454965877, 0.06316126446211874, 0.06812000187459193, 0.06139788008609464, 0.07398153517469207, 0.06789916672587626, 0.06806514069708444, 0.07738505328170445, 0.084251152844563, 0.0710731361330914, 0.07804701354829206, 0.06180670308821797, 0.08015828200443671, 0.07683421158959453, 0.0656437766004971, 0.07963663084906923, 0.06564446496632341, 0.08246930976584241, 0.07916178889088861, 0.06910071123236437, 0.06418644406188773, 0.08227257525494197, 0.06754730070841264, 0.07709415665658094, 0.08383206408438726, 0.0637525913103584, 0.0792315383138297, 0.07985604553622597, 0.07531381448970827, 0.0679626512710999, 0.08177436826918852, 0.07906680272161391, 0.07826230518502907, 0.06378282935056301, 0.08019612852486528, 0.06504532135106995, 0.0692105391861645, 0.06878448957934387, 0.06270529584628635, 0.07933406109246173, 0.06978534370659865, 0.07838145492146241, 0.07482536600919636, 0.07816065240609162, 0.07935116120688064, 0.08089011330370621, 0.0810471489928253, 0.06258024374832198, 0.0769724029624852, 0.06631616364575822, 0.059034109860312683, 0.08173263337432538, 0.07242834369566128, 0.07867489428091261, 0.07017704201256478, 0.0806682065759797, 0.07011263405768034, 0.06757632967619905, 0.06703588635319661, 0.07805595256850874, 0.07865073617441502, 0.07075888855449208, 0.0669353696163114, 0.0761728346191478, 0.05672790436784518, 0.06693054976519851, 0.07969268604529624, 0.06560602046502945, 0.061478219033417526, 0.07704735301752308, 0.06060956667089772, 0.08102576524685777, 0.08187619283818363, 0.08188796240529143, 0.06177555727426016, 0.06342977557207978, 0.08040602181091508, 0.07829073794178014, 0.07557260480650937, 0.08152582921534053, 0.08236335542292106, 0.06303809444785409, 0.08007610549850437, 0.07872271450167599, 0.06668859180677852, 0.06249475317374709, 0.06762166670195341, 0.07512582866165182, 0.07991521510546937, 0.08015409015684302, 0.06831584050630445, 0.06706510974438248, 0.06983325408299897, 0.08093458905490586, 0.08003029374424175, 0.07813130631072737, 0.07915522351683074, 0.06898649008951308, 0.0564296870620488, 0.08024901908211501, 0.053166572654182086, 0.07267751781289838, 0.0798308286472407, 0.08112239252038075, 0.06780720702552213, 0.06349420099642014, 0.08169215058311972, 0.0796048697573985, 0.06786379512652209, 0.06900448896245544, 0.06684679338641007, 0.08066800071499594, 0.06646801744803794, 0.07987710138043572, 0.06696493378360517, 0.07499640179320692, 0.08103846757169773, 0.0801062337717301, 0.0662533561343024, 0.06142966969355429, 0.07154101251076075, 0.0844491770656742, 0.05859460334716863, 0.06464345659807316, 0.06143714373963653, 0.07853367981509898, 0.07990163118517613, 0.07498468627138383, 0.06570568651882282, 0.07849386155749365, 0.06190969489920771, 0.07081254463197217, 0.06638556885624108, 0.06377905746456419, 0.06308682882347608, 0.06530600852360377, 0.07842347137341213, 0.07286706833026627, 0.0780682031922916, 0.06443364076642547, 0.07783735427431583, 0.06929501995164067, 0.08022107613808195, 0.07790118051900884, 0.06005355329987199, 0.08232060109530781, 0.06078716829201778, 0.07772569453322865, 0.0745585671468763, 0.06692010570897935, 0.06161898417516466, 0.07977008393917227, 0.07872283357891613, 0.08019068575061862, 0.07860982798282973, 0.0648094383678954, 0.07889926174509175, 0.07306956020824264, 0.06831676624150101, 0.08102477968488754, 0.06785761100802859, 0.07926133847782146, 0.06926363191544868, 0.07913260629536953, 0.06574074975362124, 0.06451537230266348, 0.06915398097108368, 0.07345190193495994, 0.08097230266217621, 0.06688647639889903, 0.08234186186178516, 0.08099394992628334, 0.07860594270431148, 0.07709014124248209, 0.07885960646861456, 0.05921781078507226, 0.06219977466080112, 0.08031131574007262, 0.0641924225072997, 0.08134148912948462, 0.06470508225348674, 0.08128713393312396, 0.07935704259267062, 0.08040315791500448, 0.07192095971799044, 0.07934109295089674, 0.06531037313533089, 0.06604477716101743, 0.0583442600338811, 0.07465915392998428, 0.06710990036987856, 0.08007779555489078, 0.07141411171592113, 0.06597623554433876, 0.07953889924157297, 0.08086687583337852, 0.0796792796496437, 0.08443040519524958, 0.061403797134480124, 0.07916594592864237, 0.06801987844378338, 0.07094097395122653, 0.06315075786210084, 0.08088000012730338, 0.05257181703075746, 0.0631777215769904, 0.0642528229761677, 0.06703195809953377, 0.07320748336869345, 0.06846721993737127, 0.05592537450131837, 0.07965321784000497, 0.06270228397776269, 0.06464399567400328, 0.07697059753173432, 0.07173130752231882, 0.08014407730323306, 0.08499308295556028, 0.07395548497573959, 0.05617466514153823, 0.06626429377868817, 0.07099607216437887, 0.08048924722172013, 0.07989094361046462, 0.06395146914198128, 0.08134759279513377, 0.07937425406725704, 0.07882553271871308, 0.06487762427048922, 0.08517963394504846, 0.07759811020545049, 0.07373098333502767, 0.07862999365224302, 0.0633039847081472, 0.06512310985793679, 0.07846726205197542, 0.06656734420666073, 0.0800318171419286, 0.05919111381823223, 0.07743404766650815, 0.08017023748542437, 0.07966365721879769, 0.07798264901893223, 0.0792784737920492, 0.07744569070529703, 0.07888677964499918, 0.0804643485999905, 0.08073464370345246, 0.07819553610388398, 0.07861133575528384, 0.0604024504849896, 0.06634810927639437, 0.07922223579242496, 0.060897846098315334, 0.0790860943339011, 0.0803031257248608, 0.0666517259476355, 0.07807514509980731, 0.07412749281466476, 0.07946919141232252, 0.08090034026823592, 0.06321072650471464, 0.07032609097786532, 0.0678522530717553, 0.07785987763141657, 0.0690406579357087, 0.07809956317741264, 0.07834273712588058, 0.06337651734280401, 0.07735436633321723, 0.08032448648554787, 0.05756881305672419, 0.07901848383705376, 0.0628645767180207, 0.0653460223698955, 0.07297484313526978, 0.07322978664852772, 0.06388072629079274, 0.0819524501147026, 0.07095086818244258, 0.060532620656840105, 0.06933927521051815, 0.08344232692289984, 0.08357217717330552, 0.0786879508775649, 0.06558259780584501, 0.07664981143235432, 0.05593110089694894, 0.08039047521959061, 0.0658177176275881, 0.07760614383648103, 0.06550043233632624, 0.062256525335466405, 0.05882938607806685, 0.06500256118265407, 0.06346611201901745, 0.07852773965656637, 0.06444979651143727, 0.06736943610061483, 0.07946731573716288, 0.07954530181624209, 0.061005583212798774, 0.06783125029190089, 0.0679521449302021, 0.07735481711213289, 0.06956952184948975, 0.06413537711257833, 0.06882669771261002, 0.06796485198036392, 0.08058221561017176, 0.06602089192176167, 0.08024271143737187, 0.054853718342608354, 0.06900125169500655, 0.06280726554245147, 0.06862172619200385, 0.07990159882680035, 0.06791053989569426, 0.06406398381960511, 0.07012412994501795, 0.07272802440925875, 0.07596749770500091, 0.06514020645898011, 0.06648852326093238, 0.0677441406767292, 0.08231389604449701, 0.06936639275299063, 0.05608313852482605, 0.0706959059664533, 0.07793964186386125, 0.07898160771928549, 0.07575505955263034, 0.06472867290507596, 0.05990299379931572, 0.07402648276294074, 0.07682476561212155, 0.07899138389751657, 0.08148324461397655, 0.07484224018953901, 0.06499339258973531, 0.061566669487610665, 0.08345385138547817, 0.0817654176089442, 0.060918968905993694, 0.06836588658180646, 0.06800660023993056, 0.08044855910349553, 0.07743981538093433, 0.08492663574086655, 0.07190122426323484, 0.07871531779083211, 0.059828902970302654, 0.06147428765698469, 0.0816124530037208, 0.059399744535376574, 0.0632486596531094, 0.06354549723572867, 0.06223879450790865, 0.07560651441184114, 0.08034243881453106, 0.06954739977449988, 0.05808727018157683, 0.07935215968800083, 0.07989894054993851, 0.08177267449243099, 0.06402464975692866, 0.058924665236664224, 0.06639143822464864, 0.07484894059322567, 0.07662704359758112, 0.07991989993665563, 0.06952967200941985, 0.08057013875289512, 0.06170804016534921, 0.05935541951642037, 0.07389042762680331, 0.06557774784283989, 0.0794139202688066, 0.06450915812822086, 0.060452263289661586, 0.05860619622713439, 0.06605930509324054, 0.07807038447989567, 0.08032814630026372, 0.07656570634560032, 0.0773117762209923, 0.07946342260764205, 0.08262352970298796, 0.05794686646418925, 0.07857493920957025, 0.06046594176528828, 0.06709892740106038, 0.07473723819737163, 0.08286787532864553, 0.06636209662782272, 0.08019232748457773, 0.07878311678362315, 0.05783903659640303, 0.07415230412860277, 0.08010401196421364, 0.08226698830648735, 0.06460580503277638, 0.07868662126094389, 0.07447763774135455, 0.07102039165660962, 0.0828690917794013, 0.07597162284070358, 0.0675172977243326, 0.0772135972976763, 0.0668583656109484, 0.06362753135897734, 0.0775224065847501, 0.06471908483288191, 0.07441792345481017, 0.07437244724635303, 0.07935198771666988, 0.06267389264426412, 0.06642037364538683, 0.08236180038229404, 0.06436844569256875, 0.06890550758146355, 0.06334447136102031, 0.07168926178337282, 0.07459087877746153, 0.07760033467562062, 0.0844603939645456, 0.07863569090423611, 0.07021868019300186, 0.07702682736857917, 0.0628950860391706, 0.06532859752992644, 0.06588763269863757, 0.06436324748120587, 0.07884925770887245, 0.07431879267649577, 0.07361070649692911, 0.0639588759256803, 0.07334659070448708, 0.06603082278444111, 0.08108602365430502, 0.0680296210337753, 0.060699712400373244, 0.07975366862640121, 0.07782050621772986, 0.06143656072952347, 0.07840600214207925, 0.0795613050187627, 0.07483386710261009, 0.06810704779481545, 0.07266955100260677, 0.06784252274146968, 0.06627826071171827, 0.07428188933411453, 0.07853731219554914, 0.07157718159676311, 0.0791727997740327, 0.06653362822111386, 0.06915702454521497, 0.07099046996069745, 0.05946245358934625, 0.07786665339502612, 0.06822882324699983, 0.058769504551008815, 0.0642166975346294, 0.07178764707428849, 0.06801021170320498, 0.07851257480549512, 0.07059823906966696, 0.0609497043308282, 0.059966273083825815, 0.0711050327970434, 0.08037408549062137, 0.06496513492984737, 0.08106915641478227, 0.07842025012706563, 0.08184400153234078, 0.08213223857583551, 0.05553155692757807, 0.08492603822806974, 0.08038947571473237, 0.07801265248697503, 0.08100819269981335, 0.0777234983562186, 0.06262310685873773, 0.06700575677463898, 0.06500409064301062, 0.06738468962588214, 0.07653670004553667, 0.07317716263406142, 0.07712624211312524, 0.07755988938331879, 0.0698883926670234, 0.07541989312671267, 0.070025044131186, 0.0788352644416915, 0.07061564520884708, 0.06649897864200771, 0.07258624366491233, 0.06957166839919522, 0.07623070663770296, 0.07740265035770909, 0.06712397155044204, 0.07136691155154797, 0.06465169351251496, 0.07001989372527515, 0.07674708991803218, 0.07367602202854373, 0.08113647996538492, 0.06902187621774573, 0.08124781584081489, 0.07712135574856951, 0.07159039738794044, 0.05469565644123806, 0.07904107509724814, 0.07871559355533042, 0.08109388907993009, 0.05870579879070811, 0.07927526048534159, 0.07224692116082508, 0.08033720169102651, 0.08084580656107493, 0.0680730968536956, 0.08013838539254335, 0.07820431088416877, 0.06379802400126913, 0.0682486680366925, 0.0786198063611795, 0.07726172746447338, 0.07084775991758553, 0.07322767087913998, 0.08052185748006238, 0.08021215357907825, 0.08226494301433132, 0.0688254489106114, 0.0802432832138961, 0.076751759286073, 0.07731573450322961, 0.07995049971225786, 0.07775747500733551, 0.07327840527193677, 0.07350030267518219, 0.07835907975086298, 0.08221467219649309, 0.07576557971363578, 0.07658002608469336, 0.07580998336962501, 0.07577553344030205, 0.06582392682134698, 0.06332805169477151, 0.0678742546484818, 0.062010824886349916, 0.08325140797840166, 0.0663132438676222, 0.06876679007781054, 0.06843469984036478, 0.06764087729537734, 0.07888655867154831, 0.0786647353040884, 0.08281139159817108, 0.07865490610136959, 0.061224998323249534, 0.06352658108063797, 0.05658656439314926, 0.061355906152424165, 0.07020081828249972, 0.06169747261868165, 0.06599423795613849, 0.06452882296871833, 0.07903169986436422, 0.06995542297031028, 0.07159515125731719, 0.07836725604732742, 0.07123958182611288, 0.07633001601558304, 0.07477713585607451, 0.08451120351093697, 0.06999071882834774, 0.06546976846774466, 0.07987024802997637, 0.07766172621684575, 0.06426567520617553, 0.08009566290342557, 0.05993576900333925, 0.08450540207424127, 0.0671967901327625, 0.07050518787095837, 0.07106336670497786, 0.07761427423490731, 0.0798168520483803, 0.08098745658435276, 0.06104512498206816, 0.07098807865293759, 0.07113358573185587, 0.08150943345717375, 0.062100574740622, 0.07578847312224492, 0.07103181006322141, 0.0825504737400537, 0.06391422922175198, 0.06458997609279049, 0.0717474646291952, 0.07637064459311413, 0.06723937239339935, 0.08151696719369003, 0.05146826929022312, 0.06798579301798563, 0.07085481172332138, 0.0784055070166158, 0.06433195507097739, 0.07188353997843151, 0.05071458501368267, 0.0783993172071722, 0.06052256709864216, 0.08221681696364781, 0.06410870811170633, 0.06563740320119239, 0.06277450014492551, 0.08146810854929677, 0.06978006578638496, 0.07901522026589879, 0.08002605408174393, 0.07945408799976891, 0.08040677504684643, 0.07995809296413302, 0.07765679507785377, 0.06098208080369166, 0.08017863548022293, 0.07489073913356012, 0.06557131863309969, 0.0657609332866738, 0.08016176134524942, 0.07426126844933958, 0.07947292641581645, 0.06981383639817325, 0.0781418669731984, 0.06017867246617138, 0.07951524597884198, 0.06358149185049766, 0.06150128925900104, 0.06953539454376739, 0.05988994625800818, 0.06568434955135243, 0.07591764267883776, 0.08029403643946226, 0.06890464852080876, 0.07530071222642569, 0.06785582325678029, 0.07748814198841154, 0.07236359816741965, 0.07626330460688044, 0.07307772685744002, 0.06627693465212521, 0.06512454528839638, 0.06588389828023071, 0.0791942424507131, 0.07431820272091488, 0.07012176877170624, 0.08248327357815566, 0.06402764844410491, 0.08049320594592183, 0.06105497301262417, 0.0727899386313679, 0.07210336684323097, 0.06651685202377743, 0.08006973037250906, 0.0761312822539205, 0.07385529714525989, 0.07873473072912335, 0.07885878967055633, 0.06537754684296249, 0.08051271199478709, 0.07980935992153634, 0.06930240704734035, 0.07886266149408575, 0.06438645225438684, 0.05823950789509203, 0.07162387178017739, 0.07029473227380138, 0.06341828608243996, 0.08297508153490248, 0.05837772700117751, 0.07243331205811049, 0.06234841945421837, 0.06557094153569652, 0.06725786469420073, 0.061622659562989415, 0.08093248393698844, 0.06617343186267184, 0.058325287641644755, 0.06673121151387607, 0.0804284426582515, 0.06277915125491486, 0.07912246286139732, 0.07866816722906281, 0.07007014950603364, 0.07048406392851306, 0.08109581433474493, 0.06182092765909459, 0.08033426960037156, 0.08031777312275408, 0.07892303701776193, 0.0684566985742873, 0.07064888636462875, 0.06555421613851335, 0.08086327937784045, 0.07821980755883085, 0.06440623428641017, 0.0675798862676841, 0.08045860160874171, 0.06379656748688207, 0.07833581882627015, 0.06908537996857071, 0.07599885647848781, 0.08072996194978435, 0.07973660427002686, 0.055749892262030386, 0.06699869756669428, 0.061497548259379524, 0.06831311244255718, 0.0753467565174637, 0.07268733545637786, 0.07973893496137222, 0.07815019283131275, 0.06271738208803751, 0.06884911429918268, 0.07821756641518691, 0.07320539499262596, 0.08117283025660346, 0.07816039288148563, 0.07983538999078946, 0.07478126772707326]\n"
     ]
    }
   ],
   "source": [
    "reconstructed_data = pd.DataFrame(model_a.predict(compress_data))\n",
    "\n",
    "full_data_check = full_data.drop(['index'], axis=1)\n",
    "\n",
    "r = [pearsonr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "\n",
    "s = [spearmanr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "print(r)\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cancer_type\n",
      "0            BRCA\n",
      "1            LUAD\n",
      "2            DLBC\n",
      "3            UCEC\n",
      "4            SKCM\n",
      "...           ...\n",
      "11055        BRCA\n",
      "11056        PRAD\n",
      "11057        SKCM\n",
      "11058        KIRC\n",
      "11059        BRCA\n",
      "\n",
      "[11060 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "all_labels = pd.concat([train_label_df, test_label_df], axis=0)\n",
    "all_labels = pd.DataFrame(np.array(all_labels), columns=['cancer_type'])\n",
    "\n",
    "print(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data_label = pd.concat([reconstructed_data, all_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_data = pd.DataFrame(np.array(compress_data))\n",
    "compressed_data_label = pd.concat([compress_data, all_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_label = pd.concat([full_data.drop(['index'], axis=1), all_labels], axis=1)#.drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLR(df2, test2):\n",
    "    time_laps = []\n",
    "    for i in range(4):\n",
    "        start_time = time.time()\n",
    "        clf = LogisticRegression(random_state=0).fit(df2.iloc[:,0:df2.shape[1]],df2[\"cancer_type\"])\n",
    "        pred = clf.predict(test2.iloc[:,0:test2.shape[1]])\n",
    "        accuracy = accuracy_score(test2.cancer_type,pred)\n",
    "        laps = time.time() - start_time\n",
    "        time_laps.append(laps)\n",
    "    avg_time_laps = np.mean(time_laps)\n",
    "    SVM_accuracy = accuracy\n",
    "    SVM_computation_time = avg_time_laps\n",
    "    return SVM_accuracy, SVM_computation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnDf2(c_type, df2):\n",
    "    fraction = collections.Counter(merge_train)[c_type]/len(merge_train)\n",
    "\n",
    "    df2_0 = df2[df2.cancer_type!=c_type]\n",
    "    df2_0.loc[:,\"cancer_type\"] = 0\n",
    "    df2_0 = df2_0.sample(frac = fraction)\n",
    "\n",
    "    df2_1 = df2[df2.cancer_type==c_type]\n",
    "    df2_1.loc[:,\"cancer_type\"] = 1\n",
    "    \n",
    "    #print(df2_0)\n",
    "    #print(df2_1)\n",
    "    \n",
    "    df2 = pd.concat([df2_0, df2_1])\n",
    "    df2[\"cancer_type\"] = df2[\"cancer_type\"].astype('int')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, test_full = train_test_split(full_data_label, test_size=0.1)\n",
    "train_compress, test_compress = train_test_split(compressed_data_label, test_size=0.1)\n",
    "train_reconstructed, test_reconstructed = train_test_split(reconstructed_data_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "c_type_list = collections.Counter(merge_train)\n",
    "#c_type_list = ['LUAD', 'LGG', 'PRAD', 'STAD']\n",
    "#c_type_list = ['DLBC']\n",
    "\n",
    "cols = ['cancer_type', 'Full-data acc.', 'Full-data comp. time','compress acc.','compress comp. time', 'VAE-reconst. acc.', 'VAE-reconst. time.']\n",
    "results_df = pd.DataFrame(columns = cols)\n",
    "i = 0\n",
    "for c_type in c_type_list:\n",
    "    train_full_ova = returnDf2(c_type, train_full)\n",
    "    test_full_ova = returnDf2(c_type, test_full)\n",
    "    train_compress_ova = returnDf2(c_type, train_compress)\n",
    "    test_compress_ova = returnDf2(c_type, test_compress)\n",
    "    train_reconstructed_ova = returnDf2(c_type, train_reconstructed)\n",
    "    test_reconstructed_ova = returnDf2(c_type, test_reconstructed)\n",
    "    full_acc, full_time = runLR(train_full_ova, test_full_ova)\n",
    "    compress_acc, compress_time = runLR(train_compress_ova, test_compress_ova)\n",
    "    full_reconstructed_acc, full_reconstructed_time = runLR(train_reconstructed_ova, test_reconstructed_ova)\n",
    "    results_df.loc[i] = [c_type, full_acc,full_time,compress_acc,compress_time, full_reconstructed_acc,full_reconstructed_time]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>Full-data acc.</th>\n",
       "      <th>Full-data comp. time</th>\n",
       "      <th>compress acc.</th>\n",
       "      <th>compress comp. time</th>\n",
       "      <th>VAE-reconst. acc.</th>\n",
       "      <th>VAE-reconst. time.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>0.991266</td>\n",
       "      <td>4.308974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.928997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.416042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.421776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DLBC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCEC</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>2.215578</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.146263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKCM</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.645601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.958764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRAD</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>1.271102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.450449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HNSC</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>2.427012</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.060588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.303841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KIRP</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>1.128314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.632386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CESC</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.635128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.636625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THCA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.433667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.422275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KIRC</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>2.597307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.479870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>STAD</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>2.059486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.966244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COAD</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>2.192888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.962753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>READ</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.107539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGG</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.370337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.214081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MESO</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579202</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.690903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LAML</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.151920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>2.009379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.989432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OV</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.009052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.385297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>2.409559</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.052360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.259460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571223</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.031417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>THYM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ESCA</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.057922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.204779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PAAD</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.140950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LIHC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.120754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.712921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SARC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.203284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.293043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TGCT</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.665970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.047450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KICH</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PCPG</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.193310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UCS</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.602638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.590422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CHOL</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552773</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.756229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cancer_type  Full-data acc.  Full-data comp. time  compress acc.  \\\n",
       "0         BRCA        0.991266              4.308974       1.000000   \n",
       "1         LUAD        1.000000              2.416042       1.000000   \n",
       "2         DLBC        1.000000              0.469994       1.000000   \n",
       "3         UCEC        0.960396              2.215578       0.990196   \n",
       "4         SKCM        0.988889              1.645601       1.000000   \n",
       "5         PRAD        0.990741              1.271102       1.000000   \n",
       "6         HNSC        0.982456              2.427012       0.990291   \n",
       "7         KIRP        0.985294              1.128314       1.000000   \n",
       "8         CESC        0.944444              1.635128       1.000000   \n",
       "9         THCA        1.000000              1.433667       1.000000   \n",
       "10        KIRC        0.976000              2.597307       1.000000   \n",
       "11        STAD        0.976744              2.059486       1.000000   \n",
       "12        COAD        0.979167              2.192888       1.000000   \n",
       "13        READ        0.928571              1.107539       1.000000   \n",
       "14         LGG        1.000000              1.370337       1.000000   \n",
       "15        MESO        1.000000              0.579202       0.952381   \n",
       "16        LAML        1.000000              0.673948       1.000000   \n",
       "17        BLCA        0.906667              2.009379       1.000000   \n",
       "18          OV        0.984375              1.009052       1.000000   \n",
       "19        LUSC        0.950980              2.409559       0.990741   \n",
       "20         ACC        1.000000              0.571223       0.941176   \n",
       "21        THYM        1.000000              0.609122       1.000000   \n",
       "22        ESCA        0.973684              1.057922       1.000000   \n",
       "23        PAAD        1.000000              0.825793       1.000000   \n",
       "24        LIHC        1.000000              1.120754       1.000000   \n",
       "25        SARC        1.000000              1.203284       1.000000   \n",
       "26         GBM        1.000000              0.948215       1.000000   \n",
       "27        TGCT        0.969697              0.665970       1.000000   \n",
       "28        KICH        1.000000              0.716585       1.000000   \n",
       "29        PCPG        1.000000              0.947966       1.000000   \n",
       "30         UCS        0.923077              0.602638       1.000000   \n",
       "31         UVM        1.000000              0.590422       1.000000   \n",
       "32        CHOL        1.000000              0.552773       0.857143   \n",
       "\n",
       "    compress comp. time  VAE-reconst. acc.  VAE-reconst. time.  \n",
       "0              0.099232                1.0            3.928997  \n",
       "1              0.048371                1.0            2.421776  \n",
       "2              0.023437                1.0            0.663726  \n",
       "3              0.050864                1.0            2.146263  \n",
       "4              0.072805                1.0            1.958764  \n",
       "5              0.039395                1.0            2.450449  \n",
       "6              0.060588                1.0            2.303841  \n",
       "7              0.044880                1.0            1.632386  \n",
       "8              0.042387                1.0            1.636625  \n",
       "9              0.101541                1.0            2.422275  \n",
       "10             0.077293                1.0            2.479870  \n",
       "11             0.045877                1.0            1.966244  \n",
       "12             0.072556                1.0            1.962753  \n",
       "13             0.037899                1.0            1.082107  \n",
       "14             0.038647                1.0            2.214081  \n",
       "15             0.029172                1.0            0.690903  \n",
       "16             0.022689                1.0            1.151920  \n",
       "17             0.044381                1.0            1.989432  \n",
       "18             0.044132                1.0            1.385297  \n",
       "19             0.052360                1.0            2.259460  \n",
       "20             0.031417                1.0            0.636548  \n",
       "21             0.034657                1.0            0.898099  \n",
       "22             0.041888                1.0            1.204779  \n",
       "23             0.035156                1.0            1.140950  \n",
       "24             0.042138                1.0            1.712921  \n",
       "25             0.040392                1.0            1.293043  \n",
       "26             0.034408                1.0            0.974894  \n",
       "27             0.042885                1.0            1.047450  \n",
       "28             0.051861                1.0            0.888624  \n",
       "29             0.042386                1.0            1.193310  \n",
       "30             0.029172                1.0            0.676193  \n",
       "31             0.024185                1.0            0.685667  \n",
       "32             0.027675                1.0            0.756229  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTICLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multiclass(c_type_list, df2):\n",
    "    df_main = df2[df2.cancer_type==c_type_list[0]]\n",
    "    df_main.loc[:,\"cancer_type\"] = 0\n",
    "    \n",
    "    for i in range(1,len(c_type_list)):\n",
    "        c_type = c_type_list[i]\n",
    "        df2_temp = df2[df2.cancer_type==c_type]\n",
    "        df2_temp.loc[:,\"cancer_type\"] = i\n",
    "        df_main = pd.concat([df_main, df2_temp])\n",
    "        \n",
    "    df2 = df_main\n",
    "    df2[\"cancer_type\"] = df2[\"cancer_type\"].astype('int')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "multi_class_list = ['UCEC', 'HNSC', 'SARC', 'ACC', 'LUSC', 'KIRC', 'PCPG', 'LUAD', 'HNSC', 'COAD']\n",
    "\n",
    "df2_train_full = prepare_multiclass(multi_class_list, train_full)\n",
    "df2_test_full = prepare_multiclass(multi_class_list, test_full)\n",
    "df2_train_compress = prepare_multiclass(multi_class_list, train_compress)\n",
    "df2_test_compress = prepare_multiclass(multi_class_list, test_compress)\n",
    "df2_train_reconstructed = prepare_multiclass(multi_class_list, train_reconstructed)\n",
    "df2_test_reconstructed = prepare_multiclass(multi_class_list, test_reconstructed)\n",
    "\n",
    "full_acc, full_time = runLR(df2_train_full, df2_test_full)\n",
    "compress_acc, compress_time = runLR(df2_train_compress, df2_test_compress)\n",
    "reconstructed_acc, reconstructed_time = runLR(df2_train_reconstructed, df2_test_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data-  \t Acc =  0.836405529953917 \t Time =  18.56551480293274\n",
      "Comp. Data-  \t Acc =  0.9882352941176471 \t Time =  0.6420339941978455\n",
      "Recon. Data-  \t Acc =  0.9849462365591398 \t Time =  14.962434351444244\n"
     ]
    }
   ],
   "source": [
    "print(\"Full Data- \",\"\\t Acc = \",full_acc,\"\\t Time = \", full_time)\n",
    "print(\"Comp. Data- \",\"\\t Acc = \",compress_acc,\"\\t Time = \", compress_time)\n",
    "print(\"Recon. Data- \",\"\\t Acc = \",reconstructed_acc,\"\\t Time = \", reconstructed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting pearson and spearman correlations over number of latent dimensions (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_15\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_15\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 22s - loss: -28097682.1729 - val_loss: -153526019.1682\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 27s - loss: -171791374.9455 - val_loss: -256992145.9675\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 19s - loss: -292490989.4507 - val_loss: -303691695.2188\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: -310336748.9877 - val_loss: -313033569.9096\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 17s - loss: -313772963.1312 - val_loss: -314513880.5931\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 17s - loss: -314467683.9285 - val_loss: -314695439.3345\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: -314560439.0693 - val_loss: -314765738.6474\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: -314608374.2270 - val_loss: -314786064.9548\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314633558.9279 - val_loss: -314797478.7703\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 17s - loss: -314645384.8792 - val_loss: -314816716.7884\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 17s - loss: -314657577.0078 - val_loss: -314820023.4937\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 17s - loss: -314660391.2654 - val_loss: -314828739.0669\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 17s - loss: -314669688.4195 - val_loss: -314829053.2224\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 17s - loss: -314670637.9843 - val_loss: -314834853.6130\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: -314675206.1467 - val_loss: -314840364.7306\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: -314676532.8447 - val_loss: -314840465.8807\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: -314676152.3488 - val_loss: -314844451.8192\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: -314678577.2570 - val_loss: -314846482.6908\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: -314681552.0161 - val_loss: -314842774.0470\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: -314683005.0038 - val_loss: -314846676.7161\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 17s - loss: -314682109.5439 - val_loss: -314842827.7468\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 17s - loss: -314683434.9946 - val_loss: -314848971.8626\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683173.6323 - val_loss: -314849285.6130\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685228.2869 - val_loss: -314849731.5298\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 17s - loss: -314684752.4018 - val_loss: -314850174.9005\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: -314685088.6237 - val_loss: -314850200.7667\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: -314685701.0215 - val_loss: -314850669.3092\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685368.9017 - val_loss: -314850261.6998\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685989.7288 - val_loss: -314848071.4647\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686073.4997 - val_loss: -314850385.7071\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685806.7816 - val_loss: -314851366.9439\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686470.1402 - val_loss: -314849034.0687\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686262.7607 - val_loss: -314850645.9892\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686164.6518 - val_loss: -314851208.1591\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686960.0611 - val_loss: -314849692.1808\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686580.2917 - val_loss: -314851672.9403\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686861.0970 - val_loss: -314850252.3255\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686891.8433 - val_loss: -314851576.7667\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686513.8356 - val_loss: -314851809.6203\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687101.7175 - val_loss: -314851320.6510\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687262.7977 - val_loss: -314851309.0778\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687200.8101 - val_loss: -314851705.2875\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687296.2315 - val_loss: -314851959.8987\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687298.4432 - val_loss: -314851627.3418\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687357.5375 - val_loss: -314850727.8698\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687340.3834 - val_loss: -314851936.9259\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687293.6275 - val_loss: -314852258.0832\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687440.8391 - val_loss: -314852252.6438\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687436.2548 - val_loss: -314852339.0958\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687514.4127 - val_loss: -314852295.8698\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687376.8198 - val_loss: -314852258.0832\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687396.8286 - val_loss: -314852370.9222\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687399.3104 - val_loss: -314852160.0579\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687563.6954 - val_loss: -314852399.8553\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687513.5961 - val_loss: -314851546.6763\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687539.4237 - val_loss: -314852200.2170\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687543.6801 - val_loss: -314852353.5624\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687443.6038 - val_loss: -314852414.6691\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687572.9926 - val_loss: -314852443.4286\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687590.0309 - val_loss: -314852396.9620\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687639.2493 - val_loss: -314852420.1085\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687513.7826 - val_loss: -314852411.6022\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687619.6777 - val_loss: -314852452.1085\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687661.3092 - val_loss: -314852382.4955\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687639.7637 - val_loss: -314852414.4955\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687639.6994 - val_loss: -314852449.3888\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687654.5132 - val_loss: -314852226.2568\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687640.6639 - val_loss: -314852440.5353\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687671.7766 - val_loss: -314852408.7089\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687553.7746 - val_loss: -314852463.8553\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687665.4949 - val_loss: -314851957.3526\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 17s - loss: -314687678.8684 - val_loss: -314852454.8282\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687686.1853 - val_loss: -314852466.4014\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687671.4872 - val_loss: -314852359.5226\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687683.0798 - val_loss: -314852168.5642\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687691.0332 - val_loss: -314852466.7486\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687595.5925 - val_loss: -314852469.6420\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687688.0820 - val_loss: -314852165.6709\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687689.2393 - val_loss: -314852472.3617\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687670.2335 - val_loss: -314852472.3617\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687697.0384 - val_loss: -314852472.5353\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687693.4314 - val_loss: -314852220.6438\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687700.5168 - val_loss: -314852492.6148\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687703.7187 - val_loss: -314852316.1230\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687700.9604 - val_loss: -314852478.1483\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687671.3586 - val_loss: -314852481.2152\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687701.3269 - val_loss: -314852478.1483\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687705.5511 - val_loss: -314852466.5750\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687684.5586 - val_loss: -314852495.3345\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687704.2909 - val_loss: -314852481.2152\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687651.0540 - val_loss: -314852483.934904\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687708.2516 - val_loss: -314852481.2152\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687707.8658 - val_loss: -314852469.4684\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687705.9498 - val_loss: -314852475.4286\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687705.4225 - val_loss: -314852478.1483\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687712.1993 - val_loss: -314852475.4286\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687706.0655 - val_loss: -314852483.9349\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687709.4410 - val_loss: -314852489.8951\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687692.5120 - val_loss: -314852489.7215\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687708.0780 - val_loss: -314852486.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_16\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_16\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 19s - loss: -45549631.9011 - val_loss: -193669948.6293\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 17s - loss: -228060525.4282 - val_loss: -281001268.7161\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 17s - loss: -305200215.4615 - val_loss: -309053546.8788\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 17s - loss: -312029971.7452 - val_loss: -312982758.0759\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -313179896.6253 - val_loss: -313768521.4901\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -313888712.1013 - val_loss: -314423363.1826\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314166588.2066 - val_loss: -314421199.4503\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314375765.7834 - val_loss: -314397791.3056\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314398199.1015 - val_loss: -314796401.1284\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314542040.6767 - val_loss: -314655663.1609\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314554666.1394 - val_loss: -314817789.7432\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314584292.7000 - val_loss: -314700608.3472\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314600765.5375 - val_loss: -314807867.3128\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314610007.9309 - val_loss: -314769269.4684\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314633929.4772 - val_loss: -314785790.2640\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314641973.2305 - val_loss: -314757661.3382\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314639366.1724 - val_loss: -314768595.1537\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314659611.1264 - val_loss: -314833425.8807\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314653598.5791 - val_loss: -314849969.6492\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668855.1915 - val_loss: -314850736.7233\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314656809.9594 - val_loss: -314799767.8409\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314665710.2415 - val_loss: -314851752.4485\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314669290.9046 - val_loss: -314849515.2260\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679672.6831 - val_loss: -314832992.0579\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681494.8571 - val_loss: -314838327.1465\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680192.5272 - val_loss: -314848286.2640\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682009.9755 - val_loss: -314851193.6926\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686369.1316 - val_loss: -314846913.6203\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314677592.5031 - val_loss: -314848652.6727\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682867.8545 - val_loss: -314852076.15190s - loss: -31461826\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681067.6697 - val_loss: -314850466.8354\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681546.0494 - val_loss: -314852145.0127\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678751.6142 - val_loss: -314852316.2966898.\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685144.4131 - val_loss: -314851451.1971\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686281.4258 - val_loss: -314834472.5642\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686771.6038 - val_loss: -314851500.3834\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686950.7896 - val_loss: -314851905.9675\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684853.2176 - val_loss: -314852377.0561\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686448.5883 - val_loss: -314852399.8553\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684609.2538 - val_loss: -314852299.1103\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685919.7492 - val_loss: -314829910.6835\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686347.2518 - val_loss: -314837815.3779\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686339.6584 - val_loss: -314852402.9222\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686770.3372 - val_loss: -314852287.3635\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687018.7374 - val_loss: -314852466.4014\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685477.5616 - val_loss: -314851555.3562\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687314.7229 - val_loss: -314852368.3761\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686137.6026 - val_loss: -314852386.0832\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687142.0181 - val_loss: -314852334.0036\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687435.5732 - val_loss: -314852449.5624\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687406.1065 - val_loss: -314852307.9638\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687223.8987 - val_loss: -314852173.3092\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687353.6219 - val_loss: -314852426.2423\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687395.9928 - val_loss: -314852464.2025\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687661.0778 - val_loss: -314852472.5353\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687495.2976 - val_loss: -314852458.0687\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687611.3450 - val_loss: -314852238.5244\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687645.0231 - val_loss: -314852307.2694\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687578.2327 - val_loss: -314852379.7758\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687686.9825 - val_loss: -314852504.7089\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687673.9112 - val_loss: -314852492.6148 - ETA: \n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687423.4985 - val_loss: -314851619.0090\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687686.5260 - val_loss: -314852452.4557\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687355.6600 - val_loss: -314852519.0018\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687463.0404 - val_loss: -314852498.7486\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687652.1728 - val_loss: -314852512.6944\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687628.2162 - val_loss: -314852518.4810\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687713.5560 - val_loss: -314852495.6817\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687714.8354 - val_loss: -314852501.4684\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687706.6956 - val_loss: -314852376.8825\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687694.0036 - val_loss: -314852448.5208\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314687655.8698 - val_loss: -314852516.2821\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687705.2747 - val_loss: -314852374.1627\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687700.3303 - val_loss: -314852510.1483\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687596.5248 - val_loss: -314852512.8680\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687615.0098 - val_loss: -314852443.7758\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687666.7872 - val_loss: -314852487.0018\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687708.4637 - val_loss: -314852481.2152\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687722.2745 - val_loss: -314852504.1881\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687693.2578 - val_loss: -314852501.1212\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687719.9341 - val_loss: -314852507.6022\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687720.9821 - val_loss: -314852397.3092\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687725.4764 - val_loss: -314852489.8951\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687716.4621 - val_loss: -314852495.6817\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687726.5116 - val_loss: -314852516.1085\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687724.2805 - val_loss: -314852513.3888\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687704.7024 - val_loss: -314852516.1085\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687698.8901 - val_loss: -314852507.4286\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687722.3516 - val_loss: -314852510.3219\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687720.3906 - val_loss: -314852524.6148\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687719.1497 - val_loss: -314852521.8951\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687725.1613 - val_loss: -314852518.8282\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687730.3564 - val_loss: -314852519.0018\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687723.2839 - val_loss: -314852518.8282\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687726.3187 - val_loss: -314852521.7215\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687704.6703 - val_loss: -314852504.7089\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687729.9900 - val_loss: -314852512.8680 loss: -314740\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687722.0687 - val_loss: -314852521.8951\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687723.2518 - val_loss: -314852522.0687\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687729.4177 - val_loss: -314852521.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_17\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_17\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 20s - loss: -70928764.2099 - val_loss: -256917250.6908\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -273044547.5170 - val_loss: -292573262.4087\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -307308211.9574 - val_loss: -309516164.2242\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -312223036.6502 - val_loss: -312250243.5298\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -313561558.9279 - val_loss: -313627363.3562\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314066808.6767 - val_loss: -314376291.3562\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314343460.5329 - val_loss: -314592500.8318\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314393985.2988 - val_loss: -314560579.4141\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314459540.2660 - val_loss: -314631014.3653\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314442673.1155 - val_loss: -314673836.0362\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314568079.3024 - val_loss: -314569793.8517\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314586488.6381 - val_loss: -314782772.5425\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314578762.7052 - val_loss: -314713433.8662\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314598318.6337 - val_loss: -314775958.7993\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314611536.0739 - val_loss: -314838882.6618\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314629525.3205 - val_loss: -314787445.2369\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314642601.1557 - val_loss: -314845578.8210 l\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314641412.2371 - val_loss: -314780391.3490\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314649446.3846 - val_loss: -314804171.1682\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314656874.7631 - val_loss: -314844608.6944\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314667883.4189 - val_loss: -314851563.6890\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681854.1997 - val_loss: -314851147.5732\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678901.8348 - val_loss: -314835323.7179: 1s -\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668005.3237 - val_loss: -314851876.8608\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314646953.4193 - val_loss: -314851413.5841\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682018.5461 - val_loss: -314821172.3689\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314659914.4095 - val_loss: -314852179.5009\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681879.9502 - val_loss: -314818305.9096\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682925.8429 - val_loss: -314850120.5642\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684501.2176 - val_loss: -314851026.2278\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683470.1001 - val_loss: -314790477.4250\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314669100.8334 - val_loss: -314851919.913229 - E\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686453.9892 - val_loss: -314805822.0904\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686698.2938 - val_loss: -314840653.5407\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676199.6641 - val_loss: -314825587.9060\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686389.1726 - val_loss: -314852061.8590\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685109.7898 - val_loss: -314852142.6980\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685141.8541 - val_loss: -314852391.5226\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685934.6273 - val_loss: -314837870.0036\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679879.3940 - val_loss: -314852391.5226\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685696.7973 - val_loss: -314852056.0723\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: -314684680.1656 - val_loss: -314852073.6058\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: -314677235.4302 - val_loss: -314851820.8463\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686830.5566 - val_loss: -314852475.6022\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687168.1672 - val_loss: -314852354.2568\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683160.1881 - val_loss: -314851948.8463\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682701.8107 - val_loss: -314852145.9385\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686662.1081 - val_loss: -314852434.9222\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685762.2182 - val_loss: -314852443.9494\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687055.2059 - val_loss: -314837781.1790\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687099.5379 - val_loss: -314852342.5099\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314677949.2481 - val_loss: -314851969.0995\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686922.8853 - val_loss: -314852298.9367\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675101.1453 - val_loss: -314852463.8553\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679735.8280 - val_loss: -314851158.7993\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681075.8867 - val_loss: -314852475.7758\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687193.9048 - val_loss: -314849723.8915\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686036.4461 - val_loss: -314851995.4864\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687267.6327 - val_loss: -314852501.9892\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687357.7239 - val_loss: -314851922.8065\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684422.7575 - val_loss: -314852507.6022\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684432.2154 - val_loss: -314851674.1555\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687602.9094 - val_loss: -314852484.2821\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683753.4000 - val_loss: -314823713.2731\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687468.4284 - val_loss: -314852501.6420\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687580.1423 - val_loss: -314851098.5606\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687540.7675 - val_loss: -314852478.6691\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687663.5146 - val_loss: -314852510.4955\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687725.0263 - val_loss: -314852507.6022\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687495.0918 - val_loss: -314852467.0958\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687665.4177 - val_loss: -314852501.6420\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314687556.0828 - val_loss: -314852498.7486\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687582.8684 - val_loss: -314852504.7089\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687607.5387 - val_loss: -314852333.8300\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687724.9749 - val_loss: -314852516.2821\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687712.9902 - val_loss: -314852521.8951\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687709.2867 - val_loss: -314852513.0416\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687005.5568 - val_loss: -314852513.5624\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687652.0185 - val_loss: -314852519.0018\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679312.9805 - val_loss: -314848381.5696\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687691.6890 - val_loss: -314852501.9892\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687673.3647 - val_loss: -314852524.6148\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687664.3504 - val_loss: -314852458.2423\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687608.1752 - val_loss: -314852519.0018\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687602.3307 - val_loss: -314852099.2984\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687603.6231 - val_loss: -314852394.7631\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687443.8224 - val_loss: -314852258.0832\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687671.6608 - val_loss: -314852177.5913\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687711.2220 - val_loss: -314852524.6148\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687635.6552 - val_loss: -314852518.8282\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687723.2775 - val_loss: -314852516.1085\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687735.5644 - val_loss: -314852524.6148\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687735.1336 - val_loss: -314852490.0687\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687689.5093 - val_loss: -314852527.8553\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687727.9904 - val_loss: -314852527.8553\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687736.2781 - val_loss: -314852530.5750\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687550.0518 - val_loss: -314852498.9222\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687704.0916 - val_loss: -314852519.5226\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687735.4165 - val_loss: -314852530.5750\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.6506 - val_loss: -314852504.3617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_18\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_18\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 20s - loss: -100207013.6575 - val_loss: -258147206.4231\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -298590706.2664 - val_loss: -304703137.9096\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -311571985.0834 - val_loss: -312503557.4394\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -313138241.3116 - val_loss: -312735841.7939\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -314061368.8953 - val_loss: -314624649.8373\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314187238.4746 - val_loss: -314637617.4177\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314390763.8561 - val_loss: -314348689.3020\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314492430.1258 - val_loss: -314768334.9873\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314513516.2998 - val_loss: -314668694.9729\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314560846.1129 - val_loss: -314770014.0325\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314618625.1252 - val_loss: -314848598.2206\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314609882.0591 - val_loss: -314776355.1248\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314611082.9303 - val_loss: -314720858.7920\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314616397.1806 - val_loss: -314851390.4376\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314605184.9066 - val_loss: -314846168.0145\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314643159.9052 - val_loss: -314849041.4177\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314641970.3886 - val_loss: -314744843.9783\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314612233.7537 - val_loss: -314851040.5208\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314669696.0064 - val_loss: -314768702.9005\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314658360.0981 - val_loss: -314851428.2242\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679355.6922 - val_loss: -314819430.9439\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679186.0478 - val_loss: -314852391.8698\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314673691.4607 - val_loss: -314850496.7523\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314665554.9094 - val_loss: -314851856.6076\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685233.7135 - val_loss: -314852356.4557\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678465.2795 - val_loss: -314851260.4123\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314672464.2154 - val_loss: -314848517.5552\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314674573.8236 - val_loss: -314841282.1410\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686954.3580 - val_loss: -314852333.8300\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682660.5650 - val_loss: -314851911.7541\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314670345.3808 - val_loss: -314852348.4702\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314674759.6769 - val_loss: -314852336.8969\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679693.0070 - val_loss: -314852493.9458\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685156.5521 - val_loss: -314852244.1374\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314667163.4286 - val_loss: -314818676.1374\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687116.4091 - val_loss: -314836221.1646\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681818.2327 - val_loss: -314851480.3038\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675379.9253 - val_loss: -314852397.6564\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679457.9417 - val_loss: -314852484.4557\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680899.2919 - val_loss: -314852360.0434\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314670820.3721 - val_loss: -314851911.9277\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684942.0100 - val_loss: -314852493.3092\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686735.3281 - val_loss: -314849374.3219\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680416.3536 - val_loss: -314851914.4738\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675464.4935 - val_loss: -314852516.4557\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687720.5642 - val_loss: -314852495.8553\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684309.7898 - val_loss: -314852424.0434\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314674967.5387 - val_loss: -314852524.6148\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687598.4473 - val_loss: -314852522.7631\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687657.8565 - val_loss: -314852533.9892\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687727.3860 - val_loss: -314852522.4159\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687475.5073 - val_loss: -314851908.8608\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687473.9900 - val_loss: -314852499.0958\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687656.4292 - val_loss: -314852423.8698\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687649.6395 - val_loss: -314852487.5226\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687709.6339 - val_loss: -314852493.4828\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 17s - loss: -314685625.2039 - val_loss: -314852522.2423\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687111.4454 - val_loss: -314805152.8101\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687594.3195 - val_loss: -314850386.9801\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687607.0436 - val_loss: -314852484.6293\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687527.2333 - val_loss: -314852477.6275\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 17s - loss: -314680765.6982 - val_loss: -314852531.0958\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686832.0096 - val_loss: -314852519.5226\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687684.1149 - val_loss: -314852542.4955\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687747.3691 - val_loss: -314852556.7884\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687731.1408 - val_loss: -314852554.0687\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 17s - loss: -314679605.3912 - val_loss: -314852290.7776\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 17s - loss: -314684642.9319 - val_loss: -314852531.0958\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687729.2055 - val_loss: -314852539.7758\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686961.7842 - val_loss: -314826878.8427\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687195.6472 - val_loss: -314852516.2821\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 17s - loss: -314671576.1945 - val_loss: -314852545.5624\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687457.2538 - val_loss: -314852536.1881\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687736.3745 - val_loss: -314852519.5226\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686554.9206 - val_loss: -314852455.6962\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687649.6910 - val_loss: -314852527.8553\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687628.3126 - val_loss: -314852516.4557\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687724.6277 - val_loss: -314811333.2658\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687722.6217 - val_loss: -314852531.2694\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687750.4103 - val_loss: -314852420.9765\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687757.4957 - val_loss: -314852528.2025\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 17s - loss: -314686189.0649 - val_loss: -314713079.2043\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687057.9321 - val_loss: -314851715.1826\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687701.9249 - val_loss: -314846755.7034\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 17s - loss: -314682069.8027 - val_loss: -314852501.8156\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 17s - loss: -314685642.4352 - val_loss: -314852527.8553\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687578.5734 - val_loss: -314852490.4159\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687734.6385 - val_loss: -314852452.6293\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687637.4941 - val_loss: -314819165.1067\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687720.6349 - val_loss: -314852385.7360oss: -\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687702.3814 - val_loss: -314852524.9620\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687652.4364 - val_loss: -314852522.0687\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687739.7308 - val_loss: -314852521.7215\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681650.8258 - val_loss: -314852524.7884\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687731.2694 - val_loss: -314852530.9222\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687549.6532 - val_loss: -314852501.9892\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687744.4051 - val_loss: -314852533.2948\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687332.8672 - val_loss: -314852527.8553\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687739.1328 - val_loss: -314852536.5353\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.2289 - val_loss: -314852536.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_19\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_19\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 20s - loss: -154388342.5398 - val_loss: -289768400.9837\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -310487084.9170 - val_loss: -309591870.6112\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -313493501.6789 - val_loss: -313925811.1537\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -313985611.0782 - val_loss: -314200848.7233oss: -314003790.22\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -314309134.4344 - val_loss: -314586326.3363\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314408393.9208 - val_loss: -314835124.2532\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314408423.6833 - val_loss: -314661867.1103\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314628547.0026 - val_loss: -314830833.4756\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314564858.8049 - val_loss: -314761218.2568\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314608964.6614 - val_loss: -314849877.2369\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314613904.3118 - val_loss: -314761191.5226\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314605470.5341 - val_loss: -314849822.2640\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314617563.2807 - val_loss: -314830926.0615\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314635932.7788 - val_loss: -314821432.419599\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314663634.5750 - val_loss: -314848529.3020\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314585004.7498 - val_loss: -314836588.4412\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683471.1674 - val_loss: -314851975.0597\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314664658.8387 - val_loss: -314852383.1899\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678745.5383 - val_loss: -314762083.0090\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314666279.3361 - val_loss: -314852134.3653\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314677384.9435 - val_loss: -314838987.1682\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314672592.1704 - val_loss: -314852411.9494\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314661006.6530 - val_loss: -314852440.8825\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314663764.8897 - val_loss: -314851960.5931\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314677422.5373 - val_loss: -314852440.7089\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 17s - loss: -314685419.4254 - val_loss: -314852151.5515\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687192.5417 - val_loss: -314852490.4159\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 17s - loss: -314683223.5515 - val_loss: -314852194.9512\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 17s - loss: -314680672.3408 - val_loss: -314852258.6040\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 17s - loss: -314674481.6749 - val_loss: -314852391.8698\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687428.4428 - val_loss: -314852229.8445\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676034.5011 - val_loss: -314852524.9620\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686968.9853 - val_loss: -314837861.6709\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314672939.9719 - val_loss: -314852524.9620\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683095.8602 - val_loss: -314852484.4557\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687431.4647 - val_loss: -314852533.8156\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681882.4063 - val_loss: -314852533.6420472.\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686833.8421 - val_loss: -314852524.9620\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678868.5296 - val_loss: -314852524.0362\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686431.3378 - val_loss: -314852091.1392\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314635966.4505 - val_loss: -314852507.7758\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683073.4659 - val_loss: -314852524.7884\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687499.0910 - val_loss: -314852548.2821\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686335.9486 - val_loss: -314852522.2423\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686420.0153 - val_loss: -314847748.1085\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687737.7376 - val_loss: -314852539.4286\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687664.2604 - val_loss: -314852533.6420\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687739.2871 - val_loss: -314852496.2025\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684037.0794 - val_loss: -314852444.2966\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687327.7428 - val_loss: -314852528.0289\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.4376 - val_loss: -314852530.7486\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687642.8885 - val_loss: -314852545.3888\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687731.8481 - val_loss: -314852525.1356\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681241.8662 - val_loss: -314852527.8553\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 19s - loss: -314659336.4742 - val_loss: -314546242.4882\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684329.2714 - val_loss: -314852533.9892\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680338.0542 - val_loss: -314852527.8553\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687723.9912 - val_loss: -314852513.5624\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687532.6341 - val_loss: -314852551.1754\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687745.7231 - val_loss: -314852545.3888\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683818.9946 - val_loss: -314852551.3490\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682749.2739 - val_loss: -314852539.7758\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687636.4139 - val_loss: -314810630.1917\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683535.7332 - val_loss: -314819145.2007\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687681.0737 - val_loss: -314852548.4557\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687756.5891 - val_loss: -314852542.4955\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.2423 - val_loss: -314852548.2821\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687755.0203 - val_loss: -314852539.7758\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687752.3199 - val_loss: -314852548.4557\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.4545 - val_loss: -314852545.5624\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687564.4284 - val_loss: -314852548.2821\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314686600.0305 - val_loss: -314852539.6022\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.2385 - val_loss: -314852513.7360\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687756.1905 - val_loss: -314852548.1085\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682439.8762 - val_loss: -314852548.4557\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687753.9337 - val_loss: -314852539.7758\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687758.2029 - val_loss: -314852542.4955\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 17s - loss: -314682281.1557 - val_loss: -314852004.5136\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.4314 - val_loss: -314851587.7034\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687765.1147 - val_loss: -314852545.5624\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685711.9261 - val_loss: -314852542.4955\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687531.0717 - val_loss: -314852513.9096\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.8107 - val_loss: -314852545.7360\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687760.3504 - val_loss: -314852542.3219\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.5889 - val_loss: -314852536.7089\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687758.0358 - val_loss: -314852542.6691\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687764.1053 - val_loss: -314852545.5624\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.3992 - val_loss: -314852542.6691\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687704.5353 - val_loss: -314852377.7505\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687762.2986 - val_loss: -314852531.0958\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685042.1700 - val_loss: -314308831.826467\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686239.8457 - val_loss: -314605702.5389\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687270.0952 - val_loss: -314852539.7758\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687763.4688 - val_loss: -314852536.8825357.49\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687764.3753 - val_loss: -314852545.5624\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687756.9170 - val_loss: -314852539.7758\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687762.2600 - val_loss: -314852560.2025\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687766.2913 - val_loss: -314852551.0018\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687773.1838 - val_loss: -314852560.3761\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687765.7641 - val_loss: -314852554.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_20\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_20\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 21s - loss: -190338656.1395 - val_loss: -287328449.0995\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -313473028.4300 - val_loss: -312054697.6058\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -314272337.4627 - val_loss: -314349823.3635\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -314368875.3611 - val_loss: -314290551.0307\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -314492370.0607 - val_loss: -314650331.1392\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314568675.0733 - val_loss: -314654717.3960\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314610830.2672 - val_loss: -314851986.1121\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314623652.8865 - val_loss: -314851925.5262\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314618364.2001 - val_loss: -314852223.5371\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681310.0390 - val_loss: -314843456.8101\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314644311.9052 - val_loss: -314852504.1881\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684278.1756 - val_loss: -314852185.9241\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668728.3424 - val_loss: -314802152.1013\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668990.5984 - val_loss: -314852478.1483\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 17s - loss: -314619434.5252 - val_loss: -314852504.1881\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 17s - loss: -314663599.1802 - val_loss: -314852075.9783\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 17s - loss: -314680024.6253 - val_loss: -314830442.7052\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 17s - loss: -314674106.8821 - val_loss: -314852015.0452\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 17s - loss: -314677854.4505 - val_loss: -314844837.0922\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 17s - loss: -314684506.0719 - val_loss: -314852469.4684\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687674.6120 - val_loss: -314808959.8843\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686299.4671 - val_loss: -314852449.0416\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681349.8573 - val_loss: -314799053.0199\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314677935.8296 - val_loss: -314852426.0687\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680163.7549 - val_loss: -314851534.9295 - ETA: 0s - loss: -314685917.\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686767.3603 - val_loss: -314852518.6546\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685704.2299 - val_loss: -314852515.5877 - l\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686033.5142 - val_loss: -314851335.1175\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680034.7261 - val_loss: -314852510.1483\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687003.6279 - val_loss: -314852240.8969\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675153.4756 - val_loss: -314852524.6148\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681262.6466 - val_loss: -314851572.5425\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676993.0930 - val_loss: -314852530.4014\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684648.4935 - val_loss: -314852530.4014\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686176.7394 - val_loss: -314852524.6148\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684939.9526 - val_loss: -314852530.2278\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.7304 - val_loss: -314851312.3183\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675503.6624 - val_loss: -314852518.8282\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687715.7742 - val_loss: -314852530.4014\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687728.5883 - val_loss: -314852426.0687\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687669.7577 - val_loss: -314852524.4412\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687726.6594 - val_loss: -314816401.6492\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687748.1728 - val_loss: -314852536.0145 los\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687744.5337 - val_loss: -314852527.5081\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687747.7999 - val_loss: -314852156.8174\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314670588.8174 - val_loss: -314852527.3345\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668264.4870 - val_loss: -314842805.9892\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687618.7647 - val_loss: -314851711.5949\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685909.3783 - val_loss: -314851607.43584622105.\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687447.4744 - val_loss: -314852533.121267\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687713.7103 - val_loss: -314831799.8409\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687686.2688 - val_loss: -314852521.7215\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687581.4153 - val_loss: -314852524.6148\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687743.9486 - val_loss: -314852524.6148\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.3741 - val_loss: -314852527.5081\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687748.2242 - val_loss: -314852530.4014\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687715.3048 - val_loss: -314852533.1212\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687745.1187 - val_loss: -314852536.1881\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.9054 - val_loss: -314852492.7884\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.8234 - val_loss: -314850777.0561\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687747.7356 - val_loss: -314852536.0145\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687746.7969 - val_loss: -314852536.1881\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687673.5254 - val_loss: -314852524.6148\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687752.5835 - val_loss: -314852527.5081\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687749.6645 - val_loss: -314852533.2948\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687752.3327 - val_loss: -314852533.2948\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687752.4870 - val_loss: -314852533.2948\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687746.5654 - val_loss: -314852530.4014\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687744.6430 - val_loss: -314852530.4014\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684679.7991 - val_loss: -314852530.4014\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687573.1276 - val_loss: -314852536.1881\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314684541.5053 - val_loss: -314852524.6148\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314657695.0549 - val_loss: -314852513.0416\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683391.2349 - val_loss: -314766266.2134\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684678.8989 - val_loss: -314852530.2278\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680213.3269 - val_loss: -314852530.4014\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.6096 - val_loss: -314852466.5750033.\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687678.6305 - val_loss: -314852532.9476\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687749.0215 - val_loss: -314852533.1212\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687641.3904 - val_loss: -314852539.0814\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687751.0147 - val_loss: -314852539.081460\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687751.4004 - val_loss: -314852544.8680\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.1073 - val_loss: -314852536.1881\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687753.7087 - val_loss: -314852533.2948\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687751.9727 - val_loss: -314852539.0814\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687755.8947 - val_loss: -314852541.9747\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.3516 - val_loss: -314852533.1212\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687758.9745 - val_loss: -314852541.9747\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.8338 - val_loss: -314852533.1212\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687755.5861 - val_loss: -314852536.1881 ETA: 14s - loss: -314158  - ETA: \n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.5085 - val_loss: -314852536.0145\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.7567 - val_loss: -314852541.9747\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.6795 - val_loss: -314852533.2948657.77\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687756.6470 - val_loss: -314852536.1881\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687758.3958 - val_loss: -314852536.014516\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.7181 - val_loss: -314852544.694400 -\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687537.3084 - val_loss: -314852553.5479767.91\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.0199 - val_loss: -314852536.0145\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687757.1871 - val_loss: -314852544.8680\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687759.0709 - val_loss: -314852539.4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_21\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_21\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 21s - loss: -208721246.0237 - val_loss: -296140897.6203\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -314194270.6434 - val_loss: -312596182.8571\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -314478047.7107 - val_loss: -314455755.3996\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -314523284.1567 - val_loss: -314787893.5262\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -314568123.7822 - val_loss: -314820507.0814\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314600964.0571 - val_loss: -314841848.1302\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 17s - loss: -314614544.2025 - val_loss: -314850065.1284\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 17s - loss: -314637278.1869 - val_loss: -314796553.3743\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 17s - loss: -314607469.2321 - val_loss: -314833966.5823\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314655952.4790 - val_loss: -314828162.7776\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314660768.6430 - val_loss: -314599608.8825\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 18s - loss: -314646988.9299 - val_loss: -314852481.0416\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680603.8208 - val_loss: -314852507.0814\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314673929.3615 - val_loss: -314851008.3472\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685910.0920 - val_loss: -314852345.2297\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681756.3544 - val_loss: -314852509.9747\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314673067.1232 - val_loss: -314829823.5371\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678463.0291 - val_loss: -314852487.0018\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314651685.7352 - val_loss: -314852501.1212\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314658249.5479 - val_loss: -314852501.2948\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314668674.3854 - val_loss: -314852321.9096\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314671152.5562 - val_loss: -314852510.1483\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686027.4382 - val_loss: -314852509.9747 loss: -314663619.87\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676135.4840 - val_loss: -314820359.6962\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684227.1762 - val_loss: -314781548.8463\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682312.1463 - val_loss: -314852515.7613\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314680677.6002 - val_loss: -314852512.6944\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685653.0826 - val_loss: -314852507.0814\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687586.5783 - val_loss: -314852513.0416\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683370.7503 - val_loss: -314852510.1483\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682886.6996 - val_loss: -314852498.2278\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687341.5728 - val_loss: -314852509.8011\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 18s - loss: -314672793.0496 - val_loss: -314852507.0814\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687677.8332 - val_loss: -314852510.1483\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 19s - loss: -314677369.4418 - val_loss: -314852509.9747\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687569.5270 - val_loss: -314852411.6022\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687732.1374 - val_loss: -314852513.0416\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687688.0884 - val_loss: -314852510.1483\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687722.7824 - val_loss: -314852512.8680\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686789.7545 - val_loss: -314852510.1483\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684353.2859 - val_loss: -314852507.0814\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676041.9208 - val_loss: -314852501.4684\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687428.4043 - val_loss: -314852509.9747\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687730.6329 - val_loss: -314851795.3273\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675969.4402 - val_loss: -314852513.0416\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 18s - loss: -314682780.6695 - val_loss: -314852515.7613\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683626.8981 - val_loss: -314852515.7613\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 18s - loss: -314671608.1881 - val_loss: -314851552.2893\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687731.2694 - val_loss: -314852518.8282\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687733.6420 - val_loss: -314852518.6546\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687733.2176 - val_loss: -314852521.5479\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687726.7816 - val_loss: -314852513.0416\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685207.9309 - val_loss: -314852515.9349\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687734.2913 - val_loss: -314852521.7215\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676159.2156 - val_loss: -314852524.6148\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687737.0625 - val_loss: -314852510.1483\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687737.0239 - val_loss: -314852524.614831\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 17s - loss: -314671944.3777 - val_loss: -314852519.0018\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687636.4911 - val_loss: -314852504.3617\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686969.9562 - val_loss: -314836773.4394\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687655.4454 - val_loss: -314852515.9349\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687732.9797 - val_loss: -314852504.3617\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685712.4469 - val_loss: -314852521.7215\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685888.4501 - val_loss: -314852515.9349\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687737.8405 - val_loss: -314852518.8282\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687737.3968 - val_loss: -314852521.7215\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.2516 - val_loss: -314852527.5081\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.0012 - val_loss: -314852524.7884\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.7402 - val_loss: -314852518.6546\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687735.3522 - val_loss: -314852521.7215\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.7689 - val_loss: -314852524.6148\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314687745.8260 - val_loss: -314852524.6148\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.5670 - val_loss: -314852515.7613\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.6339 - val_loss: -314852536.1881\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687742.2061 - val_loss: -314852524.9620\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687743.8650 - val_loss: -314852527.5081\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.2319 - val_loss: -314852533.2948\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.8525 - val_loss: -314852524.6148\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.7334 - val_loss: -314852524.9620\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687746.5011 - val_loss: -314852524.9620\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687745.6010 - val_loss: -314852530.7486\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.4746 - val_loss: -314852524.7884\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687739.4543 - val_loss: -314852521.7215\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.1595 - val_loss: -314852527.8553592.40\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687749.3623 - val_loss: -314852541.9747\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687747.1119 - val_loss: -314852539.0814\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687754.6667 - val_loss: -314852544.8680\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687749.6773 - val_loss: -314852539.2550\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687753.3679 - val_loss: -314852533.2948\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687640.0402 - val_loss: -314852533.4684\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687746.5204 - val_loss: -314852536.1881\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687747.4720 - val_loss: -314852530.4014\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687752.3006 - val_loss: -314852533.2948\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.2624 - val_loss: -314852533.2948\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687747.4205 - val_loss: -314852533.4684\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687747.8385 - val_loss: -314852539.0814\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687751.1433 - val_loss: -314852536.3617\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687750.8282 - val_loss: -314852536.5353\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687752.7635 - val_loss: -314852542.1483\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687752.9628 - val_loss: -314852536.3617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Output \"custom_variational_layer_22\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_22\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 1106 samples\n",
      "Epoch 1/100\n",
      "9954/9954 [==============================] - 22s - loss: -220251356.6056 - val_loss: -297294933.3526\n",
      "Epoch 2/100\n",
      "9954/9954 [==============================] - 18s - loss: -314484726.9279 - val_loss: -312827964.2387\n",
      "Epoch 3/100\n",
      "9954/9954 [==============================] - 18s - loss: -314469848.1109 - val_loss: -314476914.8644\n",
      "Epoch 4/100\n",
      "9954/9954 [==============================] - 18s - loss: -314581056.4051 - val_loss: -314823897.8662\n",
      "Epoch 5/100\n",
      "9954/9954 [==============================] - 18s - loss: -314608064.0321 - val_loss: -314583122.6329\n",
      "Epoch 6/100\n",
      "9954/9954 [==============================] - 18s - loss: -314644567.2686 - val_loss: -314819705.6347\n",
      "Epoch 7/100\n",
      "9954/9954 [==============================] - 18s - loss: -314671255.8087 - val_loss: -314852098.7776\n",
      "Epoch 8/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679426.3597 - val_loss: -314831828.6004\n",
      "Epoch 9/100\n",
      "9954/9954 [==============================] - 18s - loss: -314613450.2230 - val_loss: -314851847.2333\n",
      "Epoch 10/100\n",
      "9954/9954 [==============================] - 18s - loss: -314678181.2530 - val_loss: -314852475.4286\n",
      "Epoch 11/100\n",
      "9954/9954 [==============================] - 18s - loss: -314663461.5873 - val_loss: -314840679.2333\n",
      "Epoch 12/100\n",
      "9954/9954 [==============================] - 19s - loss: -314659750.5132 - val_loss: -314848934.0181\n",
      "Epoch 13/100\n",
      "9954/9954 [==============================] - 18s - loss: -314673533.8139 - val_loss: -314852507.2550\n",
      "Epoch 14/100\n",
      "9954/9954 [==============================] - 18s - loss: -314651720.7571 - val_loss: -314738779.9494\n",
      "Epoch 15/100\n",
      "9954/9954 [==============================] - 18s - loss: -314657384.9885 - val_loss: -314827393.3309\n",
      "Epoch 16/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684993.6845 - val_loss: -314852483.9349\n",
      "Epoch 17/100\n",
      "9954/9954 [==============================] - 18s - loss: -314669452.3191 - val_loss: -314833622.6257\n",
      "Epoch 18/100\n",
      "9954/9954 [==============================] - 18s - loss: -314669008.9612 - val_loss: -314852501.4684\n",
      "Epoch 19/100\n",
      "9954/9954 [==============================] - 18s - loss: -314650126.8588 - val_loss: -314852353.9096\n",
      "Epoch 20/100\n",
      "9954/9954 [==============================] - 18s - loss: -314681854.0904 - val_loss: -314852293.1501\n",
      "Epoch 21/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687045.8188 - val_loss: -314852223.7107310.\n",
      "Epoch 22/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683842.1218 - val_loss: -314852481.2152\n",
      "Epoch 23/100\n",
      "9954/9954 [==============================] - 19s - loss: -314677982.6369 - val_loss: -314852351.0163\n",
      "Epoch 24/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687193.5254 - val_loss: -314852426.2423\n",
      "Epoch 25/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687733.6098 - val_loss: -314852507.2550\n",
      "Epoch 26/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685873.1863 - val_loss: -314852513.0416\n",
      "Epoch 27/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686554.3034 - val_loss: -314852513.0416\n",
      "Epoch 28/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686177.4852 - val_loss: -314852301.8300\n",
      "Epoch 29/100\n",
      "9954/9954 [==============================] - 19s - loss: -314685093.8895 - val_loss: -314852524.4412\n",
      "Epoch 30/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687693.9265 - val_loss: -314852518.8282\n",
      "Epoch 31/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683406.8780 - val_loss: -314852513.0416\n",
      "Epoch 32/100\n",
      "9954/9954 [==============================] - 18s - loss: -314683486.5469 - val_loss: -314852518.8282\n",
      "Epoch 33/100\n",
      "9954/9954 [==============================] - 19s - loss: -314681114.7920 - val_loss: -314851155.9060\n",
      "Epoch 34/100\n",
      "9954/9954 [==============================] - 18s - loss: -314665783.2172 - val_loss: -314852510.1483\n",
      "Epoch 35/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687549.2031 - val_loss: -314852510.1483\n",
      "Epoch 36/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687722.9046 - val_loss: -314852521.7215\n",
      "Epoch 37/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687730.8322 - val_loss: -314852388.6293\n",
      "Epoch 38/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687728.5047 - val_loss: -314852518.8282\n",
      "Epoch 39/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679244.5248 - val_loss: -314852515.9349\n",
      "Epoch 40/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687733.7705 - val_loss: -314852518.8282\n",
      "Epoch 41/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687733.1983 - val_loss: -314851998.0325\n",
      "Epoch 42/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687730.8258 - val_loss: -314852513.0416\n",
      "Epoch 43/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687736.0981 - val_loss: -314852530.4014\n",
      "Epoch 44/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687733.2240 - val_loss: -314852515.9349\n",
      "Epoch 45/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687733.7641 - val_loss: -314852516.1085\n",
      "Epoch 46/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687698.6136 - val_loss: -314852507.2550\n",
      "Epoch 47/100\n",
      "9954/9954 [==============================] - 18s - loss: -314674383.3667 - val_loss: -314852524.7884\n",
      "Epoch 48/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687740.0908 - val_loss: -314852519.0018\n",
      "Epoch 49/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687537.2055 - val_loss: -314852527.5081\n",
      "Epoch 50/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687495.5419 - val_loss: -314852518.8282551.\n",
      "Epoch 51/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.5541 - val_loss: -314852518.8282\n",
      "Epoch 52/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.3351 - val_loss: -314852518.8282\n",
      "Epoch 53/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.2905 - val_loss: -314852515.9349\n",
      "Epoch 54/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687734.6643 - val_loss: -314852524.6148\n",
      "Epoch 55/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.4316 - val_loss: -314852521.7215\n",
      "Epoch 56/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687729.8871 - val_loss: -314852524.788452\n",
      "Epoch 57/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687732.2660 - val_loss: -314851320.9982\n",
      "Epoch 58/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.7599 - val_loss: -314852521.7215 ETA: 4s - ETA: 1s -\n",
      "Epoch 59/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687741.5953 - val_loss: -314807079.4069\n",
      "Epoch 60/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.3484 - val_loss: -314852530.4014\n",
      "Epoch 61/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687708.5666 - val_loss: -314852527.6817\n",
      "Epoch 62/100\n",
      "9954/9954 [==============================] - 18s - loss: -314679134.9455 - val_loss: -314803442.5172\n",
      "Epoch 63/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686715.8465 - val_loss: -314623594.5895\n",
      "Epoch 64/100\n",
      "9954/9954 [==============================] - 18s - loss: -314685300.9283 - val_loss: -314689046.8571\n",
      "Epoch 65/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687396.0892 - val_loss: -314743432.3906\n",
      "Epoch 66/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687682.3725 - val_loss: -314852524.6148\n",
      "Epoch 67/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686403.7356 - val_loss: -314852365.4828\n",
      "Epoch 68/100\n",
      "9954/9954 [==============================] - 18s - loss: -314676467.3659 - val_loss: -314851320.9982\n",
      "Epoch 69/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687291.5829 - val_loss: -314761694.3797\n",
      "Epoch 70/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687676.6952 - val_loss: -314852524.6148\n",
      "Epoch 71/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687735.7058 - val_loss: -314852521.7215\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954/9954 [==============================] - 18s - loss: -314687242.4352 - val_loss: -314852521.7215\n",
      "Epoch 73/100\n",
      "9954/9954 [==============================] - 18s - loss: -314684524.9234 - val_loss: -314852521.7215\n",
      "Epoch 74/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.4641 - val_loss: -314852527.5081\n",
      "Epoch 75/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687478.7350 - val_loss: -314852530.4014\n",
      "Epoch 76/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687733.7834 - val_loss: -314852518.4810\n",
      "Epoch 77/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687737.5961 - val_loss: -314852518.8282\n",
      "Epoch 78/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687739.5186 - val_loss: -314852524.6148\n",
      "Epoch 79/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.5473 - val_loss: -314852521.7215\n",
      "Epoch 80/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.4119 - val_loss: -314852524.7884\n",
      "Epoch 81/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687744.4436 - val_loss: -314852527.5081\n",
      "Epoch 82/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687743.4085 - val_loss: -314799073.6203TA: 3s - loss: -31 - ETA: 1s -\n",
      "Epoch 83/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687744.0772 - val_loss: -314852521.7215\n",
      "Epoch 84/100\n",
      "9954/9954 [==============================] - 19s - loss: -314687740.5023 - val_loss: -314852530.4014\n",
      "Epoch 85/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.4252 - val_loss: -314852527.5081\n",
      "Epoch 86/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687740.5216 - val_loss: -314852530.4014\n",
      "Epoch 87/100\n",
      "9954/9954 [==============================] - 18s - loss: -314686822.9568 - val_loss: -314852530.4014\n",
      "Epoch 88/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687743.5692 - val_loss: -314852524.6148\n",
      "Epoch 89/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687738.0655 - val_loss: -314852521.7215\n",
      "Epoch 90/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687745.4467 - val_loss: -314852530.4014\n",
      "Epoch 91/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687742.5662 - val_loss: -314852524.6148\n",
      "Epoch 92/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687743.8007 - val_loss: -314852527.5081\n",
      "Epoch 93/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687745.1573 - val_loss: -314852521.7215\n",
      "Epoch 94/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687745.1638 - val_loss: -314852521.8951\n",
      "Epoch 95/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687743.9293 - val_loss: -314852527.5081\n",
      "Epoch 96/100\n",
      "9954/9954 [==============================] - 17s - loss: -314687745.6845 - val_loss: -314852527.5081\n",
      "Epoch 97/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687745.1830 - val_loss: -314852530.4014\n",
      "Epoch 98/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687748.2178 - val_loss: -314852533.6420\n",
      "Epoch 99/100\n",
      "9954/9954 [==============================] - 18s - loss: -314675215.2510 - val_loss: -314852527.5081\n",
      "Epoch 100/100\n",
      "9954/9954 [==============================] - 18s - loss: -314687748.0185 - val_loss: -314852524.7884\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAERCAYAAABl3+CQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe60lEQVR4nO3de5RU9Znu8e9T3Q2NQnvlIqKiE6NRUJxBj5oJGvWoMUYmMYkYNd5Gl/HE2xmNMkzUxDi5mDFxjo4e43jJESMeNRNPNIhGR3TFqIAoKEgc4qVFpcFrVG5d7/mjdje7qquKBrp6N9XPZ61eXbVr197vr8R+av/e2rsUEZiZmVWSy7oAMzPr2xwUZmZWlYPCzMyqclCYmVlVDgozM6vKQWFmZlXVbVBIulnSUknzu7HujpIelfSspOclHdUbNZqZbQrqNiiAW4Eju7nuPwF3RcQ+wCTg32pVlJnZpqZugyIiZgLvpJdJ+itJ0yXNlvS4pN07VgdakttbAEt6sVQzsz6tMesCetmNwFkR8SdJ/43CkcMhwOXADEnnAJsDh2VXoplZ39JvgkLSYOBA4P9K6lg8MPl9PHBrRPyLpAOA/yNpTETkMyjVzKxP6TdBQWGa7b2IGFfmsdNJ+hkR8aSkZmBbYGkv1mdm1ifVbY+iVER8APxZ0tcAVLB38vBrwKHJ8s8AzUBbJoWamfUxqterx0r6FXAwhSODt4HLgEeA64HtgCbgzoj4vqQ9gF8Agyk0tr8TETOyqNvMrK+p26AwM7Oe0W+mnszMbMPUZTN72223jdGjR2ddhpnZJmP27NnLImJoucfqMihGjx7NrFmzsi7DzGyTIenVSo956snMzKpyUJiZWVUOCjMzq6ouexRm1v+sXr2a1tZWVqxYkXUpfVpzczOjRo2iqamp289xUJhZXWhtbWXIkCGMHj2a1PXcLCUiWL58Oa2trey8887dfp6nnsysLqxYsYJtttnGIVGFJLbZZpv1PupyUJhZ3XBIrNuGvEYOirTHfgIvP5x1FWZmfYqDIu2Jn8F/PZp1FWZmfYqDIi3XCPn2rKsws35g8ODBFR975ZVXGDNmTC9WU52DIi3XAPk1WVdhZtan+OOxabkmB4VZHfje/3uBF5d80KPb3GNkC5d9ac+Kj1988cXstNNOnH322QBcfvnlSGLmzJm8++67rF69mh/84AdMnDhxvfa7YsUKvvWtbzFr1iwaGxu5+uqr+fznP88LL7zAqaeeyqpVq8jn89xzzz2MHDmSr3/967S2ttLe3s53v/tdjjvuuI0aNzgoiuUaHRRmtkEmTZrE+eef3xkUd911F9OnT+eCCy6gpaWFZcuWsf/++3PMMces1yePrrvuOgDmzZvHwoULOfzww1m0aBE33HAD5513HieccAKrVq2ivb2dBx54gJEjR3L//fcD8P777/fI2BwUae5RmNWFau/8a2WfffZh6dKlLFmyhLa2Nrbaaiu22247LrjgAmbOnEkul+ONN97g7bffZsSIEd3e7hNPPME555wDwO67785OO+3EokWLOOCAA7jyyitpbW3lK1/5Crvuuitjx47lwgsv5OKLL+boo4/mc5/7XI+MzT2KNPcozGwjfPWrX+Xuu+9m2rRpTJo0ialTp9LW1sbs2bOZO3cuw4cPX++T3Sp9C+k3vvEN7rvvPgYNGsQRRxzBI488wqc//Wlmz57N2LFjmTx5Mt///vd7Ylg+oijiqScz2wiTJk3ijDPOYNmyZTz22GPcddddDBs2jKamJh599FFefbXiVz5UNGHCBKZOncohhxzCokWLeO2119htt91YvHgxu+yyC+eeey6LFy/m+eefZ/fdd2frrbfmxBNPZPDgwdx66609Mi4HRZqDwsw2wp577smHH37I9ttvz3bbbccJJ5zAl770JcaPH8+4cePYfffd13ubZ599NmeddRZjx46lsbGRW2+9lYEDBzJt2jRuv/12mpqaGDFiBJdeeinPPPMMF110EblcjqamJq6//voeGZcqHdZsysaPHx8b9A131/8tbLkjHH9HzxdlZjW1YMECPvOZz2Rdxiah3GslaXZEjC+3vnsUae5RmJl14amnNE89mVkvmjdvHieddFLRsoEDB/LUU09lVFF5Doo0B4WZ9aKxY8cyd+7crMtYJ089pfk8CjOzLhwUae5RmJl14aBI89STmVkXDoo0B4WZbYRqlw7flDko0tyjMDPrIpOgkHSVpIWSnpf0a0lblllnB0mPSlog6QVJ59W8MPcozKwHRAQXXXQRY8aMYezYsUybNg2AN998kwkTJjBu3DjGjBnD448/Tnt7O6ecckrnuj/72c8yrr6rrD4e+xAwOSLWSPoxMBm4uGSdNcA/RMQcSUOA2ZIeiogXa1aVp57M6sPvLoG35vXsNkeMhS/8qFur3nvvvcydO5fnnnuOZcuWse+++zJhwgTuuOMOjjjiCKZMmUJ7ezsff/wxc+fO5Y033mD+/PkAvPfeez1bdw/I5IgiImZERMdf5D8Co8qs82ZEzElufwgsALavaWEOCjPrAU888QTHH388DQ0NDB8+nIMOOohnnnmGfffdl1tuuYXLL7+cefPmMWTIEHbZZRcWL17MOeecw/Tp02lpacm6/C76wgl3pwHTqq0gaTSwD1DxdEVJZwJnAuy4444bVol7FGb1oZvv/Gul0jX0JkyYwMyZM7n//vs56aSTuOiii/jmN7/Jc889x4MPPsh1113HXXfdxc0339zLFVdXsyMKSQ9Lml/mZ2JqnSkUppimVtnOYOAe4PyIqPjdhhFxY0SMj4jxQ4cO3bCi3aMwsx4wYcIEpk2bRnt7O21tbcycOZP99tuPV199lWHDhnHGGWdw+umnM2fOHJYtW0Y+n+fYY4/liiuuYM6cOVmX30XNjigi4rBqj0s6GTgaODQqxK+kJgohMTUi7u35Kkt46snMesCXv/xlnnzySfbee28k8ZOf/IQRI0Zw2223cdVVV9HU1MTgwYP55S9/yRtvvMGpp55KPp8H4Ic//GHG1XeVyWXGJR0JXA0cFBFtFdYRcBvwTkScvz7b3+DLjN9/Icy/By7+8/o/18wy5cuMd9+mcpnxa4EhwEOS5kq6AUDSSEkPJOt8FjgJOCRZZ66ko2palXsUZmZdZNLMjohPVVi+BDgquf0EoN6syz0KM7OufGZ2mnsUZpu0evzGzp62Ia+RgyLNQWG2yWpubmb58uUOiyoiguXLl9Pc3Lxez+sL51H0HblGiHaIAPXurJeZbZxRo0bR2tpKW1vZz8dYorm5mVGjupzjXJWDIi2XvBz5dmjwS2O2KWlqamLnnXfOuoy65KmntFxD4benn8zMOjko0jqPKBwUZmYdHBRpDgozsy4cFGnpHoWZmQEOimLuUZiZdeGgSPPUk5lZFw6KNAeFmVkXDoo0B4WZWRcOirTOHoWb2WZmHRwUaT6iMDPrwkGR5qAwM+vCQZHmoDAz68JBkeYT7szMunBQpPmEOzOzLhwUaZ56MjPrwkGR5qAwM+vCQZHmHoWZWRcOijT3KMzMunBQpHnqycysCwdFmoPCzKwLB0Wag8LMrAsHRZovCmhm1oWDIs1HFGZmXTgo0hwUZmZdZBIUkq6StFDS85J+LWnLKus2SHpW0m9rXpiDwsysi6yOKB4CxkTEXsAiYHKVdc8DFvRKVT7hzsysi0yCIiJmRETH2/Y/AqPKrSdpFPBF4KZeKcwn3JmZddEXehSnAb+r8NjPge8A+V6pxFNPZmZdNNZqw5IeBkaUeWhKRPwmWWcKsAaYWub5RwNLI2K2pIO7sb8zgTMBdtxxxw0r2kFhZtZFzYIiIg6r9rikk4GjgUMjIsqs8lngGElHAc1Ai6TbI+LECvu7EbgRYPz48eW2t27uUZiZdZHVp56OBC4GjomIj8utExGTI2JURIwGJgGPVAqJHuMehZlZF1n1KK4FhgAPSZor6QYASSMlPZBRTSCBGhwUZmYpNZt6qiYiPlVh+RLgqDLL/xP4z9pWlcg1OijMzFL6wqee+hYHhZlZEQdFqVyjm9lmZikOilI59yjMzNIcFKU89WRmVsRBUcpBYWZWxEFRyj0KM7MiDopS7lGYmRVxUJTy1JOZWREHRSkHhZlZEQdFKfcozMyKOChKuUdhZlbEQVHKU09mZkUcFKUcFGZmRRwUpdyjMDMr4qAo5R6FmVmRdQaFpPMktajg3yXNkXR4bxSXCU89mZkV6c4RxWkR8QFwODAUOBX4UU2rypKDwsysSHeCQsnvo4BbIuK51LL64x6FmVmR7gTFbEkzKATFg5KGAPnalpUh9yjMzIp05zuzTwfGAYsj4mNJW1OYfqpPnnoyMyvSnSOKA4CXIuI9SScC/wS8X9uyMuSgMDMr0p2guB74WNLewHeAV4Ff1rSqLLlHYWZWpDtBsSYiApgIXBMR1wBDaltWhtyjMDMr0p0exYeSJgMnAZ+T1AA01basDHnqycysSHeOKI4DVlI4n+ItYHvgqppWlSUHhZlZkXUGRRIOU4EtJB0NrIgI9yjMzPqJ7lzC4+vA08DXgK8DT0n6aq0Ly4x7FGZmRbrTo5gC7BsRSwEkDQUeBu6uZWGZ8dSTmVmR7vQoch0hkVjezedtmhwUZmZFuvMHf7qkByWdIukU4H7gdxuzU0lXSVoo6XlJv5a0ZYX1tpR0d7LuAkkHbMx+uyXXCNEOETXflZnZpqA7zeyLgP8N7AXsDdwYEd/ZyP0+BIyJiL2ARcDkCutdA0yPiN2TfS/YyP2uWy6ZjXND28wM6F6Pgoi4F7i3476k1yJixw3daUTMSN39I9ClOS6pBZgAnJI8ZxWwakP32W25hsLv/Bpo6NbLY2ZW1za019CTlxk/jfJTWbsAbcAtkp6VdJOkzSsWJJ0paZakWW1tbRteTecRhfsUZmaw4UGxzgl8SQ9Lml/mZ2JqnSnAGgrnaZRqBP4auD4i9gE+Ai6pWFDEjRExPiLGDx06dL0H1MlBYWZWpOLciqT/WekhYPC6NhwRh1V7XNLJwNHAocm1pEq1Aq0R8VRy/26qBEWPcY/CzKxItUn4ahf+u2ZjdirpSOBi4KCI+LjcOhHxlqTXJe0WES8BhwIvbsx+uyXdozAzs8pBERHfq+F+rwUGAg9JAvhjRJwlaSRwU0Qclax3DjBV0gBgMb3xhUmeejIzK5LJx3oi4lMVli+h8JWrHffnAuN7qy7AQWFmVqJ+z7DeUA4KM7MiDopSnT0KN7PNzKBKUEj6eer2eSWP3VrDmrLlIwozsyLVjigmpG6fXPLYXjWopW/oDIrV2dZhZtZHVAsKVbhd33xEYWZWpNqnnnKStqIQJh23OwKjoeaVZcUn3JmZFakWFFsAs1kbDnNqX04f4BPuzMyKVDvhbnQv1tF3eOrJzKzIen08VtJfSZoiaX6tCsqcg8LMrMg6g0LSdpLOl/Q08AKFo5Dja15ZVtyjMDMrUu08ijMkPQI8BmwL/D3wZkR8LyLm9VaBvc49CjOzItWa2dcBTwLfiIhZAJLq/4ukPfVkZlakWlCMBL4GXC1pOHAX0NQrVWXJQWFmVqTi1FNELIuI6yNiAnAY8D6wVNICSf/caxX2NvcozMyKVOtRXCvpQICIeD0ifhoRfwP8HbCytwrsde5RmJkVqfappz8B/yLpFUk/ljQOICJeqvGXGmXLU09mZkWqTT1dExEHAAcB7wC3JNNOl0ratdcq7G0OCjOzIus8jyIiXo2IH0fEPsA3gC8DC2teWVYcFGZmRbpzwl2TpC9Jmgr8DlgEHFvzyrLiZraZWZGKH4+V9N8pnIH9ReBp4E7gzIj4qJdqy4ab2WZmRaqdR/GPwB3AhRHxTi/Vkz1PPZmZFal29djP92YhfYaDwsysyHpdPbZfcI/CzKyIg6KUexRmZkUcFKUkUIODwsws4aAoJ9fooDAzSzgoysk1ukdhZpZwUJTjIwozs06ZBIWkqyQtlPS8pF9L2rLCehdIekHSfEm/ktTcKwXm3KMwM+uQ1RHFQ8CYiNiLwiVBJpeuIGl74FxgfESMARqASb1SnY8ozMw6ZRIUETEjIjr+Ev8RGFVh1UZgkKRGYDNgSW/U56AwM1urL/QoTqNwscEiEfEG8FPgNeBN4P2ImFFpI5LOlDRL0qy2traNq8jNbDOzTjULCkkPJ72F0p+JqXWmAGuAqWWevxUwEdiZwvd3by7pxEr7i4gbI2J8RIwfOnToxhXvHoWZWadqFwXcKBFxWLXHJZ0MHA0cGhFRZpXDgD9HRFuy/r3AgcDtPV1rF556MjPrlNWnno4ELgaOiYiPK6z2GrC/pM0kCTgUWNArBToozMw6ZdWjuBYYAjwkaa6kGwAkjZT0AEBEPAXcDcwB5iW13tgr1blHYWbWqWZTT9VExKcqLF8CHJW6fxlwWW/V1ck9CjOzTn3hU099j6eezMw6OSjKcVCYmXVyUJTjHoWZWScHRTnuUZiZdXJQlOOpJzOzTg6KchwUZmadHBTluEdhZtbJQVGOexRmZp0cFOV46snMrJODohwHhZlZJwdFOe5RmJl1clCU4x6FmVknB0U5nnoyM+vkoCjHQWFm1slBUY57FGZmnRwU5bhHYWbWyUFRjqeezMw6OSjKcVCYmXVyUJSTa4TIQz6fdSVmZplzUJSTS75KPNzQNjNzUJSTayj89vSTmZmDoqyOIwoHhZmZg6IsB4WZWScHRSIi+PYdc7h7dmsqKNyjMDNzUCQk8Yf/Ws6zr73rHoWZWYqDImXYkIG8/cFKTz2ZmaU4KFKGtTTT9uEKB4WZWYqDImV4xxFFQ1NhgXsUZmbZBIWkKyQ9L2mupBmSRlZY70hJL0l6WdIlta5rWMtA2v6ykrzcozAz65DVEcVVEbFXRIwDfgtcWrqCpAbgOuALwB7A8ZL2qGVRw1uaac8HH66KwgIHhZlZNkERER+k7m4ORJnV9gNejojFEbEKuBOYWMu6hg1pBuC9FQ4KM7MOmfUoJF0p6XXgBMocUQDbA6+n7rcmyypt70xJsyTNamtr26CahrUMBOC9lUlvwkFhZla7oJD0sKT5ZX4mAkTElIjYAZgKfLvcJsosK3fkQbK9GyNifESMHzp06AbVPLylcETx7icdRxRuZpuZNdZqwxFxWDdXvQO4H7isZHkrsEPq/ihgSQ+UVtHQwYUjinc+SS4v7iMKM7PMPvW0a+ruMcDCMqs9A+wqaWdJA4BJwH21rGtAY46tNx/A8k889WRm1qFmRxTr8CNJuwF54FXgLIDkY7I3RcRREbFG0reBB4EG4OaIeKHWhQ0bMpDlH/uIwsysQyZBERHHVli+BDgqdf8B4IHeqgsKfYpl7ycB4R6FmZnPzC41bMhA2j7y1JOZWQcHRYnhLc0sczPbzKyTg6LE8JaBrMonL4uDwszMQVFq6JBm2jteFvcozMwcFKWGtwxkDb4ooJlZBwdFieEtzbSHp57MzDo4KEoMHeIjCjOzNAdFiaaGHC2bFa755KAwM3NQlLXVkM0KN9zMNjNzUJSzTUtHUPiIwszMQVHG1kMGFW44KMzMHBTlDG3ZHIB8u4PCzMxBUca2WxSC4uMVKzOuxMwsew6KMoYmU08ffbIi40rMzLLnoChj+BaDWB0NPqIwM8NBUdbwloG0k+MTB4WZmYOinG0HF87O/mSlg8LMzEFRRlNDjrwaaPvgY9rzkXU5ZmaZclBUMKBpAEvf+4grfvsiEQ4LM+u/HBQVNA8cwJgRm3HrH17hF48vzrocM7PMNGZdQJ/VOJB93p3OY1ss5OkZw/nDwl0Yuc0WDNuqhc0GbQaNA6BhIDQMgIbGwu9cIyiX/Ci531C4n18D+dUQAQ1N0NgMDQNYsSZ464MVLP9oFdsOHsB2LQMYkBPkGiDXVFgXCs8jAK3dR+GBtY91rtNBhV/51YX9R37t8o4alUvuq+Sxjn1E4XkdR1Udz1sndV2v2pGZVHg88kmdkeyrIXksX+Y16E4dZZS+XhFrXwvlKqybX7te59g69p+qO5K6cw1dt7UhdXZst1p90b5237mGta+Z9T+5BthqdI9v1kFRyTH/Cy16kB3efoEtXpvH4DeeoHFJft3PW0/NwOjkx8xsY7yX24otL32lx7froKhkl4Nhl4PJAVsC73+ymhdef4cFrW2888FfYM1Kon0VrFmFOo4W8qsLb3ijnQYFzblgYEPQKFgVOVZHjtV5aIg1NMUqmrWGbTZvYmhLM1sNauSdj9fw5gerWPrhSvLtq2mIdhpYgxCR/HTcykU7kbyjDQHkyOWEkne6+QjykYeAdjXQTiOhHESktkbhd6QDMI+AHO0oglxDAznlyOVyNOagMScaFKxuD1a151m5Jnn3nxaF7XYQsbZWur7TTa+bV45IZkRFvlADefLkiORdsggIyLH+wV1Uh+h8FTr2l4s8lNRYqEmpLUTXIZfUnYs86mZ9lV6TtWMurS9VW7JOPtl3rvM1i8JBbbLpCArVlBzVldt3aR226WgcOIgTa7HdGmyzLm0xqIkDPz2cAz89POtSzMx6lZvZZmZWlYPCzMyqclCYmVlVDgozM6sqk6CQdIWk5yXNlTRD0sgy6+wg6VFJCyS9IOm8LGo1M+vvsjqiuCoi9oqIccBvgUvLrLMG+IeI+AywP/A/JO3Rm0WamVlGQRERH6Tubk6XT6VDRLwZEXOS2x8CC4Dte6dCMzPrkNl5FJKuBL4JvA98fh3rjgb2AZ6qeWFmZlZEtboyqqSHgRFlHpoSEb9JrTcZaI6IyypsZzDwGHBlRNxbZX9nAmcmd3cDXtrA0rcFlm3gczdV/XHM0D/H3R/HDP1z3Os75p0iYmi5B2oWFN0laSfg/ogYU+axJgo9jAcj4upeqmdWRIzvjX31Ff1xzNA/x90fxwz9c9w9OeasPvW0a+ruMcDCMusI+HdgQW+FhJmZdZXVp55+JGm+pOeBw4HzACSNlPRAss5ngZOAQ5KP0c6VdFRG9ZqZ9VuZNLMj4tgKy5cARyW3n6D0Mp6948YM9pm1/jhm6J/j7o9jhv457h4bc+Y9CjMz69t8CQ8zM6vKQWFmZlU5KBKSjpT0kqSXJV2SdT21UukaWpK2lvSQpD8lv7fKutaeJqlB0rOSfpvc7w9j3lLS3ZIWJv/ND6j3cUu6IPm3PV/SryQ11+OYJd0saamk+allFccpaXLy9+0lSUesz74cFBT+gADXAV8A9gCOr+PrSlW6htYlwO8jYlfg98n9enMehUvBdOgPY74GmB4RuwN7Uxh/3Y5b0vbAucD45NysBmAS9TnmW4EjS5aVHWfy//gkYM/kOf+W/N3rFgdFwX7AyxGxOCJWAXcCEzOuqSaqXENrInBbstptwN9lU2FtSBoFfBG4KbW43sfcAkygcD4SEbEqIt6jzsdN4dOcgyQ1ApsBS6jDMUfETOCdksWVxjkRuDMiVkbEn4GXKfzd6xYHRcH2wOup+630gwsQllxDa3hEvAmFMAGGZVdZTfwc+A6QTy2r9zHvArQBtyRTbjdJ2pw6HndEvAH8FHgNeBN4PyJmUMdjLlFpnBv1N85BUVDufI26/txwcg2te4DzS67mW3ckHQ0sjYjZWdfSyxqBvwauj4h9gI+ojymXipI5+YnAzsBIYHNJJ2ZbVZ+wUX/jHBQFrcAOqfujKByu1qXkGlr3AFNTF1p8W9J2yePbAUuzqq8GPgscI+kVCtOKh0i6nfoeMxT+XbdGRMdVl++mEBz1PO7DgD9HRFtErAbuBQ6kvsecVmmcG/U3zkFR8Aywq6SdJQ2g0PS5L+OaaqLKNbTuA05Obp8M/Kb0uZuqiJgcEaMiYjSF/7aPRMSJ1PGYASLiLeB1Sbsliw4FXqS+x/0asL+kzZJ/64dS6MPV85jTKo3zPmCSpIGSdgZ2BZ7u7kZ9ZnYiuY7Uzyl8SuLmiLgy45JqQtLfAo8D81g7X/+PFPoUdwE7Uvif7WsRUdoo2+RJOhi4MCKOlrQNdT5mSeMoNPAHAIuBUym8QazbcUv6HnAchU/4PQv8PTCYOhuzpF8BB1O4nPjbwGXAf1BhnJKmAKdReF3Oj4jfdXtfDgozM6vGU09mZlaVg8LMzKpyUJiZWVUOCjMzq8pBYWZmVTkozLpJUnvqa3nn9uRVhiWNTl8F1KwvyeSrUM02UZ9ExLisizDrbT6iMNtIkl6R9GNJTyc/n0qW7yTp95KeT37vmCwfLunXkp5Lfg5MNtUg6RfJdynMkDQoWf9cSS8m27kzo2FaP+agMOu+QSVTT8elHvsgIvYDrqVwhj/J7V9GxF7AVOBfk+X/CjwWEXtTuPbSC8nyXYHrImJP4D3g2GT5JcA+yXbOqtXgzCrxmdlm3STpLxExuMzyV4BDImJxcsHFtyJiG0nLgO0iYnWy/M2I2FZSGzAqIlamtjEaeCj5whkkXQw0RcQPJE0H/kLh8gz/ERF/qfFQzYr4iMKsZ0SF25XWKWdl6nY7a3uIX6TwDYx/A8xOvpDHrNc4KMx6xnGp308mt/9A4Wq1ACcATyS3fw98Czq/x7ul0kYl5YAdIuJRCl+8tCWFC9yZ9Rq/MzHrvkGS5qbuT4+Ijo/IDpT0FIU3X8cny84FbpZ0EYVvmjs1WX4ecKOk0ykcOXyLwrexldMA3C5pCwpfPvOz5OtMzXqNexRmGynpUYyPiGVZ12JWC556MjOzqnxEYWZmVfmIwszMqnJQmJlZVQ4KMzOrykFhZmZVOSjMzKyq/w8wrXt6ojk4owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_k = [2, 5, 10, 20, 50, 100, 150, 200]\n",
    "\n",
    "list_pearson = []\n",
    "list_spearman = []\n",
    "\n",
    "for k in list_k:\n",
    "    # Set common hyper parameters\n",
    "    rnaseq_train_df = train_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "    rnaseq_test_df = test_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "\n",
    "    original_dim = rnaseq_train_df.shape[1]\n",
    "    latent_dim = k\n",
    "    beta = K.variable(0)\n",
    "    epsilon_std = 1.0\n",
    "\n",
    "    # Model A (100 hidden layer size)\n",
    "    model_a_latent_dim = 100\n",
    "    model_a_batch_size = 100\n",
    "    model_a_epochs = 100\n",
    "    model_a_learning_rate = 0.001\n",
    "    model_a_kappa = 1.0\n",
    "    \n",
    "    model_a = Tybalt(original_dim=original_dim,\n",
    "                 hidden_dim=model_a_latent_dim,\n",
    "                 latent_dim=latent_dim,\n",
    "                 batch_size=model_a_batch_size,\n",
    "                 epochs=model_a_epochs,\n",
    "                 learning_rate=model_a_learning_rate,\n",
    "                 kappa=model_a_kappa,\n",
    "                 beta=beta)\n",
    "    \n",
    "    # Compile Model A\n",
    "    model_a.build_encoder_layer()\n",
    "    model_a.build_decoder_layer()\n",
    "    model_a.compile_vae()\n",
    "    \n",
    "    model_a.train_vae()\n",
    "    \n",
    "    rnaseq_df = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "\n",
    "    model_a_compression = model_a.compress(rnaseq_df)\n",
    "    \n",
    "    learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/k_'+str(k)+'_epoch_100_learning.pdf'\n",
    "    compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_compress.tsv'\n",
    "    encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_encoder_twohidden100_vae.hdf5'\n",
    "    decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_decoder_twohidden100_vae.hdf5'\n",
    "    weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_enc_dec_weights.tsv'\n",
    "    \n",
    "    model_a.visualize_training(learning_path)\n",
    "    \n",
    "    model_a_weights = model_a.get_decoder_weights()\n",
    "    \n",
    "    model_a_compression.to_csv(compress_path, sep='\\t', compression='gzip')\n",
    "    model_a.save_models(encoder_path, decoder_path)\n",
    "    \n",
    "    extract_weights(model_a_weights, weight_path, k)\n",
    "    \n",
    "    compress_data = model_a_compression\n",
    "    full_data = rnaseq_df\n",
    "    \n",
    "    reconstructed_data = pd.DataFrame(model_a.predict(compress_data))\n",
    "\n",
    "    full_data_check = full_data#.drop(['index'], axis=1)\n",
    "\n",
    "    r = [pearsonr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "\n",
    "    s = [spearmanr(reconstructed_data.iloc[x, :], full_data_check.iloc[x, :])[0] for x in range(full_data.shape[0])]\n",
    "    \n",
    "    list_pearson.append(r)\n",
    "    list_spearman.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\RUSHI\\Anaconda Python\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specific cancer type selection\n",
    "list_label = np.array(all_labels)\n",
    "c_type_list = collections.Counter(merge_train)\n",
    "\n",
    "for c_type in c_type_list:\n",
    "    pearson_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/c_type_vae/fig__pearson_'+c_type+'.png'\n",
    "    spearman_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/c_type_vae/fig__spearman_'+c_type+'.png'\n",
    "    c_pearson = []\n",
    "    c_spearman = []\n",
    "    for i in range(len(list_label)):\n",
    "        if c_type == list_label[i]:\n",
    "            c_pearson.append(list_pearson[:,i])\n",
    "            c_spearman.append(list_spearman[:,i])\n",
    "\n",
    "    c_pearson = np.array(c_pearson)\n",
    "    c_spearman = np.array(c_spearman)\n",
    "\n",
    "    fig, ax = plt.subplots() \n",
    "    fig.suptitle('Box plot for '+str(c_type)) \n",
    "    ax.set_xlabel('Values of k') \n",
    "    ax.set_ylabel('Peason Corr.') \n",
    "    ax.boxplot(c_pearson, labels=list_k) \n",
    "    fig.savefig(pearson_path)\n",
    "    fig.clear(True) \n",
    "\n",
    "\n",
    "    fig2, ax2 = plt.subplots() \n",
    "    fig2.suptitle('Box plot for '+str(c_type)) \n",
    "    ax2.set_xlabel('Values of k') \n",
    "    ax2.set_ylabel('Spearman Corr.') \n",
    "    ax2.boxplot(c_spearman, labels=list_k) \n",
    "    fig2.savefig(spearman_path)\n",
    "    fig2.clear(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson (K=2 to 50)\n",
    "\n",
    "ACC\n",
    "GBM\n",
    "KICH\n",
    "KIRC\n",
    "KIRP\n",
    "LGG\n",
    "\n",
    "Spearman (K=2 to 50)\n",
    "\n",
    "ACC\n",
    "GBM\n",
    "KICH\n",
    "KIRC\n",
    "KIRP\n",
    "LGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_classes = ['ACC', 'GBM', 'KICH', 'KIRC', 'KIRP', 'LGG']\n",
    "list_label = np.array(all_labels)\n",
    "clean_k_list = [2, 5, 10, 20, 50]\n",
    "\n",
    "for c_type in clean_classes:\n",
    "    pearson_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/c_type_vae/select/fig__pearson_'+c_type+'.png'\n",
    "    spearman_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/c_type_vae/select/fig__spearman_'+c_type+'.png'\n",
    "    c_pearson = []\n",
    "    c_spearman = []\n",
    "    for i in range(len(list_label)):\n",
    "        if c_type == list_label[i]:\n",
    "            c_pearson.append(list_pearson[:,i])\n",
    "            c_spearman.append(list_spearman[:,i])\n",
    "\n",
    "    c_pearson = np.array(c_pearson)\n",
    "    c_spearman = np.array(c_spearman)\n",
    "    \n",
    "    c_pearson_select = c_pearson[:,:5]\n",
    "    c_spearman_select = c_spearman[:,:5]\n",
    "    \n",
    "    fig, ax = plt.subplots() \n",
    "    fig.suptitle('Box plot for '+str(c_type)) \n",
    "    ax.set_xlabel('Values of k') \n",
    "    ax.set_ylabel('Peason Corr.') \n",
    "    ax.boxplot(c_pearson_select, labels=clean_k_list) \n",
    "    fig.savefig(pearson_path)\n",
    "    fig.clear(True) \n",
    "\n",
    "\n",
    "    fig2, ax2 = plt.subplots() \n",
    "    fig2.suptitle('Box plot for '+str(c_type)) \n",
    "    ax2.set_xlabel('Values of k') \n",
    "    ax2.set_ylabel('Spearman Corr.') \n",
    "    ax2.boxplot(c_spearman_select, labels=clean_k_list) \n",
    "    fig2.savefig(spearman_path)\n",
    "    fig2.clear(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00753697 0.00785365 0.00771309 0.00759386 0.00722426 0.00647226\n",
      " 0.0064431  0.00647387]\n",
      "[0.06514269 0.07482322 0.08037008 0.07895613 0.07759474 0.07426682\n",
      " 0.07105359 0.06978897]\n"
     ]
    }
   ],
   "source": [
    "list_pearson = np.array(list_pearson)\n",
    "list_spearman = np.array(list_spearman)\n",
    "print(np.mean(list_pearson, axis=1))\n",
    "print(np.mean(list_spearman, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Box plot')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Pearson Corr.')\n",
    "plt.boxplot(list_pearson.transpose(), labels=list_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Box plot')\n",
    "\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Spearman Corr.')\n",
    "plt.boxplot(list_spearman.transpose(), labels=list_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECONSTRUCTION LOSS CALCULATION OVER K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_keras_binary_cross_entropy(x, z, p, epsilon=1e-07):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x - Reconstructed input RNAseq data\n",
    "    z - Input RNAseq data\n",
    "    p - number of features\n",
    "    epsilon - the clipping value to stabilize results (same Keras default)\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays\n",
    "    x = np.array(x)\n",
    "    z = np.array(z)\n",
    "\n",
    "    # Add clip to value\n",
    "    x[x < epsilon] = epsilon\n",
    "    x[x > (1 - epsilon)] = (1 - epsilon)\n",
    "\n",
    "    # Perform logit\n",
    "    x = np.log(x / (1 - x))\n",
    "\n",
    "    # Return approximate binary cross entropy\n",
    "    return np.mean(p * np.mean(- x * z + np.log(1 + np.exp(x)), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k = [2, 5, 10, 20, 50, 100, 150, 200]\n",
    "\n",
    "rnaseq_train_df = train_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "rnaseq_test_df = test_tcga_df.drop(['cancer_type', 'sample_id'], axis=1)\n",
    "\n",
    "rnaseq_merged = pd.concat([rnaseq_train_df, rnaseq_test_df])\n",
    "input_data = np.array(rnaseq_merged)\n",
    "\n",
    "mse_list = []\n",
    "bce_list = []\n",
    "\n",
    "for k in list_k:\n",
    "    learning_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/figure/k_'+str(k)+'_epoch_100_learning.pdf'\n",
    "    compress_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_compress.tsv'\n",
    "    encoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_encoder_twohidden100_vae.hdf5'\n",
    "    decoder_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_decoder_twohidden100_vae.hdf5'\n",
    "    weight_path = 'D://GitHub/Gene-compression-and-Cancer-type-classification/models/k_'+str(k)+'_epoch_100_enc_dec_weights.tsv'\n",
    "\n",
    "    enc_model = load_model(encoder_path)\n",
    "    dec_model = load_model(decoder_path)\n",
    "    \n",
    "#     with open(compress_path, 'rb') as fd:\n",
    "#         gzip_fd = gzip.GzipFile(fileobj=fd)\n",
    "#         compress_data = pd.read_csv(gzip_fd, sep='\\t')\n",
    "    \n",
    "#     compress_data = compress_data.drop(compress_data.columns[0], axis=1)    \n",
    "    \n",
    "    compress_data = enc_model.predict(input_data)\n",
    "    \n",
    "    reconstructed_data = dec_model.predict(np.array(compress_data))\n",
    "\n",
    "    mse = np.sum((input_data - reconstructed_data) ** 2, axis=1).mean()\n",
    "    bce = approx_keras_binary_cross_entropy(reconstructed_data, input_data, k)\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    bce_list.append(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('MSE v/s K for VAE')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.plot(list_k[:6], mse_list[:6])\n",
    "plt.show()\n",
    "\n",
    "plt.title('BCE v/s K for VAE')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "plt.plot(list_k, bce_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
